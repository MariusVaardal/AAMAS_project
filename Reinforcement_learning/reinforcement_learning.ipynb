{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pettingzoo.mpe import simple_tag_v3\n",
    "from pettingzoo import ParallelEnv\n",
    "import numpy as np\n",
    "import functools\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/mariusvaardal/AAMAS_project/AAMAS_project')\n",
    "\n",
    "import supersuit as ss\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold, BaseCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_GOOD = 1\n",
    "NUM_ADV = 2\n",
    "NUM_OBST = 0\n",
    "MAX_CYCLES = 200\n",
    "CONTINOUS_ACTIONS = False\n",
    "RENDER_MODE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_agent_0_from_dicts(dicts):\n",
    "    ret = []\n",
    "    for dict in dicts:\n",
    "        del dict['agent_0']\n",
    "        ret.append(dict)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_types.AvoidingAgent import AvoidingAgent\n",
    "# from agent_types.AvoidingNearestAdversaryAgent import AvoidingNearestAdversaryAgent\n",
    "# from agent_types.ImmobileAgent import ImmobileAgent\n",
    "\n",
    "class CustomEnvironment(ParallelEnv):\n",
    "    metadata = {\n",
    "        \"name\": \"custom_environment_v0\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, num_good, num_adversaries, num_obstacles, max_cycles, continuous_actions, render_mode):\n",
    "        self.env = simple_tag_v3.parallel_env(num_good=num_good, num_adversaries=num_adversaries, num_obstacles=num_obstacles, max_cycles=max_cycles, continuous_actions=continuous_actions, render_mode=render_mode)\n",
    "        self.env.reset() \n",
    "        # Setting all the required attributes\n",
    "        self.agents = [agent for agent in self.env.agents if agent.startswith(\"adversary\")]\n",
    "        self.possible_agents = [adv for adv in self.env.possible_agents if adv.startswith(\"adversary\")]\n",
    "        self.render_mode = render_mode\n",
    "        # Adding agent_0 as part of the environment. Agent_0 is not meant to be included in the training\n",
    "        # self.agent_0 = AvoidingNearestAdversaryAgent('agent_0', num_adversaries=NUM_ADV, num_landmarks=NUM_OBST)\n",
    "        self.agent_0 = AvoidingAgent('agent_0', num_adversaries=num_adversaries, num_landmarks=NUM_OBST)\n",
    "        \n",
    "    def reset(self, seed=None, options=None):\n",
    "        observations, infos = self.env.reset(seed=seed, options=options)\n",
    "        self.agent_0.see(observations[self.agent_0.name])\n",
    "        observations, infos = remove_agent_0_from_dicts([observations, infos])\n",
    "        return observations, infos\n",
    "\n",
    "    def step(self, actions):\n",
    "        actions['agent_0'] = self.agent_0.get_action()\n",
    "        observations, rewards, terminations, truncations, infos =  self.env.step(actions)\n",
    "        if observations:\n",
    "            self.agent_0.see(observations[self.agent_0.name])\n",
    "            observations, rewards, terminations, truncations, infos = remove_agent_0_from_dicts([observations, rewards, terminations, truncations, infos])\n",
    "        return observations, rewards, terminations, truncations, infos\n",
    "\n",
    "    def render(self):\n",
    "        self.env.render()\n",
    "\n",
    "    # Observation space should be defined here.\n",
    "    # lru_cache allows observation and action spaces to be memoized, reducing clock cycles required to get each agent's space.\n",
    "    # If your spaces change over time, remove this line (disable caching).\n",
    "    @functools.lru_cache(maxsize=None)\n",
    "    def observation_space(self, agent):\n",
    "        return self.env.observation_space(agent)\n",
    "\n",
    "    # Action space should be defined here.\n",
    "    # If your spaces change over time, remove this line (disable caching).\n",
    "    @functools.lru_cache(maxsize=None)\n",
    "    def action_space(self, agent):\n",
    "        return self.env.action_space(agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CustomEnvironment(num_good=NUM_GOOD, num_adversaries=NUM_ADV, num_obstacles=NUM_OBST, max_cycles=MAX_CYCLES, continuous_actions=CONTINOUS_ACTIONS, render_mode='human')\n",
    "observations, infos = env.reset()\n",
    "\n",
    "terminated = False\n",
    "timestep = 1\n",
    "while not terminated:\n",
    "    # this is where you would insert your policy\n",
    "    actions = {agent: env.action_space(agent).sample() for agent in env.agents}\n",
    "\n",
    "    observations, rewards, terminations, truncations, infos = env.step(actions)\n",
    "    if not observations:\n",
    "        terminated = True\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CustomEnvironment(num_good=NUM_GOOD, num_adversaries=NUM_ADV, num_obstacles=NUM_OBST, max_cycles=MAX_CYCLES, continuous_actions=CONTINOUS_ACTIONS, render_mode=RENDER_MODE)\n",
    "env.reset(seed=45)\n",
    "conv_env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
    "conv_env = ss.concat_vec_envs_v1(conv_env, 2, num_cpus=0, base_class=\"stable_baselines3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate_schedule():\n",
    "    def func(progress_remaining):\n",
    "        if progress_remaining > 0.5:\n",
    "            return 0.0001\n",
    "        if progress_remaining > 0.25:\n",
    "            return 0.00001\n",
    "        return 0.000001\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "log_path = \"./logs/2_adv_0_to_50M_steps\"\n",
    "    \n",
    "\n",
    "model = PPO(\n",
    "        MlpPolicy,\n",
    "        conv_env,\n",
    "        verbose=3,\n",
    "        learning_rate=learning_rate_schedule(),\n",
    "        batch_size=256,\n",
    "        tensorboard_log=log_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models/3_adv\"\n",
    "model = PPO.load(os.path.join(model_path, \"106M_ANAA\"), conv_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models/3_adv\"\n",
    "model = PPO.load(os.path.join(model_path, \"best_model\"), conv_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_object = {'learning_rate': 1e-4}\n",
    "\n",
    "model = PPO.load('./models/4_adv/best_model_30M/best_model', conv_env, custom_objects=custom_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintLearningRateCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(PrintLearningRateCallback, self).__init__(verbose)\n",
    "        self.step_count = 0\n",
    "    \n",
    "    def _on_step(self) -> bool:\n",
    "        self.step_count += 1\n",
    "        # Get the current learning rate from the optimizer\n",
    "        # print(f\"Progress: {self.model._current_progress_remaining}\")\n",
    "        current_lr = self.model.lr_schedule(self.model._current_progress_remaining)\n",
    "        if self.step_count % 200 == 0:\n",
    "            print(f\"Current learning rate: {current_lr}\")\n",
    "            print(f\"Progress remaining: {self.model._current_progress_remaining}\")\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_object = {'learning_rate': learning_rate_schedule()}\n",
    "model = PPO.load(\"./models/2_adv/2_adv_547_rew\", env=conv_env, custom_objects=custom_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/2_adv_0_to_50M_steps/PPO_2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 3273 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 2    |\n",
      "|    total_timesteps | 8192 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2740         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030703263 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.679       |\n",
      "|    explained_variance   | 0.02         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 696          |\n",
      "|    n_updates            | 3570         |\n",
      "|    policy_gradient_loss | -0.00469     |\n",
      "|    value_loss           | 1.26e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2563         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032244152 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.684       |\n",
      "|    explained_variance   | 0.0233       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 545          |\n",
      "|    n_updates            | 3580         |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    value_loss           | 1.09e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2548         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028571486 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.681       |\n",
      "|    explained_variance   | 0.0167       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 557          |\n",
      "|    n_updates            | 3590         |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    value_loss           | 1.23e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariusvaardal/.local/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=40000, episode_reward=539.80 +/- 68.63\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 540          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 40000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028646414 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.688       |\n",
      "|    explained_variance   | 0.0295       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 606          |\n",
      "|    n_updates            | 3600         |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    value_loss           | 1.29e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 1847  |\n",
      "|    iterations      | 5     |\n",
      "|    time_elapsed    | 22    |\n",
      "|    total_timesteps | 40960 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1909         |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038699468 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.701       |\n",
      "|    explained_variance   | 0.0327       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 654          |\n",
      "|    n_updates            | 3610         |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    value_loss           | 1.35e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1965        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002990985 |\n",
      "|    clip_fraction        | 0.0144      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.68       |\n",
      "|    explained_variance   | 0.0137      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 574         |\n",
      "|    n_updates            | 3620        |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    value_loss           | 1.22e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1997        |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002463212 |\n",
      "|    clip_fraction        | 0.0146      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.668      |\n",
      "|    explained_variance   | 0.00432     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 483         |\n",
      "|    n_updates            | 3630        |\n",
      "|    policy_gradient_loss | -0.00402    |\n",
      "|    value_loss           | 1.16e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2037         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 73728        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036432887 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.667       |\n",
      "|    explained_variance   | 0.0165       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 565          |\n",
      "|    n_updates            | 3640         |\n",
      "|    policy_gradient_loss | -0.00525     |\n",
      "|    value_loss           | 1.23e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=522.00 +/- 95.81\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 522          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028656158 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.668       |\n",
      "|    explained_variance   | 0.0215       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 708          |\n",
      "|    n_updates            | 3650         |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    value_loss           | 1.33e+03     |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 1813  |\n",
      "|    iterations      | 10    |\n",
      "|    time_elapsed    | 45    |\n",
      "|    total_timesteps | 81920 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1856         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 48           |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029542022 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.67        |\n",
      "|    explained_variance   | 0.0384       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 700          |\n",
      "|    n_updates            | 3660         |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    value_loss           | 1.26e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1880        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002654323 |\n",
      "|    clip_fraction        | 0.0138      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.656      |\n",
      "|    explained_variance   | 0.0327      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 514         |\n",
      "|    n_updates            | 3670        |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    value_loss           | 1.25e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1909         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 55           |\n",
      "|    total_timesteps      | 106496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030753321 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.655       |\n",
      "|    explained_variance   | 0.0218       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 538          |\n",
      "|    n_updates            | 3680         |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    value_loss           | 1.24e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1896         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026954277 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.643       |\n",
      "|    explained_variance   | 0.0455       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 690          |\n",
      "|    n_updates            | 3690         |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    value_loss           | 1.34e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=539.60 +/- 44.81\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 540          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 120000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022803498 |\n",
      "|    clip_fraction        | 0.00933      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.649       |\n",
      "|    explained_variance   | 0.0248       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 607          |\n",
      "|    n_updates            | 3700         |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 1.29e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1711   |\n",
      "|    iterations      | 15     |\n",
      "|    time_elapsed    | 71     |\n",
      "|    total_timesteps | 122880 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1722        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002446808 |\n",
      "|    clip_fraction        | 0.0092      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.636      |\n",
      "|    explained_variance   | 0.0277      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 781         |\n",
      "|    n_updates            | 3710        |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    value_loss           | 1.27e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1709         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036241855 |\n",
      "|    clip_fraction        | 0.0274       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.643       |\n",
      "|    explained_variance   | 0.0159       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 631          |\n",
      "|    n_updates            | 3720         |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    value_loss           | 1.29e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1704       |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 86         |\n",
      "|    total_timesteps      | 147456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00261928 |\n",
      "|    clip_fraction        | 0.0118     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.662     |\n",
      "|    explained_variance   | 0.0516     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 649        |\n",
      "|    n_updates            | 3730       |\n",
      "|    policy_gradient_loss | -0.00335   |\n",
      "|    value_loss           | 1.45e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1723         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 155648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031269416 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.658       |\n",
      "|    explained_variance   | 0.0324       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 662          |\n",
      "|    n_updates            | 3740         |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    value_loss           | 1.3e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=556.80 +/- 51.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 557         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003235112 |\n",
      "|    clip_fraction        | 0.0226      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.666      |\n",
      "|    explained_variance   | 0.00543     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 479         |\n",
      "|    n_updates            | 3750        |\n",
      "|    policy_gradient_loss | -0.00469    |\n",
      "|    value_loss           | 1.28e+03    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1629   |\n",
      "|    iterations      | 20     |\n",
      "|    time_elapsed    | 100    |\n",
      "|    total_timesteps | 163840 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1645        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002359637 |\n",
      "|    clip_fraction        | 0.00909     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.657      |\n",
      "|    explained_variance   | 0.0326      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 662         |\n",
      "|    n_updates            | 3760        |\n",
      "|    policy_gradient_loss | -0.0036     |\n",
      "|    value_loss           | 1.27e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1656         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 108          |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024287421 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.66        |\n",
      "|    explained_variance   | 0.0369       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 683          |\n",
      "|    n_updates            | 3770         |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    value_loss           | 1.33e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1677         |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 112          |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031268802 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.647       |\n",
      "|    explained_variance   | 0.0289       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 613          |\n",
      "|    n_updates            | 3780         |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    value_loss           | 1.29e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1693         |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 116          |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031001351 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.657       |\n",
      "|    explained_variance   | 0.0525       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 548          |\n",
      "|    n_updates            | 3790         |\n",
      "|    policy_gradient_loss | -0.00429     |\n",
      "|    value_loss           | 1.25e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=532.80 +/- 49.36\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 533          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 200000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022627446 |\n",
      "|    clip_fraction        | 0.00919      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.667       |\n",
      "|    explained_variance   | 0.0432       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 707          |\n",
      "|    n_updates            | 3800         |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 1.27e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1625   |\n",
      "|    iterations      | 25     |\n",
      "|    time_elapsed    | 125    |\n",
      "|    total_timesteps | 204800 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1644         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026935306 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.642       |\n",
      "|    explained_variance   | 0.0442       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 557          |\n",
      "|    n_updates            | 3810         |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    value_loss           | 1.39e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1659         |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 133          |\n",
      "|    total_timesteps      | 221184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029245005 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.638       |\n",
      "|    explained_variance   | 0.0337       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 718          |\n",
      "|    n_updates            | 3820         |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    value_loss           | 1.34e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1672         |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032444266 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.648       |\n",
      "|    explained_variance   | 0.0207       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 623          |\n",
      "|    n_updates            | 3830         |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    value_loss           | 1.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1685         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 140          |\n",
      "|    total_timesteps      | 237568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033749104 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.636       |\n",
      "|    explained_variance   | 0.0345       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 689          |\n",
      "|    n_updates            | 3840         |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    value_loss           | 1.28e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=539.20 +/- 100.12\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 539          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 240000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027518831 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.631       |\n",
      "|    explained_variance   | 0.0383       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 520          |\n",
      "|    n_updates            | 3850         |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    value_loss           | 1.23e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1615   |\n",
      "|    iterations      | 30     |\n",
      "|    time_elapsed    | 152    |\n",
      "|    total_timesteps | 245760 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1623         |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 156          |\n",
      "|    total_timesteps      | 253952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024153502 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.63        |\n",
      "|    explained_variance   | 0.0373       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 600          |\n",
      "|    n_updates            | 3860         |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    value_loss           | 1.33e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1633        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 160         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002760359 |\n",
      "|    clip_fraction        | 0.0176      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.637      |\n",
      "|    explained_variance   | 0.0406      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 617         |\n",
      "|    n_updates            | 3870        |\n",
      "|    policy_gradient_loss | -0.00422    |\n",
      "|    value_loss           | 1.26e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1644       |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 164        |\n",
      "|    total_timesteps      | 270336     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00242673 |\n",
      "|    clip_fraction        | 0.0151     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.637     |\n",
      "|    explained_variance   | 0.0438     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 769        |\n",
      "|    n_updates            | 3880       |\n",
      "|    policy_gradient_loss | -0.00339   |\n",
      "|    value_loss           | 1.23e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1651         |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 168          |\n",
      "|    total_timesteps      | 278528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024826701 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.624       |\n",
      "|    explained_variance   | 0.0108       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 596          |\n",
      "|    n_updates            | 3890         |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    value_loss           | 1.3e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=544.80 +/- 46.53\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 545         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 280000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003069988 |\n",
      "|    clip_fraction        | 0.0248      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.618      |\n",
      "|    explained_variance   | 0.035       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 802         |\n",
      "|    n_updates            | 3900        |\n",
      "|    policy_gradient_loss | -0.00454    |\n",
      "|    value_loss           | 1.45e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1595   |\n",
      "|    iterations      | 35     |\n",
      "|    time_elapsed    | 179    |\n",
      "|    total_timesteps | 286720 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1603       |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 183        |\n",
      "|    total_timesteps      | 294912     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00234622 |\n",
      "|    clip_fraction        | 0.0118     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.613     |\n",
      "|    explained_variance   | 0.0367     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 710        |\n",
      "|    n_updates            | 3910       |\n",
      "|    policy_gradient_loss | -0.00373   |\n",
      "|    value_loss           | 1.33e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1615         |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 187          |\n",
      "|    total_timesteps      | 303104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024944176 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.631       |\n",
      "|    explained_variance   | 0.0369       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 619          |\n",
      "|    n_updates            | 3920         |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    value_loss           | 1.33e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1622         |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 191          |\n",
      "|    total_timesteps      | 311296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035053855 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.623       |\n",
      "|    explained_variance   | 0.0414       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1e+03        |\n",
      "|    n_updates            | 3930         |\n",
      "|    policy_gradient_loss | -0.00444     |\n",
      "|    value_loss           | 1.27e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1630         |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 195          |\n",
      "|    total_timesteps      | 319488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031199506 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.609       |\n",
      "|    explained_variance   | 0.00982      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 674          |\n",
      "|    n_updates            | 3940         |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    value_loss           | 1.34e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=540.40 +/- 54.37\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 540         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 320000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003202392 |\n",
      "|    clip_fraction        | 0.0245      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.603      |\n",
      "|    explained_variance   | 0.0176      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 674         |\n",
      "|    n_updates            | 3950        |\n",
      "|    policy_gradient_loss | -0.00507    |\n",
      "|    value_loss           | 1.3e+03     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1588   |\n",
      "|    iterations      | 40     |\n",
      "|    time_elapsed    | 206    |\n",
      "|    total_timesteps | 327680 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1599         |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 209          |\n",
      "|    total_timesteps      | 335872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029886565 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.605       |\n",
      "|    explained_variance   | 0.0207       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 683          |\n",
      "|    n_updates            | 3960         |\n",
      "|    policy_gradient_loss | -0.0042      |\n",
      "|    value_loss           | 1.31e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1610        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003421005 |\n",
      "|    clip_fraction        | 0.0221      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.618      |\n",
      "|    explained_variance   | 0.00818     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 735         |\n",
      "|    n_updates            | 3970        |\n",
      "|    policy_gradient_loss | -0.00482    |\n",
      "|    value_loss           | 1.38e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1621         |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 217          |\n",
      "|    total_timesteps      | 352256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026511655 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.63        |\n",
      "|    explained_variance   | 0.0262       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 747          |\n",
      "|    n_updates            | 3980         |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    value_loss           | 1.44e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=542.20 +/- 60.94\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 542          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 360000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031397415 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.625       |\n",
      "|    explained_variance   | 0.042        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 708          |\n",
      "|    n_updates            | 3990         |\n",
      "|    policy_gradient_loss | -0.00529     |\n",
      "|    value_loss           | 1.26e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1586   |\n",
      "|    iterations      | 44     |\n",
      "|    time_elapsed    | 227    |\n",
      "|    total_timesteps | 360448 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1595        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 231         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003118743 |\n",
      "|    clip_fraction        | 0.0176      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.63       |\n",
      "|    explained_variance   | 0.0163      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 819         |\n",
      "|    n_updates            | 4000        |\n",
      "|    policy_gradient_loss | -0.00444    |\n",
      "|    value_loss           | 1.28e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1602         |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 235          |\n",
      "|    total_timesteps      | 376832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034280429 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.621       |\n",
      "|    explained_variance   | 0.0154       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 427          |\n",
      "|    n_updates            | 4010         |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    value_loss           | 1.23e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1607         |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 239          |\n",
      "|    total_timesteps      | 385024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027904985 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.611       |\n",
      "|    explained_variance   | 0.0149       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 723          |\n",
      "|    n_updates            | 4020         |\n",
      "|    policy_gradient_loss | -0.00486     |\n",
      "|    value_loss           | 1.35e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1614        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 243         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002768378 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.611      |\n",
      "|    explained_variance   | 0.0198      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 587         |\n",
      "|    n_updates            | 4030        |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    value_loss           | 1.21e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=549.60 +/- 54.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 550          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 400000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034775548 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.606       |\n",
      "|    explained_variance   | 0.0068       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 653          |\n",
      "|    n_updates            | 4040         |\n",
      "|    policy_gradient_loss | -0.00455     |\n",
      "|    value_loss           | 1.22e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1577   |\n",
      "|    iterations      | 49     |\n",
      "|    time_elapsed    | 254    |\n",
      "|    total_timesteps | 401408 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 258          |\n",
      "|    total_timesteps      | 409600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031544797 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.584       |\n",
      "|    explained_variance   | 0.0364       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 793          |\n",
      "|    n_updates            | 4050         |\n",
      "|    policy_gradient_loss | -0.00487     |\n",
      "|    value_loss           | 1.33e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 261          |\n",
      "|    total_timesteps      | 417792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025653134 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.595       |\n",
      "|    explained_variance   | 0.0154       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 629          |\n",
      "|    n_updates            | 4060         |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    value_loss           | 1.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1602         |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 265          |\n",
      "|    total_timesteps      | 425984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027271225 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.59        |\n",
      "|    explained_variance   | 0.0614       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 580          |\n",
      "|    n_updates            | 4070         |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    value_loss           | 1.27e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1609         |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 269          |\n",
      "|    total_timesteps      | 434176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031603388 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.607       |\n",
      "|    explained_variance   | 0.0144       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 688          |\n",
      "|    n_updates            | 4080         |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    value_loss           | 1.4e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=550.20 +/- 51.05\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 550          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 440000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029676312 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.596       |\n",
      "|    explained_variance   | 0.00958      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 866          |\n",
      "|    n_updates            | 4090         |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 1.27e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1579   |\n",
      "|    iterations      | 54     |\n",
      "|    time_elapsed    | 280    |\n",
      "|    total_timesteps | 442368 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 284          |\n",
      "|    total_timesteps      | 450560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036995397 |\n",
      "|    clip_fraction        | 0.0284       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.593       |\n",
      "|    explained_variance   | 0.028        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 544          |\n",
      "|    n_updates            | 4100         |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    value_loss           | 1.17e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1591        |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002519042 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.576      |\n",
      "|    explained_variance   | 0.0474      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 916         |\n",
      "|    n_updates            | 4110        |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    value_loss           | 1.34e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 292          |\n",
      "|    total_timesteps      | 466944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028642218 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.585       |\n",
      "|    explained_variance   | 0.0269       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 641          |\n",
      "|    n_updates            | 4120         |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    value_loss           | 1.33e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1599         |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 297          |\n",
      "|    total_timesteps      | 475136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024186568 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.601       |\n",
      "|    explained_variance   | 0.0407       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 652          |\n",
      "|    n_updates            | 4130         |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    value_loss           | 1.23e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=547.40 +/- 52.83\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 547          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 480000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023242007 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.571       |\n",
      "|    explained_variance   | -0.00977     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 792          |\n",
      "|    n_updates            | 4140         |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    value_loss           | 1.31e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1566   |\n",
      "|    iterations      | 59     |\n",
      "|    time_elapsed    | 308    |\n",
      "|    total_timesteps | 483328 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 313          |\n",
      "|    total_timesteps      | 491520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033288377 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.587       |\n",
      "|    explained_variance   | 0.0293       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 605          |\n",
      "|    n_updates            | 4150         |\n",
      "|    policy_gradient_loss | -0.00482     |\n",
      "|    value_loss           | 1.37e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 317          |\n",
      "|    total_timesteps      | 499712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025960684 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.58        |\n",
      "|    explained_variance   | 0.0153       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 553          |\n",
      "|    n_updates            | 4160         |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    value_loss           | 1.31e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 321          |\n",
      "|    total_timesteps      | 507904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027165944 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.595       |\n",
      "|    explained_variance   | 0.0257       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 711          |\n",
      "|    n_updates            | 4170         |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    value_loss           | 1.35e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 325          |\n",
      "|    total_timesteps      | 516096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025076852 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.601       |\n",
      "|    explained_variance   | 0.0288       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 663          |\n",
      "|    n_updates            | 4180         |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    value_loss           | 1.34e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=536.60 +/- 95.34\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 537         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 520000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003182407 |\n",
      "|    clip_fraction        | 0.0221      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.603      |\n",
      "|    explained_variance   | 0.0342      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 547         |\n",
      "|    n_updates            | 4190        |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    value_loss           | 1.35e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1553   |\n",
      "|    iterations      | 64     |\n",
      "|    time_elapsed    | 337    |\n",
      "|    total_timesteps | 524288 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1558         |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 341          |\n",
      "|    total_timesteps      | 532480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021816038 |\n",
      "|    clip_fraction        | 0.01         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.611       |\n",
      "|    explained_variance   | 0.0229       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 580          |\n",
      "|    n_updates            | 4200         |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    value_loss           | 1.31e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1562         |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 345          |\n",
      "|    total_timesteps      | 540672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027997834 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.622       |\n",
      "|    explained_variance   | 0.0244       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 620          |\n",
      "|    n_updates            | 4210         |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    value_loss           | 1.3e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1567        |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 350         |\n",
      "|    total_timesteps      | 548864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002203729 |\n",
      "|    clip_fraction        | 0.008       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.612      |\n",
      "|    explained_variance   | 0.00573     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 641         |\n",
      "|    n_updates            | 4220        |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    value_loss           | 1.3e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 354          |\n",
      "|    total_timesteps      | 557056       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030117994 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.616       |\n",
      "|    explained_variance   | 0.0215       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 703          |\n",
      "|    n_updates            | 4230         |\n",
      "|    policy_gradient_loss | -0.00501     |\n",
      "|    value_loss           | 1.34e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=536.80 +/- 48.89\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 537         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 560000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002695295 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.617      |\n",
      "|    explained_variance   | 0.0217      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 671         |\n",
      "|    n_updates            | 4240        |\n",
      "|    policy_gradient_loss | -0.00396    |\n",
      "|    value_loss           | 1.3e+03     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1540   |\n",
      "|    iterations      | 69     |\n",
      "|    time_elapsed    | 366    |\n",
      "|    total_timesteps | 565248 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1545         |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 370          |\n",
      "|    total_timesteps      | 573440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032457975 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.618       |\n",
      "|    explained_variance   | 0.0403       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 536          |\n",
      "|    n_updates            | 4250         |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    value_loss           | 1.23e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1550        |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 375         |\n",
      "|    total_timesteps      | 581632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002491404 |\n",
      "|    clip_fraction        | 0.0132      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.613      |\n",
      "|    explained_variance   | 0.0554      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 626         |\n",
      "|    n_updates            | 4260        |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    value_loss           | 1.3e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1554        |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 379         |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002185876 |\n",
      "|    clip_fraction        | 0.00841     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.624      |\n",
      "|    explained_variance   | 0.0271      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 694         |\n",
      "|    n_updates            | 4270        |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    value_loss           | 1.41e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1557         |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 384          |\n",
      "|    total_timesteps      | 598016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032803868 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.624       |\n",
      "|    explained_variance   | 0.00524      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 552          |\n",
      "|    n_updates            | 4280         |\n",
      "|    policy_gradient_loss | -0.00472     |\n",
      "|    value_loss           | 1.28e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=555.60 +/- 54.23\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 556          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 600000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031256939 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.619       |\n",
      "|    explained_variance   | 0.0158       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 790          |\n",
      "|    n_updates            | 4290         |\n",
      "|    policy_gradient_loss | -0.00481     |\n",
      "|    value_loss           | 1.3e+03      |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1535   |\n",
      "|    iterations      | 74     |\n",
      "|    time_elapsed    | 394    |\n",
      "|    total_timesteps | 606208 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1541        |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 398         |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003179614 |\n",
      "|    clip_fraction        | 0.0169      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.628      |\n",
      "|    explained_variance   | 0.0171      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 697         |\n",
      "|    n_updates            | 4300        |\n",
      "|    policy_gradient_loss | -0.00366    |\n",
      "|    value_loss           | 1.26e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1545       |\n",
      "|    iterations           | 76         |\n",
      "|    time_elapsed         | 402        |\n",
      "|    total_timesteps      | 622592     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00270903 |\n",
      "|    clip_fraction        | 0.0178     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.624     |\n",
      "|    explained_variance   | 0.0432     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 611        |\n",
      "|    n_updates            | 4310       |\n",
      "|    policy_gradient_loss | -0.00393   |\n",
      "|    value_loss           | 1.35e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1550         |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 406          |\n",
      "|    total_timesteps      | 630784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032881126 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.62        |\n",
      "|    explained_variance   | 0.0165       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 417          |\n",
      "|    n_updates            | 4320         |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    value_loss           | 1.31e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1555         |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 410          |\n",
      "|    total_timesteps      | 638976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032469116 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.626       |\n",
      "|    explained_variance   | 0.0254       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 591          |\n",
      "|    n_updates            | 4330         |\n",
      "|    policy_gradient_loss | -0.00507     |\n",
      "|    value_loss           | 1.35e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=565.00 +/- 59.30\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 565          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 640000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033942675 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.627       |\n",
      "|    explained_variance   | 0.0228       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 795          |\n",
      "|    n_updates            | 4340         |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    value_loss           | 1.29e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1532   |\n",
      "|    iterations      | 79     |\n",
      "|    time_elapsed    | 422    |\n",
      "|    total_timesteps | 647168 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1535        |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 426         |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002880171 |\n",
      "|    clip_fraction        | 0.0168      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.627      |\n",
      "|    explained_variance   | 0.0467      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 607         |\n",
      "|    n_updates            | 4350        |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    value_loss           | 1.26e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1538         |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 431          |\n",
      "|    total_timesteps      | 663552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022130834 |\n",
      "|    clip_fraction        | 0.00931      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.621       |\n",
      "|    explained_variance   | 0.0222       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 687          |\n",
      "|    n_updates            | 4360         |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    value_loss           | 1.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1543         |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 435          |\n",
      "|    total_timesteps      | 671744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025581378 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.622       |\n",
      "|    explained_variance   | 0.045        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 596          |\n",
      "|    n_updates            | 4370         |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    value_loss           | 1.34e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1546         |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 439          |\n",
      "|    total_timesteps      | 679936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033710878 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.618       |\n",
      "|    explained_variance   | 0.0359       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 577          |\n",
      "|    n_updates            | 4380         |\n",
      "|    policy_gradient_loss | -0.00509     |\n",
      "|    value_loss           | 1.39e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=680000, episode_reward=575.00 +/- 53.26\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 575          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 680000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029478795 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.611       |\n",
      "|    explained_variance   | 0.054        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 468          |\n",
      "|    n_updates            | 4390         |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    value_loss           | 1.29e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1525   |\n",
      "|    iterations      | 84     |\n",
      "|    time_elapsed    | 451    |\n",
      "|    total_timesteps | 688128 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1530         |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 455          |\n",
      "|    total_timesteps      | 696320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026056934 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.604       |\n",
      "|    explained_variance   | 0.0264       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 763          |\n",
      "|    n_updates            | 4400         |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 1.46e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1534       |\n",
      "|    iterations           | 86         |\n",
      "|    time_elapsed         | 459        |\n",
      "|    total_timesteps      | 704512     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00315095 |\n",
      "|    clip_fraction        | 0.0143     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.608     |\n",
      "|    explained_variance   | 0.0463     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 723        |\n",
      "|    n_updates            | 4410       |\n",
      "|    policy_gradient_loss | -0.00408   |\n",
      "|    value_loss           | 1.34e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1539         |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 462          |\n",
      "|    total_timesteps      | 712704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030228884 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.589       |\n",
      "|    explained_variance   | 0.0711       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 712          |\n",
      "|    n_updates            | 4420         |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    value_loss           | 1.35e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=552.00 +/- 52.99\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 552          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 720000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024723436 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.584       |\n",
      "|    explained_variance   | 0.0452       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 522          |\n",
      "|    n_updates            | 4430         |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    value_loss           | 1.32e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1524   |\n",
      "|    iterations      | 88     |\n",
      "|    time_elapsed    | 472    |\n",
      "|    total_timesteps | 720896 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1529         |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 476          |\n",
      "|    total_timesteps      | 729088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028097588 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.592       |\n",
      "|    explained_variance   | 0.015        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 763          |\n",
      "|    n_updates            | 4440         |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    value_loss           | 1.37e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1535         |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 480          |\n",
      "|    total_timesteps      | 737280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021282583 |\n",
      "|    clip_fraction        | 0.00818      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.598       |\n",
      "|    explained_variance   | 0.0563       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 528          |\n",
      "|    n_updates            | 4450         |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    value_loss           | 1.3e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1540         |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 483          |\n",
      "|    total_timesteps      | 745472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028295314 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.586       |\n",
      "|    explained_variance   | 0.0555       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 720          |\n",
      "|    n_updates            | 4460         |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    value_loss           | 1.36e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1545         |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 487          |\n",
      "|    total_timesteps      | 753664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026476057 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.584       |\n",
      "|    explained_variance   | 0.0498       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 604          |\n",
      "|    n_updates            | 4470         |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    value_loss           | 1.36e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=555.60 +/- 50.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 556         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 760000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002544013 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.577      |\n",
      "|    explained_variance   | 0.0213      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 594         |\n",
      "|    n_updates            | 4480        |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    value_loss           | 1.45e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1530   |\n",
      "|    iterations      | 93     |\n",
      "|    time_elapsed    | 497    |\n",
      "|    total_timesteps | 761856 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1536        |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 501         |\n",
      "|    total_timesteps      | 770048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003573547 |\n",
      "|    clip_fraction        | 0.0315      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.583      |\n",
      "|    explained_variance   | 0.0299      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 700         |\n",
      "|    n_updates            | 4490        |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    value_loss           | 1.32e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1541         |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 504          |\n",
      "|    total_timesteps      | 778240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030049104 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.573       |\n",
      "|    explained_variance   | 0.0183       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 712          |\n",
      "|    n_updates            | 4500         |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    value_loss           | 1.29e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1546         |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 508          |\n",
      "|    total_timesteps      | 786432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032379392 |\n",
      "|    clip_fraction        | 0.026        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.588       |\n",
      "|    explained_variance   | 0.0511       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 636          |\n",
      "|    n_updates            | 4510         |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    value_loss           | 1.36e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1551         |\n",
      "|    iterations           | 97           |\n",
      "|    time_elapsed         | 512          |\n",
      "|    total_timesteps      | 794624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020232757 |\n",
      "|    clip_fraction        | 0.00939      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.608       |\n",
      "|    explained_variance   | 0.0597       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 722          |\n",
      "|    n_updates            | 4520         |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    value_loss           | 1.48e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=548.00 +/- 91.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 548          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 800000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026368317 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.61        |\n",
      "|    explained_variance   | 0.024        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 478          |\n",
      "|    n_updates            | 4530         |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    value_loss           | 1.38e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1537   |\n",
      "|    iterations      | 98     |\n",
      "|    time_elapsed    | 522    |\n",
      "|    total_timesteps | 802816 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1542        |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 525         |\n",
      "|    total_timesteps      | 811008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003018985 |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.59       |\n",
      "|    explained_variance   | 0.0484      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 570         |\n",
      "|    n_updates            | 4540        |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    value_loss           | 1.28e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1546         |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 529          |\n",
      "|    total_timesteps      | 819200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023361086 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.591       |\n",
      "|    explained_variance   | 0.0493       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 643          |\n",
      "|    n_updates            | 4550         |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    value_loss           | 1.28e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1551         |\n",
      "|    iterations           | 101          |\n",
      "|    time_elapsed         | 533          |\n",
      "|    total_timesteps      | 827392       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033489522 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.587       |\n",
      "|    explained_variance   | 0.0297       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 775          |\n",
      "|    n_updates            | 4560         |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    value_loss           | 1.46e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1556         |\n",
      "|    iterations           | 102          |\n",
      "|    time_elapsed         | 536          |\n",
      "|    total_timesteps      | 835584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027665137 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.585       |\n",
      "|    explained_variance   | 0.0288       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 799          |\n",
      "|    n_updates            | 4570         |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    value_loss           | 1.41e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=840000, episode_reward=559.80 +/- 54.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 560          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 840000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034809276 |\n",
      "|    clip_fraction        | 0.0268       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.598       |\n",
      "|    explained_variance   | 0.0226       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 959          |\n",
      "|    n_updates            | 4580         |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    value_loss           | 1.35e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1542   |\n",
      "|    iterations      | 103    |\n",
      "|    time_elapsed    | 546    |\n",
      "|    total_timesteps | 843776 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1547         |\n",
      "|    iterations           | 104          |\n",
      "|    time_elapsed         | 550          |\n",
      "|    total_timesteps      | 851968       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035931426 |\n",
      "|    clip_fraction        | 0.0223       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.603       |\n",
      "|    explained_variance   | 0.0363       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 542          |\n",
      "|    n_updates            | 4590         |\n",
      "|    policy_gradient_loss | -0.00483     |\n",
      "|    value_loss           | 1.4e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1551        |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 554         |\n",
      "|    total_timesteps      | 860160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002318487 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.596      |\n",
      "|    explained_variance   | 0.0451      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 605         |\n",
      "|    n_updates            | 4600        |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    value_loss           | 1.35e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1556         |\n",
      "|    iterations           | 106          |\n",
      "|    time_elapsed         | 557          |\n",
      "|    total_timesteps      | 868352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027642406 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.593       |\n",
      "|    explained_variance   | 0.035        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 601          |\n",
      "|    n_updates            | 4610         |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    value_loss           | 1.42e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1560        |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 561         |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003191188 |\n",
      "|    clip_fraction        | 0.016       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.595      |\n",
      "|    explained_variance   | 0.0388      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 625         |\n",
      "|    n_updates            | 4620        |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    value_loss           | 1.33e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=880000, episode_reward=550.60 +/- 56.23\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 551         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 880000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002536411 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.602      |\n",
      "|    explained_variance   | 0.0515      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 909         |\n",
      "|    n_updates            | 4630        |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    value_loss           | 1.36e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1548   |\n",
      "|    iterations      | 108    |\n",
      "|    time_elapsed    | 571    |\n",
      "|    total_timesteps | 884736 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1552         |\n",
      "|    iterations           | 109          |\n",
      "|    time_elapsed         | 575          |\n",
      "|    total_timesteps      | 892928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030660783 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.595       |\n",
      "|    explained_variance   | 0.000962     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 582          |\n",
      "|    n_updates            | 4640         |\n",
      "|    policy_gradient_loss | -0.00447     |\n",
      "|    value_loss           | 1.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1556         |\n",
      "|    iterations           | 110          |\n",
      "|    time_elapsed         | 578          |\n",
      "|    total_timesteps      | 901120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030944548 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.581       |\n",
      "|    explained_variance   | 0.0329       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 673          |\n",
      "|    n_updates            | 4650         |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    value_loss           | 1.43e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1561         |\n",
      "|    iterations           | 111          |\n",
      "|    time_elapsed         | 582          |\n",
      "|    total_timesteps      | 909312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030345952 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.601       |\n",
      "|    explained_variance   | 0.0693       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 781          |\n",
      "|    n_updates            | 4660         |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    value_loss           | 1.35e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 112          |\n",
      "|    time_elapsed         | 586          |\n",
      "|    total_timesteps      | 917504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024330663 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.581       |\n",
      "|    explained_variance   | -0.00864     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 686          |\n",
      "|    n_updates            | 4670         |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    value_loss           | 1.32e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=920000, episode_reward=564.20 +/- 97.47\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 564          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 920000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022662624 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.586       |\n",
      "|    explained_variance   | 0.0111       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 691          |\n",
      "|    n_updates            | 4680         |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    value_loss           | 1.31e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1553   |\n",
      "|    iterations      | 113    |\n",
      "|    time_elapsed    | 595    |\n",
      "|    total_timesteps | 925696 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1557        |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 599         |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002649594 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.586      |\n",
      "|    explained_variance   | 0.0153      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 535         |\n",
      "|    n_updates            | 4690        |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    value_loss           | 1.38e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1560        |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 603         |\n",
      "|    total_timesteps      | 942080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002947602 |\n",
      "|    clip_fraction        | 0.0184      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.581      |\n",
      "|    explained_variance   | 0.049       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 764         |\n",
      "|    n_updates            | 4700        |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    value_loss           | 1.35e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 116          |\n",
      "|    time_elapsed         | 607          |\n",
      "|    total_timesteps      | 950272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019694876 |\n",
      "|    clip_fraction        | 0.00884      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.57        |\n",
      "|    explained_variance   | 0.0426       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 567          |\n",
      "|    n_updates            | 4710         |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    value_loss           | 1.4e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 117          |\n",
      "|    time_elapsed         | 611          |\n",
      "|    total_timesteps      | 958464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022349327 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.565       |\n",
      "|    explained_variance   | 0.00595      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 577          |\n",
      "|    n_updates            | 4720         |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    value_loss           | 1.25e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=960000, episode_reward=570.00 +/- 50.87\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 570          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 960000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020413308 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.56        |\n",
      "|    explained_variance   | 0.0367       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 737          |\n",
      "|    n_updates            | 4730         |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    value_loss           | 1.44e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 1556   |\n",
      "|    iterations      | 118    |\n",
      "|    time_elapsed    | 621    |\n",
      "|    total_timesteps | 966656 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1560         |\n",
      "|    iterations           | 119          |\n",
      "|    time_elapsed         | 624          |\n",
      "|    total_timesteps      | 974848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035031699 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.571       |\n",
      "|    explained_variance   | 0.0411       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 809          |\n",
      "|    n_updates            | 4740         |\n",
      "|    policy_gradient_loss | -0.00483     |\n",
      "|    value_loss           | 1.33e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 120          |\n",
      "|    time_elapsed         | 628          |\n",
      "|    total_timesteps      | 983040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025394363 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.571       |\n",
      "|    explained_variance   | 0.0337       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 674          |\n",
      "|    n_updates            | 4750         |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 1.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 121          |\n",
      "|    time_elapsed         | 632          |\n",
      "|    total_timesteps      | 991232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031647284 |\n",
      "|    clip_fraction        | 0.0218       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.566       |\n",
      "|    explained_variance   | 0.0104       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 745          |\n",
      "|    n_updates            | 4760         |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    value_loss           | 1.37e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1571        |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 635         |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001783974 |\n",
      "|    clip_fraction        | 0.00577     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.573      |\n",
      "|    explained_variance   | 0.0601      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 481         |\n",
      "|    n_updates            | 4770        |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    value_loss           | 1.39e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=542.40 +/- 126.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 542          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028704836 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.579       |\n",
      "|    explained_variance   | 0.0257       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 387          |\n",
      "|    n_updates            | 4780         |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    value_loss           | 1.31e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1560    |\n",
      "|    iterations      | 123     |\n",
      "|    time_elapsed    | 645     |\n",
      "|    total_timesteps | 1007616 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 124          |\n",
      "|    time_elapsed         | 649          |\n",
      "|    total_timesteps      | 1015808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026637958 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.573       |\n",
      "|    explained_variance   | 0.0397       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 710          |\n",
      "|    n_updates            | 4790         |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    value_loss           | 1.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 125          |\n",
      "|    time_elapsed         | 653          |\n",
      "|    total_timesteps      | 1024000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032854646 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.586       |\n",
      "|    explained_variance   | 0.0377       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 787          |\n",
      "|    n_updates            | 4800         |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    value_loss           | 1.37e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 126          |\n",
      "|    time_elapsed         | 656          |\n",
      "|    total_timesteps      | 1032192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024366942 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.574       |\n",
      "|    explained_variance   | 0.0319       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 872          |\n",
      "|    n_updates            | 4810         |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1040000, episode_reward=567.80 +/- 56.72\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 568          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1040000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031861786 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.59        |\n",
      "|    explained_variance   | 0.0393       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 778          |\n",
      "|    n_updates            | 4820         |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    value_loss           | 1.33e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1560    |\n",
      "|    iterations      | 127     |\n",
      "|    time_elapsed    | 666     |\n",
      "|    total_timesteps | 1040384 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 128          |\n",
      "|    time_elapsed         | 670          |\n",
      "|    total_timesteps      | 1048576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027511925 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.603       |\n",
      "|    explained_variance   | 0.0287       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 870          |\n",
      "|    n_updates            | 4830         |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    value_loss           | 1.41e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1567        |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 673         |\n",
      "|    total_timesteps      | 1056768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002190997 |\n",
      "|    clip_fraction        | 0.0115      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.594      |\n",
      "|    explained_variance   | 0.0413      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 856         |\n",
      "|    n_updates            | 4840        |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    value_loss           | 1.37e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 130          |\n",
      "|    time_elapsed         | 677          |\n",
      "|    total_timesteps      | 1064960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029840271 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.589       |\n",
      "|    explained_variance   | 0.0376       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 546          |\n",
      "|    n_updates            | 4850         |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    value_loss           | 1.39e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1575        |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 681         |\n",
      "|    total_timesteps      | 1073152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003086978 |\n",
      "|    clip_fraction        | 0.0157      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.6        |\n",
      "|    explained_variance   | 0.0217      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 835         |\n",
      "|    n_updates            | 4860        |\n",
      "|    policy_gradient_loss | -0.00337    |\n",
      "|    value_loss           | 1.46e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1080000, episode_reward=567.00 +/- 68.59\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 567         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1080000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002849398 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.584      |\n",
      "|    explained_variance   | 0.0492      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 811         |\n",
      "|    n_updates            | 4870        |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    value_loss           | 1.37e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1564    |\n",
      "|    iterations      | 132     |\n",
      "|    time_elapsed    | 691     |\n",
      "|    total_timesteps | 1081344 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 133          |\n",
      "|    time_elapsed         | 694          |\n",
      "|    total_timesteps      | 1089536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018468645 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.584       |\n",
      "|    explained_variance   | 0.0527       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 599          |\n",
      "|    n_updates            | 4880         |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    value_loss           | 1.35e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 698          |\n",
      "|    total_timesteps      | 1097728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024649445 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.581       |\n",
      "|    explained_variance   | 0.00897      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 927          |\n",
      "|    n_updates            | 4890         |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    value_loss           | 1.33e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1574        |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 702         |\n",
      "|    total_timesteps      | 1105920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002150201 |\n",
      "|    clip_fraction        | 0.00995     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.587      |\n",
      "|    explained_variance   | 0.0341      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 650         |\n",
      "|    n_updates            | 4900        |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    value_loss           | 1.49e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 136          |\n",
      "|    time_elapsed         | 706          |\n",
      "|    total_timesteps      | 1114112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031327922 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.584       |\n",
      "|    explained_variance   | 0.0302       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 760          |\n",
      "|    n_updates            | 4910         |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    value_loss           | 1.43e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1120000, episode_reward=576.80 +/- 53.08\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 577          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028631114 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.59        |\n",
      "|    explained_variance   | 0.0212       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 599          |\n",
      "|    n_updates            | 4920         |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    value_loss           | 1.47e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1566    |\n",
      "|    iterations      | 137     |\n",
      "|    time_elapsed    | 716     |\n",
      "|    total_timesteps | 1122304 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 138          |\n",
      "|    time_elapsed         | 720          |\n",
      "|    total_timesteps      | 1130496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027515122 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.587       |\n",
      "|    explained_variance   | 0.0264       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 760          |\n",
      "|    n_updates            | 4930         |\n",
      "|    policy_gradient_loss | -0.00449     |\n",
      "|    value_loss           | 1.43e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1572        |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 724         |\n",
      "|    total_timesteps      | 1138688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002324976 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.591      |\n",
      "|    explained_variance   | 0.0198      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 797         |\n",
      "|    n_updates            | 4940        |\n",
      "|    policy_gradient_loss | -0.00301    |\n",
      "|    value_loss           | 1.47e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1575         |\n",
      "|    iterations           | 140          |\n",
      "|    time_elapsed         | 727          |\n",
      "|    total_timesteps      | 1146880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028315526 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.603       |\n",
      "|    explained_variance   | 0.042        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 662          |\n",
      "|    n_updates            | 4950         |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    value_loss           | 1.4e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 141          |\n",
      "|    time_elapsed         | 731          |\n",
      "|    total_timesteps      | 1155072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027372278 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.604       |\n",
      "|    explained_variance   | 0.0295       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 714          |\n",
      "|    n_updates            | 4960         |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    value_loss           | 1.35e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1160000, episode_reward=584.00 +/- 58.24\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 584          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1160000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026772185 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.6         |\n",
      "|    explained_variance   | 0.0621       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 506          |\n",
      "|    n_updates            | 4970         |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    value_loss           | 1.32e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1568    |\n",
      "|    iterations      | 142     |\n",
      "|    time_elapsed    | 741     |\n",
      "|    total_timesteps | 1163264 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1571        |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 745         |\n",
      "|    total_timesteps      | 1171456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002478896 |\n",
      "|    clip_fraction        | 0.0132      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.612      |\n",
      "|    explained_variance   | 0.0238      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 777         |\n",
      "|    n_updates            | 4980        |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    value_loss           | 1.4e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 144          |\n",
      "|    time_elapsed         | 749          |\n",
      "|    total_timesteps      | 1179648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030949316 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.605       |\n",
      "|    explained_variance   | 0.015        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 547          |\n",
      "|    n_updates            | 4990         |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    value_loss           | 1.35e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1577       |\n",
      "|    iterations           | 145        |\n",
      "|    time_elapsed         | 752        |\n",
      "|    total_timesteps      | 1187840    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00279773 |\n",
      "|    clip_fraction        | 0.0145     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.629     |\n",
      "|    explained_variance   | 0.0534     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 635        |\n",
      "|    n_updates            | 5000       |\n",
      "|    policy_gradient_loss | -0.00378   |\n",
      "|    value_loss           | 1.39e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 146          |\n",
      "|    time_elapsed         | 756          |\n",
      "|    total_timesteps      | 1196032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020442721 |\n",
      "|    clip_fraction        | 0.00754      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.603       |\n",
      "|    explained_variance   | 0.0491       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 523          |\n",
      "|    n_updates            | 5010         |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    value_loss           | 1.36e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1200000, episode_reward=571.80 +/- 66.68\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 572          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021314216 |\n",
      "|    clip_fraction        | 0.00895      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.6         |\n",
      "|    explained_variance   | 0.0398       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 792          |\n",
      "|    n_updates            | 5020         |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    value_loss           | 1.5e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1570    |\n",
      "|    iterations      | 147     |\n",
      "|    time_elapsed    | 766     |\n",
      "|    total_timesteps | 1204224 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1574        |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 770         |\n",
      "|    total_timesteps      | 1212416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003186427 |\n",
      "|    clip_fraction        | 0.0241      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.596      |\n",
      "|    explained_variance   | 0.00316     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 947         |\n",
      "|    n_updates            | 5030        |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    value_loss           | 1.39e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 149          |\n",
      "|    time_elapsed         | 773          |\n",
      "|    total_timesteps      | 1220608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028104708 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.597       |\n",
      "|    explained_variance   | 0.0248       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 544          |\n",
      "|    n_updates            | 5040         |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    value_loss           | 1.39e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 150          |\n",
      "|    time_elapsed         | 777          |\n",
      "|    total_timesteps      | 1228800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028077038 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.603       |\n",
      "|    explained_variance   | 0.0291       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 750          |\n",
      "|    n_updates            | 5050         |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    value_loss           | 1.39e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 151          |\n",
      "|    time_elapsed         | 781          |\n",
      "|    total_timesteps      | 1236992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024945764 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.597       |\n",
      "|    explained_variance   | 0.0408       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 704          |\n",
      "|    n_updates            | 5060         |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    value_loss           | 1.43e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1240000, episode_reward=575.00 +/- 50.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 575          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1240000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031533367 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.583       |\n",
      "|    explained_variance   | 0.0562       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 753          |\n",
      "|    n_updates            | 5070         |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    value_loss           | 1.37e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1572    |\n",
      "|    iterations      | 152     |\n",
      "|    time_elapsed    | 791     |\n",
      "|    total_timesteps | 1245184 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1575         |\n",
      "|    iterations           | 153          |\n",
      "|    time_elapsed         | 795          |\n",
      "|    total_timesteps      | 1253376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025047376 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.598       |\n",
      "|    explained_variance   | 0.052        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 714          |\n",
      "|    n_updates            | 5080         |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    value_loss           | 1.46e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 154          |\n",
      "|    time_elapsed         | 799          |\n",
      "|    total_timesteps      | 1261568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030354597 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.604       |\n",
      "|    explained_variance   | 0.0321       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 841          |\n",
      "|    n_updates            | 5090         |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    value_loss           | 1.29e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 155          |\n",
      "|    time_elapsed         | 802          |\n",
      "|    total_timesteps      | 1269760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023454227 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.607       |\n",
      "|    explained_variance   | 0.0393       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 594          |\n",
      "|    n_updates            | 5100         |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    value_loss           | 1.37e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 156          |\n",
      "|    time_elapsed         | 806          |\n",
      "|    total_timesteps      | 1277952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024818308 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.613       |\n",
      "|    explained_variance   | 0.0301       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 828          |\n",
      "|    n_updates            | 5110         |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    value_loss           | 1.45e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1280000, episode_reward=566.20 +/- 105.87\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 566          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029845107 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.612       |\n",
      "|    explained_variance   | 0.04         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 759          |\n",
      "|    n_updates            | 5120         |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    value_loss           | 1.38e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1574    |\n",
      "|    iterations      | 157     |\n",
      "|    time_elapsed    | 816     |\n",
      "|    total_timesteps | 1286144 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 158          |\n",
      "|    time_elapsed         | 820          |\n",
      "|    total_timesteps      | 1294336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029762469 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.618       |\n",
      "|    explained_variance   | 0.0386       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 857          |\n",
      "|    n_updates            | 5130         |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    value_loss           | 1.33e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 159          |\n",
      "|    time_elapsed         | 824          |\n",
      "|    total_timesteps      | 1302528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027139594 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.603       |\n",
      "|    explained_variance   | 0.0558       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 626          |\n",
      "|    n_updates            | 5140         |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    value_loss           | 1.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 160          |\n",
      "|    time_elapsed         | 828          |\n",
      "|    total_timesteps      | 1310720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028664828 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.597       |\n",
      "|    explained_variance   | 0.0124       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 753          |\n",
      "|    n_updates            | 5150         |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1585        |\n",
      "|    iterations           | 161         |\n",
      "|    time_elapsed         | 831         |\n",
      "|    total_timesteps      | 1318912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002283772 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.61       |\n",
      "|    explained_variance   | 0.024       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 872         |\n",
      "|    n_updates            | 5160        |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    value_loss           | 1.44e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1320000, episode_reward=565.80 +/- 93.98\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 566          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1320000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030653665 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.588       |\n",
      "|    explained_variance   | 0.0507       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 676          |\n",
      "|    n_updates            | 5170         |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    value_loss           | 1.42e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1576    |\n",
      "|    iterations      | 162     |\n",
      "|    time_elapsed    | 841     |\n",
      "|    total_timesteps | 1327104 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 163          |\n",
      "|    time_elapsed         | 845          |\n",
      "|    total_timesteps      | 1335296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023463508 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.594       |\n",
      "|    explained_variance   | 0.014        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 387          |\n",
      "|    n_updates            | 5180         |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    value_loss           | 1.35e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1581        |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 849         |\n",
      "|    total_timesteps      | 1343488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003631685 |\n",
      "|    clip_fraction        | 0.0286      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.591      |\n",
      "|    explained_variance   | 0.00376     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 721         |\n",
      "|    n_updates            | 5190        |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    value_loss           | 1.5e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 165          |\n",
      "|    time_elapsed         | 853          |\n",
      "|    total_timesteps      | 1351680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028652505 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.583       |\n",
      "|    explained_variance   | 0.0328       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 604          |\n",
      "|    n_updates            | 5200         |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    value_loss           | 1.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 166          |\n",
      "|    time_elapsed         | 856          |\n",
      "|    total_timesteps      | 1359872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023556682 |\n",
      "|    clip_fraction        | 0.00829      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.596       |\n",
      "|    explained_variance   | 0.0205       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 666          |\n",
      "|    n_updates            | 5210         |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    value_loss           | 1.43e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1360000, episode_reward=557.80 +/- 51.24\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 558          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1360000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031576543 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.604       |\n",
      "|    explained_variance   | 0.0675       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 690          |\n",
      "|    n_updates            | 5220         |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    value_loss           | 1.4e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1577    |\n",
      "|    iterations      | 167     |\n",
      "|    time_elapsed    | 867     |\n",
      "|    total_timesteps | 1368064 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 168          |\n",
      "|    time_elapsed         | 870          |\n",
      "|    total_timesteps      | 1376256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026343565 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.589       |\n",
      "|    explained_variance   | 0.0298       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 683          |\n",
      "|    n_updates            | 5230         |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    value_loss           | 1.52e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 169          |\n",
      "|    time_elapsed         | 874          |\n",
      "|    total_timesteps      | 1384448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024914553 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.621       |\n",
      "|    explained_variance   | 0.0342       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 689          |\n",
      "|    n_updates            | 5240         |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    value_loss           | 1.36e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 170          |\n",
      "|    time_elapsed         | 878          |\n",
      "|    total_timesteps      | 1392640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030982052 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.585       |\n",
      "|    explained_variance   | 0.038        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 732          |\n",
      "|    n_updates            | 5250         |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    value_loss           | 1.37e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1400000, episode_reward=556.20 +/- 64.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 200        |\n",
      "|    mean_reward          | 556        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1400000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00285909 |\n",
      "|    clip_fraction        | 0.0189     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.597     |\n",
      "|    explained_variance   | 0.0469     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 752        |\n",
      "|    n_updates            | 5260       |\n",
      "|    policy_gradient_loss | -0.00449   |\n",
      "|    value_loss           | 1.37e+03   |\n",
      "----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1576    |\n",
      "|    iterations      | 171     |\n",
      "|    time_elapsed    | 888     |\n",
      "|    total_timesteps | 1400832 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1578        |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 892         |\n",
      "|    total_timesteps      | 1409024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002731287 |\n",
      "|    clip_fraction        | 0.0151      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.585      |\n",
      "|    explained_variance   | 0.0422      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 527         |\n",
      "|    n_updates            | 5270        |\n",
      "|    policy_gradient_loss | -0.00366    |\n",
      "|    value_loss           | 1.56e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 173          |\n",
      "|    time_elapsed         | 896          |\n",
      "|    total_timesteps      | 1417216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029643876 |\n",
      "|    clip_fraction        | 0.0223       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.584       |\n",
      "|    explained_variance   | 0.0285       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 377          |\n",
      "|    n_updates            | 5280         |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    value_loss           | 1.4e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 174          |\n",
      "|    time_elapsed         | 900          |\n",
      "|    total_timesteps      | 1425408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032214804 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.559       |\n",
      "|    explained_variance   | 0.026        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 850          |\n",
      "|    n_updates            | 5290         |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    value_loss           | 1.45e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 175          |\n",
      "|    time_elapsed         | 903          |\n",
      "|    total_timesteps      | 1433600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029362969 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.575       |\n",
      "|    explained_variance   | 0.0399       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 822          |\n",
      "|    n_updates            | 5300         |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    value_loss           | 1.43e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1440000, episode_reward=571.20 +/- 84.40\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 571          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1440000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024492063 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.565       |\n",
      "|    explained_variance   | 0.00722      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 777          |\n",
      "|    n_updates            | 5310         |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    value_loss           | 1.5e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1576    |\n",
      "|    iterations      | 176     |\n",
      "|    time_elapsed    | 914     |\n",
      "|    total_timesteps | 1441792 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 177          |\n",
      "|    time_elapsed         | 918          |\n",
      "|    total_timesteps      | 1449984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026571997 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.551       |\n",
      "|    explained_variance   | 0.045        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 649          |\n",
      "|    n_updates            | 5320         |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    value_loss           | 1.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 178          |\n",
      "|    time_elapsed         | 922          |\n",
      "|    total_timesteps      | 1458176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025830965 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.559       |\n",
      "|    explained_variance   | 0.0521       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 686          |\n",
      "|    n_updates            | 5330         |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    value_loss           | 1.41e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 179          |\n",
      "|    time_elapsed         | 925          |\n",
      "|    total_timesteps      | 1466368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034595064 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.575       |\n",
      "|    explained_variance   | 0.0359       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 662          |\n",
      "|    n_updates            | 5340         |\n",
      "|    policy_gradient_loss | -0.00481     |\n",
      "|    value_loss           | 1.34e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 180          |\n",
      "|    time_elapsed         | 929          |\n",
      "|    total_timesteps      | 1474560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024654262 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.557       |\n",
      "|    explained_variance   | 0.0593       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 751          |\n",
      "|    n_updates            | 5350         |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 1.35e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1480000, episode_reward=573.00 +/- 51.82\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 573          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1480000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030237052 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.567       |\n",
      "|    explained_variance   | -0.00215     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 758          |\n",
      "|    n_updates            | 5360         |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    value_loss           | 1.42e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1577    |\n",
      "|    iterations      | 181     |\n",
      "|    time_elapsed    | 939     |\n",
      "|    total_timesteps | 1482752 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 182          |\n",
      "|    time_elapsed         | 943          |\n",
      "|    total_timesteps      | 1490944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024210596 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.562       |\n",
      "|    explained_variance   | 0.0345       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 691          |\n",
      "|    n_updates            | 5370         |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    value_loss           | 1.46e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1581        |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 947         |\n",
      "|    total_timesteps      | 1499136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002428074 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.569      |\n",
      "|    explained_variance   | 0.0268      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 815         |\n",
      "|    n_updates            | 5380        |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    value_loss           | 1.42e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 951         |\n",
      "|    total_timesteps      | 1507328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002087526 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.561      |\n",
      "|    explained_variance   | 0.0272      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 697         |\n",
      "|    n_updates            | 5390        |\n",
      "|    policy_gradient_loss | -0.00373    |\n",
      "|    value_loss           | 1.45e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 185          |\n",
      "|    time_elapsed         | 955          |\n",
      "|    total_timesteps      | 1515520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029545643 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.573       |\n",
      "|    explained_variance   | 0.0447       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 657          |\n",
      "|    n_updates            | 5400         |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    value_loss           | 1.52e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1520000, episode_reward=572.80 +/- 48.87\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 200        |\n",
      "|    mean_reward          | 573        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1520000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00280461 |\n",
      "|    clip_fraction        | 0.0207     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.57      |\n",
      "|    explained_variance   | 0.0341     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 405        |\n",
      "|    n_updates            | 5410       |\n",
      "|    policy_gradient_loss | -0.00355   |\n",
      "|    value_loss           | 1.37e+03   |\n",
      "----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1578    |\n",
      "|    iterations      | 186     |\n",
      "|    time_elapsed    | 965     |\n",
      "|    total_timesteps | 1523712 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 187          |\n",
      "|    time_elapsed         | 969          |\n",
      "|    total_timesteps      | 1531904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027846803 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.573       |\n",
      "|    explained_variance   | 0.053        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 706          |\n",
      "|    n_updates            | 5420         |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    value_loss           | 1.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 188          |\n",
      "|    time_elapsed         | 972          |\n",
      "|    total_timesteps      | 1540096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018397848 |\n",
      "|    clip_fraction        | 0.00759      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.555       |\n",
      "|    explained_variance   | 0.0311       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 742          |\n",
      "|    n_updates            | 5430         |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 189          |\n",
      "|    time_elapsed         | 976          |\n",
      "|    total_timesteps      | 1548288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031731245 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.545       |\n",
      "|    explained_variance   | 0.0403       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 792          |\n",
      "|    n_updates            | 5440         |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 190          |\n",
      "|    time_elapsed         | 980          |\n",
      "|    total_timesteps      | 1556480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027667303 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.548       |\n",
      "|    explained_variance   | 0.0325       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 620          |\n",
      "|    n_updates            | 5450         |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1560000, episode_reward=597.00 +/- 45.57\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 597          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024713841 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.557       |\n",
      "|    explained_variance   | 0.0299       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 773          |\n",
      "|    n_updates            | 5460         |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    value_loss           | 1.39e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1580    |\n",
      "|    iterations      | 191     |\n",
      "|    time_elapsed    | 990     |\n",
      "|    total_timesteps | 1564672 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 192          |\n",
      "|    time_elapsed         | 993          |\n",
      "|    total_timesteps      | 1572864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027972762 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.542       |\n",
      "|    explained_variance   | -0.00252     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 5470         |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    value_loss           | 1.47e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 193          |\n",
      "|    time_elapsed         | 997          |\n",
      "|    total_timesteps      | 1581056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021996954 |\n",
      "|    clip_fraction        | 0.00953      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.55        |\n",
      "|    explained_variance   | 0.0248       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 899          |\n",
      "|    n_updates            | 5480         |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 194          |\n",
      "|    time_elapsed         | 1001         |\n",
      "|    total_timesteps      | 1589248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027711182 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.553       |\n",
      "|    explained_variance   | 0.045        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 601          |\n",
      "|    n_updates            | 5490         |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 195          |\n",
      "|    time_elapsed         | 1004         |\n",
      "|    total_timesteps      | 1597440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026192775 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.557       |\n",
      "|    explained_variance   | 0.0182       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 635          |\n",
      "|    n_updates            | 5500         |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    value_loss           | 1.48e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1600000, episode_reward=563.80 +/- 98.83\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 564          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1600000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028496431 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.54        |\n",
      "|    explained_variance   | 0.024        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 5510         |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    value_loss           | 1.47e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1582    |\n",
      "|    iterations      | 196     |\n",
      "|    time_elapsed    | 1014    |\n",
      "|    total_timesteps | 1605632 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 197          |\n",
      "|    time_elapsed         | 1018         |\n",
      "|    total_timesteps      | 1613824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030070315 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.545       |\n",
      "|    explained_variance   | 0.0396       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 5520         |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    value_loss           | 1.5e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 198          |\n",
      "|    time_elapsed         | 1022         |\n",
      "|    total_timesteps      | 1622016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021513482 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.546       |\n",
      "|    explained_variance   | 0.0366       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 513          |\n",
      "|    n_updates            | 5530         |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 199          |\n",
      "|    time_elapsed         | 1025         |\n",
      "|    total_timesteps      | 1630208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024090165 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.536       |\n",
      "|    explained_variance   | 0.0199       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 722          |\n",
      "|    n_updates            | 5540         |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    value_loss           | 1.45e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1591         |\n",
      "|    iterations           | 200          |\n",
      "|    time_elapsed         | 1029         |\n",
      "|    total_timesteps      | 1638400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022245604 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.527       |\n",
      "|    explained_variance   | 0.0445       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 763          |\n",
      "|    n_updates            | 5550         |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    value_loss           | 1.52e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1640000, episode_reward=570.40 +/- 100.76\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 570          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1640000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025772634 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.0497       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 879          |\n",
      "|    n_updates            | 5560         |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1583    |\n",
      "|    iterations      | 201     |\n",
      "|    time_elapsed    | 1039    |\n",
      "|    total_timesteps | 1646592 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 202          |\n",
      "|    time_elapsed         | 1043         |\n",
      "|    total_timesteps      | 1654784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021694843 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.529       |\n",
      "|    explained_variance   | 0.0392       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 784          |\n",
      "|    n_updates            | 5570         |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 203          |\n",
      "|    time_elapsed         | 1047         |\n",
      "|    total_timesteps      | 1662976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023404867 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.531       |\n",
      "|    explained_variance   | 0.0172       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 491          |\n",
      "|    n_updates            | 5580         |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    value_loss           | 1.5e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1589        |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 1051        |\n",
      "|    total_timesteps      | 1671168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002420453 |\n",
      "|    clip_fraction        | 0.0115      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.534      |\n",
      "|    explained_variance   | 0.00914     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 731         |\n",
      "|    n_updates            | 5590        |\n",
      "|    policy_gradient_loss | -0.00345    |\n",
      "|    value_loss           | 1.53e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1591        |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 1055        |\n",
      "|    total_timesteps      | 1679360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001959715 |\n",
      "|    clip_fraction        | 0.01        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.534      |\n",
      "|    explained_variance   | 0.0778      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 611         |\n",
      "|    n_updates            | 5600        |\n",
      "|    policy_gradient_loss | -0.00337    |\n",
      "|    value_loss           | 1.57e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1680000, episode_reward=566.40 +/- 54.76\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 566         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1680000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002052171 |\n",
      "|    clip_fraction        | 0.00923     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.542      |\n",
      "|    explained_variance   | 0.0255      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 735         |\n",
      "|    n_updates            | 5610        |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    value_loss           | 1.5e+03     |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1584    |\n",
      "|    iterations      | 206     |\n",
      "|    time_elapsed    | 1065    |\n",
      "|    total_timesteps | 1687552 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1586        |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 1068        |\n",
      "|    total_timesteps      | 1695744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002779855 |\n",
      "|    clip_fraction        | 0.0209      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.546      |\n",
      "|    explained_variance   | 0.0643      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 849         |\n",
      "|    n_updates            | 5620        |\n",
      "|    policy_gradient_loss | -0.00396    |\n",
      "|    value_loss           | 1.55e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1588        |\n",
      "|    iterations           | 208         |\n",
      "|    time_elapsed         | 1072        |\n",
      "|    total_timesteps      | 1703936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002437219 |\n",
      "|    clip_fraction        | 0.0185      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.535      |\n",
      "|    explained_variance   | 0.0205      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 870         |\n",
      "|    n_updates            | 5630        |\n",
      "|    policy_gradient_loss | -0.00353    |\n",
      "|    value_loss           | 1.42e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1590       |\n",
      "|    iterations           | 209        |\n",
      "|    time_elapsed         | 1076       |\n",
      "|    total_timesteps      | 1712128    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00256271 |\n",
      "|    clip_fraction        | 0.0136     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.563     |\n",
      "|    explained_variance   | 0.0198     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 713        |\n",
      "|    n_updates            | 5640       |\n",
      "|    policy_gradient_loss | -0.00387   |\n",
      "|    value_loss           | 1.51e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1720000, episode_reward=587.60 +/- 56.38\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 588          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1720000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029128455 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.542       |\n",
      "|    explained_variance   | 0.0449       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 782          |\n",
      "|    n_updates            | 5650         |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1583    |\n",
      "|    iterations      | 210     |\n",
      "|    time_elapsed    | 1086    |\n",
      "|    total_timesteps | 1720320 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 211          |\n",
      "|    time_elapsed         | 1090         |\n",
      "|    total_timesteps      | 1728512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018667384 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.541       |\n",
      "|    explained_variance   | 0.0435       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 664          |\n",
      "|    n_updates            | 5660         |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    value_loss           | 1.46e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 212          |\n",
      "|    time_elapsed         | 1094         |\n",
      "|    total_timesteps      | 1736704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024764123 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.537       |\n",
      "|    explained_variance   | 0.00396      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 800          |\n",
      "|    n_updates            | 5670         |\n",
      "|    policy_gradient_loss | -0.0043      |\n",
      "|    value_loss           | 1.42e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 213          |\n",
      "|    time_elapsed         | 1097         |\n",
      "|    total_timesteps      | 1744896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029404962 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.555       |\n",
      "|    explained_variance   | 0.0379       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 707          |\n",
      "|    n_updates            | 5680         |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    value_loss           | 1.42e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1591         |\n",
      "|    iterations           | 214          |\n",
      "|    time_elapsed         | 1101         |\n",
      "|    total_timesteps      | 1753088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019307542 |\n",
      "|    clip_fraction        | 0.00953      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.553       |\n",
      "|    explained_variance   | 0.0427       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 5690         |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1760000, episode_reward=561.40 +/- 100.34\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 561          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1760000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028267456 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.533       |\n",
      "|    explained_variance   | 0.01         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 454          |\n",
      "|    n_updates            | 5700         |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    value_loss           | 1.45e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1583    |\n",
      "|    iterations      | 215     |\n",
      "|    time_elapsed    | 1112    |\n",
      "|    total_timesteps | 1761280 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 216          |\n",
      "|    time_elapsed         | 1115         |\n",
      "|    total_timesteps      | 1769472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019313965 |\n",
      "|    clip_fraction        | 0.00901      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.526       |\n",
      "|    explained_variance   | 0.0268       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 855          |\n",
      "|    n_updates            | 5710         |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 1.43e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1587        |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 1119        |\n",
      "|    total_timesteps      | 1777664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001962985 |\n",
      "|    clip_fraction        | 0.00906     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.522      |\n",
      "|    explained_variance   | 0.0639      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 774         |\n",
      "|    n_updates            | 5720        |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    value_loss           | 1.52e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 218          |\n",
      "|    time_elapsed         | 1123         |\n",
      "|    total_timesteps      | 1785856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018685062 |\n",
      "|    clip_fraction        | 0.00797      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.525       |\n",
      "|    explained_variance   | 0.0285       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 867          |\n",
      "|    n_updates            | 5730         |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1591         |\n",
      "|    iterations           | 219          |\n",
      "|    time_elapsed         | 1127         |\n",
      "|    total_timesteps      | 1794048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018540449 |\n",
      "|    clip_fraction        | 0.00793      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.525       |\n",
      "|    explained_variance   | 0.0139       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 759          |\n",
      "|    n_updates            | 5740         |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    value_loss           | 1.44e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1800000, episode_reward=562.80 +/- 49.07\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 563         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1800000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002698406 |\n",
      "|    clip_fraction        | 0.0202      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.537      |\n",
      "|    explained_variance   | 0.0325      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 640         |\n",
      "|    n_updates            | 5750        |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    value_loss           | 1.45e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1584    |\n",
      "|    iterations      | 220     |\n",
      "|    time_elapsed    | 1137    |\n",
      "|    total_timesteps | 1802240 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 221          |\n",
      "|    time_elapsed         | 1141         |\n",
      "|    total_timesteps      | 1810432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020850832 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.535       |\n",
      "|    explained_variance   | 0.0214       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 608          |\n",
      "|    n_updates            | 5760         |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 222          |\n",
      "|    time_elapsed         | 1144         |\n",
      "|    total_timesteps      | 1818624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029067884 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.539       |\n",
      "|    explained_variance   | 0.0332       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 927          |\n",
      "|    n_updates            | 5770         |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1590         |\n",
      "|    iterations           | 223          |\n",
      "|    time_elapsed         | 1148         |\n",
      "|    total_timesteps      | 1826816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023844372 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.526       |\n",
      "|    explained_variance   | 0.0469       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 736          |\n",
      "|    n_updates            | 5780         |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    value_loss           | 1.41e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1591        |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 1152        |\n",
      "|    total_timesteps      | 1835008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002740829 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.52       |\n",
      "|    explained_variance   | 0.0332      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 677         |\n",
      "|    n_updates            | 5790        |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    value_loss           | 1.46e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1840000, episode_reward=584.60 +/- 60.41\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 585         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1840000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002770171 |\n",
      "|    clip_fraction        | 0.0201      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.52       |\n",
      "|    explained_variance   | 0.0472      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 697         |\n",
      "|    n_updates            | 5800        |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    value_loss           | 1.49e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1584    |\n",
      "|    iterations      | 225     |\n",
      "|    time_elapsed    | 1163    |\n",
      "|    total_timesteps | 1843200 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 226          |\n",
      "|    time_elapsed         | 1167         |\n",
      "|    total_timesteps      | 1851392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028994302 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.534       |\n",
      "|    explained_variance   | 0.0383       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 682          |\n",
      "|    n_updates            | 5810         |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 227          |\n",
      "|    time_elapsed         | 1171         |\n",
      "|    total_timesteps      | 1859584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028307773 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.534       |\n",
      "|    explained_variance   | 0.0336       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 566          |\n",
      "|    n_updates            | 5820         |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    value_loss           | 1.4e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 228          |\n",
      "|    time_elapsed         | 1175         |\n",
      "|    total_timesteps      | 1867776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025294358 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.527       |\n",
      "|    explained_variance   | 0.0225       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 725          |\n",
      "|    n_updates            | 5830         |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    value_loss           | 1.46e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 229          |\n",
      "|    time_elapsed         | 1180         |\n",
      "|    total_timesteps      | 1875968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015826497 |\n",
      "|    clip_fraction        | 0.00632      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.528       |\n",
      "|    explained_variance   | 0.0549       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 719          |\n",
      "|    n_updates            | 5840         |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    value_loss           | 1.55e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1880000, episode_reward=569.40 +/- 98.60\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 569          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1880000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035355997 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | 0.0395       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 700          |\n",
      "|    n_updates            | 5850         |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    value_loss           | 1.48e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1581    |\n",
      "|    iterations      | 230     |\n",
      "|    time_elapsed    | 1191    |\n",
      "|    total_timesteps | 1884160 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 231          |\n",
      "|    time_elapsed         | 1195         |\n",
      "|    total_timesteps      | 1892352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033630887 |\n",
      "|    clip_fraction        | 0.0282       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.537       |\n",
      "|    explained_variance   | 0.0161       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 823          |\n",
      "|    n_updates            | 5860         |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    value_loss           | 1.55e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 1199        |\n",
      "|    total_timesteps      | 1900544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002637885 |\n",
      "|    clip_fraction        | 0.0138      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.538      |\n",
      "|    explained_variance   | 0.0323      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 801         |\n",
      "|    n_updates            | 5870        |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    value_loss           | 1.48e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 233          |\n",
      "|    time_elapsed         | 1203         |\n",
      "|    total_timesteps      | 1908736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033772585 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.528       |\n",
      "|    explained_variance   | 0.0232       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 749          |\n",
      "|    n_updates            | 5880         |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    value_loss           | 1.5e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 234          |\n",
      "|    time_elapsed         | 1207         |\n",
      "|    total_timesteps      | 1916928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022732643 |\n",
      "|    clip_fraction        | 0.00958      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | -0.0103      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 549          |\n",
      "|    n_updates            | 5890         |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 1.42e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1920000, episode_reward=589.00 +/- 68.62\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 589         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1920000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002638967 |\n",
      "|    clip_fraction        | 0.015       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.519      |\n",
      "|    explained_variance   | 0.0406      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 838         |\n",
      "|    n_updates            | 5900        |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    value_loss           | 1.6e+03     |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1581    |\n",
      "|    iterations      | 235     |\n",
      "|    time_elapsed    | 1217    |\n",
      "|    total_timesteps | 1925120 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 236          |\n",
      "|    time_elapsed         | 1221         |\n",
      "|    total_timesteps      | 1933312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025307846 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | 0.0376       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 876          |\n",
      "|    n_updates            | 5910         |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    value_loss           | 1.48e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 237          |\n",
      "|    time_elapsed         | 1225         |\n",
      "|    total_timesteps      | 1941504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026223361 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | 0.0376       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 831          |\n",
      "|    n_updates            | 5920         |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 238          |\n",
      "|    time_elapsed         | 1228         |\n",
      "|    total_timesteps      | 1949696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024105334 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | 0.0406       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 798          |\n",
      "|    n_updates            | 5930         |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    value_loss           | 1.55e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1588        |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 1232        |\n",
      "|    total_timesteps      | 1957888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002841797 |\n",
      "|    clip_fraction        | 0.0198      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.52       |\n",
      "|    explained_variance   | 0.0119      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 662         |\n",
      "|    n_updates            | 5940        |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    value_loss           | 1.56e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1960000, episode_reward=586.80 +/- 55.19\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 587          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1960000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019787778 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | 0.0357       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 770          |\n",
      "|    n_updates            | 5950         |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1581    |\n",
      "|    iterations      | 240     |\n",
      "|    time_elapsed    | 1243    |\n",
      "|    total_timesteps | 1966080 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 241          |\n",
      "|    time_elapsed         | 1246         |\n",
      "|    total_timesteps      | 1974272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030270107 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.533       |\n",
      "|    explained_variance   | 0.0403       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 507          |\n",
      "|    n_updates            | 5960         |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.47e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 242          |\n",
      "|    time_elapsed         | 1250         |\n",
      "|    total_timesteps      | 1982464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026806118 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.534       |\n",
      "|    explained_variance   | 0.0547       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 730          |\n",
      "|    n_updates            | 5970         |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    value_loss           | 1.53e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 243          |\n",
      "|    time_elapsed         | 1254         |\n",
      "|    total_timesteps      | 1990656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017989984 |\n",
      "|    clip_fraction        | 0.00808      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.528       |\n",
      "|    explained_variance   | 0.0578       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 952          |\n",
      "|    n_updates            | 5980         |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1588        |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 1258        |\n",
      "|    total_timesteps      | 1998848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002431776 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.533      |\n",
      "|    explained_variance   | -0.00484    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 770         |\n",
      "|    n_updates            | 5990        |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    value_loss           | 1.51e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2000000, episode_reward=562.00 +/- 96.58\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 562          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030962385 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.542       |\n",
      "|    explained_variance   | 0.0547       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 712          |\n",
      "|    n_updates            | 6000         |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    value_loss           | 1.43e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1582    |\n",
      "|    iterations      | 245     |\n",
      "|    time_elapsed    | 1268    |\n",
      "|    total_timesteps | 2007040 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 246          |\n",
      "|    time_elapsed         | 1271         |\n",
      "|    total_timesteps      | 2015232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022377083 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.543       |\n",
      "|    explained_variance   | 0.0414       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 723          |\n",
      "|    n_updates            | 6010         |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    value_loss           | 1.45e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 247          |\n",
      "|    time_elapsed         | 1275         |\n",
      "|    total_timesteps      | 2023424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031423857 |\n",
      "|    clip_fraction        | 0.0216       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.549       |\n",
      "|    explained_variance   | 0.0274       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 627          |\n",
      "|    n_updates            | 6020         |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 248          |\n",
      "|    time_elapsed         | 1279         |\n",
      "|    total_timesteps      | 2031616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028935326 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.538       |\n",
      "|    explained_variance   | 0.0228       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 585          |\n",
      "|    n_updates            | 6030         |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    value_loss           | 1.45e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 249          |\n",
      "|    time_elapsed         | 1283         |\n",
      "|    total_timesteps      | 2039808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025649352 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.544       |\n",
      "|    explained_variance   | 0.0579       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 641          |\n",
      "|    n_updates            | 6040         |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    value_loss           | 1.45e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2040000, episode_reward=575.60 +/- 100.54\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 576         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2040000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002417792 |\n",
      "|    clip_fraction        | 0.0126      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.539      |\n",
      "|    explained_variance   | 0.0219      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 463         |\n",
      "|    n_updates            | 6050        |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    value_loss           | 1.43e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1583    |\n",
      "|    iterations      | 250     |\n",
      "|    time_elapsed    | 1293    |\n",
      "|    total_timesteps | 2048000 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 251          |\n",
      "|    time_elapsed         | 1297         |\n",
      "|    total_timesteps      | 2056192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025466988 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.529       |\n",
      "|    explained_variance   | 0.0268       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 6060         |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 252          |\n",
      "|    time_elapsed         | 1300         |\n",
      "|    total_timesteps      | 2064384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029746557 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.548       |\n",
      "|    explained_variance   | 0.0131       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 545          |\n",
      "|    n_updates            | 6070         |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    value_loss           | 1.43e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 253          |\n",
      "|    time_elapsed         | 1304         |\n",
      "|    total_timesteps      | 2072576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026381726 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.535       |\n",
      "|    explained_variance   | 0.0522       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 826          |\n",
      "|    n_updates            | 6080         |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    value_loss           | 1.41e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2080000, episode_reward=565.40 +/- 95.80\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 565          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2080000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025585548 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.542       |\n",
      "|    explained_variance   | 0.0507       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 560          |\n",
      "|    n_updates            | 6090         |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    value_loss           | 1.45e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1582    |\n",
      "|    iterations      | 254     |\n",
      "|    time_elapsed    | 1314    |\n",
      "|    total_timesteps | 2080768 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 255          |\n",
      "|    time_elapsed         | 1318         |\n",
      "|    total_timesteps      | 2088960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025005387 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.537       |\n",
      "|    explained_variance   | 0.0164       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 738          |\n",
      "|    n_updates            | 6100         |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    value_loss           | 1.41e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 256          |\n",
      "|    time_elapsed         | 1322         |\n",
      "|    total_timesteps      | 2097152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024587284 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.537       |\n",
      "|    explained_variance   | 0.0337       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 476          |\n",
      "|    n_updates            | 6110         |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 257          |\n",
      "|    time_elapsed         | 1325         |\n",
      "|    total_timesteps      | 2105344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028630996 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.534       |\n",
      "|    explained_variance   | 0.0239       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 667          |\n",
      "|    n_updates            | 6120         |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    value_loss           | 1.48e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 258          |\n",
      "|    time_elapsed         | 1329         |\n",
      "|    total_timesteps      | 2113536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026065765 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.0481       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 549          |\n",
      "|    n_updates            | 6130         |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    value_loss           | 1.46e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2120000, episode_reward=539.00 +/- 129.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 539          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022033723 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.545       |\n",
      "|    explained_variance   | 0.0882       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 693          |\n",
      "|    n_updates            | 6140         |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    value_loss           | 1.55e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1583    |\n",
      "|    iterations      | 259     |\n",
      "|    time_elapsed    | 1339    |\n",
      "|    total_timesteps | 2121728 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 260          |\n",
      "|    time_elapsed         | 1343         |\n",
      "|    total_timesteps      | 2129920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019908762 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.532       |\n",
      "|    explained_variance   | 0.0315       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 657          |\n",
      "|    n_updates            | 6150         |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 261          |\n",
      "|    time_elapsed         | 1347         |\n",
      "|    total_timesteps      | 2138112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031578727 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.531       |\n",
      "|    explained_variance   | 0.0318       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 679          |\n",
      "|    n_updates            | 6160         |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    value_loss           | 1.5e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 262          |\n",
      "|    time_elapsed         | 1351         |\n",
      "|    total_timesteps      | 2146304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024471781 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.549       |\n",
      "|    explained_variance   | 0.04         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 917          |\n",
      "|    n_updates            | 6170         |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 263          |\n",
      "|    time_elapsed         | 1355         |\n",
      "|    total_timesteps      | 2154496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025663555 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.549       |\n",
      "|    explained_variance   | 0.0515       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 685          |\n",
      "|    n_updates            | 6180         |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    value_loss           | 1.41e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2160000, episode_reward=559.80 +/- 98.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 560          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2160000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024232012 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.548       |\n",
      "|    explained_variance   | 0.00726      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 632          |\n",
      "|    n_updates            | 6190         |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    value_loss           | 1.54e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1584    |\n",
      "|    iterations      | 264     |\n",
      "|    time_elapsed    | 1365    |\n",
      "|    total_timesteps | 2162688 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1585        |\n",
      "|    iterations           | 265         |\n",
      "|    time_elapsed         | 1369        |\n",
      "|    total_timesteps      | 2170880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002269789 |\n",
      "|    clip_fraction        | 0.0123      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.542      |\n",
      "|    explained_variance   | 0.0529      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 688         |\n",
      "|    n_updates            | 6200        |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    value_loss           | 1.41e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 266          |\n",
      "|    time_elapsed         | 1373         |\n",
      "|    total_timesteps      | 2179072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029296959 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.531       |\n",
      "|    explained_variance   | 0.0452       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 836          |\n",
      "|    n_updates            | 6210         |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    value_loss           | 1.39e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 267          |\n",
      "|    time_elapsed         | 1376         |\n",
      "|    total_timesteps      | 2187264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027367799 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.539       |\n",
      "|    explained_variance   | 0.0446       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 784          |\n",
      "|    n_updates            | 6220         |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    value_loss           | 1.48e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 268          |\n",
      "|    time_elapsed         | 1380         |\n",
      "|    total_timesteps      | 2195456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022858637 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.55        |\n",
      "|    explained_variance   | 0.0257       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 629          |\n",
      "|    n_updates            | 6230         |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2200000, episode_reward=560.60 +/- 103.68\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 561          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025759547 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.542       |\n",
      "|    explained_variance   | 0.0383       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 715          |\n",
      "|    n_updates            | 6240         |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1583    |\n",
      "|    iterations      | 269     |\n",
      "|    time_elapsed    | 1391    |\n",
      "|    total_timesteps | 2203648 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 270          |\n",
      "|    time_elapsed         | 1395         |\n",
      "|    total_timesteps      | 2211840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020107492 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.541       |\n",
      "|    explained_variance   | 0.0305       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 903          |\n",
      "|    n_updates            | 6250         |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    value_loss           | 1.5e+03      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1586       |\n",
      "|    iterations           | 271        |\n",
      "|    time_elapsed         | 1399       |\n",
      "|    total_timesteps      | 2220032    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00232229 |\n",
      "|    clip_fraction        | 0.0109     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.526     |\n",
      "|    explained_variance   | 0.0382     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 747        |\n",
      "|    n_updates            | 6260       |\n",
      "|    policy_gradient_loss | -0.00358   |\n",
      "|    value_loss           | 1.43e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1587        |\n",
      "|    iterations           | 272         |\n",
      "|    time_elapsed         | 1403        |\n",
      "|    total_timesteps      | 2228224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002623409 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.539      |\n",
      "|    explained_variance   | 0.035       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 789         |\n",
      "|    n_updates            | 6270        |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    value_loss           | 1.59e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 273          |\n",
      "|    time_elapsed         | 1407         |\n",
      "|    total_timesteps      | 2236416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029880449 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.525       |\n",
      "|    explained_variance   | 0.0133       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 743          |\n",
      "|    n_updates            | 6280         |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    value_loss           | 1.38e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2240000, episode_reward=580.20 +/- 63.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 580          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2240000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019882107 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.529       |\n",
      "|    explained_variance   | 0.0845       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 682          |\n",
      "|    n_updates            | 6290         |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    value_loss           | 1.47e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1582    |\n",
      "|    iterations      | 274     |\n",
      "|    time_elapsed    | 1418    |\n",
      "|    total_timesteps | 2244608 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 275          |\n",
      "|    time_elapsed         | 1422         |\n",
      "|    total_timesteps      | 2252800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018572572 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.536       |\n",
      "|    explained_variance   | 0.138        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 761          |\n",
      "|    n_updates            | 6300         |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    value_loss           | 1.42e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 276          |\n",
      "|    time_elapsed         | 1426         |\n",
      "|    total_timesteps      | 2260992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023200188 |\n",
      "|    clip_fraction        | 0.00992      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.533       |\n",
      "|    explained_variance   | 0.0291       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 857          |\n",
      "|    n_updates            | 6310         |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 277          |\n",
      "|    time_elapsed         | 1430         |\n",
      "|    total_timesteps      | 2269184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029347702 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.536       |\n",
      "|    explained_variance   | 0.0337       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 579          |\n",
      "|    n_updates            | 6320         |\n",
      "|    policy_gradient_loss | -0.00466     |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1588        |\n",
      "|    iterations           | 278         |\n",
      "|    time_elapsed         | 1434        |\n",
      "|    total_timesteps      | 2277376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002585812 |\n",
      "|    clip_fraction        | 0.0146      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.531      |\n",
      "|    explained_variance   | 0.035       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 676         |\n",
      "|    n_updates            | 6330        |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    value_loss           | 1.46e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2280000, episode_reward=573.00 +/- 96.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 573          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018495941 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.533       |\n",
      "|    explained_variance   | 0.0588       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 827          |\n",
      "|    n_updates            | 6340         |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 1.44e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1582    |\n",
      "|    iterations      | 279     |\n",
      "|    time_elapsed    | 1444    |\n",
      "|    total_timesteps | 2285568 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 280         |\n",
      "|    time_elapsed         | 1447        |\n",
      "|    total_timesteps      | 2293760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002849512 |\n",
      "|    clip_fraction        | 0.0197      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.53       |\n",
      "|    explained_variance   | 0.0822      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 590         |\n",
      "|    n_updates            | 6350        |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    value_loss           | 1.44e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 281          |\n",
      "|    time_elapsed         | 1451         |\n",
      "|    total_timesteps      | 2301952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032681855 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.54        |\n",
      "|    explained_variance   | 0.0404       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 685          |\n",
      "|    n_updates            | 6360         |\n",
      "|    policy_gradient_loss | -0.0043      |\n",
      "|    value_loss           | 1.53e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 282          |\n",
      "|    time_elapsed         | 1455         |\n",
      "|    total_timesteps      | 2310144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023999908 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.528       |\n",
      "|    explained_variance   | 0.0428       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 694          |\n",
      "|    n_updates            | 6370         |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    value_loss           | 1.44e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 283          |\n",
      "|    time_elapsed         | 1459         |\n",
      "|    total_timesteps      | 2318336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029923501 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.531       |\n",
      "|    explained_variance   | 0.0229       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 572          |\n",
      "|    n_updates            | 6380         |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    value_loss           | 1.46e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2320000, episode_reward=582.60 +/- 70.73\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 583          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2320000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024890262 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.534       |\n",
      "|    explained_variance   | 0.0474       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 896          |\n",
      "|    n_updates            | 6390         |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    value_loss           | 1.46e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1583    |\n",
      "|    iterations      | 284     |\n",
      "|    time_elapsed    | 1469    |\n",
      "|    total_timesteps | 2326528 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 1473        |\n",
      "|    total_timesteps      | 2334720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002382082 |\n",
      "|    clip_fraction        | 0.0127      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.545      |\n",
      "|    explained_variance   | 0.0865      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 839         |\n",
      "|    n_updates            | 6400        |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    value_loss           | 1.52e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 286          |\n",
      "|    time_elapsed         | 1476         |\n",
      "|    total_timesteps      | 2342912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032466317 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.555       |\n",
      "|    explained_variance   | 0.0481       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 649          |\n",
      "|    n_updates            | 6410         |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    value_loss           | 1.41e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 287          |\n",
      "|    time_elapsed         | 1480         |\n",
      "|    total_timesteps      | 2351104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019208784 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.561       |\n",
      "|    explained_variance   | 0.0234       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 656          |\n",
      "|    n_updates            | 6420         |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 288          |\n",
      "|    time_elapsed         | 1484         |\n",
      "|    total_timesteps      | 2359296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028839754 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.572       |\n",
      "|    explained_variance   | 0.0228       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 530          |\n",
      "|    n_updates            | 6430         |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2360000, episode_reward=556.60 +/- 127.48\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 557         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2360000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003070679 |\n",
      "|    clip_fraction        | 0.0195      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.556      |\n",
      "|    explained_variance   | 0.0474      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 804         |\n",
      "|    n_updates            | 6440        |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    value_loss           | 1.6e+03     |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1584    |\n",
      "|    iterations      | 289     |\n",
      "|    time_elapsed    | 1494    |\n",
      "|    total_timesteps | 2367488 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1585        |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 1497        |\n",
      "|    total_timesteps      | 2375680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002407093 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.562      |\n",
      "|    explained_variance   | 0.0627      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 631         |\n",
      "|    n_updates            | 6450        |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    value_loss           | 1.44e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 291          |\n",
      "|    time_elapsed         | 1501         |\n",
      "|    total_timesteps      | 2383872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030032424 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.561       |\n",
      "|    explained_variance   | 0.0514       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 712          |\n",
      "|    n_updates            | 6460         |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    value_loss           | 1.47e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 292          |\n",
      "|    time_elapsed         | 1505         |\n",
      "|    total_timesteps      | 2392064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031427927 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.565       |\n",
      "|    explained_variance   | 0.0321       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 562          |\n",
      "|    n_updates            | 6470         |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    value_loss           | 1.38e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2400000, episode_reward=543.60 +/- 122.67\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 544          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2400000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022688254 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.558       |\n",
      "|    explained_variance   | 0.00148      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 888          |\n",
      "|    n_updates            | 6480         |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 1.58e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1583    |\n",
      "|    iterations      | 293     |\n",
      "|    time_elapsed    | 1515    |\n",
      "|    total_timesteps | 2400256 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 294          |\n",
      "|    time_elapsed         | 1519         |\n",
      "|    total_timesteps      | 2408448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029244046 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.0261       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 581          |\n",
      "|    n_updates            | 6490         |\n",
      "|    policy_gradient_loss | -0.00473     |\n",
      "|    value_loss           | 1.46e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 295          |\n",
      "|    time_elapsed         | 1522         |\n",
      "|    total_timesteps      | 2416640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027453005 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.56        |\n",
      "|    explained_variance   | 0.0464       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 736          |\n",
      "|    n_updates            | 6500         |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    value_loss           | 1.53e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 296          |\n",
      "|    time_elapsed         | 1526         |\n",
      "|    total_timesteps      | 2424832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027554883 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.561       |\n",
      "|    explained_variance   | 0.0383       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 815          |\n",
      "|    n_updates            | 6510         |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    value_loss           | 1.53e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1589        |\n",
      "|    iterations           | 297         |\n",
      "|    time_elapsed         | 1530        |\n",
      "|    total_timesteps      | 2433024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002394568 |\n",
      "|    clip_fraction        | 0.0143      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.55       |\n",
      "|    explained_variance   | 0.0509      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 634         |\n",
      "|    n_updates            | 6520        |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2440000, episode_reward=580.40 +/- 72.75\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 580          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2440000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026182001 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.541       |\n",
      "|    explained_variance   | 0.00824      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 591          |\n",
      "|    n_updates            | 6530         |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    value_loss           | 1.46e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1584    |\n",
      "|    iterations      | 298     |\n",
      "|    time_elapsed    | 1540    |\n",
      "|    total_timesteps | 2441216 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 299          |\n",
      "|    time_elapsed         | 1544         |\n",
      "|    total_timesteps      | 2449408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023448449 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.544       |\n",
      "|    explained_variance   | 0.0213       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 570          |\n",
      "|    n_updates            | 6540         |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    value_loss           | 1.44e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 300          |\n",
      "|    time_elapsed         | 1547         |\n",
      "|    total_timesteps      | 2457600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024992083 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.548       |\n",
      "|    explained_variance   | 0.0142       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 677          |\n",
      "|    n_updates            | 6550         |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.46e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 301          |\n",
      "|    time_elapsed         | 1551         |\n",
      "|    total_timesteps      | 2465792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031294678 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.567       |\n",
      "|    explained_variance   | 0.0263       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 983          |\n",
      "|    n_updates            | 6560         |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1590         |\n",
      "|    iterations           | 302          |\n",
      "|    time_elapsed         | 1555         |\n",
      "|    total_timesteps      | 2473984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024370481 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.567       |\n",
      "|    explained_variance   | 0.0184       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 615          |\n",
      "|    n_updates            | 6570         |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    value_loss           | 1.46e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2480000, episode_reward=548.20 +/- 107.16\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 548          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2480000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028315675 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.546       |\n",
      "|    explained_variance   | 0.0467       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 584          |\n",
      "|    n_updates            | 6580         |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    value_loss           | 1.5e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1586    |\n",
      "|    iterations      | 303     |\n",
      "|    time_elapsed    | 1565    |\n",
      "|    total_timesteps | 2482176 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 304          |\n",
      "|    time_elapsed         | 1568         |\n",
      "|    total_timesteps      | 2490368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021146473 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.545       |\n",
      "|    explained_variance   | 0.0349       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 814          |\n",
      "|    n_updates            | 6590         |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    value_loss           | 1.47e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 305          |\n",
      "|    time_elapsed         | 1572         |\n",
      "|    total_timesteps      | 2498560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032181102 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.539       |\n",
      "|    explained_variance   | 0.0498       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 729          |\n",
      "|    n_updates            | 6600         |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    value_loss           | 1.43e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1590        |\n",
      "|    iterations           | 306         |\n",
      "|    time_elapsed         | 1576        |\n",
      "|    total_timesteps      | 2506752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002294247 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.551      |\n",
      "|    explained_variance   | 0.0357      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 922         |\n",
      "|    n_updates            | 6610        |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    value_loss           | 1.56e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1591         |\n",
      "|    iterations           | 307          |\n",
      "|    time_elapsed         | 1579         |\n",
      "|    total_timesteps      | 2514944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029320165 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.546       |\n",
      "|    explained_variance   | 0.0505       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 657          |\n",
      "|    n_updates            | 6620         |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    value_loss           | 1.44e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2520000, episode_reward=602.00 +/- 62.99\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 602          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2520000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020833635 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.56        |\n",
      "|    explained_variance   | 0.0439       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 653          |\n",
      "|    n_updates            | 6630         |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    value_loss           | 1.38e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1586    |\n",
      "|    iterations      | 308     |\n",
      "|    time_elapsed    | 1590    |\n",
      "|    total_timesteps | 2523136 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1588        |\n",
      "|    iterations           | 309         |\n",
      "|    time_elapsed         | 1593        |\n",
      "|    total_timesteps      | 2531328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002454637 |\n",
      "|    clip_fraction        | 0.0119      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.557      |\n",
      "|    explained_variance   | 0.0406      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 879         |\n",
      "|    n_updates            | 6640        |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    value_loss           | 1.43e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 310          |\n",
      "|    time_elapsed         | 1597         |\n",
      "|    total_timesteps      | 2539520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021880325 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.0203       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 911          |\n",
      "|    n_updates            | 6650         |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1590        |\n",
      "|    iterations           | 311         |\n",
      "|    time_elapsed         | 1601        |\n",
      "|    total_timesteps      | 2547712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002992663 |\n",
      "|    clip_fraction        | 0.0194      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.548      |\n",
      "|    explained_variance   | 0.0463      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 640         |\n",
      "|    n_updates            | 6660        |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    value_loss           | 1.46e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1592         |\n",
      "|    iterations           | 312          |\n",
      "|    time_elapsed         | 1605         |\n",
      "|    total_timesteps      | 2555904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028778594 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.56        |\n",
      "|    explained_variance   | 0.0505       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 763          |\n",
      "|    n_updates            | 6670         |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    value_loss           | 1.47e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2560000, episode_reward=576.80 +/- 96.32\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 577          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026080802 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.573       |\n",
      "|    explained_variance   | 0.0277       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 630          |\n",
      "|    n_updates            | 6680         |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    value_loss           | 1.41e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1587    |\n",
      "|    iterations      | 313     |\n",
      "|    time_elapsed    | 1615    |\n",
      "|    total_timesteps | 2564096 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 314          |\n",
      "|    time_elapsed         | 1619         |\n",
      "|    total_timesteps      | 2572288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022541527 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.561       |\n",
      "|    explained_variance   | 0.00842      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 761          |\n",
      "|    n_updates            | 6690         |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    value_loss           | 1.5e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1590         |\n",
      "|    iterations           | 315          |\n",
      "|    time_elapsed         | 1622         |\n",
      "|    total_timesteps      | 2580480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029759998 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.568       |\n",
      "|    explained_variance   | 0.00595      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 795          |\n",
      "|    n_updates            | 6700         |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    value_loss           | 1.44e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1591         |\n",
      "|    iterations           | 316          |\n",
      "|    time_elapsed         | 1626         |\n",
      "|    total_timesteps      | 2588672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017551612 |\n",
      "|    clip_fraction        | 0.00723      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.559       |\n",
      "|    explained_variance   | 0.0296       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 801          |\n",
      "|    n_updates            | 6710         |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1592         |\n",
      "|    iterations           | 317          |\n",
      "|    time_elapsed         | 1630         |\n",
      "|    total_timesteps      | 2596864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025671592 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.577       |\n",
      "|    explained_variance   | 0.03         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 605          |\n",
      "|    n_updates            | 6720         |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    value_loss           | 1.52e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2600000, episode_reward=577.60 +/- 59.92\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 578          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2600000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026970685 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.555       |\n",
      "|    explained_variance   | 0.0517       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 828          |\n",
      "|    n_updates            | 6730         |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1587    |\n",
      "|    iterations      | 318     |\n",
      "|    time_elapsed    | 1640    |\n",
      "|    total_timesteps | 2605056 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 319          |\n",
      "|    time_elapsed         | 1644         |\n",
      "|    total_timesteps      | 2613248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029379935 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.564       |\n",
      "|    explained_variance   | 0.0282       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 807          |\n",
      "|    n_updates            | 6740         |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    value_loss           | 1.37e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1590         |\n",
      "|    iterations           | 320          |\n",
      "|    time_elapsed         | 1648         |\n",
      "|    total_timesteps      | 2621440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023208517 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.552       |\n",
      "|    explained_variance   | 0.0542       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 875          |\n",
      "|    n_updates            | 6750         |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    value_loss           | 1.5e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1591         |\n",
      "|    iterations           | 321          |\n",
      "|    time_elapsed         | 1652         |\n",
      "|    total_timesteps      | 2629632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031485306 |\n",
      "|    clip_fraction        | 0.0218       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.559       |\n",
      "|    explained_variance   | 0.014        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 701          |\n",
      "|    n_updates            | 6760         |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    value_loss           | 1.48e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1593         |\n",
      "|    iterations           | 322          |\n",
      "|    time_elapsed         | 1655         |\n",
      "|    total_timesteps      | 2637824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027443548 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.545       |\n",
      "|    explained_variance   | 0.0172       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 580          |\n",
      "|    n_updates            | 6770         |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    value_loss           | 1.54e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2640000, episode_reward=601.60 +/- 52.21\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 602          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2640000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024952015 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.548       |\n",
      "|    explained_variance   | 0.0524       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 627          |\n",
      "|    n_updates            | 6780         |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    value_loss           | 1.52e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1588    |\n",
      "|    iterations      | 323     |\n",
      "|    time_elapsed    | 1666    |\n",
      "|    total_timesteps | 2646016 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 324          |\n",
      "|    time_elapsed         | 1669         |\n",
      "|    total_timesteps      | 2654208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027526466 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.552       |\n",
      "|    explained_variance   | 0.0676       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 650          |\n",
      "|    n_updates            | 6790         |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    value_loss           | 1.44e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1590         |\n",
      "|    iterations           | 325          |\n",
      "|    time_elapsed         | 1673         |\n",
      "|    total_timesteps      | 2662400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029647679 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.557       |\n",
      "|    explained_variance   | 0.0216       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 716          |\n",
      "|    n_updates            | 6800         |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    value_loss           | 1.46e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1591         |\n",
      "|    iterations           | 326          |\n",
      "|    time_elapsed         | 1677         |\n",
      "|    total_timesteps      | 2670592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023211013 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.0431       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 730          |\n",
      "|    n_updates            | 6810         |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1593         |\n",
      "|    iterations           | 327          |\n",
      "|    time_elapsed         | 1681         |\n",
      "|    total_timesteps      | 2678784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024649426 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.535       |\n",
      "|    explained_variance   | 0.0488       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 778          |\n",
      "|    n_updates            | 6820         |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2680000, episode_reward=585.40 +/- 57.31\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 585          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2680000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019980436 |\n",
      "|    clip_fraction        | 0.00994      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.54        |\n",
      "|    explained_variance   | 0.0319       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 897          |\n",
      "|    n_updates            | 6830         |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 1.5e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1588    |\n",
      "|    iterations      | 328     |\n",
      "|    time_elapsed    | 1691    |\n",
      "|    total_timesteps | 2686976 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 329          |\n",
      "|    time_elapsed         | 1695         |\n",
      "|    total_timesteps      | 2695168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020382018 |\n",
      "|    clip_fraction        | 0.00812      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.543       |\n",
      "|    explained_variance   | 0.0561       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 744          |\n",
      "|    n_updates            | 6840         |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1591        |\n",
      "|    iterations           | 330         |\n",
      "|    time_elapsed         | 1698        |\n",
      "|    total_timesteps      | 2703360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002509587 |\n",
      "|    clip_fraction        | 0.0158      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.532      |\n",
      "|    explained_variance   | 0.0667      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 978         |\n",
      "|    n_updates            | 6850        |\n",
      "|    policy_gradient_loss | -0.00429    |\n",
      "|    value_loss           | 1.53e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1592         |\n",
      "|    iterations           | 331          |\n",
      "|    time_elapsed         | 1702         |\n",
      "|    total_timesteps      | 2711552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024299868 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.547       |\n",
      "|    explained_variance   | 0.0411       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 596          |\n",
      "|    n_updates            | 6860         |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    value_loss           | 1.58e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1593         |\n",
      "|    iterations           | 332          |\n",
      "|    time_elapsed         | 1706         |\n",
      "|    total_timesteps      | 2719744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027351836 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.542       |\n",
      "|    explained_variance   | 0.00609      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 538          |\n",
      "|    n_updates            | 6870         |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    value_loss           | 1.44e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2720000, episode_reward=586.20 +/- 60.73\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 586          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2720000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029885005 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.529       |\n",
      "|    explained_variance   | 0.00989      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 659          |\n",
      "|    n_updates            | 6880         |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    value_loss           | 1.5e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1589    |\n",
      "|    iterations      | 333     |\n",
      "|    time_elapsed    | 1716    |\n",
      "|    total_timesteps | 2727936 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1590         |\n",
      "|    iterations           | 334          |\n",
      "|    time_elapsed         | 1720         |\n",
      "|    total_timesteps      | 2736128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025365925 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.0387       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 709          |\n",
      "|    n_updates            | 6890         |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    value_loss           | 1.48e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1591         |\n",
      "|    iterations           | 335          |\n",
      "|    time_elapsed         | 1724         |\n",
      "|    total_timesteps      | 2744320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024201523 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.523       |\n",
      "|    explained_variance   | 0.032        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 991          |\n",
      "|    n_updates            | 6900         |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1592        |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 1727        |\n",
      "|    total_timesteps      | 2752512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002443885 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.518      |\n",
      "|    explained_variance   | 0.0047      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 818         |\n",
      "|    n_updates            | 6910        |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    value_loss           | 1.48e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2760000, episode_reward=563.20 +/- 130.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 563          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2760000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018734949 |\n",
      "|    clip_fraction        | 0.00934      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.0371       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 553          |\n",
      "|    n_updates            | 6920         |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    value_loss           | 1.54e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1588    |\n",
      "|    iterations      | 337     |\n",
      "|    time_elapsed    | 1738    |\n",
      "|    total_timesteps | 2760704 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 338          |\n",
      "|    time_elapsed         | 1741         |\n",
      "|    total_timesteps      | 2768896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024116477 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.0541       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 705          |\n",
      "|    n_updates            | 6930         |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    value_loss           | 1.55e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1590        |\n",
      "|    iterations           | 339         |\n",
      "|    time_elapsed         | 1745        |\n",
      "|    total_timesteps      | 2777088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002461948 |\n",
      "|    clip_fraction        | 0.017       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.499      |\n",
      "|    explained_variance   | 0.00757     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 761         |\n",
      "|    n_updates            | 6940        |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    value_loss           | 1.56e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1592         |\n",
      "|    iterations           | 340          |\n",
      "|    time_elapsed         | 1749         |\n",
      "|    total_timesteps      | 2785280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026218742 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0416       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 683          |\n",
      "|    n_updates            | 6950         |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    value_loss           | 1.5e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1593        |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 1753        |\n",
      "|    total_timesteps      | 2793472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001986456 |\n",
      "|    clip_fraction        | 0.00831     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.51       |\n",
      "|    explained_variance   | 0.0491      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 898         |\n",
      "|    n_updates            | 6960        |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    value_loss           | 1.56e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2800000, episode_reward=581.60 +/- 96.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 582          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2800000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023206263 |\n",
      "|    clip_fraction        | 0.00956      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | 0.0168       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 765          |\n",
      "|    n_updates            | 6970         |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    value_loss           | 1.46e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1588    |\n",
      "|    iterations      | 342     |\n",
      "|    time_elapsed    | 1763    |\n",
      "|    total_timesteps | 2801664 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1590         |\n",
      "|    iterations           | 343          |\n",
      "|    time_elapsed         | 1767         |\n",
      "|    total_timesteps      | 2809856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026545434 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0421       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 945          |\n",
      "|    n_updates            | 6980         |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1591         |\n",
      "|    iterations           | 344          |\n",
      "|    time_elapsed         | 1770         |\n",
      "|    total_timesteps      | 2818048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025069925 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0546       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 950          |\n",
      "|    n_updates            | 6990         |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1592         |\n",
      "|    iterations           | 345          |\n",
      "|    time_elapsed         | 1774         |\n",
      "|    total_timesteps      | 2826240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027249954 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0117       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 592          |\n",
      "|    n_updates            | 7000         |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    value_loss           | 1.46e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1593        |\n",
      "|    iterations           | 346         |\n",
      "|    time_elapsed         | 1778        |\n",
      "|    total_timesteps      | 2834432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002408383 |\n",
      "|    clip_fraction        | 0.0161      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.509      |\n",
      "|    explained_variance   | 0.0491      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 685         |\n",
      "|    n_updates            | 7010        |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    value_loss           | 1.5e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2840000, episode_reward=562.60 +/- 128.53\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 563         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2840000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002818978 |\n",
      "|    clip_fraction        | 0.018       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.511      |\n",
      "|    explained_variance   | 0.0476      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 785         |\n",
      "|    n_updates            | 7020        |\n",
      "|    policy_gradient_loss | -0.00422    |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1589    |\n",
      "|    iterations      | 347     |\n",
      "|    time_elapsed    | 1788    |\n",
      "|    total_timesteps | 2842624 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1590         |\n",
      "|    iterations           | 348          |\n",
      "|    time_elapsed         | 1791         |\n",
      "|    total_timesteps      | 2850816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028549791 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.00915      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 853          |\n",
      "|    n_updates            | 7030         |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1592         |\n",
      "|    iterations           | 349          |\n",
      "|    time_elapsed         | 1795         |\n",
      "|    total_timesteps      | 2859008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019225709 |\n",
      "|    clip_fraction        | 0.01         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.52        |\n",
      "|    explained_variance   | 0.0647       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 710          |\n",
      "|    n_updates            | 7040         |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.47e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1593        |\n",
      "|    iterations           | 350         |\n",
      "|    time_elapsed         | 1799        |\n",
      "|    total_timesteps      | 2867200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002172146 |\n",
      "|    clip_fraction        | 0.0104      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.525      |\n",
      "|    explained_variance   | 0.0333      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 706         |\n",
      "|    n_updates            | 7050        |\n",
      "|    policy_gradient_loss | -0.0032     |\n",
      "|    value_loss           | 1.5e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 351          |\n",
      "|    time_elapsed         | 1803         |\n",
      "|    total_timesteps      | 2875392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025145942 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0407       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 779          |\n",
      "|    n_updates            | 7060         |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2880000, episode_reward=599.20 +/- 56.63\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 599          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2880000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023460553 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0135       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 825          |\n",
      "|    n_updates            | 7070         |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    value_loss           | 1.47e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1590    |\n",
      "|    iterations      | 352     |\n",
      "|    time_elapsed    | 1812    |\n",
      "|    total_timesteps | 2883584 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1591         |\n",
      "|    iterations           | 353          |\n",
      "|    time_elapsed         | 1816         |\n",
      "|    total_timesteps      | 2891776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025188667 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0725       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 690          |\n",
      "|    n_updates            | 7080         |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1593         |\n",
      "|    iterations           | 354          |\n",
      "|    time_elapsed         | 1820         |\n",
      "|    total_timesteps      | 2899968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025451067 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.489       |\n",
      "|    explained_variance   | 0.029        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 626          |\n",
      "|    n_updates            | 7090         |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    value_loss           | 1.53e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 355          |\n",
      "|    time_elapsed         | 1823         |\n",
      "|    total_timesteps      | 2908160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023883067 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.0219       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 625          |\n",
      "|    n_updates            | 7100         |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 1.58e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 356          |\n",
      "|    time_elapsed         | 1827         |\n",
      "|    total_timesteps      | 2916352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024225903 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.0216       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 756          |\n",
      "|    n_updates            | 7110         |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    value_loss           | 1.55e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2920000, episode_reward=570.20 +/- 98.72\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 570          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2920000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026737128 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.0499       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 562          |\n",
      "|    n_updates            | 7120         |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1591    |\n",
      "|    iterations      | 357     |\n",
      "|    time_elapsed    | 1837    |\n",
      "|    total_timesteps | 2924544 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1592         |\n",
      "|    iterations           | 358          |\n",
      "|    time_elapsed         | 1841         |\n",
      "|    total_timesteps      | 2932736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026575055 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | 0.0296       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.08e+03     |\n",
      "|    n_updates            | 7130         |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 359          |\n",
      "|    time_elapsed         | 1844         |\n",
      "|    total_timesteps      | 2940928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019612724 |\n",
      "|    clip_fraction        | 0.00922      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.0156       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 719          |\n",
      "|    n_updates            | 7140         |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    value_loss           | 1.55e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 360          |\n",
      "|    time_elapsed         | 1848         |\n",
      "|    total_timesteps      | 2949120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025098105 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.469       |\n",
      "|    explained_variance   | 0.029        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 941          |\n",
      "|    n_updates            | 7150         |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1596         |\n",
      "|    iterations           | 361          |\n",
      "|    time_elapsed         | 1852         |\n",
      "|    total_timesteps      | 2957312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028570734 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.471       |\n",
      "|    explained_variance   | 0.0182       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 7160         |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    value_loss           | 1.53e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2960000, episode_reward=590.40 +/- 61.15\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 590          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2960000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017933522 |\n",
      "|    clip_fraction        | 0.01         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.477       |\n",
      "|    explained_variance   | 0.0211       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 663          |\n",
      "|    n_updates            | 7170         |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    value_loss           | 1.55e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1592    |\n",
      "|    iterations      | 362     |\n",
      "|    time_elapsed    | 1862    |\n",
      "|    total_timesteps | 2965504 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1593         |\n",
      "|    iterations           | 363          |\n",
      "|    time_elapsed         | 1865         |\n",
      "|    total_timesteps      | 2973696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022076303 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.473       |\n",
      "|    explained_variance   | 0.00895      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 7180         |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 364          |\n",
      "|    time_elapsed         | 1869         |\n",
      "|    total_timesteps      | 2981888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020291326 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.485       |\n",
      "|    explained_variance   | 0.0424       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 824          |\n",
      "|    n_updates            | 7190         |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1596         |\n",
      "|    iterations           | 365          |\n",
      "|    time_elapsed         | 1873         |\n",
      "|    total_timesteps      | 2990080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024347585 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.483       |\n",
      "|    explained_variance   | 0.0141       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 564          |\n",
      "|    n_updates            | 7200         |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    value_loss           | 1.53e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1597         |\n",
      "|    iterations           | 366          |\n",
      "|    time_elapsed         | 1876         |\n",
      "|    total_timesteps      | 2998272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020514077 |\n",
      "|    clip_fraction        | 0.00922      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.471       |\n",
      "|    explained_variance   | 0.0355       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 858          |\n",
      "|    n_updates            | 7210         |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    value_loss           | 1.54e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3000000, episode_reward=583.60 +/- 94.06\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 584         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3000000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002875634 |\n",
      "|    clip_fraction        | 0.02        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.486      |\n",
      "|    explained_variance   | 0.0572      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 489         |\n",
      "|    n_updates            | 7220        |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    value_loss           | 1.59e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1593    |\n",
      "|    iterations      | 367     |\n",
      "|    time_elapsed    | 1887    |\n",
      "|    total_timesteps | 3006464 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 368          |\n",
      "|    time_elapsed         | 1890         |\n",
      "|    total_timesteps      | 3014656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018395174 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.46        |\n",
      "|    explained_variance   | 0.0523       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 477          |\n",
      "|    n_updates            | 7230         |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 369          |\n",
      "|    time_elapsed         | 1894         |\n",
      "|    total_timesteps      | 3022848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022895052 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.477       |\n",
      "|    explained_variance   | 0.0449       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 882          |\n",
      "|    n_updates            | 7240         |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1596         |\n",
      "|    iterations           | 370          |\n",
      "|    time_elapsed         | 1898         |\n",
      "|    total_timesteps      | 3031040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022998867 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.463       |\n",
      "|    explained_variance   | 0.0405       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 895          |\n",
      "|    n_updates            | 7250         |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1597        |\n",
      "|    iterations           | 371         |\n",
      "|    time_elapsed         | 1902        |\n",
      "|    total_timesteps      | 3039232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002736122 |\n",
      "|    clip_fraction        | 0.0231      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.466      |\n",
      "|    explained_variance   | 0.0456      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 603         |\n",
      "|    n_updates            | 7260        |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    value_loss           | 1.55e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3040000, episode_reward=562.40 +/- 128.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 562          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3040000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023960932 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.464       |\n",
      "|    explained_variance   | 0.0376       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 785          |\n",
      "|    n_updates            | 7270         |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1593    |\n",
      "|    iterations      | 372     |\n",
      "|    time_elapsed    | 1912    |\n",
      "|    total_timesteps | 3047424 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 373          |\n",
      "|    time_elapsed         | 1916         |\n",
      "|    total_timesteps      | 3055616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024212277 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.0355       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 812          |\n",
      "|    n_updates            | 7280         |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    value_loss           | 1.54e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 374          |\n",
      "|    time_elapsed         | 1919         |\n",
      "|    total_timesteps      | 3063808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027034942 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.464       |\n",
      "|    explained_variance   | 0.0386       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 996          |\n",
      "|    n_updates            | 7290         |\n",
      "|    policy_gradient_loss | -0.00444     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1597        |\n",
      "|    iterations           | 375         |\n",
      "|    time_elapsed         | 1923        |\n",
      "|    total_timesteps      | 3072000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002429814 |\n",
      "|    clip_fraction        | 0.015       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.459      |\n",
      "|    explained_variance   | 0.0308      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 644         |\n",
      "|    n_updates            | 7300        |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    value_loss           | 1.62e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3080000, episode_reward=553.40 +/- 123.74\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 553          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3080000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015318308 |\n",
      "|    clip_fraction        | 0.00803      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | 0.0335       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 742          |\n",
      "|    n_updates            | 7310         |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1593    |\n",
      "|    iterations      | 376     |\n",
      "|    time_elapsed    | 1933    |\n",
      "|    total_timesteps | 3080192 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 377          |\n",
      "|    time_elapsed         | 1937         |\n",
      "|    total_timesteps      | 3088384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025979485 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.479       |\n",
      "|    explained_variance   | 0.0277       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 759          |\n",
      "|    n_updates            | 7320         |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    value_loss           | 1.52e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 378          |\n",
      "|    time_elapsed         | 1941         |\n",
      "|    total_timesteps      | 3096576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025148364 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.019        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 776          |\n",
      "|    n_updates            | 7330         |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1596         |\n",
      "|    iterations           | 379          |\n",
      "|    time_elapsed         | 1944         |\n",
      "|    total_timesteps      | 3104768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021536155 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | 0.0372       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 803          |\n",
      "|    n_updates            | 7340         |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    value_loss           | 1.46e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1597        |\n",
      "|    iterations           | 380         |\n",
      "|    time_elapsed         | 1948        |\n",
      "|    total_timesteps      | 3112960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002650275 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.474      |\n",
      "|    explained_variance   | 0.0152      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 699         |\n",
      "|    n_updates            | 7350        |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    value_loss           | 1.55e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3120000, episode_reward=599.00 +/- 70.66\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 599          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019337244 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | 0.0364       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 556          |\n",
      "|    n_updates            | 7360         |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1593    |\n",
      "|    iterations      | 381     |\n",
      "|    time_elapsed    | 1958    |\n",
      "|    total_timesteps | 3121152 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 382          |\n",
      "|    time_elapsed         | 1962         |\n",
      "|    total_timesteps      | 3129344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026879786 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0206       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 763          |\n",
      "|    n_updates            | 7370         |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    value_loss           | 1.5e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 383          |\n",
      "|    time_elapsed         | 1966         |\n",
      "|    total_timesteps      | 3137536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022190004 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.0251       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 666          |\n",
      "|    n_updates            | 7380         |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1596         |\n",
      "|    iterations           | 384          |\n",
      "|    time_elapsed         | 1970         |\n",
      "|    total_timesteps      | 3145728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020297158 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.475       |\n",
      "|    explained_variance   | 0.045        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 596          |\n",
      "|    n_updates            | 7390         |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1597       |\n",
      "|    iterations           | 385        |\n",
      "|    time_elapsed         | 1973       |\n",
      "|    total_timesteps      | 3153920    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00257719 |\n",
      "|    clip_fraction        | 0.0153     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.486     |\n",
      "|    explained_variance   | 0.0233     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 717        |\n",
      "|    n_updates            | 7400       |\n",
      "|    policy_gradient_loss | -0.00343   |\n",
      "|    value_loss           | 1.63e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3160000, episode_reward=596.20 +/- 57.06\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 596         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3160000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002089209 |\n",
      "|    clip_fraction        | 0.0101      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.483      |\n",
      "|    explained_variance   | 0.0109      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 719         |\n",
      "|    n_updates            | 7410        |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    value_loss           | 1.55e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1593    |\n",
      "|    iterations      | 386     |\n",
      "|    time_elapsed    | 1984    |\n",
      "|    total_timesteps | 3162112 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1594        |\n",
      "|    iterations           | 387         |\n",
      "|    time_elapsed         | 1987        |\n",
      "|    total_timesteps      | 3170304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002239357 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.487      |\n",
      "|    explained_variance   | 0.0451      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 731         |\n",
      "|    n_updates            | 7420        |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    value_loss           | 1.49e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1595        |\n",
      "|    iterations           | 388         |\n",
      "|    time_elapsed         | 1991        |\n",
      "|    total_timesteps      | 3178496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002388291 |\n",
      "|    clip_fraction        | 0.0152      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.472      |\n",
      "|    explained_variance   | 0.0139      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 868         |\n",
      "|    n_updates            | 7430        |\n",
      "|    policy_gradient_loss | -0.00345    |\n",
      "|    value_loss           | 1.46e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1597         |\n",
      "|    iterations           | 389          |\n",
      "|    time_elapsed         | 1995         |\n",
      "|    total_timesteps      | 3186688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023134633 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.469       |\n",
      "|    explained_variance   | 0.0264       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 709          |\n",
      "|    n_updates            | 7440         |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1598         |\n",
      "|    iterations           | 390          |\n",
      "|    time_elapsed         | 1999         |\n",
      "|    total_timesteps      | 3194880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021540374 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | 0.0527       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 696          |\n",
      "|    n_updates            | 7450         |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3200000, episode_reward=584.00 +/- 56.71\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 584          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021937885 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.0326       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 681          |\n",
      "|    n_updates            | 7460         |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 1.5e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1594    |\n",
      "|    iterations      | 391     |\n",
      "|    time_elapsed    | 2009    |\n",
      "|    total_timesteps | 3203072 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1595        |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 2013        |\n",
      "|    total_timesteps      | 3211264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002395162 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.472      |\n",
      "|    explained_variance   | 0.0188      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 734         |\n",
      "|    n_updates            | 7470        |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    value_loss           | 1.55e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1596         |\n",
      "|    iterations           | 393          |\n",
      "|    time_elapsed         | 2016         |\n",
      "|    total_timesteps      | 3219456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017083678 |\n",
      "|    clip_fraction        | 0.0093       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.468       |\n",
      "|    explained_variance   | 0.049        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.08e+03     |\n",
      "|    n_updates            | 7480         |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1597         |\n",
      "|    iterations           | 394          |\n",
      "|    time_elapsed         | 2020         |\n",
      "|    total_timesteps      | 3227648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018933167 |\n",
      "|    clip_fraction        | 0.00951      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.0418       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 843          |\n",
      "|    n_updates            | 7490         |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    value_loss           | 1.53e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1598         |\n",
      "|    iterations           | 395          |\n",
      "|    time_elapsed         | 2024         |\n",
      "|    total_timesteps      | 3235840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024610837 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.473       |\n",
      "|    explained_variance   | 0.0326       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 770          |\n",
      "|    n_updates            | 7500         |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    value_loss           | 1.52e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3240000, episode_reward=582.00 +/- 53.07\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 582          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3240000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024497132 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.472       |\n",
      "|    explained_variance   | 0.00187      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 940          |\n",
      "|    n_updates            | 7510         |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1594    |\n",
      "|    iterations      | 396     |\n",
      "|    time_elapsed    | 2034    |\n",
      "|    total_timesteps | 3244032 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 397          |\n",
      "|    time_elapsed         | 2038         |\n",
      "|    total_timesteps      | 3252224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022469386 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.463       |\n",
      "|    explained_variance   | 0.0327       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 825          |\n",
      "|    n_updates            | 7520         |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1596         |\n",
      "|    iterations           | 398          |\n",
      "|    time_elapsed         | 2042         |\n",
      "|    total_timesteps      | 3260416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022412522 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.481       |\n",
      "|    explained_variance   | 0.0556       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 601          |\n",
      "|    n_updates            | 7530         |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1597         |\n",
      "|    iterations           | 399          |\n",
      "|    time_elapsed         | 2045         |\n",
      "|    total_timesteps      | 3268608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025172674 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.0331       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 931          |\n",
      "|    n_updates            | 7540         |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1598         |\n",
      "|    iterations           | 400          |\n",
      "|    time_elapsed         | 2049         |\n",
      "|    total_timesteps      | 3276800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022047064 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.468       |\n",
      "|    explained_variance   | 0.0532       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 665          |\n",
      "|    n_updates            | 7550         |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3280000, episode_reward=598.40 +/- 57.39\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 598          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025423463 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.469       |\n",
      "|    explained_variance   | 0.0256       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 840          |\n",
      "|    n_updates            | 7560         |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1594    |\n",
      "|    iterations      | 401     |\n",
      "|    time_elapsed    | 2060    |\n",
      "|    total_timesteps | 3284992 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1595        |\n",
      "|    iterations           | 402         |\n",
      "|    time_elapsed         | 2063        |\n",
      "|    total_timesteps      | 3293184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002061998 |\n",
      "|    clip_fraction        | 0.00873     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.467      |\n",
      "|    explained_variance   | 0.0221      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 631         |\n",
      "|    n_updates            | 7570        |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    value_loss           | 1.52e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1596         |\n",
      "|    iterations           | 403          |\n",
      "|    time_elapsed         | 2067         |\n",
      "|    total_timesteps      | 3301376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020165506 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.462       |\n",
      "|    explained_variance   | 0.0387       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 580          |\n",
      "|    n_updates            | 7580         |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1597         |\n",
      "|    iterations           | 404          |\n",
      "|    time_elapsed         | 2071         |\n",
      "|    total_timesteps      | 3309568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024809735 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.473       |\n",
      "|    explained_variance   | 0.0223       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 709          |\n",
      "|    n_updates            | 7590         |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1598         |\n",
      "|    iterations           | 405          |\n",
      "|    time_elapsed         | 2075         |\n",
      "|    total_timesteps      | 3317760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026440597 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.0398       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 757          |\n",
      "|    n_updates            | 7600         |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3320000, episode_reward=594.60 +/- 62.71\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 595          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3320000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022845783 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.0449       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 761          |\n",
      "|    n_updates            | 7610         |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1594    |\n",
      "|    iterations      | 406     |\n",
      "|    time_elapsed    | 2085    |\n",
      "|    total_timesteps | 3325952 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 407          |\n",
      "|    time_elapsed         | 2089         |\n",
      "|    total_timesteps      | 3334144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019997107 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.472       |\n",
      "|    explained_variance   | 0.0139       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 773          |\n",
      "|    n_updates            | 7620         |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1596         |\n",
      "|    iterations           | 408          |\n",
      "|    time_elapsed         | 2092         |\n",
      "|    total_timesteps      | 3342336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023048841 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.481       |\n",
      "|    explained_variance   | 0.055        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 852          |\n",
      "|    n_updates            | 7630         |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1597         |\n",
      "|    iterations           | 409          |\n",
      "|    time_elapsed         | 2096         |\n",
      "|    total_timesteps      | 3350528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025955348 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0593       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 765          |\n",
      "|    n_updates            | 7640         |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1599        |\n",
      "|    iterations           | 410         |\n",
      "|    time_elapsed         | 2100        |\n",
      "|    total_timesteps      | 3358720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002613209 |\n",
      "|    clip_fraction        | 0.0152      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.488      |\n",
      "|    explained_variance   | 0.034       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 689         |\n",
      "|    n_updates            | 7650        |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    value_loss           | 1.65e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3360000, episode_reward=587.20 +/- 46.48\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 587          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3360000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024464587 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.0613       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 7660         |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1595    |\n",
      "|    iterations      | 411     |\n",
      "|    time_elapsed    | 2110    |\n",
      "|    total_timesteps | 3366912 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1596        |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 2114        |\n",
      "|    total_timesteps      | 3375104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002477908 |\n",
      "|    clip_fraction        | 0.0163      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.474      |\n",
      "|    explained_variance   | 0.0192      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 684         |\n",
      "|    n_updates            | 7670        |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    value_loss           | 1.55e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1597         |\n",
      "|    iterations           | 413          |\n",
      "|    time_elapsed         | 2117         |\n",
      "|    total_timesteps      | 3383296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030828523 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.473       |\n",
      "|    explained_variance   | 0.0164       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 505          |\n",
      "|    n_updates            | 7680         |\n",
      "|    policy_gradient_loss | -0.00451     |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1598        |\n",
      "|    iterations           | 414         |\n",
      "|    time_elapsed         | 2121        |\n",
      "|    total_timesteps      | 3391488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002889703 |\n",
      "|    clip_fraction        | 0.0199      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.479      |\n",
      "|    explained_variance   | 0.0409      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 702         |\n",
      "|    n_updates            | 7690        |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    value_loss           | 1.65e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1599         |\n",
      "|    iterations           | 415          |\n",
      "|    time_elapsed         | 2125         |\n",
      "|    total_timesteps      | 3399680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024868988 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.472       |\n",
      "|    explained_variance   | 0.0268       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 737          |\n",
      "|    n_updates            | 7700         |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    value_loss           | 1.53e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3400000, episode_reward=599.40 +/- 67.03\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 599          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3400000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019419114 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.0378       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 753          |\n",
      "|    n_updates            | 7710         |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1595    |\n",
      "|    iterations      | 416     |\n",
      "|    time_elapsed    | 2135    |\n",
      "|    total_timesteps | 3407872 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1596         |\n",
      "|    iterations           | 417          |\n",
      "|    time_elapsed         | 2139         |\n",
      "|    total_timesteps      | 3416064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018133738 |\n",
      "|    clip_fraction        | 0.00903      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.0566       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 666          |\n",
      "|    n_updates            | 7720         |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    value_loss           | 1.55e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1597        |\n",
      "|    iterations           | 418         |\n",
      "|    time_elapsed         | 2143        |\n",
      "|    total_timesteps      | 3424256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002143802 |\n",
      "|    clip_fraction        | 0.0119      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.458      |\n",
      "|    explained_variance   | 0.0468      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 848         |\n",
      "|    n_updates            | 7730        |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    value_loss           | 1.76e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1598         |\n",
      "|    iterations           | 419          |\n",
      "|    time_elapsed         | 2146         |\n",
      "|    total_timesteps      | 3432448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034398302 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.0442       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 580          |\n",
      "|    n_updates            | 7740         |\n",
      "|    policy_gradient_loss | -0.0043      |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3440000, episode_reward=599.60 +/- 50.59\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 600          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3440000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020586033 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.0355       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 676          |\n",
      "|    n_updates            | 7750         |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    value_loss           | 1.55e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1594    |\n",
      "|    iterations      | 420     |\n",
      "|    time_elapsed    | 2157    |\n",
      "|    total_timesteps | 3440640 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 421          |\n",
      "|    time_elapsed         | 2161         |\n",
      "|    total_timesteps      | 3448832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027041482 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.452       |\n",
      "|    explained_variance   | 0.0472       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 895          |\n",
      "|    n_updates            | 7760         |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1596         |\n",
      "|    iterations           | 422          |\n",
      "|    time_elapsed         | 2165         |\n",
      "|    total_timesteps      | 3457024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023062811 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.0388       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 919          |\n",
      "|    n_updates            | 7770         |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1597         |\n",
      "|    iterations           | 423          |\n",
      "|    time_elapsed         | 2169         |\n",
      "|    total_timesteps      | 3465216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015973763 |\n",
      "|    clip_fraction        | 0.00736      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.0463       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 7780         |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    value_loss           | 1.53e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1598         |\n",
      "|    iterations           | 424          |\n",
      "|    time_elapsed         | 2172         |\n",
      "|    total_timesteps      | 3473408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027050888 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | 0.00323      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 829          |\n",
      "|    n_updates            | 7790         |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3480000, episode_reward=603.60 +/- 91.16\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 604          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3480000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023354953 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.471       |\n",
      "|    explained_variance   | 0.0275       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 735          |\n",
      "|    n_updates            | 7800         |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1595    |\n",
      "|    iterations      | 425     |\n",
      "|    time_elapsed    | 2182    |\n",
      "|    total_timesteps | 3481600 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1596         |\n",
      "|    iterations           | 426          |\n",
      "|    time_elapsed         | 2186         |\n",
      "|    total_timesteps      | 3489792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015445141 |\n",
      "|    clip_fraction        | 0.00708      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.0319       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 842          |\n",
      "|    n_updates            | 7810         |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1597        |\n",
      "|    iterations           | 427         |\n",
      "|    time_elapsed         | 2189        |\n",
      "|    total_timesteps      | 3497984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002339323 |\n",
      "|    clip_fraction        | 0.0137      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.476      |\n",
      "|    explained_variance   | 0.0426      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 7820        |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    value_loss           | 1.56e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1597         |\n",
      "|    iterations           | 428          |\n",
      "|    time_elapsed         | 2194         |\n",
      "|    total_timesteps      | 3506176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020294925 |\n",
      "|    clip_fraction        | 0.00953      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.472       |\n",
      "|    explained_variance   | 0.0229       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 863          |\n",
      "|    n_updates            | 7830         |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1598         |\n",
      "|    iterations           | 429          |\n",
      "|    time_elapsed         | 2198         |\n",
      "|    total_timesteps      | 3514368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026492723 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.472       |\n",
      "|    explained_variance   | 0.0275       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 987          |\n",
      "|    n_updates            | 7840         |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3520000, episode_reward=612.60 +/- 46.21\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 613          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3520000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023820659 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.479       |\n",
      "|    explained_variance   | 0.0352       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 653          |\n",
      "|    n_updates            | 7850         |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1593    |\n",
      "|    iterations      | 430     |\n",
      "|    time_elapsed    | 2210    |\n",
      "|    total_timesteps | 3522560 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1593        |\n",
      "|    iterations           | 431         |\n",
      "|    time_elapsed         | 2216        |\n",
      "|    total_timesteps      | 3530752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002223617 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.467      |\n",
      "|    explained_variance   | 0.0503      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 7860        |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    value_loss           | 1.69e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1593         |\n",
      "|    iterations           | 432          |\n",
      "|    time_elapsed         | 2220         |\n",
      "|    total_timesteps      | 3538944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022428194 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.0249       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 7870         |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 433          |\n",
      "|    time_elapsed         | 2224         |\n",
      "|    total_timesteps      | 3547136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024316115 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.479       |\n",
      "|    explained_variance   | 0.0391       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 696          |\n",
      "|    n_updates            | 7880         |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    value_loss           | 1.55e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 434          |\n",
      "|    time_elapsed         | 2227         |\n",
      "|    total_timesteps      | 3555328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026414893 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.471       |\n",
      "|    explained_variance   | 0.0196       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 898          |\n",
      "|    n_updates            | 7890         |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3560000, episode_reward=605.60 +/- 64.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 606          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021205735 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | -0.004       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 746          |\n",
      "|    n_updates            | 7900         |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1591    |\n",
      "|    iterations      | 435     |\n",
      "|    time_elapsed    | 2238    |\n",
      "|    total_timesteps | 3563520 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1592         |\n",
      "|    iterations           | 436          |\n",
      "|    time_elapsed         | 2242         |\n",
      "|    total_timesteps      | 3571712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027729212 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.0572       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 581          |\n",
      "|    n_updates            | 7910         |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1593         |\n",
      "|    iterations           | 437          |\n",
      "|    time_elapsed         | 2246         |\n",
      "|    total_timesteps      | 3579904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022764772 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.489       |\n",
      "|    explained_variance   | 0.0275       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 869          |\n",
      "|    n_updates            | 7920         |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 438          |\n",
      "|    time_elapsed         | 2249         |\n",
      "|    total_timesteps      | 3588096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030203233 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.481       |\n",
      "|    explained_variance   | 0.0353       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 529          |\n",
      "|    n_updates            | 7930         |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    value_loss           | 1.55e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 439          |\n",
      "|    time_elapsed         | 2253         |\n",
      "|    total_timesteps      | 3596288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021183556 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0106       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 878          |\n",
      "|    n_updates            | 7940         |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3600000, episode_reward=603.80 +/- 47.45\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 604          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3600000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020840561 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.0315       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 693          |\n",
      "|    n_updates            | 7950         |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1592    |\n",
      "|    iterations      | 440     |\n",
      "|    time_elapsed    | 2263    |\n",
      "|    total_timesteps | 3604480 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1593         |\n",
      "|    iterations           | 441          |\n",
      "|    time_elapsed         | 2267         |\n",
      "|    total_timesteps      | 3612672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023292513 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.0457       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 990          |\n",
      "|    n_updates            | 7960         |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    value_loss           | 1.48e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 442          |\n",
      "|    time_elapsed         | 2271         |\n",
      "|    total_timesteps      | 3620864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024500918 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.0304       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 489          |\n",
      "|    n_updates            | 7970         |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 443          |\n",
      "|    time_elapsed         | 2275         |\n",
      "|    total_timesteps      | 3629056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023356662 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.0439       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 742          |\n",
      "|    n_updates            | 7980         |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 444          |\n",
      "|    time_elapsed         | 2279         |\n",
      "|    total_timesteps      | 3637248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025803037 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0556       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 963          |\n",
      "|    n_updates            | 7990         |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3640000, episode_reward=606.00 +/- 55.17\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 606          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3640000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021463612 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | 0.027        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 879          |\n",
      "|    n_updates            | 8000         |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1592    |\n",
      "|    iterations      | 445     |\n",
      "|    time_elapsed    | 2289    |\n",
      "|    total_timesteps | 3645440 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1593         |\n",
      "|    iterations           | 446          |\n",
      "|    time_elapsed         | 2293         |\n",
      "|    total_timesteps      | 3653632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025133942 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.0308       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 989          |\n",
      "|    n_updates            | 8010         |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1594        |\n",
      "|    iterations           | 447         |\n",
      "|    time_elapsed         | 2297        |\n",
      "|    total_timesteps      | 3661824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002154693 |\n",
      "|    clip_fraction        | 0.0104      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.515      |\n",
      "|    explained_variance   | 0.0267      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.03e+03    |\n",
      "|    n_updates            | 8020        |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1595        |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 2300        |\n",
      "|    total_timesteps      | 3670016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002151038 |\n",
      "|    clip_fraction        | 0.0109      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.518      |\n",
      "|    explained_variance   | 0.0423      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 740         |\n",
      "|    n_updates            | 8030        |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    value_loss           | 1.58e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 449          |\n",
      "|    time_elapsed         | 2304         |\n",
      "|    total_timesteps      | 3678208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021707807 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.0535       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 860          |\n",
      "|    n_updates            | 8040         |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3680000, episode_reward=604.20 +/- 69.40\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 604          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3680000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024484121 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | 0.0366       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 858          |\n",
      "|    n_updates            | 8050         |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1592    |\n",
      "|    iterations      | 450     |\n",
      "|    time_elapsed    | 2315    |\n",
      "|    total_timesteps | 3686400 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1593         |\n",
      "|    iterations           | 451          |\n",
      "|    time_elapsed         | 2318         |\n",
      "|    total_timesteps      | 3694592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026730804 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.0366       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 935          |\n",
      "|    n_updates            | 8060         |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 452          |\n",
      "|    time_elapsed         | 2322         |\n",
      "|    total_timesteps      | 3702784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033127125 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.038        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 744          |\n",
      "|    n_updates            | 8070         |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 453          |\n",
      "|    time_elapsed         | 2326         |\n",
      "|    total_timesteps      | 3710976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018758224 |\n",
      "|    clip_fraction        | 0.00924      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0141       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 688          |\n",
      "|    n_updates            | 8080         |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    value_loss           | 1.53e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1596         |\n",
      "|    iterations           | 454          |\n",
      "|    time_elapsed         | 2330         |\n",
      "|    total_timesteps      | 3719168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022277655 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.0531       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 988          |\n",
      "|    n_updates            | 8090         |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3720000, episode_reward=585.80 +/- 60.93\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 586         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3720000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001705198 |\n",
      "|    clip_fraction        | 0.00709     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.498      |\n",
      "|    explained_variance   | 0.0616      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 698         |\n",
      "|    n_updates            | 8100        |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    value_loss           | 1.63e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1592    |\n",
      "|    iterations      | 455     |\n",
      "|    time_elapsed    | 2340    |\n",
      "|    total_timesteps | 3727360 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1593         |\n",
      "|    iterations           | 456          |\n",
      "|    time_elapsed         | 2344         |\n",
      "|    total_timesteps      | 3735552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026593276 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | -0.00292     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 845          |\n",
      "|    n_updates            | 8110         |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 457          |\n",
      "|    time_elapsed         | 2348         |\n",
      "|    total_timesteps      | 3743744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021495945 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.0643       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 889          |\n",
      "|    n_updates            | 8120         |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    value_loss           | 1.52e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1595        |\n",
      "|    iterations           | 458         |\n",
      "|    time_elapsed         | 2352        |\n",
      "|    total_timesteps      | 3751936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001975834 |\n",
      "|    clip_fraction        | 0.00952     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.484      |\n",
      "|    explained_variance   | 0.0268      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 805         |\n",
      "|    n_updates            | 8130        |\n",
      "|    policy_gradient_loss | -0.00239    |\n",
      "|    value_loss           | 1.62e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3760000, episode_reward=582.40 +/- 57.98\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 582          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3760000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021284805 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.0354       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 672          |\n",
      "|    n_updates            | 8140         |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    value_loss           | 1.52e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1591    |\n",
      "|    iterations      | 459     |\n",
      "|    time_elapsed    | 2362    |\n",
      "|    total_timesteps | 3760128 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1592         |\n",
      "|    iterations           | 460          |\n",
      "|    time_elapsed         | 2365         |\n",
      "|    total_timesteps      | 3768320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020773085 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.0785       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 892          |\n",
      "|    n_updates            | 8150         |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1593        |\n",
      "|    iterations           | 461         |\n",
      "|    time_elapsed         | 2369        |\n",
      "|    total_timesteps      | 3776512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002358919 |\n",
      "|    clip_fraction        | 0.0151      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.504      |\n",
      "|    explained_variance   | 0.0605      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 535         |\n",
      "|    n_updates            | 8160        |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    value_loss           | 1.45e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1594        |\n",
      "|    iterations           | 462         |\n",
      "|    time_elapsed         | 2373        |\n",
      "|    total_timesteps      | 3784704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002640443 |\n",
      "|    clip_fraction        | 0.0154      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.507      |\n",
      "|    explained_variance   | 0.0285      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 701         |\n",
      "|    n_updates            | 8170        |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    value_loss           | 1.52e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 463          |\n",
      "|    time_elapsed         | 2377         |\n",
      "|    total_timesteps      | 3792896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026875264 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.0176       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 636          |\n",
      "|    n_updates            | 8180         |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    value_loss           | 1.58e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3800000, episode_reward=582.60 +/- 65.99\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 583          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3800000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020250133 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.0599       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 794          |\n",
      "|    n_updates            | 8190         |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1591    |\n",
      "|    iterations      | 464     |\n",
      "|    time_elapsed    | 2387    |\n",
      "|    total_timesteps | 3801088 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1592         |\n",
      "|    iterations           | 465          |\n",
      "|    time_elapsed         | 2391         |\n",
      "|    total_timesteps      | 3809280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024865437 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.484       |\n",
      "|    explained_variance   | -0.00231     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 715          |\n",
      "|    n_updates            | 8200         |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1593         |\n",
      "|    iterations           | 466          |\n",
      "|    time_elapsed         | 2395         |\n",
      "|    total_timesteps      | 3817472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025207892 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.475       |\n",
      "|    explained_variance   | 0.0401       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 592          |\n",
      "|    n_updates            | 8210         |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1594        |\n",
      "|    iterations           | 467         |\n",
      "|    time_elapsed         | 2400        |\n",
      "|    total_timesteps      | 3825664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002539392 |\n",
      "|    clip_fraction        | 0.015       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.5        |\n",
      "|    explained_variance   | 0.0308      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 888         |\n",
      "|    n_updates            | 8220        |\n",
      "|    policy_gradient_loss | -0.00351    |\n",
      "|    value_loss           | 1.52e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 468          |\n",
      "|    time_elapsed         | 2403         |\n",
      "|    total_timesteps      | 3833856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021356235 |\n",
      "|    clip_fraction        | 0.00947      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.0651       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 8230         |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3840000, episode_reward=568.60 +/- 59.83\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 569          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3840000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021274504 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.0387       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 950          |\n",
      "|    n_updates            | 8240         |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1591    |\n",
      "|    iterations      | 469     |\n",
      "|    time_elapsed    | 2414    |\n",
      "|    total_timesteps | 3842048 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1592         |\n",
      "|    iterations           | 470          |\n",
      "|    time_elapsed         | 2418         |\n",
      "|    total_timesteps      | 3850240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024242958 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0347       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 444          |\n",
      "|    n_updates            | 8250         |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    value_loss           | 1.54e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1593         |\n",
      "|    iterations           | 471          |\n",
      "|    time_elapsed         | 2421         |\n",
      "|    total_timesteps      | 3858432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023028967 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.0323       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 787          |\n",
      "|    n_updates            | 8260         |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 472          |\n",
      "|    time_elapsed         | 2425         |\n",
      "|    total_timesteps      | 3866624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018622492 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.0355       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 752          |\n",
      "|    n_updates            | 8270         |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1594        |\n",
      "|    iterations           | 473         |\n",
      "|    time_elapsed         | 2429        |\n",
      "|    total_timesteps      | 3874816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002305915 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.521      |\n",
      "|    explained_variance   | 0.0465      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 993         |\n",
      "|    n_updates            | 8280        |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    value_loss           | 1.58e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3880000, episode_reward=567.80 +/- 99.63\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 568         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3880000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003022122 |\n",
      "|    clip_fraction        | 0.0218      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.499      |\n",
      "|    explained_variance   | 0.0418      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 568         |\n",
      "|    n_updates            | 8290        |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    value_loss           | 1.59e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1591    |\n",
      "|    iterations      | 474     |\n",
      "|    time_elapsed    | 2439    |\n",
      "|    total_timesteps | 3883008 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1592         |\n",
      "|    iterations           | 475          |\n",
      "|    time_elapsed         | 2443         |\n",
      "|    total_timesteps      | 3891200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027154274 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0489       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 833          |\n",
      "|    n_updates            | 8300         |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    value_loss           | 1.5e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1593         |\n",
      "|    iterations           | 476          |\n",
      "|    time_elapsed         | 2447         |\n",
      "|    total_timesteps      | 3899392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021100356 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.519       |\n",
      "|    explained_variance   | 0.0501       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 8310         |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 477          |\n",
      "|    time_elapsed         | 2451         |\n",
      "|    total_timesteps      | 3907584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024376814 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.00697      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 787          |\n",
      "|    n_updates            | 8320         |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 478          |\n",
      "|    time_elapsed         | 2455         |\n",
      "|    total_timesteps      | 3915776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025426522 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.516       |\n",
      "|    explained_variance   | 0.0302       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 808          |\n",
      "|    n_updates            | 8330         |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3920000, episode_reward=599.40 +/- 48.18\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 599          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3920000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025089139 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.0493       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 948          |\n",
      "|    n_updates            | 8340         |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    value_loss           | 1.49e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1591    |\n",
      "|    iterations      | 479     |\n",
      "|    time_elapsed    | 2465    |\n",
      "|    total_timesteps | 3923968 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1592         |\n",
      "|    iterations           | 480          |\n",
      "|    time_elapsed         | 2469         |\n",
      "|    total_timesteps      | 3932160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019124683 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.0266       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 8350         |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1593        |\n",
      "|    iterations           | 481         |\n",
      "|    time_elapsed         | 2473        |\n",
      "|    total_timesteps      | 3940352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002632528 |\n",
      "|    clip_fraction        | 0.0226      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.513      |\n",
      "|    explained_variance   | 0.0399      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 951         |\n",
      "|    n_updates            | 8360        |\n",
      "|    policy_gradient_loss | -0.00397    |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 482          |\n",
      "|    time_elapsed         | 2476         |\n",
      "|    total_timesteps      | 3948544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022116986 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.525       |\n",
      "|    explained_variance   | 0.0643       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 701          |\n",
      "|    n_updates            | 8370         |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 483          |\n",
      "|    time_elapsed         | 2480         |\n",
      "|    total_timesteps      | 3956736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023525364 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.0253       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 8380         |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    value_loss           | 1.58e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3960000, episode_reward=609.40 +/- 84.34\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 609          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3960000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016271803 |\n",
      "|    clip_fraction        | 0.00674      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0252       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 888          |\n",
      "|    n_updates            | 8390         |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    value_loss           | 1.53e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1591    |\n",
      "|    iterations      | 484     |\n",
      "|    time_elapsed    | 2490    |\n",
      "|    total_timesteps | 3964928 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1592        |\n",
      "|    iterations           | 485         |\n",
      "|    time_elapsed         | 2494        |\n",
      "|    total_timesteps      | 3973120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002311741 |\n",
      "|    clip_fraction        | 0.0138      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.511      |\n",
      "|    explained_variance   | 0.0631      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 940         |\n",
      "|    n_updates            | 8400        |\n",
      "|    policy_gradient_loss | -0.00366    |\n",
      "|    value_loss           | 1.63e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1593         |\n",
      "|    iterations           | 486          |\n",
      "|    time_elapsed         | 2498         |\n",
      "|    total_timesteps      | 3981312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022878568 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0327       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 578          |\n",
      "|    n_updates            | 8410         |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 487          |\n",
      "|    time_elapsed         | 2502         |\n",
      "|    total_timesteps      | 3989504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029505854 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0278       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 697          |\n",
      "|    n_updates            | 8420         |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    value_loss           | 1.54e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1595         |\n",
      "|    iterations           | 488          |\n",
      "|    time_elapsed         | 2506         |\n",
      "|    total_timesteps      | 3997696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025043255 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0511       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 689          |\n",
      "|    n_updates            | 8430         |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    value_loss           | 1.58e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4000000, episode_reward=607.80 +/- 57.70\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 608          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025403076 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.0256       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 983          |\n",
      "|    n_updates            | 8440         |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1591    |\n",
      "|    iterations      | 489     |\n",
      "|    time_elapsed    | 2516    |\n",
      "|    total_timesteps | 4005888 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1592         |\n",
      "|    iterations           | 490          |\n",
      "|    time_elapsed         | 2520         |\n",
      "|    total_timesteps      | 4014080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030025179 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.0201       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 706          |\n",
      "|    n_updates            | 8450         |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1593         |\n",
      "|    iterations           | 491          |\n",
      "|    time_elapsed         | 2524         |\n",
      "|    total_timesteps      | 4022272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029932852 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | 0.0392       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 642          |\n",
      "|    n_updates            | 8460         |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 492          |\n",
      "|    time_elapsed         | 2528         |\n",
      "|    total_timesteps      | 4030464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022259294 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.0443       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 765          |\n",
      "|    n_updates            | 8470         |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 493          |\n",
      "|    time_elapsed         | 2532         |\n",
      "|    total_timesteps      | 4038656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026146472 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.0699       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 601          |\n",
      "|    n_updates            | 8480         |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4040000, episode_reward=618.20 +/- 54.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 618          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4040000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026019076 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.0468       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 505          |\n",
      "|    n_updates            | 8490         |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    value_loss           | 1.53e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1591    |\n",
      "|    iterations      | 494     |\n",
      "|    time_elapsed    | 2542    |\n",
      "|    total_timesteps | 4046848 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1592         |\n",
      "|    iterations           | 495          |\n",
      "|    time_elapsed         | 2546         |\n",
      "|    total_timesteps      | 4055040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024189053 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.483       |\n",
      "|    explained_variance   | 0.0129       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 615          |\n",
      "|    n_updates            | 8500         |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1592         |\n",
      "|    iterations           | 496          |\n",
      "|    time_elapsed         | 2550         |\n",
      "|    total_timesteps      | 4063232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025037928 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.484       |\n",
      "|    explained_variance   | 0.021        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 848          |\n",
      "|    n_updates            | 8510         |\n",
      "|    policy_gradient_loss | -0.00395     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1593         |\n",
      "|    iterations           | 497          |\n",
      "|    time_elapsed         | 2554         |\n",
      "|    total_timesteps      | 4071424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030512111 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0293       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 979          |\n",
      "|    n_updates            | 8520         |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1594         |\n",
      "|    iterations           | 498          |\n",
      "|    time_elapsed         | 2558         |\n",
      "|    total_timesteps      | 4079616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026906107 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0287       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 657          |\n",
      "|    n_updates            | 8530         |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4080000, episode_reward=595.80 +/- 104.31\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 596          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4080000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030515427 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.035        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 643          |\n",
      "|    n_updates            | 8540         |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    value_loss           | 1.55e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1591    |\n",
      "|    iterations      | 499     |\n",
      "|    time_elapsed    | 2569    |\n",
      "|    total_timesteps | 4087808 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1591         |\n",
      "|    iterations           | 500          |\n",
      "|    time_elapsed         | 2573         |\n",
      "|    total_timesteps      | 4096000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026157578 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.472       |\n",
      "|    explained_variance   | 0.018        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 8550         |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1592         |\n",
      "|    iterations           | 501          |\n",
      "|    time_elapsed         | 2577         |\n",
      "|    total_timesteps      | 4104192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023383438 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | -0.0234      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 789          |\n",
      "|    n_updates            | 8560         |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1593         |\n",
      "|    iterations           | 502          |\n",
      "|    time_elapsed         | 2581         |\n",
      "|    total_timesteps      | 4112384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020103864 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.0128       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 784          |\n",
      "|    n_updates            | 8570         |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4120000, episode_reward=593.80 +/- 78.71\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 594         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4120000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002260103 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.473      |\n",
      "|    explained_variance   | 0.000839    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 908         |\n",
      "|    n_updates            | 8580        |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1589    |\n",
      "|    iterations      | 503     |\n",
      "|    time_elapsed    | 2593    |\n",
      "|    total_timesteps | 4120576 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 504          |\n",
      "|    time_elapsed         | 2597         |\n",
      "|    total_timesteps      | 4128768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019579742 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.47        |\n",
      "|    explained_variance   | 0.0494       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 8590         |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1590         |\n",
      "|    iterations           | 505          |\n",
      "|    time_elapsed         | 2601         |\n",
      "|    total_timesteps      | 4136960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031503902 |\n",
      "|    clip_fraction        | 0.023        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.0164       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 8600         |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1590        |\n",
      "|    iterations           | 506         |\n",
      "|    time_elapsed         | 2606        |\n",
      "|    total_timesteps      | 4145152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001616007 |\n",
      "|    clip_fraction        | 0.00724     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.46       |\n",
      "|    explained_variance   | 0.0278      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 8610        |\n",
      "|    policy_gradient_loss | -0.00298    |\n",
      "|    value_loss           | 1.79e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1590         |\n",
      "|    iterations           | 507          |\n",
      "|    time_elapsed         | 2611         |\n",
      "|    total_timesteps      | 4153344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016542345 |\n",
      "|    clip_fraction        | 0.00563      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.0456       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 617          |\n",
      "|    n_updates            | 8620         |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4160000, episode_reward=605.20 +/- 55.51\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 605          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4160000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017977162 |\n",
      "|    clip_fraction        | 0.00769      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | 0.0364       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 874          |\n",
      "|    n_updates            | 8630         |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1587    |\n",
      "|    iterations      | 508     |\n",
      "|    time_elapsed    | 2622    |\n",
      "|    total_timesteps | 4161536 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1587        |\n",
      "|    iterations           | 509         |\n",
      "|    time_elapsed         | 2626        |\n",
      "|    total_timesteps      | 4169728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002719781 |\n",
      "|    clip_fraction        | 0.0178      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.47       |\n",
      "|    explained_variance   | 0.0195      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 927         |\n",
      "|    n_updates            | 8640        |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    value_loss           | 1.57e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 510          |\n",
      "|    time_elapsed         | 2631         |\n",
      "|    total_timesteps      | 4177920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021489626 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.454       |\n",
      "|    explained_variance   | 0.034        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 737          |\n",
      "|    n_updates            | 8650         |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 511          |\n",
      "|    time_elapsed         | 2635         |\n",
      "|    total_timesteps      | 4186112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019784058 |\n",
      "|    clip_fraction        | 0.00933      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.462       |\n",
      "|    explained_variance   | 0.0437       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 894          |\n",
      "|    n_updates            | 8660         |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 512          |\n",
      "|    time_elapsed         | 2639         |\n",
      "|    total_timesteps      | 4194304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020802882 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.456       |\n",
      "|    explained_variance   | 0.0406       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 779          |\n",
      "|    n_updates            | 8670         |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 1.54e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4200000, episode_reward=592.40 +/- 101.83\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 592          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029382652 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.0462       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 8680         |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1585    |\n",
      "|    iterations      | 513     |\n",
      "|    time_elapsed    | 2651    |\n",
      "|    total_timesteps | 4202496 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 514          |\n",
      "|    time_elapsed         | 2655         |\n",
      "|    total_timesteps      | 4210688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022780632 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.459       |\n",
      "|    explained_variance   | 0.0506       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 730          |\n",
      "|    n_updates            | 8690         |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1586        |\n",
      "|    iterations           | 515         |\n",
      "|    time_elapsed         | 2659        |\n",
      "|    total_timesteps      | 4218880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002495929 |\n",
      "|    clip_fraction        | 0.0167      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.467      |\n",
      "|    explained_variance   | 0.0285      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 865         |\n",
      "|    n_updates            | 8700        |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    value_loss           | 1.58e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 516          |\n",
      "|    time_elapsed         | 2663         |\n",
      "|    total_timesteps      | 4227072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022533596 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.47        |\n",
      "|    explained_variance   | 0.0374       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 804          |\n",
      "|    n_updates            | 8710         |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 517          |\n",
      "|    time_elapsed         | 2667         |\n",
      "|    total_timesteps      | 4235264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028381224 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.473       |\n",
      "|    explained_variance   | 0.0209       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.08e+03     |\n",
      "|    n_updates            | 8720         |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4240000, episode_reward=602.40 +/- 55.34\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 602         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4240000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002040579 |\n",
      "|    clip_fraction        | 0.0126      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.479      |\n",
      "|    explained_variance   | 0.0305      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 701         |\n",
      "|    n_updates            | 8730        |\n",
      "|    policy_gradient_loss | -0.00314    |\n",
      "|    value_loss           | 1.76e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1584    |\n",
      "|    iterations      | 518     |\n",
      "|    time_elapsed    | 2678    |\n",
      "|    total_timesteps | 4243456 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 519          |\n",
      "|    time_elapsed         | 2682         |\n",
      "|    total_timesteps      | 4251648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023175236 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.46        |\n",
      "|    explained_variance   | 0.0239       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 916          |\n",
      "|    n_updates            | 8740         |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 520          |\n",
      "|    time_elapsed         | 2686         |\n",
      "|    total_timesteps      | 4259840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018343942 |\n",
      "|    clip_fraction        | 0.00889      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.463       |\n",
      "|    explained_variance   | 0.061        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 886          |\n",
      "|    n_updates            | 8750         |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 521          |\n",
      "|    time_elapsed         | 2690         |\n",
      "|    total_timesteps      | 4268032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023678292 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.467       |\n",
      "|    explained_variance   | 0.0235       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 685          |\n",
      "|    n_updates            | 8760         |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 1.58e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 522          |\n",
      "|    time_elapsed         | 2694         |\n",
      "|    total_timesteps      | 4276224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021746508 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.456       |\n",
      "|    explained_variance   | 0.0131       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 864          |\n",
      "|    n_updates            | 8770         |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4280000, episode_reward=595.60 +/- 57.73\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 596          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022301925 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | 0.0326       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 746          |\n",
      "|    n_updates            | 8780         |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1583    |\n",
      "|    iterations      | 523     |\n",
      "|    time_elapsed    | 2705    |\n",
      "|    total_timesteps | 4284416 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 524          |\n",
      "|    time_elapsed         | 2709         |\n",
      "|    total_timesteps      | 4292608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018362983 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | 0.0333       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 704          |\n",
      "|    n_updates            | 8790         |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1585        |\n",
      "|    iterations           | 525         |\n",
      "|    time_elapsed         | 2713        |\n",
      "|    total_timesteps      | 4300800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002483377 |\n",
      "|    clip_fraction        | 0.0173      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.489      |\n",
      "|    explained_variance   | 0.0368      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 821         |\n",
      "|    n_updates            | 8800        |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 526          |\n",
      "|    time_elapsed         | 2717         |\n",
      "|    total_timesteps      | 4308992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021492126 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.483       |\n",
      "|    explained_variance   | 0.0268       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 884          |\n",
      "|    n_updates            | 8810         |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 527          |\n",
      "|    time_elapsed         | 2721         |\n",
      "|    total_timesteps      | 4317184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025761472 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.0558       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 8820         |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4320000, episode_reward=614.80 +/- 53.19\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 615          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4320000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025121882 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.481       |\n",
      "|    explained_variance   | 0.037        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 672          |\n",
      "|    n_updates            | 8830         |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1583    |\n",
      "|    iterations      | 528     |\n",
      "|    time_elapsed    | 2732    |\n",
      "|    total_timesteps | 4325376 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 529          |\n",
      "|    time_elapsed         | 2736         |\n",
      "|    total_timesteps      | 4333568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019187706 |\n",
      "|    clip_fraction        | 0.00806      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.484       |\n",
      "|    explained_variance   | 0.0549       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 647          |\n",
      "|    n_updates            | 8840         |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1584       |\n",
      "|    iterations           | 530        |\n",
      "|    time_elapsed         | 2739       |\n",
      "|    total_timesteps      | 4341760    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00191665 |\n",
      "|    clip_fraction        | 0.00939    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.469     |\n",
      "|    explained_variance   | 0.0333     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 690        |\n",
      "|    n_updates            | 8850       |\n",
      "|    policy_gradient_loss | -0.0026    |\n",
      "|    value_loss           | 1.54e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 531          |\n",
      "|    time_elapsed         | 2743         |\n",
      "|    total_timesteps      | 4349952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022527175 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.0357       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 816          |\n",
      "|    n_updates            | 8860         |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 532          |\n",
      "|    time_elapsed         | 2747         |\n",
      "|    total_timesteps      | 4358144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024462736 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | 0.056        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 698          |\n",
      "|    n_updates            | 8870         |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    value_loss           | 1.52e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4360000, episode_reward=601.20 +/- 61.86\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 601          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4360000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018848369 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.484       |\n",
      "|    explained_variance   | 0.0522       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 694          |\n",
      "|    n_updates            | 8880         |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1583    |\n",
      "|    iterations      | 533     |\n",
      "|    time_elapsed    | 2757    |\n",
      "|    total_timesteps | 4366336 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 534          |\n",
      "|    time_elapsed         | 2761         |\n",
      "|    total_timesteps      | 4374528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021263019 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.477       |\n",
      "|    explained_variance   | 0.0371       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 898          |\n",
      "|    n_updates            | 8890         |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 535          |\n",
      "|    time_elapsed         | 2765         |\n",
      "|    total_timesteps      | 4382720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019905965 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.467       |\n",
      "|    explained_variance   | 0.0225       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 581          |\n",
      "|    n_updates            | 8900         |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1585        |\n",
      "|    iterations           | 536         |\n",
      "|    time_elapsed         | 2768        |\n",
      "|    total_timesteps      | 4390912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003069704 |\n",
      "|    clip_fraction        | 0.0217      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.488      |\n",
      "|    explained_variance   | 0.0691      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 790         |\n",
      "|    n_updates            | 8910        |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    value_loss           | 1.57e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 537          |\n",
      "|    time_elapsed         | 2772         |\n",
      "|    total_timesteps      | 4399104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022762981 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.0766       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 864          |\n",
      "|    n_updates            | 8920         |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4400000, episode_reward=608.20 +/- 62.25\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 608         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4400000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001785173 |\n",
      "|    clip_fraction        | 0.011       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.484      |\n",
      "|    explained_variance   | 0.0995      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 819         |\n",
      "|    n_updates            | 8930        |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    value_loss           | 1.57e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1583    |\n",
      "|    iterations      | 538     |\n",
      "|    time_elapsed    | 2782    |\n",
      "|    total_timesteps | 4407296 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 539          |\n",
      "|    time_elapsed         | 2786         |\n",
      "|    total_timesteps      | 4415488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028686398 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.479       |\n",
      "|    explained_variance   | 0.0279       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 922          |\n",
      "|    n_updates            | 8940         |\n",
      "|    policy_gradient_loss | -0.00449     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 540          |\n",
      "|    time_elapsed         | 2790         |\n",
      "|    total_timesteps      | 4423680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020152456 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.0156       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 713          |\n",
      "|    n_updates            | 8950         |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 541          |\n",
      "|    time_elapsed         | 2794         |\n",
      "|    total_timesteps      | 4431872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015665945 |\n",
      "|    clip_fraction        | 0.00712      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.484       |\n",
      "|    explained_variance   | 0.0175       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 852          |\n",
      "|    n_updates            | 8960         |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4440000, episode_reward=627.60 +/- 72.10\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 628         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002182212 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.477      |\n",
      "|    explained_variance   | 0.0353      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 815         |\n",
      "|    n_updates            | 8970        |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    value_loss           | 1.63e+03    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1583    |\n",
      "|    iterations      | 542     |\n",
      "|    time_elapsed    | 2804    |\n",
      "|    total_timesteps | 4440064 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 543          |\n",
      "|    time_elapsed         | 2808         |\n",
      "|    total_timesteps      | 4448256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025980328 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0396       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 921          |\n",
      "|    n_updates            | 8980         |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 544          |\n",
      "|    time_elapsed         | 2811         |\n",
      "|    total_timesteps      | 4456448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020572343 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | -0.00202     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 574          |\n",
      "|    n_updates            | 8990         |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 545          |\n",
      "|    time_elapsed         | 2815         |\n",
      "|    total_timesteps      | 4464640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024523786 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0121       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 829          |\n",
      "|    n_updates            | 9000         |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    value_loss           | 1.58e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 546          |\n",
      "|    time_elapsed         | 2819         |\n",
      "|    total_timesteps      | 4472832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022544013 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.0111       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 572          |\n",
      "|    n_updates            | 9010         |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4480000, episode_reward=612.20 +/- 57.39\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 612          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4480000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023155347 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0144       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 934          |\n",
      "|    n_updates            | 9020         |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1583    |\n",
      "|    iterations      | 547     |\n",
      "|    time_elapsed    | 2829    |\n",
      "|    total_timesteps | 4481024 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 548         |\n",
      "|    time_elapsed         | 2833        |\n",
      "|    total_timesteps      | 4489216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002680491 |\n",
      "|    clip_fraction        | 0.0177      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.515      |\n",
      "|    explained_variance   | 0.00481     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 744         |\n",
      "|    n_updates            | 9030        |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    value_loss           | 1.56e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 549          |\n",
      "|    time_elapsed         | 2837         |\n",
      "|    total_timesteps      | 4497408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023524025 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.0378       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 929          |\n",
      "|    n_updates            | 9040         |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 550          |\n",
      "|    time_elapsed         | 2840         |\n",
      "|    total_timesteps      | 4505600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025633066 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.523       |\n",
      "|    explained_variance   | 0.0409       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 975          |\n",
      "|    n_updates            | 9050         |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 551          |\n",
      "|    time_elapsed         | 2844         |\n",
      "|    total_timesteps      | 4513792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024596157 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.0585       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 742          |\n",
      "|    n_updates            | 9060         |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4520000, episode_reward=596.40 +/- 109.89\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 596          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4520000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016766065 |\n",
      "|    clip_fraction        | 0.00658      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.0683       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 591          |\n",
      "|    n_updates            | 9070         |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    value_loss           | 1.55e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1584    |\n",
      "|    iterations      | 552     |\n",
      "|    time_elapsed    | 2854    |\n",
      "|    total_timesteps | 4521984 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 553          |\n",
      "|    time_elapsed         | 2858         |\n",
      "|    total_timesteps      | 4530176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035638276 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.0457       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 9080         |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 554          |\n",
      "|    time_elapsed         | 2861         |\n",
      "|    total_timesteps      | 4538368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026063076 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.52        |\n",
      "|    explained_variance   | 0.0306       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 900          |\n",
      "|    n_updates            | 9090         |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 555          |\n",
      "|    time_elapsed         | 2865         |\n",
      "|    total_timesteps      | 4546560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023633335 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.07         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 819          |\n",
      "|    n_updates            | 9100         |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 556          |\n",
      "|    time_elapsed         | 2869         |\n",
      "|    total_timesteps      | 4554752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027283733 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.519       |\n",
      "|    explained_variance   | 0.0538       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 809          |\n",
      "|    n_updates            | 9110         |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4560000, episode_reward=613.00 +/- 52.85\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 613          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026859012 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.535       |\n",
      "|    explained_variance   | 0.0139       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 726          |\n",
      "|    n_updates            | 9120         |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1584    |\n",
      "|    iterations      | 557     |\n",
      "|    time_elapsed    | 2879    |\n",
      "|    total_timesteps | 4562944 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1585       |\n",
      "|    iterations           | 558        |\n",
      "|    time_elapsed         | 2882       |\n",
      "|    total_timesteps      | 4571136    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00275934 |\n",
      "|    clip_fraction        | 0.0181     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.526     |\n",
      "|    explained_variance   | 0.0404     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 763        |\n",
      "|    n_updates            | 9130       |\n",
      "|    policy_gradient_loss | -0.00391   |\n",
      "|    value_loss           | 1.53e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1586        |\n",
      "|    iterations           | 559         |\n",
      "|    time_elapsed         | 2886        |\n",
      "|    total_timesteps      | 4579328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002865924 |\n",
      "|    clip_fraction        | 0.0215      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.524      |\n",
      "|    explained_variance   | 0.0295      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 820         |\n",
      "|    n_updates            | 9140        |\n",
      "|    policy_gradient_loss | -0.00472    |\n",
      "|    value_loss           | 1.58e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1587        |\n",
      "|    iterations           | 560         |\n",
      "|    time_elapsed         | 2890        |\n",
      "|    total_timesteps      | 4587520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002436996 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.524      |\n",
      "|    explained_variance   | 0.0259      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 9150        |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    value_loss           | 1.66e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 561          |\n",
      "|    time_elapsed         | 2894         |\n",
      "|    total_timesteps      | 4595712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025675753 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.033        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 749          |\n",
      "|    n_updates            | 9160         |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4600000, episode_reward=614.20 +/- 58.79\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 614         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4600000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002424915 |\n",
      "|    clip_fraction        | 0.0189      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.509      |\n",
      "|    explained_variance   | 0.0418      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 890         |\n",
      "|    n_updates            | 9170        |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    value_loss           | 1.66e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1585    |\n",
      "|    iterations      | 562     |\n",
      "|    time_elapsed    | 2904    |\n",
      "|    total_timesteps | 4603904 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 563          |\n",
      "|    time_elapsed         | 2908         |\n",
      "|    total_timesteps      | 4612096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026652617 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.0302       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 710          |\n",
      "|    n_updates            | 9180         |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 564          |\n",
      "|    time_elapsed         | 2911         |\n",
      "|    total_timesteps      | 4620288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023807946 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.51        |\n",
      "|    explained_variance   | 0.0519       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 844          |\n",
      "|    n_updates            | 9190         |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 565          |\n",
      "|    time_elapsed         | 2915         |\n",
      "|    total_timesteps      | 4628480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029016747 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | -0.00953     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 775          |\n",
      "|    n_updates            | 9200         |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 566          |\n",
      "|    time_elapsed         | 2919         |\n",
      "|    total_timesteps      | 4636672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022261676 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.0336       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.08e+03     |\n",
      "|    n_updates            | 9210         |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4640000, episode_reward=611.20 +/- 58.43\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 611          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4640000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020023189 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.0309       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 863          |\n",
      "|    n_updates            | 9220         |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1585    |\n",
      "|    iterations      | 567     |\n",
      "|    time_elapsed    | 2929    |\n",
      "|    total_timesteps | 4644864 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 568          |\n",
      "|    time_elapsed         | 2933         |\n",
      "|    total_timesteps      | 4653056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030819927 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.0162       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 791          |\n",
      "|    n_updates            | 9230         |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 569          |\n",
      "|    time_elapsed         | 2937         |\n",
      "|    total_timesteps      | 4661248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021832306 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0647       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 811          |\n",
      "|    n_updates            | 9240         |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 570          |\n",
      "|    time_elapsed         | 2940         |\n",
      "|    total_timesteps      | 4669440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021200886 |\n",
      "|    clip_fraction        | 0.00964      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.00782      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 689          |\n",
      "|    n_updates            | 9250         |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 571          |\n",
      "|    time_elapsed         | 2944         |\n",
      "|    total_timesteps      | 4677632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027301465 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0275       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 712          |\n",
      "|    n_updates            | 9260         |\n",
      "|    policy_gradient_loss | -0.00443     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4680000, episode_reward=619.00 +/- 56.58\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 619          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4680000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026806223 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.0434       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 973          |\n",
      "|    n_updates            | 9270         |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1585    |\n",
      "|    iterations      | 572     |\n",
      "|    time_elapsed    | 2954    |\n",
      "|    total_timesteps | 4685824 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 573          |\n",
      "|    time_elapsed         | 2958         |\n",
      "|    total_timesteps      | 4694016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024600718 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.0428       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 702          |\n",
      "|    n_updates            | 9280         |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 574          |\n",
      "|    time_elapsed         | 2962         |\n",
      "|    total_timesteps      | 4702208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024712782 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.485       |\n",
      "|    explained_variance   | 0.0474       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 675          |\n",
      "|    n_updates            | 9290         |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    value_loss           | 1.58e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1588        |\n",
      "|    iterations           | 575         |\n",
      "|    time_elapsed         | 2966        |\n",
      "|    total_timesteps      | 4710400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002744168 |\n",
      "|    clip_fraction        | 0.0206      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.502      |\n",
      "|    explained_variance   | 0.0565      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.09e+03    |\n",
      "|    n_updates            | 9300        |\n",
      "|    policy_gradient_loss | -0.00366    |\n",
      "|    value_loss           | 1.62e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1588        |\n",
      "|    iterations           | 576         |\n",
      "|    time_elapsed         | 2969        |\n",
      "|    total_timesteps      | 4718592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002284207 |\n",
      "|    clip_fraction        | 0.0127      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.486      |\n",
      "|    explained_variance   | -0.00113    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 723         |\n",
      "|    n_updates            | 9310        |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    value_loss           | 1.78e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4720000, episode_reward=628.00 +/- 55.32\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 628          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4720000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030077235 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.485       |\n",
      "|    explained_variance   | 0.0499       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 860          |\n",
      "|    n_updates            | 9320         |\n",
      "|    policy_gradient_loss | -0.00494     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1585    |\n",
      "|    iterations      | 577     |\n",
      "|    time_elapsed    | 2980    |\n",
      "|    total_timesteps | 4726784 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 578          |\n",
      "|    time_elapsed         | 2984         |\n",
      "|    total_timesteps      | 4734976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020780293 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | -0.00435     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 867          |\n",
      "|    n_updates            | 9330         |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    value_loss           | 1.58e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 579          |\n",
      "|    time_elapsed         | 2988         |\n",
      "|    total_timesteps      | 4743168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024277512 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.485       |\n",
      "|    explained_variance   | 0.042        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 442          |\n",
      "|    n_updates            | 9340         |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 580          |\n",
      "|    time_elapsed         | 2991         |\n",
      "|    total_timesteps      | 4751360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019179013 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.0413       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 675          |\n",
      "|    n_updates            | 9350         |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1588      |\n",
      "|    iterations           | 581       |\n",
      "|    time_elapsed         | 2995      |\n",
      "|    total_timesteps      | 4759552   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0022965 |\n",
      "|    clip_fraction        | 0.0125    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.485    |\n",
      "|    explained_variance   | 0.00666   |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 821       |\n",
      "|    n_updates            | 9360      |\n",
      "|    policy_gradient_loss | -0.00277  |\n",
      "|    value_loss           | 1.74e+03  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=4760000, episode_reward=599.20 +/- 103.09\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 599          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4760000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029897392 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.472       |\n",
      "|    explained_variance   | 0.0567       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 859          |\n",
      "|    n_updates            | 9370         |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1586    |\n",
      "|    iterations      | 582     |\n",
      "|    time_elapsed    | 3005    |\n",
      "|    total_timesteps | 4767744 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 583          |\n",
      "|    time_elapsed         | 3009         |\n",
      "|    total_timesteps      | 4775936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021091716 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0194       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 821          |\n",
      "|    n_updates            | 9380         |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 584          |\n",
      "|    time_elapsed         | 3012         |\n",
      "|    total_timesteps      | 4784128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021595473 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.0579       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 814          |\n",
      "|    n_updates            | 9390         |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 585          |\n",
      "|    time_elapsed         | 3016         |\n",
      "|    total_timesteps      | 4792320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022565085 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0523       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 842          |\n",
      "|    n_updates            | 9400         |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4800000, episode_reward=613.40 +/- 77.29\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 613          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4800000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020153741 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.473       |\n",
      "|    explained_variance   | 0.0458       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 829          |\n",
      "|    n_updates            | 9410         |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1585    |\n",
      "|    iterations      | 586     |\n",
      "|    time_elapsed    | 3027    |\n",
      "|    total_timesteps | 4800512 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 587          |\n",
      "|    time_elapsed         | 3030         |\n",
      "|    total_timesteps      | 4808704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022439365 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.471       |\n",
      "|    explained_variance   | 0.0149       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 9420         |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 588          |\n",
      "|    time_elapsed         | 3034         |\n",
      "|    total_timesteps      | 4816896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024077813 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.0504       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 714          |\n",
      "|    n_updates            | 9430         |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 589          |\n",
      "|    time_elapsed         | 3038         |\n",
      "|    total_timesteps      | 4825088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019670532 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.479       |\n",
      "|    explained_variance   | 0.0245       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 795          |\n",
      "|    n_updates            | 9440         |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 590          |\n",
      "|    time_elapsed         | 3042         |\n",
      "|    total_timesteps      | 4833280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027444481 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0385       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 770          |\n",
      "|    n_updates            | 9450         |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4840000, episode_reward=606.20 +/- 53.36\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 606         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4840000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002014581 |\n",
      "|    clip_fraction        | 0.0108      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.479      |\n",
      "|    explained_variance   | 0.0302      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 928         |\n",
      "|    n_updates            | 9460        |\n",
      "|    policy_gradient_loss | -0.00297    |\n",
      "|    value_loss           | 1.63e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1586    |\n",
      "|    iterations      | 591     |\n",
      "|    time_elapsed    | 3052    |\n",
      "|    total_timesteps | 4841472 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 592          |\n",
      "|    time_elapsed         | 3056         |\n",
      "|    total_timesteps      | 4849664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031365515 |\n",
      "|    clip_fraction        | 0.0251       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0271       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 958          |\n",
      "|    n_updates            | 9470         |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 593          |\n",
      "|    time_elapsed         | 3059         |\n",
      "|    total_timesteps      | 4857856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023584757 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.017        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 9480         |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 594          |\n",
      "|    time_elapsed         | 3063         |\n",
      "|    total_timesteps      | 4866048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019803466 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.473       |\n",
      "|    explained_variance   | 0.0328       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 845          |\n",
      "|    n_updates            | 9490         |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    value_loss           | 1.58e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 595          |\n",
      "|    time_elapsed         | 3067         |\n",
      "|    total_timesteps      | 4874240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028154133 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.489       |\n",
      "|    explained_variance   | 0.0285       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 622          |\n",
      "|    n_updates            | 9500         |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4880000, episode_reward=620.40 +/- 57.17\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 620          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4880000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023084204 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0181       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 773          |\n",
      "|    n_updates            | 9510         |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1586    |\n",
      "|    iterations      | 596     |\n",
      "|    time_elapsed    | 3077    |\n",
      "|    total_timesteps | 4882432 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1587        |\n",
      "|    iterations           | 597         |\n",
      "|    time_elapsed         | 3080        |\n",
      "|    total_timesteps      | 4890624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002533928 |\n",
      "|    clip_fraction        | 0.0213      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.489      |\n",
      "|    explained_variance   | 0.0319      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 824         |\n",
      "|    n_updates            | 9520        |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    value_loss           | 1.71e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 598          |\n",
      "|    time_elapsed         | 3084         |\n",
      "|    total_timesteps      | 4898816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025569303 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.0235       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 591          |\n",
      "|    n_updates            | 9530         |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 599          |\n",
      "|    time_elapsed         | 3088         |\n",
      "|    total_timesteps      | 4907008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022886307 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.472       |\n",
      "|    explained_variance   | 0.0664       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 934          |\n",
      "|    n_updates            | 9540         |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 600          |\n",
      "|    time_elapsed         | 3092         |\n",
      "|    total_timesteps      | 4915200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023345451 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.0394       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 881          |\n",
      "|    n_updates            | 9550         |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4920000, episode_reward=613.20 +/- 56.80\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 613          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4920000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023058164 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 0.0365       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 683          |\n",
      "|    n_updates            | 9560         |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1587    |\n",
      "|    iterations      | 601     |\n",
      "|    time_elapsed    | 3102    |\n",
      "|    total_timesteps | 4923392 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 602          |\n",
      "|    time_elapsed         | 3105         |\n",
      "|    total_timesteps      | 4931584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022253671 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.467       |\n",
      "|    explained_variance   | 0.0326       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 998          |\n",
      "|    n_updates            | 9570         |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 603          |\n",
      "|    time_elapsed         | 3109         |\n",
      "|    total_timesteps      | 4939776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027960124 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.468       |\n",
      "|    explained_variance   | 0.038        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.08e+03     |\n",
      "|    n_updates            | 9580         |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1589        |\n",
      "|    iterations           | 604         |\n",
      "|    time_elapsed         | 3113        |\n",
      "|    total_timesteps      | 4947968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002124207 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.479      |\n",
      "|    explained_variance   | 0.0403      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 671         |\n",
      "|    n_updates            | 9590        |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 605          |\n",
      "|    time_elapsed         | 3117         |\n",
      "|    total_timesteps      | 4956160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023229686 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.457       |\n",
      "|    explained_variance   | 0.0393       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 685          |\n",
      "|    n_updates            | 9600         |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4960000, episode_reward=618.00 +/- 60.70\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 618          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4960000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021486646 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.481       |\n",
      "|    explained_variance   | 0.0184       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 805          |\n",
      "|    n_updates            | 9610         |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1587    |\n",
      "|    iterations      | 606     |\n",
      "|    time_elapsed    | 3127    |\n",
      "|    total_timesteps | 4964352 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 607          |\n",
      "|    time_elapsed         | 3130         |\n",
      "|    total_timesteps      | 4972544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023668534 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.459       |\n",
      "|    explained_variance   | 0.0448       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 796          |\n",
      "|    n_updates            | 9620         |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1588        |\n",
      "|    iterations           | 608         |\n",
      "|    time_elapsed         | 3134        |\n",
      "|    total_timesteps      | 4980736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002131716 |\n",
      "|    clip_fraction        | 0.013       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.483      |\n",
      "|    explained_variance   | 0.0231      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 871         |\n",
      "|    n_updates            | 9630        |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    value_loss           | 1.71e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1589        |\n",
      "|    iterations           | 609         |\n",
      "|    time_elapsed         | 3138        |\n",
      "|    total_timesteps      | 4988928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002439015 |\n",
      "|    clip_fraction        | 0.0138      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.469      |\n",
      "|    explained_variance   | 0.0375      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 806         |\n",
      "|    n_updates            | 9640        |\n",
      "|    policy_gradient_loss | -0.00353    |\n",
      "|    value_loss           | 1.63e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1590         |\n",
      "|    iterations           | 610          |\n",
      "|    time_elapsed         | 3142         |\n",
      "|    total_timesteps      | 4997120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029829335 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.0201       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 825          |\n",
      "|    n_updates            | 9650         |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5000000, episode_reward=619.60 +/- 56.35\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 620          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023377277 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.0512       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 739          |\n",
      "|    n_updates            | 9660         |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1587    |\n",
      "|    iterations      | 611     |\n",
      "|    time_elapsed    | 3152    |\n",
      "|    total_timesteps | 5005312 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 612          |\n",
      "|    time_elapsed         | 3155         |\n",
      "|    total_timesteps      | 5013504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021473528 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.47        |\n",
      "|    explained_variance   | 0.00795      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 885          |\n",
      "|    n_updates            | 9670         |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 613          |\n",
      "|    time_elapsed         | 3159         |\n",
      "|    total_timesteps      | 5021696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024642046 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.0423       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 936          |\n",
      "|    n_updates            | 9680         |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1590         |\n",
      "|    iterations           | 614          |\n",
      "|    time_elapsed         | 3163         |\n",
      "|    total_timesteps      | 5029888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024205428 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.472       |\n",
      "|    explained_variance   | 0.0576       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 988          |\n",
      "|    n_updates            | 9690         |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    value_loss           | 1.95e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1590         |\n",
      "|    iterations           | 615          |\n",
      "|    time_elapsed         | 3167         |\n",
      "|    total_timesteps      | 5038080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022101053 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.489       |\n",
      "|    explained_variance   | 0.0181       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 900          |\n",
      "|    n_updates            | 9700         |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5040000, episode_reward=622.60 +/- 57.16\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 623          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5040000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023097233 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.0147       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.25e+03     |\n",
      "|    n_updates            | 9710         |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1587    |\n",
      "|    iterations      | 616     |\n",
      "|    time_elapsed    | 3178    |\n",
      "|    total_timesteps | 5046272 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1588        |\n",
      "|    iterations           | 617         |\n",
      "|    time_elapsed         | 3181        |\n",
      "|    total_timesteps      | 5054464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002258062 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.477      |\n",
      "|    explained_variance   | 0.0261      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 915         |\n",
      "|    n_updates            | 9720        |\n",
      "|    policy_gradient_loss | -0.00351    |\n",
      "|    value_loss           | 1.63e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1589       |\n",
      "|    iterations           | 618        |\n",
      "|    time_elapsed         | 3185       |\n",
      "|    total_timesteps      | 5062656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00265484 |\n",
      "|    clip_fraction        | 0.0163     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.472     |\n",
      "|    explained_variance   | 0.00047    |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 982        |\n",
      "|    n_updates            | 9730       |\n",
      "|    policy_gradient_loss | -0.00397   |\n",
      "|    value_loss           | 1.87e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1589         |\n",
      "|    iterations           | 619          |\n",
      "|    time_elapsed         | 3190         |\n",
      "|    total_timesteps      | 5070848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023092758 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.0235       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 890          |\n",
      "|    n_updates            | 9740         |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1590        |\n",
      "|    iterations           | 620         |\n",
      "|    time_elapsed         | 3194        |\n",
      "|    total_timesteps      | 5079040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002995446 |\n",
      "|    clip_fraction        | 0.0233      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.469      |\n",
      "|    explained_variance   | 0.0219      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 988         |\n",
      "|    n_updates            | 9750        |\n",
      "|    policy_gradient_loss | -0.00445    |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5080000, episode_reward=614.40 +/- 57.66\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 614          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5080000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018624596 |\n",
      "|    clip_fraction        | 0.00977      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.454       |\n",
      "|    explained_variance   | 0.0372       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 9760         |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1586    |\n",
      "|    iterations      | 621     |\n",
      "|    time_elapsed    | 3206    |\n",
      "|    total_timesteps | 5087232 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 622          |\n",
      "|    time_elapsed         | 3211         |\n",
      "|    total_timesteps      | 5095424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024065543 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.0577       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 994          |\n",
      "|    n_updates            | 9770         |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 623          |\n",
      "|    time_elapsed         | 3214         |\n",
      "|    total_timesteps      | 5103616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021788222 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.46        |\n",
      "|    explained_variance   | 0.0229       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 791          |\n",
      "|    n_updates            | 9780         |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 624          |\n",
      "|    time_elapsed         | 3218         |\n",
      "|    total_timesteps      | 5111808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021476657 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.456       |\n",
      "|    explained_variance   | 0.0331       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 877          |\n",
      "|    n_updates            | 9790         |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5120000, episode_reward=625.60 +/- 62.39\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 626          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018780278 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.0615       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 9800         |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1585    |\n",
      "|    iterations      | 625     |\n",
      "|    time_elapsed    | 3229    |\n",
      "|    total_timesteps | 5120000 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 626          |\n",
      "|    time_elapsed         | 3233         |\n",
      "|    total_timesteps      | 5128192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028633713 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.459       |\n",
      "|    explained_variance   | -0.011       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 776          |\n",
      "|    n_updates            | 9810         |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1586        |\n",
      "|    iterations           | 627         |\n",
      "|    time_elapsed         | 3237        |\n",
      "|    total_timesteps      | 5136384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001979438 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.46       |\n",
      "|    explained_variance   | 0.0367      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.13e+03    |\n",
      "|    n_updates            | 9820        |\n",
      "|    policy_gradient_loss | -0.00345    |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1587        |\n",
      "|    iterations           | 628         |\n",
      "|    time_elapsed         | 3241        |\n",
      "|    total_timesteps      | 5144576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002104593 |\n",
      "|    clip_fraction        | 0.0119      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.453      |\n",
      "|    explained_variance   | 0.027       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 828         |\n",
      "|    n_updates            | 9830        |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    value_loss           | 1.71e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 629          |\n",
      "|    time_elapsed         | 3245         |\n",
      "|    total_timesteps      | 5152768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024434591 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.454       |\n",
      "|    explained_variance   | 0.0256       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 923          |\n",
      "|    n_updates            | 9840         |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5160000, episode_reward=600.00 +/- 56.60\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 600          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5160000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022664745 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.467       |\n",
      "|    explained_variance   | 0.0259       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 653          |\n",
      "|    n_updates            | 9850         |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1585    |\n",
      "|    iterations      | 630     |\n",
      "|    time_elapsed    | 3255    |\n",
      "|    total_timesteps | 5160960 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 631          |\n",
      "|    time_elapsed         | 3259         |\n",
      "|    total_timesteps      | 5169152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024170892 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.457       |\n",
      "|    explained_variance   | 0.0419       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.08e+03     |\n",
      "|    n_updates            | 9860         |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 632          |\n",
      "|    time_elapsed         | 3263         |\n",
      "|    total_timesteps      | 5177344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022529848 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.0345       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 829          |\n",
      "|    n_updates            | 9870         |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 633          |\n",
      "|    time_elapsed         | 3267         |\n",
      "|    total_timesteps      | 5185536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025006384 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.456       |\n",
      "|    explained_variance   | -0.016       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 912          |\n",
      "|    n_updates            | 9880         |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 634          |\n",
      "|    time_elapsed         | 3271         |\n",
      "|    total_timesteps      | 5193728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018326405 |\n",
      "|    clip_fraction        | 0.00948      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.0234       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 781          |\n",
      "|    n_updates            | 9890         |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5200000, episode_reward=614.60 +/- 60.83\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 615          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023755776 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.0327       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 930          |\n",
      "|    n_updates            | 9900         |\n",
      "|    policy_gradient_loss | -0.00395     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1585    |\n",
      "|    iterations      | 635     |\n",
      "|    time_elapsed    | 3281    |\n",
      "|    total_timesteps | 5201920 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 636          |\n",
      "|    time_elapsed         | 3284         |\n",
      "|    total_timesteps      | 5210112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016709692 |\n",
      "|    clip_fraction        | 0.00785      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.443       |\n",
      "|    explained_variance   | 0.0305       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 655          |\n",
      "|    n_updates            | 9910         |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1586        |\n",
      "|    iterations           | 637         |\n",
      "|    time_elapsed         | 3288        |\n",
      "|    total_timesteps      | 5218304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001751455 |\n",
      "|    clip_fraction        | 0.00847     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.459      |\n",
      "|    explained_variance   | 0.0533      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.11e+03    |\n",
      "|    n_updates            | 9920        |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    value_loss           | 1.59e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 638          |\n",
      "|    time_elapsed         | 3292         |\n",
      "|    total_timesteps      | 5226496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020676577 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.457       |\n",
      "|    explained_variance   | 0.0274       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 572          |\n",
      "|    n_updates            | 9930         |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    value_loss           | 1.53e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 639          |\n",
      "|    time_elapsed         | 3296         |\n",
      "|    total_timesteps      | 5234688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026895348 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.0316       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 862          |\n",
      "|    n_updates            | 9940         |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5240000, episode_reward=609.00 +/- 54.16\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 609          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5240000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021401923 |\n",
      "|    clip_fraction        | 0.00974      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.467       |\n",
      "|    explained_variance   | -0.0151      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 900          |\n",
      "|    n_updates            | 9950         |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1585    |\n",
      "|    iterations      | 640     |\n",
      "|    time_elapsed    | 3306    |\n",
      "|    total_timesteps | 5242880 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 641          |\n",
      "|    time_elapsed         | 3309         |\n",
      "|    total_timesteps      | 5251072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022579262 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.456       |\n",
      "|    explained_variance   | 0.0477       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 932          |\n",
      "|    n_updates            | 9960         |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1587        |\n",
      "|    iterations           | 642         |\n",
      "|    time_elapsed         | 3313        |\n",
      "|    total_timesteps      | 5259264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001829207 |\n",
      "|    clip_fraction        | 0.0123      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.426      |\n",
      "|    explained_variance   | 0.0225      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 816         |\n",
      "|    n_updates            | 9970        |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 643          |\n",
      "|    time_elapsed         | 3317         |\n",
      "|    total_timesteps      | 5267456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025638025 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.0177       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 860          |\n",
      "|    n_updates            | 9980         |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 644          |\n",
      "|    time_elapsed         | 3321         |\n",
      "|    total_timesteps      | 5275648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017918288 |\n",
      "|    clip_fraction        | 0.00981      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 0.0324       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 634          |\n",
      "|    n_updates            | 9990         |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    value_loss           | 1.53e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5280000, episode_reward=631.00 +/- 60.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 631          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017250081 |\n",
      "|    clip_fraction        | 0.0079       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.444       |\n",
      "|    explained_variance   | 0.0394       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 968          |\n",
      "|    n_updates            | 10000        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1585    |\n",
      "|    iterations      | 645     |\n",
      "|    time_elapsed    | 3331    |\n",
      "|    total_timesteps | 5283840 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1586        |\n",
      "|    iterations           | 646         |\n",
      "|    time_elapsed         | 3335        |\n",
      "|    total_timesteps      | 5292032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002465926 |\n",
      "|    clip_fraction        | 0.012       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.459      |\n",
      "|    explained_variance   | 0.0246      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 974         |\n",
      "|    n_updates            | 10010       |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    value_loss           | 1.69e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 647          |\n",
      "|    time_elapsed         | 3339         |\n",
      "|    total_timesteps      | 5300224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017671452 |\n",
      "|    clip_fraction        | 0.00874      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.0127       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1e+03        |\n",
      "|    n_updates            | 10020        |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 648          |\n",
      "|    time_elapsed         | 3343         |\n",
      "|    total_timesteps      | 5308416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018911109 |\n",
      "|    clip_fraction        | 0.00929      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.456       |\n",
      "|    explained_variance   | 0.043        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 685          |\n",
      "|    n_updates            | 10030        |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1588         |\n",
      "|    iterations           | 649          |\n",
      "|    time_elapsed         | 3347         |\n",
      "|    total_timesteps      | 5316608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024172622 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.0545       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 825          |\n",
      "|    n_updates            | 10040        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5320000, episode_reward=601.40 +/- 67.11\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 601          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5320000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023864028 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.462       |\n",
      "|    explained_variance   | 0.0535       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 10050        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1585    |\n",
      "|    iterations      | 650     |\n",
      "|    time_elapsed    | 3358    |\n",
      "|    total_timesteps | 5324800 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 651          |\n",
      "|    time_elapsed         | 3363         |\n",
      "|    total_timesteps      | 5332992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017976235 |\n",
      "|    clip_fraction        | 0.00809      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.47        |\n",
      "|    explained_variance   | 0.0449       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 824          |\n",
      "|    n_updates            | 10060        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 652          |\n",
      "|    time_elapsed         | 3366         |\n",
      "|    total_timesteps      | 5341184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022623334 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.452       |\n",
      "|    explained_variance   | 0.0502       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 841          |\n",
      "|    n_updates            | 10070        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1586        |\n",
      "|    iterations           | 653         |\n",
      "|    time_elapsed         | 3370        |\n",
      "|    total_timesteps      | 5349376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002108027 |\n",
      "|    clip_fraction        | 0.0154      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.468      |\n",
      "|    explained_variance   | 0.035       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 750         |\n",
      "|    n_updates            | 10080       |\n",
      "|    policy_gradient_loss | -0.00351    |\n",
      "|    value_loss           | 1.57e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 654          |\n",
      "|    time_elapsed         | 3374         |\n",
      "|    total_timesteps      | 5357568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029126327 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.463       |\n",
      "|    explained_variance   | -0.000107    |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 596          |\n",
      "|    n_updates            | 10090        |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5360000, episode_reward=626.00 +/- 71.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 626          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5360000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022153056 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.457       |\n",
      "|    explained_variance   | 0.0268       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 678          |\n",
      "|    n_updates            | 10100        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1584    |\n",
      "|    iterations      | 655     |\n",
      "|    time_elapsed    | 3385    |\n",
      "|    total_timesteps | 5365760 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1585       |\n",
      "|    iterations           | 656        |\n",
      "|    time_elapsed         | 3389       |\n",
      "|    total_timesteps      | 5373952    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00240346 |\n",
      "|    clip_fraction        | 0.0141     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.448     |\n",
      "|    explained_variance   | 0.0414     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 807        |\n",
      "|    n_updates            | 10110      |\n",
      "|    policy_gradient_loss | -0.00341   |\n",
      "|    value_loss           | 1.71e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 657          |\n",
      "|    time_elapsed         | 3393         |\n",
      "|    total_timesteps      | 5382144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022375346 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.467       |\n",
      "|    explained_variance   | 0.0334       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.08e+03     |\n",
      "|    n_updates            | 10120        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1586       |\n",
      "|    iterations           | 658        |\n",
      "|    time_elapsed         | 3397       |\n",
      "|    total_timesteps      | 5390336    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00248353 |\n",
      "|    clip_fraction        | 0.0151     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.466     |\n",
      "|    explained_variance   | 0.0277     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 664        |\n",
      "|    n_updates            | 10130      |\n",
      "|    policy_gradient_loss | -0.00322   |\n",
      "|    value_loss           | 1.64e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1587         |\n",
      "|    iterations           | 659          |\n",
      "|    time_elapsed         | 3401         |\n",
      "|    total_timesteps      | 5398528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018444487 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.471       |\n",
      "|    explained_variance   | 0.0328       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 805          |\n",
      "|    n_updates            | 10140        |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5400000, episode_reward=625.00 +/- 65.86\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 625          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5400000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019910622 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.477       |\n",
      "|    explained_variance   | 0.0392       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 761          |\n",
      "|    n_updates            | 10150        |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1583    |\n",
      "|    iterations      | 660     |\n",
      "|    time_elapsed    | 3413    |\n",
      "|    total_timesteps | 5406720 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 661          |\n",
      "|    time_elapsed         | 3417         |\n",
      "|    total_timesteps      | 5414912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019940329 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.471       |\n",
      "|    explained_variance   | 0.0437       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 609          |\n",
      "|    n_updates            | 10160        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 662          |\n",
      "|    time_elapsed         | 3421         |\n",
      "|    total_timesteps      | 5423104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020369792 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.475       |\n",
      "|    explained_variance   | 0.0186       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 811          |\n",
      "|    n_updates            | 10170        |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 663          |\n",
      "|    time_elapsed         | 3425         |\n",
      "|    total_timesteps      | 5431296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025037988 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.485       |\n",
      "|    explained_variance   | 0.0311       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 945          |\n",
      "|    n_updates            | 10180        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1586         |\n",
      "|    iterations           | 664          |\n",
      "|    time_elapsed         | 3429         |\n",
      "|    total_timesteps      | 5439488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022831792 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.0145       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 954          |\n",
      "|    n_updates            | 10190        |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5440000, episode_reward=622.80 +/- 56.78\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 623          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5440000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021436564 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | 0.0497       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 732          |\n",
      "|    n_updates            | 10200        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1583    |\n",
      "|    iterations      | 665     |\n",
      "|    time_elapsed    | 3439    |\n",
      "|    total_timesteps | 5447680 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 666          |\n",
      "|    time_elapsed         | 3443         |\n",
      "|    total_timesteps      | 5455872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021462864 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.479       |\n",
      "|    explained_variance   | 0.0185       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 688          |\n",
      "|    n_updates            | 10210        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 667          |\n",
      "|    time_elapsed         | 3447         |\n",
      "|    total_timesteps      | 5464064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030625928 |\n",
      "|    clip_fraction        | 0.0287       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.468       |\n",
      "|    explained_variance   | 0.0531       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 871          |\n",
      "|    n_updates            | 10220        |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 668          |\n",
      "|    time_elapsed         | 3451         |\n",
      "|    total_timesteps      | 5472256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028364891 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.464       |\n",
      "|    explained_variance   | 0.0409       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 986          |\n",
      "|    n_updates            | 10230        |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5480000, episode_reward=605.60 +/- 54.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 606          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5480000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028329184 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.00748      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 10240        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1583    |\n",
      "|    iterations      | 669     |\n",
      "|    time_elapsed    | 3461    |\n",
      "|    total_timesteps | 5480448 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 670          |\n",
      "|    time_elapsed         | 3464         |\n",
      "|    total_timesteps      | 5488640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020752759 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.462       |\n",
      "|    explained_variance   | 0.0405       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 706          |\n",
      "|    n_updates            | 10250        |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 671          |\n",
      "|    time_elapsed         | 3468         |\n",
      "|    total_timesteps      | 5496832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021473705 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.454       |\n",
      "|    explained_variance   | 0.0452       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 870          |\n",
      "|    n_updates            | 10260        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 672          |\n",
      "|    time_elapsed         | 3472         |\n",
      "|    total_timesteps      | 5505024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027470172 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | 0.0305       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 608          |\n",
      "|    n_updates            | 10270        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 673          |\n",
      "|    time_elapsed         | 3477         |\n",
      "|    total_timesteps      | 5513216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017420523 |\n",
      "|    clip_fraction        | 0.00931      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | -0.0101      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 765          |\n",
      "|    n_updates            | 10280        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5520000, episode_reward=585.60 +/- 102.82\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 586          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5520000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021002674 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.469       |\n",
      "|    explained_variance   | 0.0418       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 766          |\n",
      "|    n_updates            | 10290        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1583    |\n",
      "|    iterations      | 674     |\n",
      "|    time_elapsed    | 3487    |\n",
      "|    total_timesteps | 5521408 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 675          |\n",
      "|    time_elapsed         | 3491         |\n",
      "|    total_timesteps      | 5529600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025354887 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.475       |\n",
      "|    explained_variance   | 0.0259       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 884          |\n",
      "|    n_updates            | 10300        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 676         |\n",
      "|    time_elapsed         | 3495        |\n",
      "|    total_timesteps      | 5537792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002317673 |\n",
      "|    clip_fraction        | 0.0132      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.483      |\n",
      "|    explained_variance   | 0.023       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 935         |\n",
      "|    n_updates            | 10310       |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    value_loss           | 1.7e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 677          |\n",
      "|    time_elapsed         | 3500         |\n",
      "|    total_timesteps      | 5545984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026470758 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.0467       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 561          |\n",
      "|    n_updates            | 10320        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 678         |\n",
      "|    time_elapsed         | 3504        |\n",
      "|    total_timesteps      | 5554176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002323696 |\n",
      "|    clip_fraction        | 0.0143      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.467      |\n",
      "|    explained_variance   | 0.0459      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 845         |\n",
      "|    n_updates            | 10330       |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    value_loss           | 1.6e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5560000, episode_reward=610.80 +/- 56.10\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 611         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002659367 |\n",
      "|    clip_fraction        | 0.0196      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.47       |\n",
      "|    explained_variance   | 0.0498      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 864         |\n",
      "|    n_updates            | 10340       |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    value_loss           | 1.62e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1582    |\n",
      "|    iterations      | 679     |\n",
      "|    time_elapsed    | 3514    |\n",
      "|    total_timesteps | 5562368 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 680          |\n",
      "|    time_elapsed         | 3518         |\n",
      "|    total_timesteps      | 5570560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024298648 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.467       |\n",
      "|    explained_variance   | 0.0711       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 984          |\n",
      "|    n_updates            | 10350        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    value_loss           | 1.48e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 681         |\n",
      "|    time_elapsed         | 3522        |\n",
      "|    total_timesteps      | 5578752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002653005 |\n",
      "|    clip_fraction        | 0.02        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.467      |\n",
      "|    explained_variance   | 0.024       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 830         |\n",
      "|    n_updates            | 10360       |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    value_loss           | 1.73e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 682          |\n",
      "|    time_elapsed         | 3527         |\n",
      "|    total_timesteps      | 5586944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018560023 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.475       |\n",
      "|    explained_variance   | 0.0413       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 10370        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 683         |\n",
      "|    time_elapsed         | 3532        |\n",
      "|    total_timesteps      | 5595136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002832979 |\n",
      "|    clip_fraction        | 0.0207      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.476      |\n",
      "|    explained_variance   | 0.0273      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 995         |\n",
      "|    n_updates            | 10380       |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    value_loss           | 1.6e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5600000, episode_reward=627.00 +/- 49.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 627          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5600000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028711648 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.475       |\n",
      "|    explained_variance   | 0.0164       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 917          |\n",
      "|    n_updates            | 10390        |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1581    |\n",
      "|    iterations      | 684     |\n",
      "|    time_elapsed    | 3543    |\n",
      "|    total_timesteps | 5603328 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 685          |\n",
      "|    time_elapsed         | 3548         |\n",
      "|    total_timesteps      | 5611520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022732473 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.481       |\n",
      "|    explained_variance   | 0.0323       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 991          |\n",
      "|    n_updates            | 10400        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 686          |\n",
      "|    time_elapsed         | 3553         |\n",
      "|    total_timesteps      | 5619712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030376983 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.0271       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 10410        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1582        |\n",
      "|    iterations           | 687         |\n",
      "|    time_elapsed         | 3557        |\n",
      "|    total_timesteps      | 5627904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002806664 |\n",
      "|    clip_fraction        | 0.0215      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.472      |\n",
      "|    explained_variance   | 0.0771      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 692         |\n",
      "|    n_updates            | 10420       |\n",
      "|    policy_gradient_loss | -0.00377    |\n",
      "|    value_loss           | 1.62e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1582        |\n",
      "|    iterations           | 688         |\n",
      "|    time_elapsed         | 3561        |\n",
      "|    total_timesteps      | 5636096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002540967 |\n",
      "|    clip_fraction        | 0.016       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.463      |\n",
      "|    explained_variance   | 0.0286      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 825         |\n",
      "|    n_updates            | 10430       |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    value_loss           | 1.65e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5640000, episode_reward=606.60 +/- 70.98\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 607          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5640000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026549655 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.0141       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 821          |\n",
      "|    n_updates            | 10440        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1580    |\n",
      "|    iterations      | 689     |\n",
      "|    time_elapsed    | 3571    |\n",
      "|    total_timesteps | 5644288 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 690          |\n",
      "|    time_elapsed         | 3575         |\n",
      "|    total_timesteps      | 5652480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021751174 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.459       |\n",
      "|    explained_variance   | 0.0199       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 644          |\n",
      "|    n_updates            | 10450        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1581        |\n",
      "|    iterations           | 691         |\n",
      "|    time_elapsed         | 3579        |\n",
      "|    total_timesteps      | 5660672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002060936 |\n",
      "|    clip_fraction        | 0.0104      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.45       |\n",
      "|    explained_variance   | 0.0226      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.03e+03    |\n",
      "|    n_updates            | 10460       |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    value_loss           | 1.63e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 692          |\n",
      "|    time_elapsed         | 3583         |\n",
      "|    total_timesteps      | 5668864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027773408 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | 0.0565       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 10470        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1582        |\n",
      "|    iterations           | 693         |\n",
      "|    time_elapsed         | 3587        |\n",
      "|    total_timesteps      | 5677056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002255409 |\n",
      "|    clip_fraction        | 0.0159      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.456      |\n",
      "|    explained_variance   | 0.0292      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 965         |\n",
      "|    n_updates            | 10480       |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    value_loss           | 1.78e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5680000, episode_reward=609.40 +/- 60.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 609          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5680000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021503798 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 0.0523       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 549          |\n",
      "|    n_updates            | 10490        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1580    |\n",
      "|    iterations      | 694     |\n",
      "|    time_elapsed    | 3597    |\n",
      "|    total_timesteps | 5685248 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 695          |\n",
      "|    time_elapsed         | 3601         |\n",
      "|    total_timesteps      | 5693440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024578827 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.46        |\n",
      "|    explained_variance   | 0.0479       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 10500        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 696          |\n",
      "|    time_elapsed         | 3605         |\n",
      "|    total_timesteps      | 5701632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030941782 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.0556       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 625          |\n",
      "|    n_updates            | 10510        |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 697          |\n",
      "|    time_elapsed         | 3609         |\n",
      "|    total_timesteps      | 5709824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022107852 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.462       |\n",
      "|    explained_variance   | 0.0467       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 670          |\n",
      "|    n_updates            | 10520        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 698          |\n",
      "|    time_elapsed         | 3613         |\n",
      "|    total_timesteps      | 5718016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025355588 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.0676       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 795          |\n",
      "|    n_updates            | 10530        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5720000, episode_reward=615.00 +/- 57.63\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 615          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5720000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024815681 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 0.0539       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 987          |\n",
      "|    n_updates            | 10540        |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1580    |\n",
      "|    iterations      | 699     |\n",
      "|    time_elapsed    | 3623    |\n",
      "|    total_timesteps | 5726208 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 700          |\n",
      "|    time_elapsed         | 3627         |\n",
      "|    total_timesteps      | 5734400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022689858 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.456       |\n",
      "|    explained_variance   | 0.0541       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 785          |\n",
      "|    n_updates            | 10550        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 701          |\n",
      "|    time_elapsed         | 3631         |\n",
      "|    total_timesteps      | 5742592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028106254 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.454       |\n",
      "|    explained_variance   | 0.0166       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 10560        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 702          |\n",
      "|    time_elapsed         | 3635         |\n",
      "|    total_timesteps      | 5750784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021306076 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.0426       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 873          |\n",
      "|    n_updates            | 10570        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 703          |\n",
      "|    time_elapsed         | 3639         |\n",
      "|    total_timesteps      | 5758976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028387713 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.462       |\n",
      "|    explained_variance   | 0.07         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 871          |\n",
      "|    n_updates            | 10580        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5760000, episode_reward=618.20 +/- 67.25\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 618         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5760000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002428645 |\n",
      "|    clip_fraction        | 0.0168      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.446      |\n",
      "|    explained_variance   | 0.0757      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 813         |\n",
      "|    n_updates            | 10590       |\n",
      "|    policy_gradient_loss | -0.0033     |\n",
      "|    value_loss           | 1.62e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1580    |\n",
      "|    iterations      | 704     |\n",
      "|    time_elapsed    | 3649    |\n",
      "|    total_timesteps | 5767168 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 705          |\n",
      "|    time_elapsed         | 3653         |\n",
      "|    total_timesteps      | 5775360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022537638 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.452       |\n",
      "|    explained_variance   | 0.0122       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 10600        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1581        |\n",
      "|    iterations           | 706         |\n",
      "|    time_elapsed         | 3657        |\n",
      "|    total_timesteps      | 5783552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002497777 |\n",
      "|    clip_fraction        | 0.0151      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.463      |\n",
      "|    explained_variance   | -0.00246    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 892         |\n",
      "|    n_updates            | 10610       |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    value_loss           | 1.78e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 707          |\n",
      "|    time_elapsed         | 3661         |\n",
      "|    total_timesteps      | 5791744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027831004 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.448       |\n",
      "|    explained_variance   | 0.0748       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 796          |\n",
      "|    n_updates            | 10620        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 708          |\n",
      "|    time_elapsed         | 3664         |\n",
      "|    total_timesteps      | 5799936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025429577 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.0343       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 977          |\n",
      "|    n_updates            | 10630        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5800000, episode_reward=619.60 +/- 56.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 620          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5800000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022378992 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.459       |\n",
      "|    explained_variance   | 0.0608       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 704          |\n",
      "|    n_updates            | 10640        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1580    |\n",
      "|    iterations      | 709     |\n",
      "|    time_elapsed    | 3675    |\n",
      "|    total_timesteps | 5808128 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1581        |\n",
      "|    iterations           | 710         |\n",
      "|    time_elapsed         | 3678        |\n",
      "|    total_timesteps      | 5816320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002193199 |\n",
      "|    clip_fraction        | 0.0132      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.469      |\n",
      "|    explained_variance   | 0.06        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 816         |\n",
      "|    n_updates            | 10650       |\n",
      "|    policy_gradient_loss | -0.00337    |\n",
      "|    value_loss           | 1.85e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 711          |\n",
      "|    time_elapsed         | 3682         |\n",
      "|    total_timesteps      | 5824512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018857688 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.0351       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 459          |\n",
      "|    n_updates            | 10660        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 712          |\n",
      "|    time_elapsed         | 3686         |\n",
      "|    total_timesteps      | 5832704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017967313 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | 0.0324       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 773          |\n",
      "|    n_updates            | 10670        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5840000, episode_reward=631.40 +/- 57.90\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 631          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5840000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023549956 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | 0.0341       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 878          |\n",
      "|    n_updates            | 10680        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1580    |\n",
      "|    iterations      | 713     |\n",
      "|    time_elapsed    | 3696    |\n",
      "|    total_timesteps | 5840896 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1580        |\n",
      "|    iterations           | 714         |\n",
      "|    time_elapsed         | 3700        |\n",
      "|    total_timesteps      | 5849088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002782382 |\n",
      "|    clip_fraction        | 0.0224      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.476      |\n",
      "|    explained_variance   | 0.0255      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 803         |\n",
      "|    n_updates            | 10690       |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    value_loss           | 1.8e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 715          |\n",
      "|    time_elapsed         | 3703         |\n",
      "|    total_timesteps      | 5857280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023398548 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.464       |\n",
      "|    explained_variance   | 0.0467       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 665          |\n",
      "|    n_updates            | 10700        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 716          |\n",
      "|    time_elapsed         | 3707         |\n",
      "|    total_timesteps      | 5865472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023658844 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.467       |\n",
      "|    explained_variance   | 0.0331       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 713          |\n",
      "|    n_updates            | 10710        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 717          |\n",
      "|    time_elapsed         | 3711         |\n",
      "|    total_timesteps      | 5873664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023642734 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.456       |\n",
      "|    explained_variance   | 0.00417      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 671          |\n",
      "|    n_updates            | 10720        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5880000, episode_reward=619.00 +/- 92.37\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 619          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5880000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019327109 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.0142       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 913          |\n",
      "|    n_updates            | 10730        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1580    |\n",
      "|    iterations      | 718     |\n",
      "|    time_elapsed    | 3721    |\n",
      "|    total_timesteps | 5881856 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1580        |\n",
      "|    iterations           | 719         |\n",
      "|    time_elapsed         | 3725        |\n",
      "|    total_timesteps      | 5890048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002728451 |\n",
      "|    clip_fraction        | 0.0229      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.457      |\n",
      "|    explained_variance   | 0.0365      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 839         |\n",
      "|    n_updates            | 10740       |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 720          |\n",
      "|    time_elapsed         | 3729         |\n",
      "|    total_timesteps      | 5898240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017058612 |\n",
      "|    clip_fraction        | 0.00825      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | 0.0204       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 842          |\n",
      "|    n_updates            | 10750        |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 721          |\n",
      "|    time_elapsed         | 3733         |\n",
      "|    total_timesteps      | 5906432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025314128 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.0229       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 10760        |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 722          |\n",
      "|    time_elapsed         | 3737         |\n",
      "|    total_timesteps      | 5914624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022339833 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | 0.0481       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 946          |\n",
      "|    n_updates            | 10770        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5920000, episode_reward=601.20 +/- 99.89\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 601          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5920000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021356733 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.447       |\n",
      "|    explained_variance   | 0.0603       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 947          |\n",
      "|    n_updates            | 10780        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1580    |\n",
      "|    iterations      | 723     |\n",
      "|    time_elapsed    | 3747    |\n",
      "|    total_timesteps | 5922816 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 724          |\n",
      "|    time_elapsed         | 3750         |\n",
      "|    total_timesteps      | 5931008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019584617 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.445       |\n",
      "|    explained_variance   | 0.0179       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 858          |\n",
      "|    n_updates            | 10790        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1581       |\n",
      "|    iterations           | 725        |\n",
      "|    time_elapsed         | 3754       |\n",
      "|    total_timesteps      | 5939200    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00210816 |\n",
      "|    clip_fraction        | 0.0123     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.455     |\n",
      "|    explained_variance   | 0.0607     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.03e+03   |\n",
      "|    n_updates            | 10800      |\n",
      "|    policy_gradient_loss | -0.00295   |\n",
      "|    value_loss           | 1.68e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1582        |\n",
      "|    iterations           | 726         |\n",
      "|    time_elapsed         | 3758        |\n",
      "|    total_timesteps      | 5947392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001847255 |\n",
      "|    clip_fraction        | 0.0114      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.444      |\n",
      "|    explained_variance   | 0.0469      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 797         |\n",
      "|    n_updates            | 10810       |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    value_loss           | 1.74e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 727          |\n",
      "|    time_elapsed         | 3762         |\n",
      "|    total_timesteps      | 5955584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026284908 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.0601       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 887          |\n",
      "|    n_updates            | 10820        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5960000, episode_reward=603.60 +/- 51.02\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 604          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5960000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024532098 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.0355       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 601          |\n",
      "|    n_updates            | 10830        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1580    |\n",
      "|    iterations      | 728     |\n",
      "|    time_elapsed    | 3772    |\n",
      "|    total_timesteps | 5963776 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 729          |\n",
      "|    time_elapsed         | 3776         |\n",
      "|    total_timesteps      | 5971968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025234362 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.0234       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.21e+03     |\n",
      "|    n_updates            | 10840        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 730          |\n",
      "|    time_elapsed         | 3780         |\n",
      "|    total_timesteps      | 5980160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023971975 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.056        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 929          |\n",
      "|    n_updates            | 10850        |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 731          |\n",
      "|    time_elapsed         | 3784         |\n",
      "|    total_timesteps      | 5988352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020303493 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.0452       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 495          |\n",
      "|    n_updates            | 10860        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1582       |\n",
      "|    iterations           | 732        |\n",
      "|    time_elapsed         | 3788       |\n",
      "|    total_timesteps      | 5996544    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00190305 |\n",
      "|    clip_fraction        | 0.0106     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.468     |\n",
      "|    explained_variance   | 0.0864     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 853        |\n",
      "|    n_updates            | 10870      |\n",
      "|    policy_gradient_loss | -0.00355   |\n",
      "|    value_loss           | 1.72e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=6000000, episode_reward=610.40 +/- 108.94\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 610          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027556084 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.462       |\n",
      "|    explained_variance   | 0.0893       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 601          |\n",
      "|    n_updates            | 10880        |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1580    |\n",
      "|    iterations      | 733     |\n",
      "|    time_elapsed    | 3799    |\n",
      "|    total_timesteps | 6004736 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 734          |\n",
      "|    time_elapsed         | 3803         |\n",
      "|    total_timesteps      | 6012928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019214089 |\n",
      "|    clip_fraction        | 0.00925      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.0265       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 633          |\n",
      "|    n_updates            | 10890        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 735          |\n",
      "|    time_elapsed         | 3807         |\n",
      "|    total_timesteps      | 6021120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020093108 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.447       |\n",
      "|    explained_variance   | 0.0537       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 10900        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 736          |\n",
      "|    time_elapsed         | 3812         |\n",
      "|    total_timesteps      | 6029312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024925307 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.433       |\n",
      "|    explained_variance   | 0.0506       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 853          |\n",
      "|    n_updates            | 10910        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 737          |\n",
      "|    time_elapsed         | 3816         |\n",
      "|    total_timesteps      | 6037504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017580905 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.447       |\n",
      "|    explained_variance   | 0.0102       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 10920        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6040000, episode_reward=619.20 +/- 52.95\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 619          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6040000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023274864 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.46        |\n",
      "|    explained_variance   | 0.0137       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 936          |\n",
      "|    n_updates            | 10930        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1579    |\n",
      "|    iterations      | 738     |\n",
      "|    time_elapsed    | 3827    |\n",
      "|    total_timesteps | 6045696 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 739          |\n",
      "|    time_elapsed         | 3833         |\n",
      "|    total_timesteps      | 6053888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021931129 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.0297       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 858          |\n",
      "|    n_updates            | 10940        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 740          |\n",
      "|    time_elapsed         | 3838         |\n",
      "|    total_timesteps      | 6062080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025469826 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.456       |\n",
      "|    explained_variance   | 0.0277       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 856          |\n",
      "|    n_updates            | 10950        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 741          |\n",
      "|    time_elapsed         | 3842         |\n",
      "|    total_timesteps      | 6070272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019964164 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.0458       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 686          |\n",
      "|    n_updates            | 10960        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1579        |\n",
      "|    iterations           | 742         |\n",
      "|    time_elapsed         | 3847        |\n",
      "|    total_timesteps      | 6078464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002013104 |\n",
      "|    clip_fraction        | 0.0108      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.461      |\n",
      "|    explained_variance   | 0.00904     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 800         |\n",
      "|    n_updates            | 10970       |\n",
      "|    policy_gradient_loss | -0.00321    |\n",
      "|    value_loss           | 1.64e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6080000, episode_reward=612.00 +/- 106.73\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 612          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6080000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017618886 |\n",
      "|    clip_fraction        | 0.00979      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.454       |\n",
      "|    explained_variance   | 0.0118       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 855          |\n",
      "|    n_updates            | 10980        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1577    |\n",
      "|    iterations      | 743     |\n",
      "|    time_elapsed    | 3859    |\n",
      "|    total_timesteps | 6086656 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 744          |\n",
      "|    time_elapsed         | 3863         |\n",
      "|    total_timesteps      | 6094848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019946466 |\n",
      "|    clip_fraction        | 0.00999      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.452       |\n",
      "|    explained_variance   | 0.0286       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 943          |\n",
      "|    n_updates            | 10990        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 745          |\n",
      "|    time_elapsed         | 3867         |\n",
      "|    total_timesteps      | 6103040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028760047 |\n",
      "|    clip_fraction        | 0.0218       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.444       |\n",
      "|    explained_variance   | 0.0292       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 943          |\n",
      "|    n_updates            | 11000        |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 746          |\n",
      "|    time_elapsed         | 3872         |\n",
      "|    total_timesteps      | 6111232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021204236 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.433       |\n",
      "|    explained_variance   | 0.04         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 11010        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 747          |\n",
      "|    time_elapsed         | 3877         |\n",
      "|    total_timesteps      | 6119424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021224485 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.437       |\n",
      "|    explained_variance   | 0.0374       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 864          |\n",
      "|    n_updates            | 11020        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6120000, episode_reward=622.20 +/- 66.55\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 622          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023076949 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.463       |\n",
      "|    explained_variance   | 0.0595       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 990          |\n",
      "|    n_updates            | 11030        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1575    |\n",
      "|    iterations      | 748     |\n",
      "|    time_elapsed    | 3889    |\n",
      "|    total_timesteps | 6127616 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1575        |\n",
      "|    iterations           | 749         |\n",
      "|    time_elapsed         | 3894        |\n",
      "|    total_timesteps      | 6135808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002169354 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.462      |\n",
      "|    explained_variance   | 0.0193      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 984         |\n",
      "|    n_updates            | 11040       |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    value_loss           | 1.75e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1575         |\n",
      "|    iterations           | 750          |\n",
      "|    time_elapsed         | 3899         |\n",
      "|    total_timesteps      | 6144000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024136289 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.456       |\n",
      "|    explained_variance   | 0.0178       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 743          |\n",
      "|    n_updates            | 11050        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1575         |\n",
      "|    iterations           | 751          |\n",
      "|    time_elapsed         | 3904         |\n",
      "|    total_timesteps      | 6152192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017255195 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.446       |\n",
      "|    explained_variance   | 0.0605       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 858          |\n",
      "|    n_updates            | 11060        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    value_loss           | 1.91e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6160000, episode_reward=615.80 +/- 104.25\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 616          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6160000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020237216 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.0676       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 759          |\n",
      "|    n_updates            | 11070        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1572    |\n",
      "|    iterations      | 752     |\n",
      "|    time_elapsed    | 3918    |\n",
      "|    total_timesteps | 6160384 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1572        |\n",
      "|    iterations           | 753         |\n",
      "|    time_elapsed         | 3923        |\n",
      "|    total_timesteps      | 6168576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002276754 |\n",
      "|    clip_fraction        | 0.0109      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.46       |\n",
      "|    explained_variance   | 0.0583      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.05e+03    |\n",
      "|    n_updates            | 11080       |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    value_loss           | 1.73e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1572         |\n",
      "|    iterations           | 754          |\n",
      "|    time_elapsed         | 3928         |\n",
      "|    total_timesteps      | 6176768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023188214 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.446       |\n",
      "|    explained_variance   | 0.0891       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 904          |\n",
      "|    n_updates            | 11090        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1572        |\n",
      "|    iterations           | 755         |\n",
      "|    time_elapsed         | 3932        |\n",
      "|    total_timesteps      | 6184960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002223265 |\n",
      "|    clip_fraction        | 0.0138      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.452      |\n",
      "|    explained_variance   | 0.0746      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 748         |\n",
      "|    n_updates            | 11100       |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    value_loss           | 1.64e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1573         |\n",
      "|    iterations           | 756          |\n",
      "|    time_elapsed         | 3936         |\n",
      "|    total_timesteps      | 6193152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023846012 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.449       |\n",
      "|    explained_variance   | 0.0484       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 11110        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6200000, episode_reward=612.20 +/- 55.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 612          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020703594 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.0208       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 884          |\n",
      "|    n_updates            | 11120        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1570    |\n",
      "|    iterations      | 757     |\n",
      "|    time_elapsed    | 3948    |\n",
      "|    total_timesteps | 6201344 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 758          |\n",
      "|    time_elapsed         | 3952         |\n",
      "|    total_timesteps      | 6209536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021302095 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.469       |\n",
      "|    explained_variance   | 0.0511       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 906          |\n",
      "|    n_updates            | 11130        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 759          |\n",
      "|    time_elapsed         | 3956         |\n",
      "|    total_timesteps      | 6217728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023292666 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.463       |\n",
      "|    explained_variance   | 0.0391       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 11140        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1572         |\n",
      "|    iterations           | 760          |\n",
      "|    time_elapsed         | 3960         |\n",
      "|    total_timesteps      | 6225920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026538083 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.0364       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 828          |\n",
      "|    n_updates            | 11150        |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1572         |\n",
      "|    iterations           | 761          |\n",
      "|    time_elapsed         | 3964         |\n",
      "|    total_timesteps      | 6234112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017815857 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.438       |\n",
      "|    explained_variance   | 0.0412       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 844          |\n",
      "|    n_updates            | 11160        |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6240000, episode_reward=615.80 +/- 58.24\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 616          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6240000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017937007 |\n",
      "|    clip_fraction        | 0.00906      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.0313       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 613          |\n",
      "|    n_updates            | 11170        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1570    |\n",
      "|    iterations      | 762     |\n",
      "|    time_elapsed    | 3975    |\n",
      "|    total_timesteps | 6242304 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 763          |\n",
      "|    time_elapsed         | 3979         |\n",
      "|    total_timesteps      | 6250496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020751166 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.438       |\n",
      "|    explained_variance   | 0.0377       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 952          |\n",
      "|    n_updates            | 11180        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 764          |\n",
      "|    time_elapsed         | 3983         |\n",
      "|    total_timesteps      | 6258688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015970692 |\n",
      "|    clip_fraction        | 0.00522      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.435       |\n",
      "|    explained_variance   | 0.00084      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 876          |\n",
      "|    n_updates            | 11190        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 765          |\n",
      "|    time_elapsed         | 3987         |\n",
      "|    total_timesteps      | 6266880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021839747 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.443       |\n",
      "|    explained_variance   | 0.0195       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 713          |\n",
      "|    n_updates            | 11200        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1572         |\n",
      "|    iterations           | 766          |\n",
      "|    time_elapsed         | 3991         |\n",
      "|    total_timesteps      | 6275072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026370073 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.441       |\n",
      "|    explained_variance   | 0.046        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 832          |\n",
      "|    n_updates            | 11210        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6280000, episode_reward=615.20 +/- 103.68\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 615          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018820373 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.44        |\n",
      "|    explained_variance   | 0.0355       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 855          |\n",
      "|    n_updates            | 11220        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1569    |\n",
      "|    iterations      | 767     |\n",
      "|    time_elapsed    | 4002    |\n",
      "|    total_timesteps | 6283264 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1570        |\n",
      "|    iterations           | 768         |\n",
      "|    time_elapsed         | 4006        |\n",
      "|    total_timesteps      | 6291456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001526475 |\n",
      "|    clip_fraction        | 0.00714     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.432      |\n",
      "|    explained_variance   | 0.0364      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 738         |\n",
      "|    n_updates            | 11230       |\n",
      "|    policy_gradient_loss | -0.00264    |\n",
      "|    value_loss           | 1.95e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 769          |\n",
      "|    time_elapsed         | 4010         |\n",
      "|    total_timesteps      | 6299648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020097764 |\n",
      "|    clip_fraction        | 0.00897      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.439       |\n",
      "|    explained_variance   | 0.0173       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 757          |\n",
      "|    n_updates            | 11240        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 770          |\n",
      "|    time_elapsed         | 4014         |\n",
      "|    total_timesteps      | 6307840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020178363 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.0385       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 11250        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 771          |\n",
      "|    time_elapsed         | 4018         |\n",
      "|    total_timesteps      | 6316032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027504677 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.426       |\n",
      "|    explained_variance   | 0.0186       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 609          |\n",
      "|    n_updates            | 11260        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6320000, episode_reward=608.40 +/- 97.08\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 608          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6320000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018022512 |\n",
      "|    clip_fraction        | 0.0087       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.428       |\n",
      "|    explained_variance   | 0.0463       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 861          |\n",
      "|    n_updates            | 11270        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1569    |\n",
      "|    iterations      | 772     |\n",
      "|    time_elapsed    | 4028    |\n",
      "|    total_timesteps | 6324224 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 773          |\n",
      "|    time_elapsed         | 4032         |\n",
      "|    total_timesteps      | 6332416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019948087 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.433       |\n",
      "|    explained_variance   | 0.0209       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 944          |\n",
      "|    n_updates            | 11280        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 774          |\n",
      "|    time_elapsed         | 4036         |\n",
      "|    total_timesteps      | 6340608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019316094 |\n",
      "|    clip_fraction        | 0.00989      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.427       |\n",
      "|    explained_variance   | 0.0443       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 800          |\n",
      "|    n_updates            | 11290        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 775          |\n",
      "|    time_elapsed         | 4040         |\n",
      "|    total_timesteps      | 6348800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017959358 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.433       |\n",
      "|    explained_variance   | 0.0443       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 768          |\n",
      "|    n_updates            | 11300        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1571        |\n",
      "|    iterations           | 776         |\n",
      "|    time_elapsed         | 4044        |\n",
      "|    total_timesteps      | 6356992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002185104 |\n",
      "|    clip_fraction        | 0.0144      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.437      |\n",
      "|    explained_variance   | 0.0515      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 799         |\n",
      "|    n_updates            | 11310       |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    value_loss           | 1.8e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6360000, episode_reward=599.20 +/- 116.92\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 599          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6360000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021477905 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.0437       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 797          |\n",
      "|    n_updates            | 11320        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1569    |\n",
      "|    iterations      | 777     |\n",
      "|    time_elapsed    | 4055    |\n",
      "|    total_timesteps | 6365184 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 778          |\n",
      "|    time_elapsed         | 4059         |\n",
      "|    total_timesteps      | 6373376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024032556 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.435       |\n",
      "|    explained_variance   | 0.015        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 777          |\n",
      "|    n_updates            | 11330        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 779          |\n",
      "|    time_elapsed         | 4063         |\n",
      "|    total_timesteps      | 6381568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022022545 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.437       |\n",
      "|    explained_variance   | 0.0695       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 11340        |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 780          |\n",
      "|    time_elapsed         | 4067         |\n",
      "|    total_timesteps      | 6389760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022967225 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.419       |\n",
      "|    explained_variance   | 0.0601       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 723          |\n",
      "|    n_updates            | 11350        |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 781          |\n",
      "|    time_elapsed         | 4070         |\n",
      "|    total_timesteps      | 6397952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021521535 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.449       |\n",
      "|    explained_variance   | 0.0135       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 603          |\n",
      "|    n_updates            | 11360        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6400000, episode_reward=599.00 +/- 99.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 599          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6400000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023352215 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.438       |\n",
      "|    explained_variance   | 0.0169       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 11370        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1569    |\n",
      "|    iterations      | 782     |\n",
      "|    time_elapsed    | 4081    |\n",
      "|    total_timesteps | 6406144 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 783          |\n",
      "|    time_elapsed         | 4085         |\n",
      "|    total_timesteps      | 6414336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020608804 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.438       |\n",
      "|    explained_variance   | 0.0189       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1e+03        |\n",
      "|    n_updates            | 11380        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 784          |\n",
      "|    time_elapsed         | 4089         |\n",
      "|    total_timesteps      | 6422528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023309377 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.441       |\n",
      "|    explained_variance   | 0.03         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 687          |\n",
      "|    n_updates            | 11390        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 785          |\n",
      "|    time_elapsed         | 4093         |\n",
      "|    total_timesteps      | 6430720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028092368 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.429       |\n",
      "|    explained_variance   | 0.0368       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 11400        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1571        |\n",
      "|    iterations           | 786         |\n",
      "|    time_elapsed         | 4097        |\n",
      "|    total_timesteps      | 6438912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002119071 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.435      |\n",
      "|    explained_variance   | 0.0275      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 659         |\n",
      "|    n_updates            | 11410       |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    value_loss           | 1.62e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6440000, episode_reward=598.00 +/- 62.64\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 598         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 6440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001922101 |\n",
      "|    clip_fraction        | 0.0111      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.434      |\n",
      "|    explained_variance   | 0.0546      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 962         |\n",
      "|    n_updates            | 11420       |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1569    |\n",
      "|    iterations      | 787     |\n",
      "|    time_elapsed    | 4108    |\n",
      "|    total_timesteps | 6447104 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 788          |\n",
      "|    time_elapsed         | 4112         |\n",
      "|    total_timesteps      | 6455296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024201772 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.445       |\n",
      "|    explained_variance   | 0.00833      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 885          |\n",
      "|    n_updates            | 11430        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 789          |\n",
      "|    time_elapsed         | 4116         |\n",
      "|    total_timesteps      | 6463488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017789368 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.441       |\n",
      "|    explained_variance   | 0.0425       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 771          |\n",
      "|    n_updates            | 11440        |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 790          |\n",
      "|    time_elapsed         | 4120         |\n",
      "|    total_timesteps      | 6471680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021666046 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.448       |\n",
      "|    explained_variance   | 0.00493      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 674          |\n",
      "|    n_updates            | 11450        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1570        |\n",
      "|    iterations           | 791         |\n",
      "|    time_elapsed         | 4125        |\n",
      "|    total_timesteps      | 6479872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002557616 |\n",
      "|    clip_fraction        | 0.0157      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.468      |\n",
      "|    explained_variance   | 0.0214      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 698         |\n",
      "|    n_updates            | 11460       |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6480000, episode_reward=610.40 +/- 58.79\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 610          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6480000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020199865 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.445       |\n",
      "|    explained_variance   | -0.00237     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 706          |\n",
      "|    n_updates            | 11470        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1568    |\n",
      "|    iterations      | 792     |\n",
      "|    time_elapsed    | 4136    |\n",
      "|    total_timesteps | 6488064 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 793          |\n",
      "|    time_elapsed         | 4140         |\n",
      "|    total_timesteps      | 6496256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016409825 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.473       |\n",
      "|    explained_variance   | 0.0427       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 729          |\n",
      "|    n_updates            | 11480        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 794          |\n",
      "|    time_elapsed         | 4144         |\n",
      "|    total_timesteps      | 6504448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016837453 |\n",
      "|    clip_fraction        | 0.00762      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 0.0258       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 632          |\n",
      "|    n_updates            | 11490        |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 795          |\n",
      "|    time_elapsed         | 4148         |\n",
      "|    total_timesteps      | 6512640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019436602 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.439       |\n",
      "|    explained_variance   | 0.0505       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 772          |\n",
      "|    n_updates            | 11500        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6520000, episode_reward=609.00 +/- 72.92\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 609          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6520000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020833858 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.437       |\n",
      "|    explained_variance   | 0.0619       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 11510        |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1567    |\n",
      "|    iterations      | 796     |\n",
      "|    time_elapsed    | 4158    |\n",
      "|    total_timesteps | 6520832 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 797          |\n",
      "|    time_elapsed         | 4162         |\n",
      "|    total_timesteps      | 6529024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024332027 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.462       |\n",
      "|    explained_variance   | 0.0372       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 11520        |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 798          |\n",
      "|    time_elapsed         | 4166         |\n",
      "|    total_timesteps      | 6537216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025586793 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.452       |\n",
      "|    explained_variance   | 0.0216       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 878          |\n",
      "|    n_updates            | 11530        |\n",
      "|    policy_gradient_loss | -0.00447     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 799          |\n",
      "|    time_elapsed         | 4170         |\n",
      "|    total_timesteps      | 6545408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019844752 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.448       |\n",
      "|    explained_variance   | 0.0217       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 792          |\n",
      "|    n_updates            | 11540        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 800          |\n",
      "|    time_elapsed         | 4174         |\n",
      "|    total_timesteps      | 6553600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026209312 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.0492       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 691          |\n",
      "|    n_updates            | 11550        |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6560000, episode_reward=579.20 +/- 158.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 579          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022213573 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | 0.0389       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1e+03        |\n",
      "|    n_updates            | 11560        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1567    |\n",
      "|    iterations      | 801     |\n",
      "|    time_elapsed    | 4184    |\n",
      "|    total_timesteps | 6561792 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1568        |\n",
      "|    iterations           | 802         |\n",
      "|    time_elapsed         | 4188        |\n",
      "|    total_timesteps      | 6569984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002658663 |\n",
      "|    clip_fraction        | 0.0176      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.466      |\n",
      "|    explained_variance   | 0.00571     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 731         |\n",
      "|    n_updates            | 11570       |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    value_loss           | 1.66e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 803          |\n",
      "|    time_elapsed         | 4192         |\n",
      "|    total_timesteps      | 6578176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023748816 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.471       |\n",
      "|    explained_variance   | 0.0306       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 706          |\n",
      "|    n_updates            | 11580        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 804          |\n",
      "|    time_elapsed         | 4196         |\n",
      "|    total_timesteps      | 6586368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029885692 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.0623       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 785          |\n",
      "|    n_updates            | 11590        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1570        |\n",
      "|    iterations           | 805         |\n",
      "|    time_elapsed         | 4200        |\n",
      "|    total_timesteps      | 6594560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002187486 |\n",
      "|    clip_fraction        | 0.0118      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.472      |\n",
      "|    explained_variance   | 0.0569      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 596         |\n",
      "|    n_updates            | 11600       |\n",
      "|    policy_gradient_loss | -0.00314    |\n",
      "|    value_loss           | 1.65e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6600000, episode_reward=612.40 +/- 51.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 612          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6600000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017899186 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.473       |\n",
      "|    explained_variance   | 0.0377       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 597          |\n",
      "|    n_updates            | 11610        |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1568    |\n",
      "|    iterations      | 806     |\n",
      "|    time_elapsed    | 4210    |\n",
      "|    total_timesteps | 6602752 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 807          |\n",
      "|    time_elapsed         | 4214         |\n",
      "|    total_timesteps      | 6610944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027779515 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.0283       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 801          |\n",
      "|    n_updates            | 11620        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 808          |\n",
      "|    time_elapsed         | 4218         |\n",
      "|    total_timesteps      | 6619136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025315834 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0412       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 803          |\n",
      "|    n_updates            | 11630        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 809          |\n",
      "|    time_elapsed         | 4222         |\n",
      "|    total_timesteps      | 6627328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026279653 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.023        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 743          |\n",
      "|    n_updates            | 11640        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1569        |\n",
      "|    iterations           | 810         |\n",
      "|    time_elapsed         | 4226        |\n",
      "|    total_timesteps      | 6635520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002817853 |\n",
      "|    clip_fraction        | 0.0205      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.481      |\n",
      "|    explained_variance   | 0.0323      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 930         |\n",
      "|    n_updates            | 11650       |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    value_loss           | 1.91e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6640000, episode_reward=624.40 +/- 44.50\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 624          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6640000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023431797 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.0535       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 880          |\n",
      "|    n_updates            | 11660        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1568    |\n",
      "|    iterations      | 811     |\n",
      "|    time_elapsed    | 4237    |\n",
      "|    total_timesteps | 6643712 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 812          |\n",
      "|    time_elapsed         | 4240         |\n",
      "|    total_timesteps      | 6651904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024018185 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.457       |\n",
      "|    explained_variance   | 0.0543       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 443          |\n",
      "|    n_updates            | 11670        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 813          |\n",
      "|    time_elapsed         | 4244         |\n",
      "|    total_timesteps      | 6660096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029917932 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.47        |\n",
      "|    explained_variance   | 0.0838       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 916          |\n",
      "|    n_updates            | 11680        |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 814          |\n",
      "|    time_elapsed         | 4248         |\n",
      "|    total_timesteps      | 6668288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025218632 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | 0.0441       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 851          |\n",
      "|    n_updates            | 11690        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 815          |\n",
      "|    time_elapsed         | 4252         |\n",
      "|    total_timesteps      | 6676480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029059723 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.0556       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 950          |\n",
      "|    n_updates            | 11700        |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6680000, episode_reward=612.80 +/- 58.99\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 613          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6680000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023227953 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.489       |\n",
      "|    explained_variance   | 0.049        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 778          |\n",
      "|    n_updates            | 11710        |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1568    |\n",
      "|    iterations      | 816     |\n",
      "|    time_elapsed    | 4262    |\n",
      "|    total_timesteps | 6684672 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 817          |\n",
      "|    time_elapsed         | 4266         |\n",
      "|    total_timesteps      | 6692864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022539617 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.471       |\n",
      "|    explained_variance   | 0.052        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 766          |\n",
      "|    n_updates            | 11720        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 818          |\n",
      "|    time_elapsed         | 4270         |\n",
      "|    total_timesteps      | 6701056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027098693 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.469       |\n",
      "|    explained_variance   | 0.0462       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 970          |\n",
      "|    n_updates            | 11730        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 819          |\n",
      "|    time_elapsed         | 4274         |\n",
      "|    total_timesteps      | 6709248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022723642 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.457       |\n",
      "|    explained_variance   | 0.0501       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 636          |\n",
      "|    n_updates            | 11740        |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 820          |\n",
      "|    time_elapsed         | 4278         |\n",
      "|    total_timesteps      | 6717440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024912483 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.464       |\n",
      "|    explained_variance   | 0.0161       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 827          |\n",
      "|    n_updates            | 11750        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6720000, episode_reward=619.80 +/- 62.14\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 620          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6720000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024525053 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.456       |\n",
      "|    explained_variance   | 0.0604       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 11760        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1568    |\n",
      "|    iterations      | 821     |\n",
      "|    time_elapsed    | 4288    |\n",
      "|    total_timesteps | 6725632 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 822          |\n",
      "|    time_elapsed         | 4291         |\n",
      "|    total_timesteps      | 6733824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021719849 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.445       |\n",
      "|    explained_variance   | 0.0613       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 786          |\n",
      "|    n_updates            | 11770        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1569        |\n",
      "|    iterations           | 823         |\n",
      "|    time_elapsed         | 4295        |\n",
      "|    total_timesteps      | 6742016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001864221 |\n",
      "|    clip_fraction        | 0.00728     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.446      |\n",
      "|    explained_variance   | 0.0455      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 937         |\n",
      "|    n_updates            | 11780       |\n",
      "|    policy_gradient_loss | -0.00243    |\n",
      "|    value_loss           | 1.65e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 824          |\n",
      "|    time_elapsed         | 4299         |\n",
      "|    total_timesteps      | 6750208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019375251 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.441       |\n",
      "|    explained_variance   | 0.0769       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 11790        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 825          |\n",
      "|    time_elapsed         | 4303         |\n",
      "|    total_timesteps      | 6758400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020990605 |\n",
      "|    clip_fraction        | 0.00945      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.438       |\n",
      "|    explained_variance   | 0.034        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 811          |\n",
      "|    n_updates            | 11800        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6760000, episode_reward=623.20 +/- 58.73\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 623          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6760000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024297321 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.454       |\n",
      "|    explained_variance   | 0.0259       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1e+03        |\n",
      "|    n_updates            | 11810        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1568    |\n",
      "|    iterations      | 826     |\n",
      "|    time_elapsed    | 4313    |\n",
      "|    total_timesteps | 6766592 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 827          |\n",
      "|    time_elapsed         | 4317         |\n",
      "|    total_timesteps      | 6774784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021994752 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.0106       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 703          |\n",
      "|    n_updates            | 11820        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 828          |\n",
      "|    time_elapsed         | 4320         |\n",
      "|    total_timesteps      | 6782976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017041309 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.0603       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 752          |\n",
      "|    n_updates            | 11830        |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 829          |\n",
      "|    time_elapsed         | 4324         |\n",
      "|    total_timesteps      | 6791168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019105289 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.468       |\n",
      "|    explained_variance   | 0.021        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 566          |\n",
      "|    n_updates            | 11840        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 830          |\n",
      "|    time_elapsed         | 4328         |\n",
      "|    total_timesteps      | 6799360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026142858 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.0301       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 616          |\n",
      "|    n_updates            | 11850        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6800000, episode_reward=604.60 +/- 94.89\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 605          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6800000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019935623 |\n",
      "|    clip_fraction        | 0.0077       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.0415       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 983          |\n",
      "|    n_updates            | 11860        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1569    |\n",
      "|    iterations      | 831     |\n",
      "|    time_elapsed    | 4338    |\n",
      "|    total_timesteps | 6807552 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 832          |\n",
      "|    time_elapsed         | 4342         |\n",
      "|    total_timesteps      | 6815744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025089346 |\n",
      "|    clip_fraction        | 0.0216       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.0215       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 757          |\n",
      "|    n_updates            | 11870        |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1570       |\n",
      "|    iterations           | 833        |\n",
      "|    time_elapsed         | 4346       |\n",
      "|    total_timesteps      | 6823936    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00232653 |\n",
      "|    clip_fraction        | 0.0151     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.455     |\n",
      "|    explained_variance   | 0.0354     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 767        |\n",
      "|    n_updates            | 11880      |\n",
      "|    policy_gradient_loss | -0.00359   |\n",
      "|    value_loss           | 1.68e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 834          |\n",
      "|    time_elapsed         | 4350         |\n",
      "|    total_timesteps      | 6832128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023655342 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.0149       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 660          |\n",
      "|    n_updates            | 11890        |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6840000, episode_reward=618.60 +/- 51.26\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 619          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6840000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017320269 |\n",
      "|    clip_fraction        | 0.00974      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.441       |\n",
      "|    explained_variance   | 0.0307       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 11900        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1568    |\n",
      "|    iterations      | 835     |\n",
      "|    time_elapsed    | 4360    |\n",
      "|    total_timesteps | 6840320 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 836          |\n",
      "|    time_elapsed         | 4364         |\n",
      "|    total_timesteps      | 6848512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017642786 |\n",
      "|    clip_fraction        | 0.00848      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.0445       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 11910        |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 837          |\n",
      "|    time_elapsed         | 4367         |\n",
      "|    total_timesteps      | 6856704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019939016 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.441       |\n",
      "|    explained_variance   | 0.0264       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 762          |\n",
      "|    n_updates            | 11920        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 838          |\n",
      "|    time_elapsed         | 4371         |\n",
      "|    total_timesteps      | 6864896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022463782 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.0306       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 785          |\n",
      "|    n_updates            | 11930        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1570        |\n",
      "|    iterations           | 839         |\n",
      "|    time_elapsed         | 4375        |\n",
      "|    total_timesteps      | 6873088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002666012 |\n",
      "|    clip_fraction        | 0.0191      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.465      |\n",
      "|    explained_variance   | 0.0385      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 586         |\n",
      "|    n_updates            | 11940       |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    value_loss           | 1.76e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6880000, episode_reward=620.80 +/- 59.16\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 621          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6880000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022683558 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.454       |\n",
      "|    explained_variance   | 0.0405       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 855          |\n",
      "|    n_updates            | 11950        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1569    |\n",
      "|    iterations      | 840     |\n",
      "|    time_elapsed    | 4385    |\n",
      "|    total_timesteps | 6881280 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1569        |\n",
      "|    iterations           | 841         |\n",
      "|    time_elapsed         | 4389        |\n",
      "|    total_timesteps      | 6889472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002158365 |\n",
      "|    clip_fraction        | 0.0122      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.472      |\n",
      "|    explained_variance   | 0.00966     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 999         |\n",
      "|    n_updates            | 11960       |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1570        |\n",
      "|    iterations           | 842         |\n",
      "|    time_elapsed         | 4392        |\n",
      "|    total_timesteps      | 6897664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002339645 |\n",
      "|    clip_fraction        | 0.0104      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.486      |\n",
      "|    explained_variance   | 0.0164      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 723         |\n",
      "|    n_updates            | 11970       |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1570        |\n",
      "|    iterations           | 843         |\n",
      "|    time_elapsed         | 4396        |\n",
      "|    total_timesteps      | 6905856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002176506 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.486      |\n",
      "|    explained_variance   | 0.0285      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 933         |\n",
      "|    n_updates            | 11980       |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    value_loss           | 1.8e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 844          |\n",
      "|    time_elapsed         | 4400         |\n",
      "|    total_timesteps      | 6914048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018111954 |\n",
      "|    clip_fraction        | 0.00911      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.489       |\n",
      "|    explained_variance   | 0.0264       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 697          |\n",
      "|    n_updates            | 11990        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6920000, episode_reward=609.80 +/- 58.12\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 610         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 6920000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001931323 |\n",
      "|    clip_fraction        | 0.0114      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.468      |\n",
      "|    explained_variance   | 0.0504      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 698         |\n",
      "|    n_updates            | 12000       |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    value_loss           | 1.65e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1569    |\n",
      "|    iterations      | 845     |\n",
      "|    time_elapsed    | 4410    |\n",
      "|    total_timesteps | 6922240 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 846          |\n",
      "|    time_elapsed         | 4414         |\n",
      "|    total_timesteps      | 6930432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023064795 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.472       |\n",
      "|    explained_variance   | 0.0591       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.21e+03     |\n",
      "|    n_updates            | 12010        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 847          |\n",
      "|    time_elapsed         | 4418         |\n",
      "|    total_timesteps      | 6938624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023963652 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.0385       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 695          |\n",
      "|    n_updates            | 12020        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 848          |\n",
      "|    time_elapsed         | 4422         |\n",
      "|    total_timesteps      | 6946816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021485344 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | 0.0495       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 762          |\n",
      "|    n_updates            | 12030        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 849          |\n",
      "|    time_elapsed         | 4426         |\n",
      "|    total_timesteps      | 6955008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030881618 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.473       |\n",
      "|    explained_variance   | 0.0407       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 871          |\n",
      "|    n_updates            | 12040        |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6960000, episode_reward=638.40 +/- 65.10\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 638          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6960000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022516246 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.443       |\n",
      "|    explained_variance   | 0.0558       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 918          |\n",
      "|    n_updates            | 12050        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1569    |\n",
      "|    iterations      | 850     |\n",
      "|    time_elapsed    | 4436    |\n",
      "|    total_timesteps | 6963200 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 851          |\n",
      "|    time_elapsed         | 4440         |\n",
      "|    total_timesteps      | 6971392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020167732 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.462       |\n",
      "|    explained_variance   | 0.0284       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 862          |\n",
      "|    n_updates            | 12060        |\n",
      "|    policy_gradient_loss | -0.0029      |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 852          |\n",
      "|    time_elapsed         | 4443         |\n",
      "|    total_timesteps      | 6979584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026969863 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.464       |\n",
      "|    explained_variance   | 0.0424       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 798          |\n",
      "|    n_updates            | 12070        |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 853          |\n",
      "|    time_elapsed         | 4447         |\n",
      "|    total_timesteps      | 6987776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024023606 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.467       |\n",
      "|    explained_variance   | 0.0523       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 12080        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 854          |\n",
      "|    time_elapsed         | 4451         |\n",
      "|    total_timesteps      | 6995968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023297248 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.0341       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 501          |\n",
      "|    n_updates            | 12090        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7000000, episode_reward=632.40 +/- 54.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 632          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025789824 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 0.0481       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 888          |\n",
      "|    n_updates            | 12100        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1569    |\n",
      "|    iterations      | 855     |\n",
      "|    time_elapsed    | 4461    |\n",
      "|    total_timesteps | 7004160 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 856          |\n",
      "|    time_elapsed         | 4465         |\n",
      "|    total_timesteps      | 7012352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023687584 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | 0.0658       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 12110        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 857          |\n",
      "|    time_elapsed         | 4469         |\n",
      "|    total_timesteps      | 7020544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028689376 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.0488       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 861          |\n",
      "|    n_updates            | 12120        |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 858          |\n",
      "|    time_elapsed         | 4473         |\n",
      "|    total_timesteps      | 7028736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020956395 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.0992       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 874          |\n",
      "|    n_updates            | 12130        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1571        |\n",
      "|    iterations           | 859         |\n",
      "|    time_elapsed         | 4477        |\n",
      "|    total_timesteps      | 7036928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002540762 |\n",
      "|    clip_fraction        | 0.0174      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.461      |\n",
      "|    explained_variance   | 0.0385      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1e+03       |\n",
      "|    n_updates            | 12140       |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=7040000, episode_reward=637.00 +/- 56.54\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 637          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7040000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024205316 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.456       |\n",
      "|    explained_variance   | 0.0501       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1e+03        |\n",
      "|    n_updates            | 12150        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1569    |\n",
      "|    iterations      | 860     |\n",
      "|    time_elapsed    | 4487    |\n",
      "|    total_timesteps | 7045120 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 861          |\n",
      "|    time_elapsed         | 4491         |\n",
      "|    total_timesteps      | 7053312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022116038 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.443       |\n",
      "|    explained_variance   | 0.0295       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 840          |\n",
      "|    n_updates            | 12160        |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 862          |\n",
      "|    time_elapsed         | 4495         |\n",
      "|    total_timesteps      | 7061504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021007014 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.0383       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 880          |\n",
      "|    n_updates            | 12170        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 863          |\n",
      "|    time_elapsed         | 4499         |\n",
      "|    total_timesteps      | 7069696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026192842 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.469       |\n",
      "|    explained_variance   | 0.0627       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 730          |\n",
      "|    n_updates            | 12180        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 864          |\n",
      "|    time_elapsed         | 4503         |\n",
      "|    total_timesteps      | 7077888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024068924 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.457       |\n",
      "|    explained_variance   | 0.0241       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 804          |\n",
      "|    n_updates            | 12190        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7080000, episode_reward=597.20 +/- 130.32\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 597         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 7080000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001846486 |\n",
      "|    clip_fraction        | 0.00801     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.457      |\n",
      "|    explained_variance   | 0.0196      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 972         |\n",
      "|    n_updates            | 12200       |\n",
      "|    policy_gradient_loss | -0.00263    |\n",
      "|    value_loss           | 1.72e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1569    |\n",
      "|    iterations      | 865     |\n",
      "|    time_elapsed    | 4513    |\n",
      "|    total_timesteps | 7086080 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 866          |\n",
      "|    time_elapsed         | 4518         |\n",
      "|    total_timesteps      | 7094272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022594798 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.467       |\n",
      "|    explained_variance   | 0.0247       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 630          |\n",
      "|    n_updates            | 12210        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 867          |\n",
      "|    time_elapsed         | 4523         |\n",
      "|    total_timesteps      | 7102464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019750965 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.0242       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 776          |\n",
      "|    n_updates            | 12220        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1570        |\n",
      "|    iterations           | 868         |\n",
      "|    time_elapsed         | 4527        |\n",
      "|    total_timesteps      | 7110656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001728632 |\n",
      "|    clip_fraction        | 0.00696     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.468      |\n",
      "|    explained_variance   | 0.0242      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 768         |\n",
      "|    n_updates            | 12230       |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    value_loss           | 1.78e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 869          |\n",
      "|    time_elapsed         | 4531         |\n",
      "|    total_timesteps      | 7118848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022672934 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.462       |\n",
      "|    explained_variance   | 0.0422       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 567          |\n",
      "|    n_updates            | 12240        |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7120000, episode_reward=624.60 +/- 56.82\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 625          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019593844 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.464       |\n",
      "|    explained_variance   | 0.00743      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 961          |\n",
      "|    n_updates            | 12250        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1569    |\n",
      "|    iterations      | 870     |\n",
      "|    time_elapsed    | 4542    |\n",
      "|    total_timesteps | 7127040 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 871          |\n",
      "|    time_elapsed         | 4545         |\n",
      "|    total_timesteps      | 7135232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021584225 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.0561       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 678          |\n",
      "|    n_updates            | 12260        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 872          |\n",
      "|    time_elapsed         | 4550         |\n",
      "|    total_timesteps      | 7143424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018952023 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.0305       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 680          |\n",
      "|    n_updates            | 12270        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1570        |\n",
      "|    iterations           | 873         |\n",
      "|    time_elapsed         | 4554        |\n",
      "|    total_timesteps      | 7151616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002106233 |\n",
      "|    clip_fraction        | 0.0127      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.481      |\n",
      "|    explained_variance   | 0.046       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 983         |\n",
      "|    n_updates            | 12280       |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    value_loss           | 1.65e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 874          |\n",
      "|    time_elapsed         | 4558         |\n",
      "|    total_timesteps      | 7159808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027622806 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.469       |\n",
      "|    explained_variance   | 0.052        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 606          |\n",
      "|    n_updates            | 12290        |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7160000, episode_reward=617.20 +/- 57.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 617         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 7160000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002654493 |\n",
      "|    clip_fraction        | 0.0185      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.47       |\n",
      "|    explained_variance   | 0.0281      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 12300       |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    value_loss           | 1.71e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1568    |\n",
      "|    iterations      | 875     |\n",
      "|    time_elapsed    | 4571    |\n",
      "|    total_timesteps | 7168000 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 876          |\n",
      "|    time_elapsed         | 4575         |\n",
      "|    total_timesteps      | 7176192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021669203 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.467       |\n",
      "|    explained_variance   | 0.0256       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 815          |\n",
      "|    n_updates            | 12310        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 877          |\n",
      "|    time_elapsed         | 4579         |\n",
      "|    total_timesteps      | 7184384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018780783 |\n",
      "|    clip_fraction        | 0.00919      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.477       |\n",
      "|    explained_variance   | 0.0271       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 575          |\n",
      "|    n_updates            | 12320        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 878          |\n",
      "|    time_elapsed         | 4584         |\n",
      "|    total_timesteps      | 7192576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022319737 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.044        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 12330        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7200000, episode_reward=602.80 +/- 53.82\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 603          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026144825 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.481       |\n",
      "|    explained_variance   | 0.0241       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 724          |\n",
      "|    n_updates            | 12340        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    value_loss           | 1.58e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1566    |\n",
      "|    iterations      | 879     |\n",
      "|    time_elapsed    | 4595    |\n",
      "|    total_timesteps | 7200768 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 880          |\n",
      "|    time_elapsed         | 4599         |\n",
      "|    total_timesteps      | 7208960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023852056 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.477       |\n",
      "|    explained_variance   | 0.0226       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 633          |\n",
      "|    n_updates            | 12350        |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    value_loss           | 1.53e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 881          |\n",
      "|    time_elapsed         | 4603         |\n",
      "|    total_timesteps      | 7217152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030616918 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.0236       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 947          |\n",
      "|    n_updates            | 12360        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1568        |\n",
      "|    iterations           | 882         |\n",
      "|    time_elapsed         | 4607        |\n",
      "|    total_timesteps      | 7225344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002803116 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.482      |\n",
      "|    explained_variance   | 0.0404      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 560         |\n",
      "|    n_updates            | 12370       |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    value_loss           | 1.69e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 883          |\n",
      "|    time_elapsed         | 4611         |\n",
      "|    total_timesteps      | 7233536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020278885 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.0828       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 751          |\n",
      "|    n_updates            | 12380        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7240000, episode_reward=600.40 +/- 54.48\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 600         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 7240000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002736302 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.483      |\n",
      "|    explained_variance   | 0.0701      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 767         |\n",
      "|    n_updates            | 12390       |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    value_loss           | 1.59e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1566    |\n",
      "|    iterations      | 884     |\n",
      "|    time_elapsed    | 4622    |\n",
      "|    total_timesteps | 7241728 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1567        |\n",
      "|    iterations           | 885         |\n",
      "|    time_elapsed         | 4626        |\n",
      "|    total_timesteps      | 7249920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002126863 |\n",
      "|    clip_fraction        | 0.0107      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.489      |\n",
      "|    explained_variance   | 0.0408      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 981         |\n",
      "|    n_updates            | 12400       |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    value_loss           | 1.77e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 886          |\n",
      "|    time_elapsed         | 4630         |\n",
      "|    total_timesteps      | 7258112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019196616 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.477       |\n",
      "|    explained_variance   | 0.0668       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 872          |\n",
      "|    n_updates            | 12410        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 887          |\n",
      "|    time_elapsed         | 4634         |\n",
      "|    total_timesteps      | 7266304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024549009 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.485       |\n",
      "|    explained_variance   | 0.0596       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 721          |\n",
      "|    n_updates            | 12420        |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1568        |\n",
      "|    iterations           | 888         |\n",
      "|    time_elapsed         | 4638        |\n",
      "|    total_timesteps      | 7274496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002351508 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.488      |\n",
      "|    explained_variance   | -0.0175     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 944         |\n",
      "|    n_updates            | 12430       |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    value_loss           | 1.75e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=7280000, episode_reward=600.60 +/- 103.68\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 601          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021218162 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.481       |\n",
      "|    explained_variance   | 0.0523       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 805          |\n",
      "|    n_updates            | 12440        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1566    |\n",
      "|    iterations      | 889     |\n",
      "|    time_elapsed    | 4648    |\n",
      "|    total_timesteps | 7282688 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 890          |\n",
      "|    time_elapsed         | 4652         |\n",
      "|    total_timesteps      | 7290880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015370261 |\n",
      "|    clip_fraction        | 0.00874      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.473       |\n",
      "|    explained_variance   | 0.05         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.23e+03     |\n",
      "|    n_updates            | 12450        |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 891          |\n",
      "|    time_elapsed         | 4656         |\n",
      "|    total_timesteps      | 7299072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026891697 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.468       |\n",
      "|    explained_variance   | 0.0288       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 649          |\n",
      "|    n_updates            | 12460        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 892          |\n",
      "|    time_elapsed         | 4660         |\n",
      "|    total_timesteps      | 7307264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024706102 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | 0.0281       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 810          |\n",
      "|    n_updates            | 12470        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1568        |\n",
      "|    iterations           | 893         |\n",
      "|    time_elapsed         | 4664        |\n",
      "|    total_timesteps      | 7315456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002543453 |\n",
      "|    clip_fraction        | 0.0189      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.459      |\n",
      "|    explained_variance   | -0.00412    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 798         |\n",
      "|    n_updates            | 12480       |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    value_loss           | 1.75e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=7320000, episode_reward=610.00 +/- 53.18\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 610          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7320000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023969356 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.471       |\n",
      "|    explained_variance   | 0.0363       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 675          |\n",
      "|    n_updates            | 12490        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    value_loss           | 1.58e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1566    |\n",
      "|    iterations      | 894     |\n",
      "|    time_elapsed    | 4675    |\n",
      "|    total_timesteps | 7323648 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 895          |\n",
      "|    time_elapsed         | 4679         |\n",
      "|    total_timesteps      | 7331840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025163356 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.462       |\n",
      "|    explained_variance   | 0.0126       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 786          |\n",
      "|    n_updates            | 12500        |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 896          |\n",
      "|    time_elapsed         | 4683         |\n",
      "|    total_timesteps      | 7340032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020617007 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 0.0192       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 852          |\n",
      "|    n_updates            | 12510        |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 897          |\n",
      "|    time_elapsed         | 4687         |\n",
      "|    total_timesteps      | 7348224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021408931 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.454       |\n",
      "|    explained_variance   | 0.0223       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 943          |\n",
      "|    n_updates            | 12520        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 898          |\n",
      "|    time_elapsed         | 4691         |\n",
      "|    total_timesteps      | 7356416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018883602 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.457       |\n",
      "|    explained_variance   | 0.0374       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 740          |\n",
      "|    n_updates            | 12530        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 1.54e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7360000, episode_reward=613.60 +/- 51.60\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 614          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7360000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025441782 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.456       |\n",
      "|    explained_variance   | 0.0234       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 780          |\n",
      "|    n_updates            | 12540        |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1566    |\n",
      "|    iterations      | 899     |\n",
      "|    time_elapsed    | 4702    |\n",
      "|    total_timesteps | 7364608 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 900          |\n",
      "|    time_elapsed         | 4706         |\n",
      "|    total_timesteps      | 7372800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021289703 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | 0.0236       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 826          |\n",
      "|    n_updates            | 12550        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 901          |\n",
      "|    time_elapsed         | 4710         |\n",
      "|    total_timesteps      | 7380992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017252633 |\n",
      "|    clip_fraction        | 0.00828      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.0244       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 856          |\n",
      "|    n_updates            | 12560        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 902          |\n",
      "|    time_elapsed         | 4714         |\n",
      "|    total_timesteps      | 7389184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020531449 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 0.0422       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 744          |\n",
      "|    n_updates            | 12570        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 903          |\n",
      "|    time_elapsed         | 4718         |\n",
      "|    total_timesteps      | 7397376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024409578 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.467       |\n",
      "|    explained_variance   | 0.0366       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 772          |\n",
      "|    n_updates            | 12580        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7400000, episode_reward=621.40 +/- 51.30\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 621          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7400000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024040947 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.0444       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 864          |\n",
      "|    n_updates            | 12590        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1565    |\n",
      "|    iterations      | 904     |\n",
      "|    time_elapsed    | 4729    |\n",
      "|    total_timesteps | 7405568 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 905          |\n",
      "|    time_elapsed         | 4733         |\n",
      "|    total_timesteps      | 7413760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028901221 |\n",
      "|    clip_fraction        | 0.0268       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.457       |\n",
      "|    explained_variance   | 0.0384       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 849          |\n",
      "|    n_updates            | 12600        |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 906          |\n",
      "|    time_elapsed         | 4738         |\n",
      "|    total_timesteps      | 7421952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022297567 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.46        |\n",
      "|    explained_variance   | 0.0126       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 823          |\n",
      "|    n_updates            | 12610        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 907          |\n",
      "|    time_elapsed         | 4742         |\n",
      "|    total_timesteps      | 7430144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023929228 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.0377       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 858          |\n",
      "|    n_updates            | 12620        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 908          |\n",
      "|    time_elapsed         | 4746         |\n",
      "|    total_timesteps      | 7438336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021505565 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.465       |\n",
      "|    explained_variance   | 0.0274       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 609          |\n",
      "|    n_updates            | 12630        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7440000, episode_reward=623.00 +/- 64.54\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 623          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7440000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021335431 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.46        |\n",
      "|    explained_variance   | 0.00664      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 993          |\n",
      "|    n_updates            | 12640        |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1565    |\n",
      "|    iterations      | 909     |\n",
      "|    time_elapsed    | 4757    |\n",
      "|    total_timesteps | 7446528 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 910          |\n",
      "|    time_elapsed         | 4762         |\n",
      "|    total_timesteps      | 7454720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024567181 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.456       |\n",
      "|    explained_variance   | 0.0478       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 12650        |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 911          |\n",
      "|    time_elapsed         | 4766         |\n",
      "|    total_timesteps      | 7462912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034827194 |\n",
      "|    clip_fraction        | 0.0284       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.0355       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 757          |\n",
      "|    n_updates            | 12660        |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 912          |\n",
      "|    time_elapsed         | 4770         |\n",
      "|    total_timesteps      | 7471104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022096997 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.452       |\n",
      "|    explained_variance   | 0.0497       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 981          |\n",
      "|    n_updates            | 12670        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 913          |\n",
      "|    time_elapsed         | 4774         |\n",
      "|    total_timesteps      | 7479296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020801628 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.462       |\n",
      "|    explained_variance   | 0.0501       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 573          |\n",
      "|    n_updates            | 12680        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7480000, episode_reward=623.40 +/- 56.24\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 623          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7480000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020942476 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.464       |\n",
      "|    explained_variance   | 0.0159       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 12690        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1564    |\n",
      "|    iterations      | 914     |\n",
      "|    time_elapsed    | 4785    |\n",
      "|    total_timesteps | 7487488 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 915          |\n",
      "|    time_elapsed         | 4789         |\n",
      "|    total_timesteps      | 7495680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021062451 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 0.018        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.31e+03     |\n",
      "|    n_updates            | 12700        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1565        |\n",
      "|    iterations           | 916         |\n",
      "|    time_elapsed         | 4793        |\n",
      "|    total_timesteps      | 7503872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002963813 |\n",
      "|    clip_fraction        | 0.0246      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.455      |\n",
      "|    explained_variance   | 0.0316      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 827         |\n",
      "|    n_updates            | 12710       |\n",
      "|    policy_gradient_loss | -0.00402    |\n",
      "|    value_loss           | 1.62e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1565       |\n",
      "|    iterations           | 917        |\n",
      "|    time_elapsed         | 4797       |\n",
      "|    total_timesteps      | 7512064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00232282 |\n",
      "|    clip_fraction        | 0.0176     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.457     |\n",
      "|    explained_variance   | 0.028      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 749        |\n",
      "|    n_updates            | 12720      |\n",
      "|    policy_gradient_loss | -0.00385   |\n",
      "|    value_loss           | 1.62e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=7520000, episode_reward=629.80 +/- 60.15\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 630          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7520000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024932926 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.0119       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 735          |\n",
      "|    n_updates            | 12730        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1563    |\n",
      "|    iterations      | 918     |\n",
      "|    time_elapsed    | 4808    |\n",
      "|    total_timesteps | 7520256 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 919          |\n",
      "|    time_elapsed         | 4812         |\n",
      "|    total_timesteps      | 7528448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026044506 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.449       |\n",
      "|    explained_variance   | 0.0334       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 754          |\n",
      "|    n_updates            | 12740        |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 920          |\n",
      "|    time_elapsed         | 4817         |\n",
      "|    total_timesteps      | 7536640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026472365 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 0.0315       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 840          |\n",
      "|    n_updates            | 12750        |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 921          |\n",
      "|    time_elapsed         | 4821         |\n",
      "|    total_timesteps      | 7544832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019056131 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.0593       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 12760        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 922          |\n",
      "|    time_elapsed         | 4825         |\n",
      "|    total_timesteps      | 7553024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025095493 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 0.0269       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 874          |\n",
      "|    n_updates            | 12770        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7560000, episode_reward=616.60 +/- 46.11\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 617          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018721679 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.447       |\n",
      "|    explained_variance   | 0.00112      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 12780        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1563    |\n",
      "|    iterations      | 923     |\n",
      "|    time_elapsed    | 4836    |\n",
      "|    total_timesteps | 7561216 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1563         |\n",
      "|    iterations           | 924          |\n",
      "|    time_elapsed         | 4840         |\n",
      "|    total_timesteps      | 7569408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027422819 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.012        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 12790        |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 925          |\n",
      "|    time_elapsed         | 4844         |\n",
      "|    total_timesteps      | 7577600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018683139 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.438       |\n",
      "|    explained_variance   | 0.0231       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 964          |\n",
      "|    n_updates            | 12800        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 926          |\n",
      "|    time_elapsed         | 4848         |\n",
      "|    total_timesteps      | 7585792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026160502 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.457       |\n",
      "|    explained_variance   | 0.00395      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 745          |\n",
      "|    n_updates            | 12810        |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 927          |\n",
      "|    time_elapsed         | 4853         |\n",
      "|    total_timesteps      | 7593984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023312168 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.439       |\n",
      "|    explained_variance   | 0.00911      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 705          |\n",
      "|    n_updates            | 12820        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7600000, episode_reward=618.00 +/- 56.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 618          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7600000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029173703 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.0227       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 12830        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1562    |\n",
      "|    iterations      | 928     |\n",
      "|    time_elapsed    | 4863    |\n",
      "|    total_timesteps | 7602176 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1563         |\n",
      "|    iterations           | 929          |\n",
      "|    time_elapsed         | 4867         |\n",
      "|    total_timesteps      | 7610368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022320289 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.0498       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 794          |\n",
      "|    n_updates            | 12840        |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    value_loss           | 1.58e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1563         |\n",
      "|    iterations           | 930          |\n",
      "|    time_elapsed         | 4871         |\n",
      "|    total_timesteps      | 7618560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023098167 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.445       |\n",
      "|    explained_variance   | 0.0565       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 845          |\n",
      "|    n_updates            | 12850        |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 931          |\n",
      "|    time_elapsed         | 4875         |\n",
      "|    total_timesteps      | 7626752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020903023 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.448       |\n",
      "|    explained_variance   | 0.0265       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 956          |\n",
      "|    n_updates            | 12860        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 932          |\n",
      "|    time_elapsed         | 4879         |\n",
      "|    total_timesteps      | 7634944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025196178 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.44        |\n",
      "|    explained_variance   | 0.0475       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 901          |\n",
      "|    n_updates            | 12870        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7640000, episode_reward=618.80 +/- 53.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 619          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7640000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021466657 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.0232       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 950          |\n",
      "|    n_updates            | 12880        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1563    |\n",
      "|    iterations      | 933     |\n",
      "|    time_elapsed    | 4889    |\n",
      "|    total_timesteps | 7643136 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1563         |\n",
      "|    iterations           | 934          |\n",
      "|    time_elapsed         | 4893         |\n",
      "|    total_timesteps      | 7651328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022895276 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.441       |\n",
      "|    explained_variance   | 0.0235       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 819          |\n",
      "|    n_updates            | 12890        |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 935          |\n",
      "|    time_elapsed         | 4896         |\n",
      "|    total_timesteps      | 7659520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028454352 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.44        |\n",
      "|    explained_variance   | 0.0191       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 909          |\n",
      "|    n_updates            | 12900        |\n",
      "|    policy_gradient_loss | -0.00444     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 936          |\n",
      "|    time_elapsed         | 4900         |\n",
      "|    total_timesteps      | 7667712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023291106 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.441       |\n",
      "|    explained_variance   | 0.0277       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 746          |\n",
      "|    n_updates            | 12910        |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 937          |\n",
      "|    time_elapsed         | 4904         |\n",
      "|    total_timesteps      | 7675904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018639069 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.434       |\n",
      "|    explained_variance   | 0.0712       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 876          |\n",
      "|    n_updates            | 12920        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7680000, episode_reward=603.20 +/- 70.89\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 603          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7680000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021723644 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.431       |\n",
      "|    explained_variance   | 0.0688       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 974          |\n",
      "|    n_updates            | 12930        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1563    |\n",
      "|    iterations      | 938     |\n",
      "|    time_elapsed    | 4914    |\n",
      "|    total_timesteps | 7684096 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1563         |\n",
      "|    iterations           | 939          |\n",
      "|    time_elapsed         | 4918         |\n",
      "|    total_timesteps      | 7692288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019611851 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.0636       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 12940        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 940          |\n",
      "|    time_elapsed         | 4922         |\n",
      "|    total_timesteps      | 7700480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029283124 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.446       |\n",
      "|    explained_variance   | 0.0572       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 636          |\n",
      "|    n_updates            | 12950        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 941          |\n",
      "|    time_elapsed         | 4925         |\n",
      "|    total_timesteps      | 7708672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024513435 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.0247       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 717          |\n",
      "|    n_updates            | 12960        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 942          |\n",
      "|    time_elapsed         | 4929         |\n",
      "|    total_timesteps      | 7716864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020327123 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.439       |\n",
      "|    explained_variance   | 0.0243       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 922          |\n",
      "|    n_updates            | 12970        |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7720000, episode_reward=611.80 +/- 58.47\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 612          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7720000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022260486 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.449       |\n",
      "|    explained_variance   | 0.0147       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 12980        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1563    |\n",
      "|    iterations      | 943     |\n",
      "|    time_elapsed    | 4939    |\n",
      "|    total_timesteps | 7725056 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 944          |\n",
      "|    time_elapsed         | 4943         |\n",
      "|    total_timesteps      | 7733248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021860078 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.0312       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 853          |\n",
      "|    n_updates            | 12990        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 945          |\n",
      "|    time_elapsed         | 4947         |\n",
      "|    total_timesteps      | 7741440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027854848 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.44        |\n",
      "|    explained_variance   | 0.0299       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 816          |\n",
      "|    n_updates            | 13000        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    value_loss           | 1.52e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 946          |\n",
      "|    time_elapsed         | 4951         |\n",
      "|    total_timesteps      | 7749632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020088223 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.0209       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 935          |\n",
      "|    n_updates            | 13010        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 947          |\n",
      "|    time_elapsed         | 4954         |\n",
      "|    total_timesteps      | 7757824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021757246 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.0333       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 781          |\n",
      "|    n_updates            | 13020        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7760000, episode_reward=603.80 +/- 55.85\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 604          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7760000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017005347 |\n",
      "|    clip_fraction        | 0.00948      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.443       |\n",
      "|    explained_variance   | 0.0318       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 677          |\n",
      "|    n_updates            | 13030        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1564    |\n",
      "|    iterations      | 948     |\n",
      "|    time_elapsed    | 4964    |\n",
      "|    total_timesteps | 7766016 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 949          |\n",
      "|    time_elapsed         | 4968         |\n",
      "|    total_timesteps      | 7774208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025122266 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.454       |\n",
      "|    explained_variance   | 0.0514       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 707          |\n",
      "|    n_updates            | 13040        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 950          |\n",
      "|    time_elapsed         | 4972         |\n",
      "|    total_timesteps      | 7782400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019642585 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.0434       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 586          |\n",
      "|    n_updates            | 13050        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    value_loss           | 1.56e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 951          |\n",
      "|    time_elapsed         | 4976         |\n",
      "|    total_timesteps      | 7790592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027229912 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.0123       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 611          |\n",
      "|    n_updates            | 13060        |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 952          |\n",
      "|    time_elapsed         | 4979         |\n",
      "|    total_timesteps      | 7798784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022455622 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.0106       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 908          |\n",
      "|    n_updates            | 13070        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7800000, episode_reward=621.60 +/- 49.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 622          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7800000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024450817 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.0311       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 740          |\n",
      "|    n_updates            | 13080        |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1564    |\n",
      "|    iterations      | 953     |\n",
      "|    time_elapsed    | 4989    |\n",
      "|    total_timesteps | 7806976 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 954          |\n",
      "|    time_elapsed         | 4993         |\n",
      "|    total_timesteps      | 7815168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021413935 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.456       |\n",
      "|    explained_variance   | 0.0278       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 820          |\n",
      "|    n_updates            | 13090        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 955          |\n",
      "|    time_elapsed         | 4997         |\n",
      "|    total_timesteps      | 7823360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023693661 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.459       |\n",
      "|    explained_variance   | 0.0301       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 747          |\n",
      "|    n_updates            | 13100        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 956          |\n",
      "|    time_elapsed         | 5001         |\n",
      "|    total_timesteps      | 7831552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022345146 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.0335       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 877          |\n",
      "|    n_updates            | 13110        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 957          |\n",
      "|    time_elapsed         | 5004         |\n",
      "|    total_timesteps      | 7839744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019870112 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.464       |\n",
      "|    explained_variance   | 0.0423       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 679          |\n",
      "|    n_updates            | 13120        |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7840000, episode_reward=610.60 +/- 50.37\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 611         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 7840000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002505284 |\n",
      "|    clip_fraction        | 0.0133      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.448      |\n",
      "|    explained_variance   | 0.0162      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 800         |\n",
      "|    n_updates            | 13130       |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    value_loss           | 1.69e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1564    |\n",
      "|    iterations      | 958     |\n",
      "|    time_elapsed    | 5014    |\n",
      "|    total_timesteps | 7847936 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 959          |\n",
      "|    time_elapsed         | 5018         |\n",
      "|    total_timesteps      | 7856128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019662685 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.0362       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 681          |\n",
      "|    n_updates            | 13140        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1565        |\n",
      "|    iterations           | 960         |\n",
      "|    time_elapsed         | 5022        |\n",
      "|    total_timesteps      | 7864320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002363255 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.449      |\n",
      "|    explained_variance   | 0.0238      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 13150       |\n",
      "|    policy_gradient_loss | -0.0033     |\n",
      "|    value_loss           | 1.87e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 961          |\n",
      "|    time_elapsed         | 5026         |\n",
      "|    total_timesteps      | 7872512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021645976 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.449       |\n",
      "|    explained_variance   | 0.00992      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1e+03        |\n",
      "|    n_updates            | 13160        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7880000, episode_reward=600.80 +/- 54.47\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 601          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7880000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026018154 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.445       |\n",
      "|    explained_variance   | 0.0195       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 653          |\n",
      "|    n_updates            | 13170        |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1564    |\n",
      "|    iterations      | 962     |\n",
      "|    time_elapsed    | 5036    |\n",
      "|    total_timesteps | 7880704 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 963          |\n",
      "|    time_elapsed         | 5039         |\n",
      "|    total_timesteps      | 7888896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020499115 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.457       |\n",
      "|    explained_variance   | 0.0489       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 733          |\n",
      "|    n_updates            | 13180        |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 964          |\n",
      "|    time_elapsed         | 5043         |\n",
      "|    total_timesteps      | 7897088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017285501 |\n",
      "|    clip_fraction        | 0.00972      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.437       |\n",
      "|    explained_variance   | 0.027        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 895          |\n",
      "|    n_updates            | 13190        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 965          |\n",
      "|    time_elapsed         | 5047         |\n",
      "|    total_timesteps      | 7905280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019371269 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.445       |\n",
      "|    explained_variance   | 0.036        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 780          |\n",
      "|    n_updates            | 13200        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 966          |\n",
      "|    time_elapsed         | 5051         |\n",
      "|    total_timesteps      | 7913472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019153277 |\n",
      "|    clip_fraction        | 0.00857      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.46        |\n",
      "|    explained_variance   | 0.00638      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 757          |\n",
      "|    n_updates            | 13210        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7920000, episode_reward=615.80 +/- 55.72\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 616          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7920000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020974337 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.456       |\n",
      "|    explained_variance   | 0.0343       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 850          |\n",
      "|    n_updates            | 13220        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1565    |\n",
      "|    iterations      | 967     |\n",
      "|    time_elapsed    | 5061    |\n",
      "|    total_timesteps | 7921664 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 968          |\n",
      "|    time_elapsed         | 5065         |\n",
      "|    total_timesteps      | 7929856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020782803 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.464       |\n",
      "|    explained_variance   | 0.0222       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 522          |\n",
      "|    n_updates            | 13230        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 969          |\n",
      "|    time_elapsed         | 5068         |\n",
      "|    total_timesteps      | 7938048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026661847 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.461       |\n",
      "|    explained_variance   | 0.0455       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 620          |\n",
      "|    n_updates            | 13240        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 970          |\n",
      "|    time_elapsed         | 5072         |\n",
      "|    total_timesteps      | 7946240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020059836 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.0468       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 783          |\n",
      "|    n_updates            | 13250        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 971          |\n",
      "|    time_elapsed         | 5076         |\n",
      "|    total_timesteps      | 7954432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021087308 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.463       |\n",
      "|    explained_variance   | 0.00746      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 644          |\n",
      "|    n_updates            | 13260        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7960000, episode_reward=596.20 +/- 100.26\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 596         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 7960000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002093561 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.442      |\n",
      "|    explained_variance   | 0.0265      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 967         |\n",
      "|    n_updates            | 13270       |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    value_loss           | 1.84e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1565    |\n",
      "|    iterations      | 972     |\n",
      "|    time_elapsed    | 5086    |\n",
      "|    total_timesteps | 7962624 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 973          |\n",
      "|    time_elapsed         | 5090         |\n",
      "|    total_timesteps      | 7970816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018643318 |\n",
      "|    clip_fraction        | 0.00891      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.0351       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 766          |\n",
      "|    n_updates            | 13280        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 974          |\n",
      "|    time_elapsed         | 5093         |\n",
      "|    total_timesteps      | 7979008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023319703 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.0355       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 701          |\n",
      "|    n_updates            | 13290        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 975          |\n",
      "|    time_elapsed         | 5097         |\n",
      "|    total_timesteps      | 7987200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021824948 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.447       |\n",
      "|    explained_variance   | 0.0278       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 875          |\n",
      "|    n_updates            | 13300        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 976          |\n",
      "|    time_elapsed         | 5101         |\n",
      "|    total_timesteps      | 7995392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020467313 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.0423       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 844          |\n",
      "|    n_updates            | 13310        |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8000000, episode_reward=627.80 +/- 61.94\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 628          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022428934 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.468       |\n",
      "|    explained_variance   | 0.0281       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 943          |\n",
      "|    n_updates            | 13320        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1565    |\n",
      "|    iterations      | 977     |\n",
      "|    time_elapsed    | 5111    |\n",
      "|    total_timesteps | 8003584 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 978          |\n",
      "|    time_elapsed         | 5115         |\n",
      "|    total_timesteps      | 8011776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018799107 |\n",
      "|    clip_fraction        | 0.00869      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 0.0118       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 891          |\n",
      "|    n_updates            | 13330        |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1566        |\n",
      "|    iterations           | 979         |\n",
      "|    time_elapsed         | 5119        |\n",
      "|    total_timesteps      | 8019968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001972447 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.455      |\n",
      "|    explained_variance   | 0.0162      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 927         |\n",
      "|    n_updates            | 13340       |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    value_loss           | 1.66e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 980          |\n",
      "|    time_elapsed         | 5123         |\n",
      "|    total_timesteps      | 8028160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026333933 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.0391       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 732          |\n",
      "|    n_updates            | 13350        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1567        |\n",
      "|    iterations           | 981         |\n",
      "|    time_elapsed         | 5126        |\n",
      "|    total_timesteps      | 8036352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002470081 |\n",
      "|    clip_fraction        | 0.0184      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.446      |\n",
      "|    explained_variance   | 0.0267      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 877         |\n",
      "|    n_updates            | 13360       |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    value_loss           | 1.73e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=8040000, episode_reward=622.80 +/- 61.71\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 623          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8040000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020046877 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.439       |\n",
      "|    explained_variance   | 0.0389       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 991          |\n",
      "|    n_updates            | 13370        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1565    |\n",
      "|    iterations      | 982     |\n",
      "|    time_elapsed    | 5137    |\n",
      "|    total_timesteps | 8044544 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 983          |\n",
      "|    time_elapsed         | 5140         |\n",
      "|    total_timesteps      | 8052736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018757478 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.457       |\n",
      "|    explained_variance   | 0.0502       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 489          |\n",
      "|    n_updates            | 13380        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 984          |\n",
      "|    time_elapsed         | 5144         |\n",
      "|    total_timesteps      | 8060928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024612162 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.0308       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 889          |\n",
      "|    n_updates            | 13390        |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 985          |\n",
      "|    time_elapsed         | 5148         |\n",
      "|    total_timesteps      | 8069120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022630556 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.444       |\n",
      "|    explained_variance   | 0.0193       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 910          |\n",
      "|    n_updates            | 13400        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 986          |\n",
      "|    time_elapsed         | 5152         |\n",
      "|    total_timesteps      | 8077312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025780338 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.0287       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 837          |\n",
      "|    n_updates            | 13410        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8080000, episode_reward=622.00 +/- 63.84\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 622          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8080000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025130736 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.437       |\n",
      "|    explained_variance   | 0.0237       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 13420        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1566    |\n",
      "|    iterations      | 987     |\n",
      "|    time_elapsed    | 5162    |\n",
      "|    total_timesteps | 8085504 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 988          |\n",
      "|    time_elapsed         | 5166         |\n",
      "|    total_timesteps      | 8093696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026541194 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.0269       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 617          |\n",
      "|    n_updates            | 13430        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 989          |\n",
      "|    time_elapsed         | 5170         |\n",
      "|    total_timesteps      | 8101888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020238748 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.436       |\n",
      "|    explained_variance   | 0.0489       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 13440        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 1.92e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 990          |\n",
      "|    time_elapsed         | 5173         |\n",
      "|    total_timesteps      | 8110080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021996778 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.434       |\n",
      "|    explained_variance   | 0.0215       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 854          |\n",
      "|    n_updates            | 13450        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 991          |\n",
      "|    time_elapsed         | 5177         |\n",
      "|    total_timesteps      | 8118272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021555196 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.438       |\n",
      "|    explained_variance   | 0.0408       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 773          |\n",
      "|    n_updates            | 13460        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8120000, episode_reward=618.40 +/- 43.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 618          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022947267 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.429       |\n",
      "|    explained_variance   | 0.0243       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 13470        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1566    |\n",
      "|    iterations      | 992     |\n",
      "|    time_elapsed    | 5188    |\n",
      "|    total_timesteps | 8126464 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1566        |\n",
      "|    iterations           | 993         |\n",
      "|    time_elapsed         | 5192        |\n",
      "|    total_timesteps      | 8134656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001960442 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.431      |\n",
      "|    explained_variance   | 0.0388      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 943         |\n",
      "|    n_updates            | 13480       |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    value_loss           | 1.88e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 994          |\n",
      "|    time_elapsed         | 5195         |\n",
      "|    total_timesteps      | 8142848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015033162 |\n",
      "|    clip_fraction        | 0.00754      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.425       |\n",
      "|    explained_variance   | 0.0363       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 531          |\n",
      "|    n_updates            | 13490        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 995          |\n",
      "|    time_elapsed         | 5199         |\n",
      "|    total_timesteps      | 8151040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019496859 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.416       |\n",
      "|    explained_variance   | 0.0756       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.21e+03     |\n",
      "|    n_updates            | 13500        |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1567        |\n",
      "|    iterations           | 996         |\n",
      "|    time_elapsed         | 5203        |\n",
      "|    total_timesteps      | 8159232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002523544 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.425      |\n",
      "|    explained_variance   | 0.0514      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.03e+03    |\n",
      "|    n_updates            | 13510       |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    value_loss           | 1.78e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=8160000, episode_reward=616.40 +/- 52.87\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 616         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 8160000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001821428 |\n",
      "|    clip_fraction        | 0.0104      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.419      |\n",
      "|    explained_variance   | -0.00317    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.02e+03    |\n",
      "|    n_updates            | 13520       |\n",
      "|    policy_gradient_loss | -0.00301    |\n",
      "|    value_loss           | 1.76e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1566    |\n",
      "|    iterations      | 997     |\n",
      "|    time_elapsed    | 5214    |\n",
      "|    total_timesteps | 8167424 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 998          |\n",
      "|    time_elapsed         | 5218         |\n",
      "|    total_timesteps      | 8175616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028085313 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.441       |\n",
      "|    explained_variance   | 0.0613       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 777          |\n",
      "|    n_updates            | 13530        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 999          |\n",
      "|    time_elapsed         | 5222         |\n",
      "|    total_timesteps      | 8183808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019044592 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.434       |\n",
      "|    explained_variance   | 0.0327       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 707          |\n",
      "|    n_updates            | 13540        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 1000         |\n",
      "|    time_elapsed         | 5226         |\n",
      "|    total_timesteps      | 8192000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020784107 |\n",
      "|    clip_fraction        | 0.00972      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.429       |\n",
      "|    explained_variance   | 0.0365       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 13550        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8200000, episode_reward=611.80 +/- 52.75\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 612         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 8200000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002271012 |\n",
      "|    clip_fraction        | 0.0127      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.433      |\n",
      "|    explained_variance   | 0.0112      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.02e+03    |\n",
      "|    n_updates            | 13560       |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    value_loss           | 1.81e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1565    |\n",
      "|    iterations      | 1001    |\n",
      "|    time_elapsed    | 5237    |\n",
      "|    total_timesteps | 8200192 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1566        |\n",
      "|    iterations           | 1002        |\n",
      "|    time_elapsed         | 5241        |\n",
      "|    total_timesteps      | 8208384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002450135 |\n",
      "|    clip_fraction        | 0.0151      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.432      |\n",
      "|    explained_variance   | 0.0563      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 717         |\n",
      "|    n_updates            | 13570       |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    value_loss           | 1.62e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1003         |\n",
      "|    time_elapsed         | 5245         |\n",
      "|    total_timesteps      | 8216576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016474038 |\n",
      "|    clip_fraction        | 0.00787      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.417       |\n",
      "|    explained_variance   | 0.0309       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 757          |\n",
      "|    n_updates            | 13580        |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1004         |\n",
      "|    time_elapsed         | 5249         |\n",
      "|    total_timesteps      | 8224768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015797913 |\n",
      "|    clip_fraction        | 0.009        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.426       |\n",
      "|    explained_variance   | 0.0337       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 13590        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 1005         |\n",
      "|    time_elapsed         | 5253         |\n",
      "|    total_timesteps      | 8232960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020043817 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.427       |\n",
      "|    explained_variance   | 0.0256       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 13600        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8240000, episode_reward=611.20 +/- 63.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 611          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8240000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022323516 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.0295       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 745          |\n",
      "|    n_updates            | 13610        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1565    |\n",
      "|    iterations      | 1006    |\n",
      "|    time_elapsed    | 5263    |\n",
      "|    total_timesteps | 8241152 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1007         |\n",
      "|    time_elapsed         | 5267         |\n",
      "|    total_timesteps      | 8249344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019742385 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.423       |\n",
      "|    explained_variance   | 0.0141       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 822          |\n",
      "|    n_updates            | 13620        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1008         |\n",
      "|    time_elapsed         | 5271         |\n",
      "|    total_timesteps      | 8257536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019754411 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.409       |\n",
      "|    explained_variance   | 0.0181       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 766          |\n",
      "|    n_updates            | 13630        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1009         |\n",
      "|    time_elapsed         | 5275         |\n",
      "|    total_timesteps      | 8265728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021521524 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.408       |\n",
      "|    explained_variance   | -0.0112      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 885          |\n",
      "|    n_updates            | 13640        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1567        |\n",
      "|    iterations           | 1010        |\n",
      "|    time_elapsed         | 5279        |\n",
      "|    total_timesteps      | 8273920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002126278 |\n",
      "|    clip_fraction        | 0.0132      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.411      |\n",
      "|    explained_variance   | 0.0375      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 822         |\n",
      "|    n_updates            | 13650       |\n",
      "|    policy_gradient_loss | -0.0033     |\n",
      "|    value_loss           | 1.81e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=8280000, episode_reward=614.60 +/- 64.72\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 615          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018942072 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.413       |\n",
      "|    explained_variance   | 0.0202       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 13660        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1565    |\n",
      "|    iterations      | 1011    |\n",
      "|    time_elapsed    | 5291    |\n",
      "|    total_timesteps | 8282112 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1565        |\n",
      "|    iterations           | 1012        |\n",
      "|    time_elapsed         | 5295        |\n",
      "|    total_timesteps      | 8290304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002330325 |\n",
      "|    clip_fraction        | 0.0194      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.418      |\n",
      "|    explained_variance   | 0.04        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 989         |\n",
      "|    n_updates            | 13670       |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    value_loss           | 1.63e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1565        |\n",
      "|    iterations           | 1013        |\n",
      "|    time_elapsed         | 5299        |\n",
      "|    total_timesteps      | 8298496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002332711 |\n",
      "|    clip_fraction        | 0.0176      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.406      |\n",
      "|    explained_variance   | 0.033       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 856         |\n",
      "|    n_updates            | 13680       |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    value_loss           | 1.59e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1014         |\n",
      "|    time_elapsed         | 5304         |\n",
      "|    total_timesteps      | 8306688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016861738 |\n",
      "|    clip_fraction        | 0.00961      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.421       |\n",
      "|    explained_variance   | 0.0394       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 935          |\n",
      "|    n_updates            | 13690        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1015         |\n",
      "|    time_elapsed         | 5308         |\n",
      "|    total_timesteps      | 8314880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025737043 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.422       |\n",
      "|    explained_variance   | 0.049        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 736          |\n",
      "|    n_updates            | 13700        |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8320000, episode_reward=608.40 +/- 43.47\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 200        |\n",
      "|    mean_reward          | 608        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 8320000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00231751 |\n",
      "|    clip_fraction        | 0.0147     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.432     |\n",
      "|    explained_variance   | 0.0518     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 986        |\n",
      "|    n_updates            | 13710      |\n",
      "|    policy_gradient_loss | -0.00344   |\n",
      "|    value_loss           | 1.68e+03   |\n",
      "----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1564    |\n",
      "|    iterations      | 1016    |\n",
      "|    time_elapsed    | 5318    |\n",
      "|    total_timesteps | 8323072 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1017         |\n",
      "|    time_elapsed         | 5323         |\n",
      "|    total_timesteps      | 8331264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020754384 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.445       |\n",
      "|    explained_variance   | 0.02         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 794          |\n",
      "|    n_updates            | 13720        |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1018         |\n",
      "|    time_elapsed         | 5327         |\n",
      "|    total_timesteps      | 8339456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020530825 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.449       |\n",
      "|    explained_variance   | 0.0219       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 653          |\n",
      "|    n_updates            | 13730        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1565        |\n",
      "|    iterations           | 1019        |\n",
      "|    time_elapsed         | 5331        |\n",
      "|    total_timesteps      | 8347648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002444217 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.435      |\n",
      "|    explained_variance   | 0.0619      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.11e+03    |\n",
      "|    n_updates            | 13740       |\n",
      "|    policy_gradient_loss | -0.00373    |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1020         |\n",
      "|    time_elapsed         | 5335         |\n",
      "|    total_timesteps      | 8355840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018634364 |\n",
      "|    clip_fraction        | 0.00879      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.43        |\n",
      "|    explained_variance   | 0.0333       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 716          |\n",
      "|    n_updates            | 13750        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8360000, episode_reward=626.00 +/- 57.58\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 626          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8360000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022516334 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.439       |\n",
      "|    explained_variance   | 0.00452      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 863          |\n",
      "|    n_updates            | 13760        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1564    |\n",
      "|    iterations      | 1021    |\n",
      "|    time_elapsed    | 5346    |\n",
      "|    total_timesteps | 8364032 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 1022         |\n",
      "|    time_elapsed         | 5350         |\n",
      "|    total_timesteps      | 8372224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019885967 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.443       |\n",
      "|    explained_variance   | 0.0343       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 820          |\n",
      "|    n_updates            | 13770        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1023         |\n",
      "|    time_elapsed         | 5354         |\n",
      "|    total_timesteps      | 8380416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023738542 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.434       |\n",
      "|    explained_variance   | 0.0394       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 839          |\n",
      "|    n_updates            | 13780        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1565        |\n",
      "|    iterations           | 1024        |\n",
      "|    time_elapsed         | 5358        |\n",
      "|    total_timesteps      | 8388608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002209695 |\n",
      "|    clip_fraction        | 0.0174      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.429      |\n",
      "|    explained_variance   | 0.033       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 791         |\n",
      "|    n_updates            | 13790       |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    value_loss           | 1.65e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1025         |\n",
      "|    time_elapsed         | 5362         |\n",
      "|    total_timesteps      | 8396800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019962485 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.43        |\n",
      "|    explained_variance   | 0.0417       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 917          |\n",
      "|    n_updates            | 13800        |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8400000, episode_reward=621.80 +/- 62.76\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 622         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 8400000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002467901 |\n",
      "|    clip_fraction        | 0.0181      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.441      |\n",
      "|    explained_variance   | 0.0426      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 979         |\n",
      "|    n_updates            | 13810       |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    value_loss           | 1.77e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1564    |\n",
      "|    iterations      | 1026    |\n",
      "|    time_elapsed    | 5372    |\n",
      "|    total_timesteps | 8404992 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 1027         |\n",
      "|    time_elapsed         | 5376         |\n",
      "|    total_timesteps      | 8413184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016787734 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.428       |\n",
      "|    explained_variance   | 0.0279       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 814          |\n",
      "|    n_updates            | 13820        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1028         |\n",
      "|    time_elapsed         | 5380         |\n",
      "|    total_timesteps      | 8421376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017892374 |\n",
      "|    clip_fraction        | 0.00952      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.436       |\n",
      "|    explained_variance   | 0.0202       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 629          |\n",
      "|    n_updates            | 13830        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1565        |\n",
      "|    iterations           | 1029        |\n",
      "|    time_elapsed         | 5384        |\n",
      "|    total_timesteps      | 8429568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002160822 |\n",
      "|    clip_fraction        | 0.0152      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.439      |\n",
      "|    explained_variance   | 0.0185      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.21e+03    |\n",
      "|    n_updates            | 13840       |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    value_loss           | 1.59e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1030         |\n",
      "|    time_elapsed         | 5388         |\n",
      "|    total_timesteps      | 8437760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025522932 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.445       |\n",
      "|    explained_variance   | 0.0414       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 720          |\n",
      "|    n_updates            | 13850        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8440000, episode_reward=620.40 +/- 59.09\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 620          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8440000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027212831 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.448       |\n",
      "|    explained_variance   | 0.0268       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 716          |\n",
      "|    n_updates            | 13860        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1564    |\n",
      "|    iterations      | 1031    |\n",
      "|    time_elapsed    | 5398    |\n",
      "|    total_timesteps | 8445952 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 1032         |\n",
      "|    time_elapsed         | 5402         |\n",
      "|    total_timesteps      | 8454144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014559717 |\n",
      "|    clip_fraction        | 0.00793      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.441       |\n",
      "|    explained_variance   | 0.0388       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 882          |\n",
      "|    n_updates            | 13870        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1033         |\n",
      "|    time_elapsed         | 5406         |\n",
      "|    total_timesteps      | 8462336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019638713 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.445       |\n",
      "|    explained_variance   | 0.0325       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 809          |\n",
      "|    n_updates            | 13880        |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1034         |\n",
      "|    time_elapsed         | 5410         |\n",
      "|    total_timesteps      | 8470528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026423377 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.459       |\n",
      "|    explained_variance   | 0.0175       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 13890        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1035         |\n",
      "|    time_elapsed         | 5414         |\n",
      "|    total_timesteps      | 8478720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020982844 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.443       |\n",
      "|    explained_variance   | 0.0178       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 706          |\n",
      "|    n_updates            | 13900        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8480000, episode_reward=613.20 +/- 52.06\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 613          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8480000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027115415 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.44        |\n",
      "|    explained_variance   | 0.0202       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 13910        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1564    |\n",
      "|    iterations      | 1036    |\n",
      "|    time_elapsed    | 5424    |\n",
      "|    total_timesteps | 8486912 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1565        |\n",
      "|    iterations           | 1037        |\n",
      "|    time_elapsed         | 5428        |\n",
      "|    total_timesteps      | 8495104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001875565 |\n",
      "|    clip_fraction        | 0.00937     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.456      |\n",
      "|    explained_variance   | 0.0525      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 785         |\n",
      "|    n_updates            | 13920       |\n",
      "|    policy_gradient_loss | -0.00254    |\n",
      "|    value_loss           | 1.65e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1038         |\n",
      "|    time_elapsed         | 5431         |\n",
      "|    total_timesteps      | 8503296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018136906 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.438       |\n",
      "|    explained_variance   | 0.0597       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 775          |\n",
      "|    n_updates            | 13930        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1039         |\n",
      "|    time_elapsed         | 5435         |\n",
      "|    total_timesteps      | 8511488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023087726 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.444       |\n",
      "|    explained_variance   | 0.0507       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 859          |\n",
      "|    n_updates            | 13940        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1040         |\n",
      "|    time_elapsed         | 5439         |\n",
      "|    total_timesteps      | 8519680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031474642 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.44        |\n",
      "|    explained_variance   | 0.0394       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 710          |\n",
      "|    n_updates            | 13950        |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8520000, episode_reward=624.40 +/- 62.20\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 624          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8520000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023633929 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.443       |\n",
      "|    explained_variance   | 0.0565       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 846          |\n",
      "|    n_updates            | 13960        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1564    |\n",
      "|    iterations      | 1041    |\n",
      "|    time_elapsed    | 5449    |\n",
      "|    total_timesteps | 8527872 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1042         |\n",
      "|    time_elapsed         | 5453         |\n",
      "|    total_timesteps      | 8536064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017536025 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.444       |\n",
      "|    explained_variance   | -0.0118      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 785          |\n",
      "|    n_updates            | 13970        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1043         |\n",
      "|    time_elapsed         | 5456         |\n",
      "|    total_timesteps      | 8544256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025880474 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.427       |\n",
      "|    explained_variance   | 0.00895      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 845          |\n",
      "|    n_updates            | 13980        |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1044         |\n",
      "|    time_elapsed         | 5460         |\n",
      "|    total_timesteps      | 8552448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017988039 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.434       |\n",
      "|    explained_variance   | 0.0266       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1e+03        |\n",
      "|    n_updates            | 13990        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8560000, episode_reward=633.60 +/- 61.93\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 634          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020145061 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.425       |\n",
      "|    explained_variance   | 0.0317       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 677          |\n",
      "|    n_updates            | 14000        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1564    |\n",
      "|    iterations      | 1045    |\n",
      "|    time_elapsed    | 5470    |\n",
      "|    total_timesteps | 8560640 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1565        |\n",
      "|    iterations           | 1046        |\n",
      "|    time_elapsed         | 5474        |\n",
      "|    total_timesteps      | 8568832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001928295 |\n",
      "|    clip_fraction        | 0.0111      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.448      |\n",
      "|    explained_variance   | 0.041       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 782         |\n",
      "|    n_updates            | 14010       |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    value_loss           | 1.69e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1047         |\n",
      "|    time_elapsed         | 5478         |\n",
      "|    total_timesteps      | 8577024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025771863 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.43        |\n",
      "|    explained_variance   | 0.01         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 858          |\n",
      "|    n_updates            | 14020        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1048         |\n",
      "|    time_elapsed         | 5482         |\n",
      "|    total_timesteps      | 8585216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022644214 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.446       |\n",
      "|    explained_variance   | 0.0143       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 790          |\n",
      "|    n_updates            | 14030        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1049         |\n",
      "|    time_elapsed         | 5486         |\n",
      "|    total_timesteps      | 8593408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026796465 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.433       |\n",
      "|    explained_variance   | 0.0425       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 636          |\n",
      "|    n_updates            | 14040        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8600000, episode_reward=608.40 +/- 63.60\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 608          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8600000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017232286 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.423       |\n",
      "|    explained_variance   | 0.00603      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 879          |\n",
      "|    n_updates            | 14050        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1564    |\n",
      "|    iterations      | 1050    |\n",
      "|    time_elapsed    | 5496    |\n",
      "|    total_timesteps | 8601600 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1051         |\n",
      "|    time_elapsed         | 5499         |\n",
      "|    total_timesteps      | 8609792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015213666 |\n",
      "|    clip_fraction        | 0.00771      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.428       |\n",
      "|    explained_variance   | 0.0171       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 14060        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    value_loss           | 1.92e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1052         |\n",
      "|    time_elapsed         | 5503         |\n",
      "|    total_timesteps      | 8617984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020410474 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.431       |\n",
      "|    explained_variance   | 0.0148       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 550          |\n",
      "|    n_updates            | 14070        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1566        |\n",
      "|    iterations           | 1053        |\n",
      "|    time_elapsed         | 5507        |\n",
      "|    total_timesteps      | 8626176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002983104 |\n",
      "|    clip_fraction        | 0.0272      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.43       |\n",
      "|    explained_variance   | 0.0319      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 969         |\n",
      "|    n_updates            | 14080       |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    value_loss           | 1.63e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1566        |\n",
      "|    iterations           | 1054        |\n",
      "|    time_elapsed         | 5511        |\n",
      "|    total_timesteps      | 8634368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002342793 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.433      |\n",
      "|    explained_variance   | 0.0324      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 830         |\n",
      "|    n_updates            | 14090       |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    value_loss           | 1.72e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=8640000, episode_reward=631.60 +/- 54.16\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 632          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8640000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023083708 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.0303       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 14100        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1565    |\n",
      "|    iterations      | 1055    |\n",
      "|    time_elapsed    | 5521    |\n",
      "|    total_timesteps | 8642560 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1056         |\n",
      "|    time_elapsed         | 5525         |\n",
      "|    total_timesteps      | 8650752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032386053 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.441       |\n",
      "|    explained_variance   | 0.0377       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 14110        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1057         |\n",
      "|    time_elapsed         | 5529         |\n",
      "|    total_timesteps      | 8658944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019034117 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.434       |\n",
      "|    explained_variance   | 0.0347       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 772          |\n",
      "|    n_updates            | 14120        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1058         |\n",
      "|    time_elapsed         | 5534         |\n",
      "|    total_timesteps      | 8667136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026650666 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.429       |\n",
      "|    explained_variance   | 0.0609       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 685          |\n",
      "|    n_updates            | 14130        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1059         |\n",
      "|    time_elapsed         | 5537         |\n",
      "|    total_timesteps      | 8675328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022655067 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.0434       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 611          |\n",
      "|    n_updates            | 14140        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8680000, episode_reward=634.80 +/- 61.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 635         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 8680000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002413476 |\n",
      "|    clip_fraction        | 0.0177      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.44       |\n",
      "|    explained_variance   | 0.0645      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 925         |\n",
      "|    n_updates            | 14150       |\n",
      "|    policy_gradient_loss | -0.00353    |\n",
      "|    value_loss           | 1.78e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1565    |\n",
      "|    iterations      | 1060    |\n",
      "|    time_elapsed    | 5548    |\n",
      "|    total_timesteps | 8683520 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1061         |\n",
      "|    time_elapsed         | 5552         |\n",
      "|    total_timesteps      | 8691712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024216957 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.443       |\n",
      "|    explained_variance   | 0.0127       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 869          |\n",
      "|    n_updates            | 14160        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1062         |\n",
      "|    time_elapsed         | 5556         |\n",
      "|    total_timesteps      | 8699904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025171181 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.421       |\n",
      "|    explained_variance   | 0.0633       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 825          |\n",
      "|    n_updates            | 14170        |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1063         |\n",
      "|    time_elapsed         | 5560         |\n",
      "|    total_timesteps      | 8708096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022805142 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.434       |\n",
      "|    explained_variance   | 0.0395       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 905          |\n",
      "|    n_updates            | 14180        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1566        |\n",
      "|    iterations           | 1064        |\n",
      "|    time_elapsed         | 5564        |\n",
      "|    total_timesteps      | 8716288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002125415 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.436      |\n",
      "|    explained_variance   | 0.0305      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 968         |\n",
      "|    n_updates            | 14190       |\n",
      "|    policy_gradient_loss | -0.00326    |\n",
      "|    value_loss           | 1.75e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=8720000, episode_reward=617.40 +/- 53.84\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 617          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8720000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020564597 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.43        |\n",
      "|    explained_variance   | 0.0347       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 745          |\n",
      "|    n_updates            | 14200        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1565    |\n",
      "|    iterations      | 1065    |\n",
      "|    time_elapsed    | 5574    |\n",
      "|    total_timesteps | 8724480 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1066         |\n",
      "|    time_elapsed         | 5578         |\n",
      "|    total_timesteps      | 8732672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018713861 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.434       |\n",
      "|    explained_variance   | 0.034        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 733          |\n",
      "|    n_updates            | 14210        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1067         |\n",
      "|    time_elapsed         | 5581         |\n",
      "|    total_timesteps      | 8740864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035956355 |\n",
      "|    clip_fraction        | 0.0311       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.441       |\n",
      "|    explained_variance   | 0.0209       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 866          |\n",
      "|    n_updates            | 14220        |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1068         |\n",
      "|    time_elapsed         | 5585         |\n",
      "|    total_timesteps      | 8749056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019576566 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | -0.00238     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 814          |\n",
      "|    n_updates            | 14230        |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1069         |\n",
      "|    time_elapsed         | 5589         |\n",
      "|    total_timesteps      | 8757248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031430854 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.449       |\n",
      "|    explained_variance   | 0.0637       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 709          |\n",
      "|    n_updates            | 14240        |\n",
      "|    policy_gradient_loss | -0.00417     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8760000, episode_reward=603.80 +/- 52.84\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 604         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 8760000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002062329 |\n",
      "|    clip_fraction        | 0.0127      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.453      |\n",
      "|    explained_variance   | 0.0684      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 743         |\n",
      "|    n_updates            | 14250       |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    value_loss           | 1.62e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1565    |\n",
      "|    iterations      | 1070    |\n",
      "|    time_elapsed    | 5599    |\n",
      "|    total_timesteps | 8765440 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1565        |\n",
      "|    iterations           | 1071        |\n",
      "|    time_elapsed         | 5603        |\n",
      "|    total_timesteps      | 8773632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002768529 |\n",
      "|    clip_fraction        | 0.0202      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.441      |\n",
      "|    explained_variance   | 0.0567      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 818         |\n",
      "|    n_updates            | 14260       |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1072         |\n",
      "|    time_elapsed         | 5606         |\n",
      "|    total_timesteps      | 8781824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023807893 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.437       |\n",
      "|    explained_variance   | 0.00271      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 780          |\n",
      "|    n_updates            | 14270        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1073         |\n",
      "|    time_elapsed         | 5610         |\n",
      "|    total_timesteps      | 8790016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018463716 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.429       |\n",
      "|    explained_variance   | 0.0159       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 810          |\n",
      "|    n_updates            | 14280        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 1074         |\n",
      "|    time_elapsed         | 5614         |\n",
      "|    total_timesteps      | 8798208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020381685 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.438       |\n",
      "|    explained_variance   | 0.0313       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 623          |\n",
      "|    n_updates            | 14290        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8800000, episode_reward=614.40 +/- 49.12\n",
      "Episode length: 200.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 200       |\n",
      "|    mean_reward          | 614       |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 8800000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0025455 |\n",
      "|    clip_fraction        | 0.0158    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.436    |\n",
      "|    explained_variance   | 0.0319    |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 909       |\n",
      "|    n_updates            | 14300     |\n",
      "|    policy_gradient_loss | -0.00375  |\n",
      "|    value_loss           | 1.72e+03  |\n",
      "---------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1565    |\n",
      "|    iterations      | 1075    |\n",
      "|    time_elapsed    | 5624    |\n",
      "|    total_timesteps | 8806400 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1076         |\n",
      "|    time_elapsed         | 5628         |\n",
      "|    total_timesteps      | 8814592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018557651 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.43        |\n",
      "|    explained_variance   | 0.0398       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 821          |\n",
      "|    n_updates            | 14310        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1566        |\n",
      "|    iterations           | 1077        |\n",
      "|    time_elapsed         | 5633        |\n",
      "|    total_timesteps      | 8822784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002846012 |\n",
      "|    clip_fraction        | 0.0196      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.432      |\n",
      "|    explained_variance   | 0.0196      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 622         |\n",
      "|    n_updates            | 14320       |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    value_loss           | 1.64e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1078         |\n",
      "|    time_elapsed         | 5636         |\n",
      "|    total_timesteps      | 8830976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017609387 |\n",
      "|    clip_fraction        | 0.00911      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.419       |\n",
      "|    explained_variance   | 0.0331       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 822          |\n",
      "|    n_updates            | 14330        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 1079         |\n",
      "|    time_elapsed         | 5640         |\n",
      "|    total_timesteps      | 8839168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023828642 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.43        |\n",
      "|    explained_variance   | 0.00522      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 828          |\n",
      "|    n_updates            | 14340        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8840000, episode_reward=590.00 +/- 99.86\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 590          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8840000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025879508 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.436       |\n",
      "|    explained_variance   | 0.0376       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 666          |\n",
      "|    n_updates            | 14350        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1565    |\n",
      "|    iterations      | 1080    |\n",
      "|    time_elapsed    | 5650    |\n",
      "|    total_timesteps | 8847360 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1081         |\n",
      "|    time_elapsed         | 5654         |\n",
      "|    total_timesteps      | 8855552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022874146 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.435       |\n",
      "|    explained_variance   | 0.0251       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 970          |\n",
      "|    n_updates            | 14360        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1566        |\n",
      "|    iterations           | 1082        |\n",
      "|    time_elapsed         | 5658        |\n",
      "|    total_timesteps      | 8863744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002132932 |\n",
      "|    clip_fraction        | 0.0145      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.44       |\n",
      "|    explained_variance   | 0.0357      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 801         |\n",
      "|    n_updates            | 14370       |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1566        |\n",
      "|    iterations           | 1083        |\n",
      "|    time_elapsed         | 5662        |\n",
      "|    total_timesteps      | 8871936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002301723 |\n",
      "|    clip_fraction        | 0.0155      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.431      |\n",
      "|    explained_variance   | 0.064       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 751         |\n",
      "|    n_updates            | 14380       |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    value_loss           | 1.52e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=8880000, episode_reward=619.60 +/- 46.73\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 620          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8880000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026204062 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.43        |\n",
      "|    explained_variance   | 0.0458       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 614          |\n",
      "|    n_updates            | 14390        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1565    |\n",
      "|    iterations      | 1084    |\n",
      "|    time_elapsed    | 5672    |\n",
      "|    total_timesteps | 8880128 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1565        |\n",
      "|    iterations           | 1085        |\n",
      "|    time_elapsed         | 5675        |\n",
      "|    total_timesteps      | 8888320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002749822 |\n",
      "|    clip_fraction        | 0.0219      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.425      |\n",
      "|    explained_variance   | 0.0497      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 761         |\n",
      "|    n_updates            | 14400       |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    value_loss           | 1.76e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1086         |\n",
      "|    time_elapsed         | 5679         |\n",
      "|    total_timesteps      | 8896512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024887973 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.423       |\n",
      "|    explained_variance   | 0.0305       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 904          |\n",
      "|    n_updates            | 14410        |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1566        |\n",
      "|    iterations           | 1087        |\n",
      "|    time_elapsed         | 5683        |\n",
      "|    total_timesteps      | 8904704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002043555 |\n",
      "|    clip_fraction        | 0.0109      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.425      |\n",
      "|    explained_variance   | 0.045       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1e+03       |\n",
      "|    n_updates            | 14420       |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    value_loss           | 1.69e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 1088         |\n",
      "|    time_elapsed         | 5686         |\n",
      "|    total_timesteps      | 8912896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020845425 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.417       |\n",
      "|    explained_variance   | 0.065        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 14430        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8920000, episode_reward=614.80 +/- 61.65\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 615          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8920000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021559387 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.427       |\n",
      "|    explained_variance   | 0.0313       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 768          |\n",
      "|    n_updates            | 14440        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1566    |\n",
      "|    iterations      | 1089    |\n",
      "|    time_elapsed    | 5696    |\n",
      "|    total_timesteps | 8921088 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1090         |\n",
      "|    time_elapsed         | 5700         |\n",
      "|    total_timesteps      | 8929280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017423843 |\n",
      "|    clip_fraction        | 0.00931      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.0461       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 838          |\n",
      "|    n_updates            | 14450        |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1091         |\n",
      "|    time_elapsed         | 5703         |\n",
      "|    total_timesteps      | 8937472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021169123 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.439       |\n",
      "|    explained_variance   | 0.0324       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 604          |\n",
      "|    n_updates            | 14460        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1567        |\n",
      "|    iterations           | 1092        |\n",
      "|    time_elapsed         | 5707        |\n",
      "|    total_timesteps      | 8945664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002826983 |\n",
      "|    clip_fraction        | 0.0203      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.433      |\n",
      "|    explained_variance   | 0.0256      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 766         |\n",
      "|    n_updates            | 14470       |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    value_loss           | 1.62e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 1093         |\n",
      "|    time_elapsed         | 5711         |\n",
      "|    total_timesteps      | 8953856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020022336 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.444       |\n",
      "|    explained_variance   | 0.0094       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 787          |\n",
      "|    n_updates            | 14480        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8960000, episode_reward=610.40 +/- 52.80\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 610         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 8960000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002342909 |\n",
      "|    clip_fraction        | 0.0165      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.432      |\n",
      "|    explained_variance   | 0.018       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 804         |\n",
      "|    n_updates            | 14490       |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    value_loss           | 1.77e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1566    |\n",
      "|    iterations      | 1094    |\n",
      "|    time_elapsed    | 5721    |\n",
      "|    total_timesteps | 8962048 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1566         |\n",
      "|    iterations           | 1095         |\n",
      "|    time_elapsed         | 5725         |\n",
      "|    total_timesteps      | 8970240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018623983 |\n",
      "|    clip_fraction        | 0.00946      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.429       |\n",
      "|    explained_variance   | 0.0531       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 14500        |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 1096         |\n",
      "|    time_elapsed         | 5729         |\n",
      "|    total_timesteps      | 8978432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018309847 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.433       |\n",
      "|    explained_variance   | 0.0374       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 870          |\n",
      "|    n_updates            | 14510        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 1097         |\n",
      "|    time_elapsed         | 5732         |\n",
      "|    total_timesteps      | 8986624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015683717 |\n",
      "|    clip_fraction        | 0.00555      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.0431       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 967          |\n",
      "|    n_updates            | 14520        |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 1098         |\n",
      "|    time_elapsed         | 5736         |\n",
      "|    total_timesteps      | 8994816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023286184 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.0369       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 919          |\n",
      "|    n_updates            | 14530        |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9000000, episode_reward=612.40 +/- 50.86\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 612          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028884942 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.434       |\n",
      "|    explained_variance   | 0.0122       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 14540        |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1566    |\n",
      "|    iterations      | 1099    |\n",
      "|    time_elapsed    | 5746    |\n",
      "|    total_timesteps | 9003008 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 1100         |\n",
      "|    time_elapsed         | 5749         |\n",
      "|    total_timesteps      | 9011200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024174093 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.425       |\n",
      "|    explained_variance   | 0.038        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 593          |\n",
      "|    n_updates            | 14550        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 1101         |\n",
      "|    time_elapsed         | 5753         |\n",
      "|    total_timesteps      | 9019392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020787222 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.427       |\n",
      "|    explained_variance   | 0.0291       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 962          |\n",
      "|    n_updates            | 14560        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 1102         |\n",
      "|    time_elapsed         | 5757         |\n",
      "|    total_timesteps      | 9027584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022449528 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.429       |\n",
      "|    explained_variance   | 0.0308       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 863          |\n",
      "|    n_updates            | 14570        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 1103         |\n",
      "|    time_elapsed         | 5761         |\n",
      "|    total_timesteps      | 9035776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021877284 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.429       |\n",
      "|    explained_variance   | 0.0566       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 787          |\n",
      "|    n_updates            | 14580        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9040000, episode_reward=593.60 +/- 100.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 594          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9040000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020250953 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.44        |\n",
      "|    explained_variance   | 0.0616       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 773          |\n",
      "|    n_updates            | 14590        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1567    |\n",
      "|    iterations      | 1104    |\n",
      "|    time_elapsed    | 5771    |\n",
      "|    total_timesteps | 9043968 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 1105         |\n",
      "|    time_elapsed         | 5774         |\n",
      "|    total_timesteps      | 9052160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021625552 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.433       |\n",
      "|    explained_variance   | 0.0313       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 752          |\n",
      "|    n_updates            | 14600        |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 1106         |\n",
      "|    time_elapsed         | 5778         |\n",
      "|    total_timesteps      | 9060352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019390146 |\n",
      "|    clip_fraction        | 0.00968      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.0266       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 761          |\n",
      "|    n_updates            | 14610        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 1107         |\n",
      "|    time_elapsed         | 5782         |\n",
      "|    total_timesteps      | 9068544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025092666 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.447       |\n",
      "|    explained_variance   | 0.0384       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 793          |\n",
      "|    n_updates            | 14620        |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1568        |\n",
      "|    iterations           | 1108        |\n",
      "|    time_elapsed         | 5786        |\n",
      "|    total_timesteps      | 9076736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002284452 |\n",
      "|    clip_fraction        | 0.0153      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.44       |\n",
      "|    explained_variance   | 0.0302      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 956         |\n",
      "|    n_updates            | 14630       |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=9080000, episode_reward=607.20 +/- 62.32\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 607          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9080000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021044195 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.449       |\n",
      "|    explained_variance   | 0.015        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 760          |\n",
      "|    n_updates            | 14640        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1567    |\n",
      "|    iterations      | 1109    |\n",
      "|    time_elapsed    | 5796    |\n",
      "|    total_timesteps | 9084928 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1567         |\n",
      "|    iterations           | 1110         |\n",
      "|    time_elapsed         | 5799         |\n",
      "|    total_timesteps      | 9093120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026601423 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.446       |\n",
      "|    explained_variance   | 0.0142       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 865          |\n",
      "|    n_updates            | 14650        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 1111         |\n",
      "|    time_elapsed         | 5803         |\n",
      "|    total_timesteps      | 9101312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019976404 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.443       |\n",
      "|    explained_variance   | 0.0367       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 657          |\n",
      "|    n_updates            | 14660        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 1112         |\n",
      "|    time_elapsed         | 5807         |\n",
      "|    total_timesteps      | 9109504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020293458 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.437       |\n",
      "|    explained_variance   | 0.0428       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 589          |\n",
      "|    n_updates            | 14670        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 1113         |\n",
      "|    time_elapsed         | 5811         |\n",
      "|    total_timesteps      | 9117696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017826605 |\n",
      "|    clip_fraction        | 0.00927      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.436       |\n",
      "|    explained_variance   | 0.0367       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 914          |\n",
      "|    n_updates            | 14680        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9120000, episode_reward=608.00 +/- 60.93\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 608          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019987193 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.02         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 946          |\n",
      "|    n_updates            | 14690        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1567    |\n",
      "|    iterations      | 1114    |\n",
      "|    time_elapsed    | 5821    |\n",
      "|    total_timesteps | 9125888 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 1115         |\n",
      "|    time_elapsed         | 5824         |\n",
      "|    total_timesteps      | 9134080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020802948 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.427       |\n",
      "|    explained_variance   | 0.0273       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 745          |\n",
      "|    n_updates            | 14700        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 1116         |\n",
      "|    time_elapsed         | 5828         |\n",
      "|    total_timesteps      | 9142272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016982728 |\n",
      "|    clip_fraction        | 0.00776      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.424       |\n",
      "|    explained_variance   | 0.041        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.25e+03     |\n",
      "|    n_updates            | 14710        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 1117         |\n",
      "|    time_elapsed         | 5832         |\n",
      "|    total_timesteps      | 9150464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021279799 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.423       |\n",
      "|    explained_variance   | 0.0678       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 874          |\n",
      "|    n_updates            | 14720        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 1118         |\n",
      "|    time_elapsed         | 5836         |\n",
      "|    total_timesteps      | 9158656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021357872 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.422       |\n",
      "|    explained_variance   | 0.0338       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 761          |\n",
      "|    n_updates            | 14730        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9160000, episode_reward=621.40 +/- 57.24\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 621         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 9160000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002104404 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.412      |\n",
      "|    explained_variance   | 0.0383      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 800         |\n",
      "|    n_updates            | 14740       |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    value_loss           | 1.72e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1568    |\n",
      "|    iterations      | 1119    |\n",
      "|    time_elapsed    | 5845    |\n",
      "|    total_timesteps | 9166848 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 1120         |\n",
      "|    time_elapsed         | 5849         |\n",
      "|    total_timesteps      | 9175040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019937241 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.0571       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 943          |\n",
      "|    n_updates            | 14750        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 1121         |\n",
      "|    time_elapsed         | 5853         |\n",
      "|    total_timesteps      | 9183232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020911586 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.424       |\n",
      "|    explained_variance   | 0.0445       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 783          |\n",
      "|    n_updates            | 14760        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 1122         |\n",
      "|    time_elapsed         | 5857         |\n",
      "|    total_timesteps      | 9191424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018043914 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.424       |\n",
      "|    explained_variance   | 0.00831      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 934          |\n",
      "|    n_updates            | 14770        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 1123         |\n",
      "|    time_elapsed         | 5860         |\n",
      "|    total_timesteps      | 9199616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019035224 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.411       |\n",
      "|    explained_variance   | 0.0366       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 612          |\n",
      "|    n_updates            | 14780        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9200000, episode_reward=617.00 +/- 64.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 617          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019416618 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.413       |\n",
      "|    explained_variance   | 0.0334       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 14790        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1568    |\n",
      "|    iterations      | 1124    |\n",
      "|    time_elapsed    | 5870    |\n",
      "|    total_timesteps | 9207808 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 1125         |\n",
      "|    time_elapsed         | 5874         |\n",
      "|    total_timesteps      | 9216000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019787136 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.418       |\n",
      "|    explained_variance   | 0.0561       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 632          |\n",
      "|    n_updates            | 14800        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 1126         |\n",
      "|    time_elapsed         | 5878         |\n",
      "|    total_timesteps      | 9224192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016975233 |\n",
      "|    clip_fraction        | 0.00815      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.411       |\n",
      "|    explained_variance   | 0.0518       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 14810        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 1127         |\n",
      "|    time_elapsed         | 5882         |\n",
      "|    total_timesteps      | 9232384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020693843 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.411       |\n",
      "|    explained_variance   | 0.0666       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 609          |\n",
      "|    n_updates            | 14820        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9240000, episode_reward=625.00 +/- 61.94\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 625          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9240000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018973679 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.394       |\n",
      "|    explained_variance   | 0.00657      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 972          |\n",
      "|    n_updates            | 14830        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1568    |\n",
      "|    iterations      | 1128    |\n",
      "|    time_elapsed    | 5893    |\n",
      "|    total_timesteps | 9240576 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 1129         |\n",
      "|    time_elapsed         | 5897         |\n",
      "|    total_timesteps      | 9248768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019409221 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.408       |\n",
      "|    explained_variance   | 0.0276       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 607          |\n",
      "|    n_updates            | 14840        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 1130         |\n",
      "|    time_elapsed         | 5900         |\n",
      "|    total_timesteps      | 9256960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022253525 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.403       |\n",
      "|    explained_variance   | 0.0318       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 14850        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 1131         |\n",
      "|    time_elapsed         | 5904         |\n",
      "|    total_timesteps      | 9265152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017340604 |\n",
      "|    clip_fraction        | 0.00817      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.392       |\n",
      "|    explained_variance   | 0.0545       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 967          |\n",
      "|    n_updates            | 14860        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1569        |\n",
      "|    iterations           | 1132        |\n",
      "|    time_elapsed         | 5908        |\n",
      "|    total_timesteps      | 9273344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002592557 |\n",
      "|    clip_fraction        | 0.0185      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.395      |\n",
      "|    explained_variance   | 0.0641      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 966         |\n",
      "|    n_updates            | 14870       |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=9280000, episode_reward=609.80 +/- 60.98\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 610         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 9280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002128741 |\n",
      "|    clip_fraction        | 0.0149      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.398      |\n",
      "|    explained_variance   | 0.0246      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 724         |\n",
      "|    n_updates            | 14880       |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1568    |\n",
      "|    iterations      | 1133    |\n",
      "|    time_elapsed    | 5918    |\n",
      "|    total_timesteps | 9281536 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 1134         |\n",
      "|    time_elapsed         | 5922         |\n",
      "|    total_timesteps      | 9289728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019575781 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.4         |\n",
      "|    explained_variance   | 0.057        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 949          |\n",
      "|    n_updates            | 14890        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1568         |\n",
      "|    iterations           | 1135         |\n",
      "|    time_elapsed         | 5926         |\n",
      "|    total_timesteps      | 9297920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017547454 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.391       |\n",
      "|    explained_variance   | 0.0433       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 698          |\n",
      "|    n_updates            | 14900        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 1136         |\n",
      "|    time_elapsed         | 5929         |\n",
      "|    total_timesteps      | 9306112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021666226 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.399       |\n",
      "|    explained_variance   | 0.00759      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 737          |\n",
      "|    n_updates            | 14910        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1569        |\n",
      "|    iterations           | 1137        |\n",
      "|    time_elapsed         | 5933        |\n",
      "|    total_timesteps      | 9314304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002538483 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.397      |\n",
      "|    explained_variance   | 0.0534      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 738         |\n",
      "|    n_updates            | 14920       |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    value_loss           | 1.57e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=9320000, episode_reward=605.20 +/- 57.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 605          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9320000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022818104 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.402       |\n",
      "|    explained_variance   | 0.036        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 14930        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1568    |\n",
      "|    iterations      | 1138    |\n",
      "|    time_elapsed    | 5943    |\n",
      "|    total_timesteps | 9322496 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1568        |\n",
      "|    iterations           | 1139        |\n",
      "|    time_elapsed         | 5947        |\n",
      "|    total_timesteps      | 9330688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002129742 |\n",
      "|    clip_fraction        | 0.0126      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.412      |\n",
      "|    explained_variance   | 0.0324      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1e+03       |\n",
      "|    n_updates            | 14940       |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    value_loss           | 1.84e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1569        |\n",
      "|    iterations           | 1140        |\n",
      "|    time_elapsed         | 5951        |\n",
      "|    total_timesteps      | 9338880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001980932 |\n",
      "|    clip_fraction        | 0.0126      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.404      |\n",
      "|    explained_variance   | 0.0353      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 864         |\n",
      "|    n_updates            | 14950       |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    value_loss           | 1.59e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 1141         |\n",
      "|    time_elapsed         | 5954         |\n",
      "|    total_timesteps      | 9347072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022659963 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.402       |\n",
      "|    explained_variance   | 0.0396       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 660          |\n",
      "|    n_updates            | 14960        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 1142         |\n",
      "|    time_elapsed         | 5958         |\n",
      "|    total_timesteps      | 9355264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019767955 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.407       |\n",
      "|    explained_variance   | 0.0409       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 908          |\n",
      "|    n_updates            | 14970        |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9360000, episode_reward=597.40 +/- 61.83\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 597          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9360000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023720802 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.418       |\n",
      "|    explained_variance   | 0.00341      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 820          |\n",
      "|    n_updates            | 14980        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1568    |\n",
      "|    iterations      | 1143    |\n",
      "|    time_elapsed    | 5968    |\n",
      "|    total_timesteps | 9363456 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 1144         |\n",
      "|    time_elapsed         | 5972         |\n",
      "|    total_timesteps      | 9371648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015795438 |\n",
      "|    clip_fraction        | 0.00732      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.415       |\n",
      "|    explained_variance   | 0.0376       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 915          |\n",
      "|    n_updates            | 14990        |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 1145         |\n",
      "|    time_elapsed         | 5976         |\n",
      "|    total_timesteps      | 9379840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020143797 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.411       |\n",
      "|    explained_variance   | 0.0476       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 796          |\n",
      "|    n_updates            | 15000        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 1146         |\n",
      "|    time_elapsed         | 5980         |\n",
      "|    total_timesteps      | 9388032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020062318 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.407       |\n",
      "|    explained_variance   | 0.0162       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 738          |\n",
      "|    n_updates            | 15010        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1570        |\n",
      "|    iterations           | 1147        |\n",
      "|    time_elapsed         | 5984        |\n",
      "|    total_timesteps      | 9396224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001994461 |\n",
      "|    clip_fraction        | 0.0107      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.419      |\n",
      "|    explained_variance   | 0.0141      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.18e+03    |\n",
      "|    n_updates            | 15020       |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    value_loss           | 1.79e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=9400000, episode_reward=620.20 +/- 74.63\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 620          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9400000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025611315 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.0215       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 759          |\n",
      "|    n_updates            | 15030        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 1.51e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1568    |\n",
      "|    iterations      | 1148    |\n",
      "|    time_elapsed    | 5994    |\n",
      "|    total_timesteps | 9404416 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 1149         |\n",
      "|    time_elapsed         | 5998         |\n",
      "|    total_timesteps      | 9412608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022599306 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.419       |\n",
      "|    explained_variance   | 0.033        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 552          |\n",
      "|    n_updates            | 15040        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    value_loss           | 1.59e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 1150         |\n",
      "|    time_elapsed         | 6001         |\n",
      "|    total_timesteps      | 9420800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021326253 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.425       |\n",
      "|    explained_variance   | 0.0527       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 820          |\n",
      "|    n_updates            | 15050        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 1151         |\n",
      "|    time_elapsed         | 6005         |\n",
      "|    total_timesteps      | 9428992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022521745 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.42        |\n",
      "|    explained_variance   | 0.0247       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 962          |\n",
      "|    n_updates            | 15060        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 1152         |\n",
      "|    time_elapsed         | 6009         |\n",
      "|    total_timesteps      | 9437184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022724024 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.416       |\n",
      "|    explained_variance   | 0.0178       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 831          |\n",
      "|    n_updates            | 15070        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9440000, episode_reward=617.80 +/- 71.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 618         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 9440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002018365 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.41       |\n",
      "|    explained_variance   | 0.0407      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 15080       |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1569    |\n",
      "|    iterations      | 1153    |\n",
      "|    time_elapsed    | 6019    |\n",
      "|    total_timesteps | 9445376 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 1154         |\n",
      "|    time_elapsed         | 6023         |\n",
      "|    total_timesteps      | 9453568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017492989 |\n",
      "|    clip_fraction        | 0.00801      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.416       |\n",
      "|    explained_variance   | 0.0227       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 834          |\n",
      "|    n_updates            | 15090        |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 1155         |\n",
      "|    time_elapsed         | 6026         |\n",
      "|    total_timesteps      | 9461760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017325887 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.406       |\n",
      "|    explained_variance   | 0.0351       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 742          |\n",
      "|    n_updates            | 15100        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 1156         |\n",
      "|    time_elapsed         | 6030         |\n",
      "|    total_timesteps      | 9469952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020674362 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.393       |\n",
      "|    explained_variance   | 0.0222       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 909          |\n",
      "|    n_updates            | 15110        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1570        |\n",
      "|    iterations           | 1157        |\n",
      "|    time_elapsed         | 6034        |\n",
      "|    total_timesteps      | 9478144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001919383 |\n",
      "|    clip_fraction        | 0.0115      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.413      |\n",
      "|    explained_variance   | 0.0425      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 829         |\n",
      "|    n_updates            | 15120       |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    value_loss           | 1.64e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=9480000, episode_reward=595.00 +/- 58.52\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 595          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9480000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022768604 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.408       |\n",
      "|    explained_variance   | 0.0527       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 893          |\n",
      "|    n_updates            | 15130        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1569    |\n",
      "|    iterations      | 1158    |\n",
      "|    time_elapsed    | 6044    |\n",
      "|    total_timesteps | 9486336 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 1159         |\n",
      "|    time_elapsed         | 6047         |\n",
      "|    total_timesteps      | 9494528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020486484 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.406       |\n",
      "|    explained_variance   | 0.0386       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 740          |\n",
      "|    n_updates            | 15140        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 1160         |\n",
      "|    time_elapsed         | 6051         |\n",
      "|    total_timesteps      | 9502720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022375751 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.412       |\n",
      "|    explained_variance   | 0.0601       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 909          |\n",
      "|    n_updates            | 15150        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1570        |\n",
      "|    iterations           | 1161        |\n",
      "|    time_elapsed         | 6055        |\n",
      "|    total_timesteps      | 9510912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002361049 |\n",
      "|    clip_fraction        | 0.017       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.407      |\n",
      "|    explained_variance   | 0.0512      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 947         |\n",
      "|    n_updates            | 15160       |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    value_loss           | 1.76e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 1162         |\n",
      "|    time_elapsed         | 6058         |\n",
      "|    total_timesteps      | 9519104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020112526 |\n",
      "|    clip_fraction        | 0.00859      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.411       |\n",
      "|    explained_variance   | 0.0288       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 861          |\n",
      "|    n_updates            | 15170        |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9520000, episode_reward=627.00 +/- 59.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 627         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 9520000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002277893 |\n",
      "|    clip_fraction        | 0.0159      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.405      |\n",
      "|    explained_variance   | 0.0573      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 799         |\n",
      "|    n_updates            | 15180       |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    value_loss           | 1.71e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1569    |\n",
      "|    iterations      | 1163    |\n",
      "|    time_elapsed    | 6069    |\n",
      "|    total_timesteps | 9527296 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 1164         |\n",
      "|    time_elapsed         | 6072         |\n",
      "|    total_timesteps      | 9535488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017728803 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.406       |\n",
      "|    explained_variance   | 0.0477       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 970          |\n",
      "|    n_updates            | 15190        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 1165         |\n",
      "|    time_elapsed         | 6076         |\n",
      "|    total_timesteps      | 9543680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016421573 |\n",
      "|    clip_fraction        | 0.00809      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.419       |\n",
      "|    explained_variance   | 0.0243       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 700          |\n",
      "|    n_updates            | 15200        |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 1166         |\n",
      "|    time_elapsed         | 6079         |\n",
      "|    total_timesteps      | 9551872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023535104 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.408       |\n",
      "|    explained_variance   | 0.0352       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 551          |\n",
      "|    n_updates            | 15210        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9560000, episode_reward=622.00 +/- 55.86\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 622          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020812703 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.412       |\n",
      "|    explained_variance   | 0.0213       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 690          |\n",
      "|    n_updates            | 15220        |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1569    |\n",
      "|    iterations      | 1167    |\n",
      "|    time_elapsed    | 6089    |\n",
      "|    total_timesteps | 9560064 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 1168         |\n",
      "|    time_elapsed         | 6093         |\n",
      "|    total_timesteps      | 9568256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019644317 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.428       |\n",
      "|    explained_variance   | 0.00623      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 814          |\n",
      "|    n_updates            | 15230        |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 1169         |\n",
      "|    time_elapsed         | 6097         |\n",
      "|    total_timesteps      | 9576448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019402863 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.416       |\n",
      "|    explained_variance   | 0.0336       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1e+03        |\n",
      "|    n_updates            | 15240        |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 1170         |\n",
      "|    time_elapsed         | 6100         |\n",
      "|    total_timesteps      | 9584640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023143576 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.43        |\n",
      "|    explained_variance   | 0.0224       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 955          |\n",
      "|    n_updates            | 15250        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 1171         |\n",
      "|    time_elapsed         | 6104         |\n",
      "|    total_timesteps      | 9592832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019299472 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.423       |\n",
      "|    explained_variance   | 0.0242       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 826          |\n",
      "|    n_updates            | 15260        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9600000, episode_reward=626.40 +/- 57.12\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 626          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9600000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022147947 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.415       |\n",
      "|    explained_variance   | 0.0373       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 15270        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1570    |\n",
      "|    iterations      | 1172    |\n",
      "|    time_elapsed    | 6114    |\n",
      "|    total_timesteps | 9601024 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 1173         |\n",
      "|    time_elapsed         | 6118         |\n",
      "|    total_timesteps      | 9609216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015147722 |\n",
      "|    clip_fraction        | 0.00863      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.417       |\n",
      "|    explained_variance   | 0.0259       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 813          |\n",
      "|    n_updates            | 15280        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 1174         |\n",
      "|    time_elapsed         | 6121         |\n",
      "|    total_timesteps      | 9617408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024349121 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.419       |\n",
      "|    explained_variance   | 0.0249       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 838          |\n",
      "|    n_updates            | 15290        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1571        |\n",
      "|    iterations           | 1175        |\n",
      "|    time_elapsed         | 6125        |\n",
      "|    total_timesteps      | 9625600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002109028 |\n",
      "|    clip_fraction        | 0.0114      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.416      |\n",
      "|    explained_variance   | 0.0603      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 882         |\n",
      "|    n_updates            | 15300       |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    value_loss           | 1.72e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 1176         |\n",
      "|    time_elapsed         | 6129         |\n",
      "|    total_timesteps      | 9633792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021013806 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.418       |\n",
      "|    explained_variance   | 0.0122       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 774          |\n",
      "|    n_updates            | 15310        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9640000, episode_reward=597.20 +/- 58.79\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 597          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9640000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021787211 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.431       |\n",
      "|    explained_variance   | 0.0363       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 867          |\n",
      "|    n_updates            | 15320        |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1570    |\n",
      "|    iterations      | 1177    |\n",
      "|    time_elapsed    | 6139    |\n",
      "|    total_timesteps | 9641984 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 1178         |\n",
      "|    time_elapsed         | 6143         |\n",
      "|    total_timesteps      | 9650176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017845584 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.437       |\n",
      "|    explained_variance   | 0.0338       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 539          |\n",
      "|    n_updates            | 15330        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 1179         |\n",
      "|    time_elapsed         | 6148         |\n",
      "|    total_timesteps      | 9658368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018002675 |\n",
      "|    clip_fraction        | 0.00822      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.433       |\n",
      "|    explained_variance   | 0.0355       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 915          |\n",
      "|    n_updates            | 15340        |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 1180         |\n",
      "|    time_elapsed         | 6152         |\n",
      "|    total_timesteps      | 9666560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022854544 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.434       |\n",
      "|    explained_variance   | 0.0279       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 797          |\n",
      "|    n_updates            | 15350        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1571        |\n",
      "|    iterations           | 1181        |\n",
      "|    time_elapsed         | 6156        |\n",
      "|    total_timesteps      | 9674752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002007584 |\n",
      "|    clip_fraction        | 0.0119      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.436      |\n",
      "|    explained_variance   | 0.0171      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 801         |\n",
      "|    n_updates            | 15360       |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    value_loss           | 1.77e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=9680000, episode_reward=619.00 +/- 49.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 619         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 9680000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001648736 |\n",
      "|    clip_fraction        | 0.00867     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.428      |\n",
      "|    explained_variance   | 0.0332      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 951         |\n",
      "|    n_updates            | 15370       |\n",
      "|    policy_gradient_loss | -0.00248    |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1570    |\n",
      "|    iterations      | 1182    |\n",
      "|    time_elapsed    | 6166    |\n",
      "|    total_timesteps | 9682944 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 1183         |\n",
      "|    time_elapsed         | 6170         |\n",
      "|    total_timesteps      | 9691136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021052787 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.436       |\n",
      "|    explained_variance   | 0.0401       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 547          |\n",
      "|    n_updates            | 15380        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 1184         |\n",
      "|    time_elapsed         | 6173         |\n",
      "|    total_timesteps      | 9699328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023956024 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.42        |\n",
      "|    explained_variance   | 0.0533       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 15390        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1571        |\n",
      "|    iterations           | 1185        |\n",
      "|    time_elapsed         | 6177        |\n",
      "|    total_timesteps      | 9707520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001752395 |\n",
      "|    clip_fraction        | 0.00859     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.424      |\n",
      "|    explained_variance   | 0.0434      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 852         |\n",
      "|    n_updates            | 15400       |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    value_loss           | 1.91e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 1186         |\n",
      "|    time_elapsed         | 6181         |\n",
      "|    total_timesteps      | 9715712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021064267 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.433       |\n",
      "|    explained_variance   | 0.0469       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 749          |\n",
      "|    n_updates            | 15410        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9720000, episode_reward=601.20 +/- 98.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 601          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9720000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022093165 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.417       |\n",
      "|    explained_variance   | 0.03         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 955          |\n",
      "|    n_updates            | 15420        |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1570    |\n",
      "|    iterations      | 1187    |\n",
      "|    time_elapsed    | 6191    |\n",
      "|    total_timesteps | 9723904 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 1188         |\n",
      "|    time_elapsed         | 6195         |\n",
      "|    total_timesteps      | 9732096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018141728 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.413       |\n",
      "|    explained_variance   | 0.0333       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 751          |\n",
      "|    n_updates            | 15430        |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1571        |\n",
      "|    iterations           | 1189        |\n",
      "|    time_elapsed         | 6198        |\n",
      "|    total_timesteps      | 9740288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002006831 |\n",
      "|    clip_fraction        | 0.0131      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.425      |\n",
      "|    explained_variance   | 0.0269      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.09e+03    |\n",
      "|    n_updates            | 15440       |\n",
      "|    policy_gradient_loss | -0.00326    |\n",
      "|    value_loss           | 1.84e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 1190         |\n",
      "|    time_elapsed         | 6202         |\n",
      "|    total_timesteps      | 9748480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015350193 |\n",
      "|    clip_fraction        | 0.00839      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.422       |\n",
      "|    explained_variance   | 0.0359       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 784          |\n",
      "|    n_updates            | 15450        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 1572      |\n",
      "|    iterations           | 1191      |\n",
      "|    time_elapsed         | 6206      |\n",
      "|    total_timesteps      | 9756672   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0022143 |\n",
      "|    clip_fraction        | 0.0126    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.421    |\n",
      "|    explained_variance   | 0.0439    |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 782       |\n",
      "|    n_updates            | 15460     |\n",
      "|    policy_gradient_loss | -0.00324  |\n",
      "|    value_loss           | 1.78e+03  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=9760000, episode_reward=613.00 +/- 54.01\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 613          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9760000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021151467 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.429       |\n",
      "|    explained_variance   | 0.0453       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 15470        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1570    |\n",
      "|    iterations      | 1192    |\n",
      "|    time_elapsed    | 6216    |\n",
      "|    total_timesteps | 9764864 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 1193         |\n",
      "|    time_elapsed         | 6219         |\n",
      "|    total_timesteps      | 9773056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017670706 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.416       |\n",
      "|    explained_variance   | 0.0539       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 658          |\n",
      "|    n_updates            | 15480        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1571        |\n",
      "|    iterations           | 1194        |\n",
      "|    time_elapsed         | 6223        |\n",
      "|    total_timesteps      | 9781248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001744854 |\n",
      "|    clip_fraction        | 0.00935     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.426      |\n",
      "|    explained_variance   | 0.0313      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 772         |\n",
      "|    n_updates            | 15490       |\n",
      "|    policy_gradient_loss | -0.00297    |\n",
      "|    value_loss           | 1.8e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1572         |\n",
      "|    iterations           | 1195         |\n",
      "|    time_elapsed         | 6227         |\n",
      "|    total_timesteps      | 9789440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019231961 |\n",
      "|    clip_fraction        | 0.00935      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.427       |\n",
      "|    explained_variance   | 0.0532       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 889          |\n",
      "|    n_updates            | 15500        |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1572         |\n",
      "|    iterations           | 1196         |\n",
      "|    time_elapsed         | 6230         |\n",
      "|    total_timesteps      | 9797632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024900963 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.425       |\n",
      "|    explained_variance   | 0.0358       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 998          |\n",
      "|    n_updates            | 15510        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9800000, episode_reward=615.40 +/- 64.41\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 615          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9800000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019174635 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.414       |\n",
      "|    explained_variance   | 0.0512       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 15520        |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1571    |\n",
      "|    iterations      | 1197    |\n",
      "|    time_elapsed    | 6240    |\n",
      "|    total_timesteps | 9805824 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 1198         |\n",
      "|    time_elapsed         | 6244         |\n",
      "|    total_timesteps      | 9814016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020468442 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.426       |\n",
      "|    explained_variance   | 0.026        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 828          |\n",
      "|    n_updates            | 15530        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 1199         |\n",
      "|    time_elapsed         | 6248         |\n",
      "|    total_timesteps      | 9822208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022283853 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.419       |\n",
      "|    explained_variance   | 0.0253       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 626          |\n",
      "|    n_updates            | 15540        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1572         |\n",
      "|    iterations           | 1200         |\n",
      "|    time_elapsed         | 6251         |\n",
      "|    total_timesteps      | 9830400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018431823 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.421       |\n",
      "|    explained_variance   | 0.0326       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 674          |\n",
      "|    n_updates            | 15550        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1572         |\n",
      "|    iterations           | 1201         |\n",
      "|    time_elapsed         | 6255         |\n",
      "|    total_timesteps      | 9838592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022228358 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.407       |\n",
      "|    explained_variance   | 0.0563       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 949          |\n",
      "|    n_updates            | 15560        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9840000, episode_reward=609.40 +/- 57.25\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 200        |\n",
      "|    mean_reward          | 609        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 9840000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00189284 |\n",
      "|    clip_fraction        | 0.0129     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.435     |\n",
      "|    explained_variance   | 0.0549     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 712        |\n",
      "|    n_updates            | 15570      |\n",
      "|    policy_gradient_loss | -0.00327   |\n",
      "|    value_loss           | 1.66e+03   |\n",
      "----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1571    |\n",
      "|    iterations      | 1202    |\n",
      "|    time_elapsed    | 6265    |\n",
      "|    total_timesteps | 9846784 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1571         |\n",
      "|    iterations           | 1203         |\n",
      "|    time_elapsed         | 6269         |\n",
      "|    total_timesteps      | 9854976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028535551 |\n",
      "|    clip_fraction        | 0.0216       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | -0.00584     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 936          |\n",
      "|    n_updates            | 15580        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1572         |\n",
      "|    iterations           | 1204         |\n",
      "|    time_elapsed         | 6272         |\n",
      "|    total_timesteps      | 9863168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026935046 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.435       |\n",
      "|    explained_variance   | 0.0304       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 799          |\n",
      "|    n_updates            | 15590        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1572         |\n",
      "|    iterations           | 1205         |\n",
      "|    time_elapsed         | 6276         |\n",
      "|    total_timesteps      | 9871360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024266567 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.436       |\n",
      "|    explained_variance   | 0.0406       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 858          |\n",
      "|    n_updates            | 15600        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1573         |\n",
      "|    iterations           | 1206         |\n",
      "|    time_elapsed         | 6280         |\n",
      "|    total_timesteps      | 9879552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013933417 |\n",
      "|    clip_fraction        | 0.00771      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.431       |\n",
      "|    explained_variance   | 0.0355       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 933          |\n",
      "|    n_updates            | 15610        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9880000, episode_reward=619.80 +/- 59.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 620          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9880000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025293105 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.0216       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 15620        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1571    |\n",
      "|    iterations      | 1207    |\n",
      "|    time_elapsed    | 6290    |\n",
      "|    total_timesteps | 9887744 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1572        |\n",
      "|    iterations           | 1208        |\n",
      "|    time_elapsed         | 6293        |\n",
      "|    total_timesteps      | 9895936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002230681 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.451      |\n",
      "|    explained_variance   | 0.0453      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 734         |\n",
      "|    n_updates            | 15630       |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    value_loss           | 1.69e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1572         |\n",
      "|    iterations           | 1209         |\n",
      "|    time_elapsed         | 6297         |\n",
      "|    total_timesteps      | 9904128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021887617 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.427       |\n",
      "|    explained_variance   | 0.0095       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 776          |\n",
      "|    n_updates            | 15640        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1572         |\n",
      "|    iterations           | 1210         |\n",
      "|    time_elapsed         | 6301         |\n",
      "|    total_timesteps      | 9912320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018480825 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.0184       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 750          |\n",
      "|    n_updates            | 15650        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    value_loss           | 1.91e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9920000, episode_reward=602.20 +/- 54.05\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 602          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9920000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019967598 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.0267       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 663          |\n",
      "|    n_updates            | 15660        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1571    |\n",
      "|    iterations      | 1211    |\n",
      "|    time_elapsed    | 6311    |\n",
      "|    total_timesteps | 9920512 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1572         |\n",
      "|    iterations           | 1212         |\n",
      "|    time_elapsed         | 6315         |\n",
      "|    total_timesteps      | 9928704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014240649 |\n",
      "|    clip_fraction        | 0.00624      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.43        |\n",
      "|    explained_variance   | 0.0317       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 771          |\n",
      "|    n_updates            | 15670        |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1572         |\n",
      "|    iterations           | 1213         |\n",
      "|    time_elapsed         | 6318         |\n",
      "|    total_timesteps      | 9936896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024038313 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.434       |\n",
      "|    explained_variance   | 0.0384       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 683          |\n",
      "|    n_updates            | 15680        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1572         |\n",
      "|    iterations           | 1214         |\n",
      "|    time_elapsed         | 6322         |\n",
      "|    total_timesteps      | 9945088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021125446 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.44        |\n",
      "|    explained_variance   | 0.0491       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 865          |\n",
      "|    n_updates            | 15690        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    value_loss           | 1.96e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1573        |\n",
      "|    iterations           | 1215        |\n",
      "|    time_elapsed         | 6326        |\n",
      "|    total_timesteps      | 9953280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002007104 |\n",
      "|    clip_fraction        | 0.012       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.429      |\n",
      "|    explained_variance   | 0.0193      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 934         |\n",
      "|    n_updates            | 15700       |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    value_loss           | 1.76e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=9960000, episode_reward=619.20 +/- 52.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 619          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9960000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021306016 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.426       |\n",
      "|    explained_variance   | 0.0783       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 824          |\n",
      "|    n_updates            | 15710        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 1572    |\n",
      "|    iterations      | 1216    |\n",
      "|    time_elapsed    | 6336    |\n",
      "|    total_timesteps | 9961472 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1572        |\n",
      "|    iterations           | 1217        |\n",
      "|    time_elapsed         | 6339        |\n",
      "|    total_timesteps      | 9969664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002745648 |\n",
      "|    clip_fraction        | 0.0174      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.43       |\n",
      "|    explained_variance   | 0.0161      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 814         |\n",
      "|    n_updates            | 15720       |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    value_loss           | 1.71e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1572         |\n",
      "|    iterations           | 1218         |\n",
      "|    time_elapsed         | 6343         |\n",
      "|    total_timesteps      | 9977856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012953684 |\n",
      "|    clip_fraction        | 0.00608      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.428       |\n",
      "|    explained_variance   | 0.0455       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 813          |\n",
      "|    n_updates            | 15730        |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1573        |\n",
      "|    iterations           | 1219        |\n",
      "|    time_elapsed         | 6347        |\n",
      "|    total_timesteps      | 9986048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002160198 |\n",
      "|    clip_fraction        | 0.0121      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.433      |\n",
      "|    explained_variance   | 0.0408      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 901         |\n",
      "|    n_updates            | 15740       |\n",
      "|    policy_gradient_loss | -0.00266    |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1573         |\n",
      "|    iterations           | 1220         |\n",
      "|    time_elapsed         | 6351         |\n",
      "|    total_timesteps      | 9994240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018017415 |\n",
      "|    clip_fraction        | 0.00913      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.423       |\n",
      "|    explained_variance   | 0.0408       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 710          |\n",
      "|    n_updates            | 15750        |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10000000, episode_reward=626.40 +/- 55.63\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 626         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002924558 |\n",
      "|    clip_fraction        | 0.0206      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.433      |\n",
      "|    explained_variance   | 0.05        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 879         |\n",
      "|    n_updates            | 15760       |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    value_loss           | 1.69e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1572     |\n",
      "|    iterations      | 1221     |\n",
      "|    time_elapsed    | 6361     |\n",
      "|    total_timesteps | 10002432 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1572         |\n",
      "|    iterations           | 1222         |\n",
      "|    time_elapsed         | 6365         |\n",
      "|    total_timesteps      | 10010624     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025778117 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.428       |\n",
      "|    explained_variance   | 0.0367       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 714          |\n",
      "|    n_updates            | 15770        |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1573        |\n",
      "|    iterations           | 1223        |\n",
      "|    time_elapsed         | 6369        |\n",
      "|    total_timesteps      | 10018816    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001981601 |\n",
      "|    clip_fraction        | 0.012       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.442      |\n",
      "|    explained_variance   | 0.0666      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 759         |\n",
      "|    n_updates            | 15780       |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    value_loss           | 1.66e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1573       |\n",
      "|    iterations           | 1224       |\n",
      "|    time_elapsed         | 6372       |\n",
      "|    total_timesteps      | 10027008   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00265498 |\n",
      "|    clip_fraction        | 0.018      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.45      |\n",
      "|    explained_variance   | 0.0662     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 717        |\n",
      "|    n_updates            | 15790      |\n",
      "|    policy_gradient_loss | -0.0042    |\n",
      "|    value_loss           | 1.7e+03    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1573         |\n",
      "|    iterations           | 1225         |\n",
      "|    time_elapsed         | 6376         |\n",
      "|    total_timesteps      | 10035200     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024002173 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.444       |\n",
      "|    explained_variance   | 0.0274       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 851          |\n",
      "|    n_updates            | 15800        |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10040000, episode_reward=619.60 +/- 58.31\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 620          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10040000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017905775 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.0242       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 930          |\n",
      "|    n_updates            | 15810        |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1572     |\n",
      "|    iterations      | 1226     |\n",
      "|    time_elapsed    | 6386     |\n",
      "|    total_timesteps | 10043392 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1572        |\n",
      "|    iterations           | 1227        |\n",
      "|    time_elapsed         | 6390        |\n",
      "|    total_timesteps      | 10051584    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002197386 |\n",
      "|    clip_fraction        | 0.0149      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.449      |\n",
      "|    explained_variance   | 0.042       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.08e+03    |\n",
      "|    n_updates            | 15820       |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    value_loss           | 1.75e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1573         |\n",
      "|    iterations           | 1228         |\n",
      "|    time_elapsed         | 6393         |\n",
      "|    total_timesteps      | 10059776     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033059595 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.443       |\n",
      "|    explained_variance   | 0.0264       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 801          |\n",
      "|    n_updates            | 15830        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1573        |\n",
      "|    iterations           | 1229        |\n",
      "|    time_elapsed         | 6397        |\n",
      "|    total_timesteps      | 10067968    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002369058 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.454      |\n",
      "|    explained_variance   | 0.0567      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 872         |\n",
      "|    n_updates            | 15840       |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 1230         |\n",
      "|    time_elapsed         | 6401         |\n",
      "|    total_timesteps      | 10076160     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019194351 |\n",
      "|    clip_fraction        | 0.00946      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.0131       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 15850        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10080000, episode_reward=623.00 +/- 51.78\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 623          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10080000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021153218 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.438       |\n",
      "|    explained_variance   | 0.047        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 761          |\n",
      "|    n_updates            | 15860        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1572     |\n",
      "|    iterations      | 1231     |\n",
      "|    time_elapsed    | 6411     |\n",
      "|    total_timesteps | 10084352 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1573         |\n",
      "|    iterations           | 1232         |\n",
      "|    time_elapsed         | 6415         |\n",
      "|    total_timesteps      | 10092544     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018928945 |\n",
      "|    clip_fraction        | 0.00928      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.445       |\n",
      "|    explained_variance   | 0.0125       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 852          |\n",
      "|    n_updates            | 15870        |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1573        |\n",
      "|    iterations           | 1233        |\n",
      "|    time_elapsed         | 6419        |\n",
      "|    total_timesteps      | 10100736    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002351582 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.452      |\n",
      "|    explained_variance   | 0.0274      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 753         |\n",
      "|    n_updates            | 15880       |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    value_loss           | 1.72e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1573         |\n",
      "|    iterations           | 1234         |\n",
      "|    time_elapsed         | 6423         |\n",
      "|    total_timesteps      | 10108928     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025468396 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.444       |\n",
      "|    explained_variance   | 0.0277       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 751          |\n",
      "|    n_updates            | 15890        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 1235         |\n",
      "|    time_elapsed         | 6426         |\n",
      "|    total_timesteps      | 10117120     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018450427 |\n",
      "|    clip_fraction        | 0.00879      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.452       |\n",
      "|    explained_variance   | 0.0347       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 966          |\n",
      "|    n_updates            | 15900        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10120000, episode_reward=603.60 +/- 56.60\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 604          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10120000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029318393 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.439       |\n",
      "|    explained_variance   | 0.0162       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 817          |\n",
      "|    n_updates            | 15910        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1573     |\n",
      "|    iterations      | 1236     |\n",
      "|    time_elapsed    | 6436     |\n",
      "|    total_timesteps | 10125312 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1573         |\n",
      "|    iterations           | 1237         |\n",
      "|    time_elapsed         | 6439         |\n",
      "|    total_timesteps      | 10133504     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024702535 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.447       |\n",
      "|    explained_variance   | 0.0324       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 15920        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1573         |\n",
      "|    iterations           | 1238         |\n",
      "|    time_elapsed         | 6443         |\n",
      "|    total_timesteps      | 10141696     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022333432 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.454       |\n",
      "|    explained_variance   | 0.0322       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 840          |\n",
      "|    n_updates            | 15930        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 1239         |\n",
      "|    time_elapsed         | 6447         |\n",
      "|    total_timesteps      | 10149888     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021890132 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.0435       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 15940        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 1240         |\n",
      "|    time_elapsed         | 6451         |\n",
      "|    total_timesteps      | 10158080     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028252196 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.452       |\n",
      "|    explained_variance   | 0.0465       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.18e+03     |\n",
      "|    n_updates            | 15950        |\n",
      "|    policy_gradient_loss | -0.00474     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10160000, episode_reward=613.60 +/- 61.60\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 614          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10160000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024787518 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.0389       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.08e+03     |\n",
      "|    n_updates            | 15960        |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1573     |\n",
      "|    iterations      | 1241     |\n",
      "|    time_elapsed    | 6461     |\n",
      "|    total_timesteps | 10166272 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1573         |\n",
      "|    iterations           | 1242         |\n",
      "|    time_elapsed         | 6464         |\n",
      "|    total_timesteps      | 10174464     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024209965 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.459       |\n",
      "|    explained_variance   | 0.0448       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 775          |\n",
      "|    n_updates            | 15970        |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 1243         |\n",
      "|    time_elapsed         | 6468         |\n",
      "|    total_timesteps      | 10182656     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023836154 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.452       |\n",
      "|    explained_variance   | 0.0404       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 772          |\n",
      "|    n_updates            | 15980        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 1244         |\n",
      "|    time_elapsed         | 6472         |\n",
      "|    total_timesteps      | 10190848     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017762294 |\n",
      "|    clip_fraction        | 0.00798      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 0.0179       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 823          |\n",
      "|    n_updates            | 15990        |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 1245         |\n",
      "|    time_elapsed         | 6475         |\n",
      "|    total_timesteps      | 10199040     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023212216 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.456       |\n",
      "|    explained_variance   | 0.0195       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 16000        |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10200000, episode_reward=604.00 +/- 60.89\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 604          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10200000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020713247 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.0561       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 592          |\n",
      "|    n_updates            | 16010        |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1573     |\n",
      "|    iterations      | 1246     |\n",
      "|    time_elapsed    | 6486     |\n",
      "|    total_timesteps | 10207232 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1573        |\n",
      "|    iterations           | 1247        |\n",
      "|    time_elapsed         | 6490        |\n",
      "|    total_timesteps      | 10215424    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002412002 |\n",
      "|    clip_fraction        | 0.0143      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.447      |\n",
      "|    explained_variance   | 0.0316      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 925         |\n",
      "|    n_updates            | 16020       |\n",
      "|    policy_gradient_loss | -0.0033     |\n",
      "|    value_loss           | 1.79e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 1248         |\n",
      "|    time_elapsed         | 6494         |\n",
      "|    total_timesteps      | 10223616     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021052952 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.448       |\n",
      "|    explained_variance   | 0.0301       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 620          |\n",
      "|    n_updates            | 16030        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 1249         |\n",
      "|    time_elapsed         | 6498         |\n",
      "|    total_timesteps      | 10231808     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022565217 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.441       |\n",
      "|    explained_variance   | 0.04         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 16040        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10240000, episode_reward=612.20 +/- 59.74\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 612         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10240000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002301408 |\n",
      "|    clip_fraction        | 0.0143      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.445      |\n",
      "|    explained_variance   | 0.00249     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 797         |\n",
      "|    n_updates            | 16050       |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    value_loss           | 1.6e+03     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1573     |\n",
      "|    iterations      | 1250     |\n",
      "|    time_elapsed    | 6507     |\n",
      "|    total_timesteps | 10240000 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1573         |\n",
      "|    iterations           | 1251         |\n",
      "|    time_elapsed         | 6511         |\n",
      "|    total_timesteps      | 10248192     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018765104 |\n",
      "|    clip_fraction        | 0.00791      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.437       |\n",
      "|    explained_variance   | 0.0169       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 16060        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 1252         |\n",
      "|    time_elapsed         | 6515         |\n",
      "|    total_timesteps      | 10256384     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025500883 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.441       |\n",
      "|    explained_variance   | 0.0567       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 16070        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1574        |\n",
      "|    iterations           | 1253        |\n",
      "|    time_elapsed         | 6519        |\n",
      "|    total_timesteps      | 10264576    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002140935 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.446      |\n",
      "|    explained_variance   | 0.0204      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 948         |\n",
      "|    n_updates            | 16080       |\n",
      "|    policy_gradient_loss | -0.00337    |\n",
      "|    value_loss           | 1.6e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 1254         |\n",
      "|    time_elapsed         | 6522         |\n",
      "|    total_timesteps      | 10272768     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024496801 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.427       |\n",
      "|    explained_variance   | 0.0471       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 862          |\n",
      "|    n_updates            | 16090        |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    value_loss           | 1.53e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10280000, episode_reward=607.60 +/- 54.57\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 608          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10280000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021189023 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.0516       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 873          |\n",
      "|    n_updates            | 16100        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1573     |\n",
      "|    iterations      | 1255     |\n",
      "|    time_elapsed    | 6532     |\n",
      "|    total_timesteps | 10280960 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 1256         |\n",
      "|    time_elapsed         | 6536         |\n",
      "|    total_timesteps      | 10289152     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028038935 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.421       |\n",
      "|    explained_variance   | 0.05         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 962          |\n",
      "|    n_updates            | 16110        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 1257         |\n",
      "|    time_elapsed         | 6540         |\n",
      "|    total_timesteps      | 10297344     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024212203 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.421       |\n",
      "|    explained_variance   | -0.011       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 16120        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 1258         |\n",
      "|    time_elapsed         | 6544         |\n",
      "|    total_timesteps      | 10305536     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020313598 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.428       |\n",
      "|    explained_variance   | 0.0454       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.21e+03     |\n",
      "|    n_updates            | 16130        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1575        |\n",
      "|    iterations           | 1259        |\n",
      "|    time_elapsed         | 6548        |\n",
      "|    total_timesteps      | 10313728    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002040864 |\n",
      "|    clip_fraction        | 0.013       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.443      |\n",
      "|    explained_variance   | 0.0608      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 834         |\n",
      "|    n_updates            | 16140       |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10320000, episode_reward=608.40 +/- 66.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 608          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10320000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022214837 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.425       |\n",
      "|    explained_variance   | 0.0418       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 16150        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1573     |\n",
      "|    iterations      | 1260     |\n",
      "|    time_elapsed    | 6558     |\n",
      "|    total_timesteps | 10321920 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1574        |\n",
      "|    iterations           | 1261        |\n",
      "|    time_elapsed         | 6561        |\n",
      "|    total_timesteps      | 10330112    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001997039 |\n",
      "|    clip_fraction        | 0.0121      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.449      |\n",
      "|    explained_variance   | 0.0575      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.02e+03    |\n",
      "|    n_updates            | 16160       |\n",
      "|    policy_gradient_loss | -0.00297    |\n",
      "|    value_loss           | 1.75e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 1262         |\n",
      "|    time_elapsed         | 6565         |\n",
      "|    total_timesteps      | 10338304     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027240596 |\n",
      "|    clip_fraction        | 0.0216       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.459       |\n",
      "|    explained_variance   | 0.0562       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 722          |\n",
      "|    n_updates            | 16170        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1575        |\n",
      "|    iterations           | 1263        |\n",
      "|    time_elapsed         | 6568        |\n",
      "|    total_timesteps      | 10346496    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002715424 |\n",
      "|    clip_fraction        | 0.0169      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.447      |\n",
      "|    explained_variance   | 0.0198      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 911         |\n",
      "|    n_updates            | 16180       |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1575         |\n",
      "|    iterations           | 1264         |\n",
      "|    time_elapsed         | 6572         |\n",
      "|    total_timesteps      | 10354688     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017088926 |\n",
      "|    clip_fraction        | 0.00852      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.446       |\n",
      "|    explained_variance   | 0.037        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 665          |\n",
      "|    n_updates            | 16190        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10360000, episode_reward=613.00 +/- 65.73\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 613          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10360000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018367327 |\n",
      "|    clip_fraction        | 0.00906      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.443       |\n",
      "|    explained_variance   | 0.0626       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 929          |\n",
      "|    n_updates            | 16200        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1574     |\n",
      "|    iterations      | 1265     |\n",
      "|    time_elapsed    | 6582     |\n",
      "|    total_timesteps | 10362880 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 1266         |\n",
      "|    time_elapsed         | 6586         |\n",
      "|    total_timesteps      | 10371072     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028803693 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.0491       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 808          |\n",
      "|    n_updates            | 16210        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 1267         |\n",
      "|    time_elapsed         | 6590         |\n",
      "|    total_timesteps      | 10379264     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025584726 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.458       |\n",
      "|    explained_variance   | 0.0488       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 616          |\n",
      "|    n_updates            | 16220        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1575         |\n",
      "|    iterations           | 1268         |\n",
      "|    time_elapsed         | 6593         |\n",
      "|    total_timesteps      | 10387456     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031540443 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.0519       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 793          |\n",
      "|    n_updates            | 16230        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1575         |\n",
      "|    iterations           | 1269         |\n",
      "|    time_elapsed         | 6597         |\n",
      "|    total_timesteps      | 10395648     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019728558 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.452       |\n",
      "|    explained_variance   | 0.052        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 659          |\n",
      "|    n_updates            | 16240        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10400000, episode_reward=593.80 +/- 59.90\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 594          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10400000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020909463 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.0431       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 923          |\n",
      "|    n_updates            | 16250        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1574     |\n",
      "|    iterations      | 1270     |\n",
      "|    time_elapsed    | 6607     |\n",
      "|    total_timesteps | 10403840 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1574         |\n",
      "|    iterations           | 1271         |\n",
      "|    time_elapsed         | 6611         |\n",
      "|    total_timesteps      | 10412032     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023180956 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.0567       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 732          |\n",
      "|    n_updates            | 16260        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    value_loss           | 1.52e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1575         |\n",
      "|    iterations           | 1272         |\n",
      "|    time_elapsed         | 6614         |\n",
      "|    total_timesteps      | 10420224     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025540097 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.0368       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 726          |\n",
      "|    n_updates            | 16270        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1575         |\n",
      "|    iterations           | 1273         |\n",
      "|    time_elapsed         | 6618         |\n",
      "|    total_timesteps      | 10428416     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021681585 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.448       |\n",
      "|    explained_variance   | 0.0225       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 16280        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1576         |\n",
      "|    iterations           | 1274         |\n",
      "|    time_elapsed         | 6622         |\n",
      "|    total_timesteps      | 10436608     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018681805 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.447       |\n",
      "|    explained_variance   | 0.036        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 967          |\n",
      "|    n_updates            | 16290        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10440000, episode_reward=613.00 +/- 50.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 613          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10440000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023289237 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.00707      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 714          |\n",
      "|    n_updates            | 16300        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    value_loss           | 1.58e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1574     |\n",
      "|    iterations      | 1275     |\n",
      "|    time_elapsed    | 6632     |\n",
      "|    total_timesteps | 10444800 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1575         |\n",
      "|    iterations           | 1276         |\n",
      "|    time_elapsed         | 6635         |\n",
      "|    total_timesteps      | 10452992     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024971948 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.447       |\n",
      "|    explained_variance   | 0.0433       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.24e+03     |\n",
      "|    n_updates            | 16310        |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1575        |\n",
      "|    iterations           | 1277        |\n",
      "|    time_elapsed         | 6639        |\n",
      "|    total_timesteps      | 10461184    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002425779 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.442      |\n",
      "|    explained_variance   | 0.013       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 830         |\n",
      "|    n_updates            | 16320       |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    value_loss           | 1.56e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1575       |\n",
      "|    iterations           | 1278       |\n",
      "|    time_elapsed         | 6643       |\n",
      "|    total_timesteps      | 10469376   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00183997 |\n",
      "|    clip_fraction        | 0.0107     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.437     |\n",
      "|    explained_variance   | 0.0358     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 579        |\n",
      "|    n_updates            | 16330      |\n",
      "|    policy_gradient_loss | -0.00345   |\n",
      "|    value_loss           | 1.56e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1576        |\n",
      "|    iterations           | 1279        |\n",
      "|    time_elapsed         | 6647        |\n",
      "|    total_timesteps      | 10477568    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001914077 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.442      |\n",
      "|    explained_variance   | 0.0519      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.04e+03    |\n",
      "|    n_updates            | 16340       |\n",
      "|    policy_gradient_loss | -0.00256    |\n",
      "|    value_loss           | 1.63e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10480000, episode_reward=598.60 +/- 51.46\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 599          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10480000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020819264 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.438       |\n",
      "|    explained_variance   | 0.0344       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 796          |\n",
      "|    n_updates            | 16350        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1575     |\n",
      "|    iterations      | 1280     |\n",
      "|    time_elapsed    | 6657     |\n",
      "|    total_timesteps | 10485760 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1575         |\n",
      "|    iterations           | 1281         |\n",
      "|    time_elapsed         | 6660         |\n",
      "|    total_timesteps      | 10493952     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015692199 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.423       |\n",
      "|    explained_variance   | 0.0216       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 850          |\n",
      "|    n_updates            | 16360        |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    value_loss           | 1.58e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1575         |\n",
      "|    iterations           | 1282         |\n",
      "|    time_elapsed         | 6664         |\n",
      "|    total_timesteps      | 10502144     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020264797 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.0366       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 743          |\n",
      "|    n_updates            | 16370        |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1576        |\n",
      "|    iterations           | 1283        |\n",
      "|    time_elapsed         | 6667        |\n",
      "|    total_timesteps      | 10510336    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002067417 |\n",
      "|    clip_fraction        | 0.012       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.428      |\n",
      "|    explained_variance   | 0.0372      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 625         |\n",
      "|    n_updates            | 16380       |\n",
      "|    policy_gradient_loss | -0.00246    |\n",
      "|    value_loss           | 1.7e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1576        |\n",
      "|    iterations           | 1284        |\n",
      "|    time_elapsed         | 6671        |\n",
      "|    total_timesteps      | 10518528    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002016763 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.436      |\n",
      "|    explained_variance   | 0.0525      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 698         |\n",
      "|    n_updates            | 16390       |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    value_loss           | 1.56e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10520000, episode_reward=606.00 +/- 64.71\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 606          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10520000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021566525 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.418       |\n",
      "|    explained_variance   | 0.0251       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 883          |\n",
      "|    n_updates            | 16400        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1575     |\n",
      "|    iterations      | 1285     |\n",
      "|    time_elapsed    | 6681     |\n",
      "|    total_timesteps | 10526720 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1575         |\n",
      "|    iterations           | 1286         |\n",
      "|    time_elapsed         | 6685         |\n",
      "|    total_timesteps      | 10534912     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021253093 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.433       |\n",
      "|    explained_variance   | 0.0278       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 617          |\n",
      "|    n_updates            | 16410        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1576         |\n",
      "|    iterations           | 1287         |\n",
      "|    time_elapsed         | 6689         |\n",
      "|    total_timesteps      | 10543104     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022306014 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.439       |\n",
      "|    explained_variance   | 0.0274       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 766          |\n",
      "|    n_updates            | 16420        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1576         |\n",
      "|    iterations           | 1288         |\n",
      "|    time_elapsed         | 6692         |\n",
      "|    total_timesteps      | 10551296     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021188767 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.43        |\n",
      "|    explained_variance   | 0.0532       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 16430        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1576         |\n",
      "|    iterations           | 1289         |\n",
      "|    time_elapsed         | 6696         |\n",
      "|    total_timesteps      | 10559488     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020915805 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.444       |\n",
      "|    explained_variance   | 0.0814       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 813          |\n",
      "|    n_updates            | 16440        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10560000, episode_reward=611.80 +/- 63.80\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 612          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10560000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028099217 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.446       |\n",
      "|    explained_variance   | 0.0195       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 686          |\n",
      "|    n_updates            | 16450        |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1575     |\n",
      "|    iterations      | 1290     |\n",
      "|    time_elapsed    | 6706     |\n",
      "|    total_timesteps | 10567680 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1576         |\n",
      "|    iterations           | 1291         |\n",
      "|    time_elapsed         | 6710         |\n",
      "|    total_timesteps      | 10575872     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024678714 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.447       |\n",
      "|    explained_variance   | 0.0346       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 880          |\n",
      "|    n_updates            | 16460        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1576         |\n",
      "|    iterations           | 1292         |\n",
      "|    time_elapsed         | 6713         |\n",
      "|    total_timesteps      | 10584064     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024988365 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.44        |\n",
      "|    explained_variance   | 0.0519       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 16470        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1576        |\n",
      "|    iterations           | 1293        |\n",
      "|    time_elapsed         | 6717        |\n",
      "|    total_timesteps      | 10592256    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002621825 |\n",
      "|    clip_fraction        | 0.016       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.442      |\n",
      "|    explained_variance   | 0.0323      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 806         |\n",
      "|    n_updates            | 16480       |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    value_loss           | 1.83e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10600000, episode_reward=586.40 +/- 104.55\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 586          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10600000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026234817 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.429       |\n",
      "|    explained_variance   | 0.0258       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 705          |\n",
      "|    n_updates            | 16490        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1575     |\n",
      "|    iterations      | 1294     |\n",
      "|    time_elapsed    | 6727     |\n",
      "|    total_timesteps | 10600448 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1575        |\n",
      "|    iterations           | 1295        |\n",
      "|    time_elapsed         | 6731        |\n",
      "|    total_timesteps      | 10608640    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002361252 |\n",
      "|    clip_fraction        | 0.017       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.441      |\n",
      "|    explained_variance   | 0.0377      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 884         |\n",
      "|    n_updates            | 16500       |\n",
      "|    policy_gradient_loss | -0.0036     |\n",
      "|    value_loss           | 1.77e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1576        |\n",
      "|    iterations           | 1296        |\n",
      "|    time_elapsed         | 6735        |\n",
      "|    total_timesteps      | 10616832    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002268735 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.431      |\n",
      "|    explained_variance   | 0.0165      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 730         |\n",
      "|    n_updates            | 16510       |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1576         |\n",
      "|    iterations           | 1297         |\n",
      "|    time_elapsed         | 6739         |\n",
      "|    total_timesteps      | 10625024     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021354747 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.0087       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 828          |\n",
      "|    n_updates            | 16520        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1576        |\n",
      "|    iterations           | 1298        |\n",
      "|    time_elapsed         | 6742        |\n",
      "|    total_timesteps      | 10633216    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002178364 |\n",
      "|    clip_fraction        | 0.0169      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.439      |\n",
      "|    explained_variance   | 0.0303      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 704         |\n",
      "|    n_updates            | 16530       |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    value_loss           | 1.69e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10640000, episode_reward=624.20 +/- 59.64\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 624         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10640000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002377247 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.455      |\n",
      "|    explained_variance   | 0.062       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 776         |\n",
      "|    n_updates            | 16540       |\n",
      "|    policy_gradient_loss | -0.00314    |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1575     |\n",
      "|    iterations      | 1299     |\n",
      "|    time_elapsed    | 6752     |\n",
      "|    total_timesteps | 10641408 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1576         |\n",
      "|    iterations           | 1300         |\n",
      "|    time_elapsed         | 6756         |\n",
      "|    total_timesteps      | 10649600     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025957962 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.444       |\n",
      "|    explained_variance   | 0.0643       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 16550        |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1576        |\n",
      "|    iterations           | 1301        |\n",
      "|    time_elapsed         | 6760        |\n",
      "|    total_timesteps      | 10657792    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001974082 |\n",
      "|    clip_fraction        | 0.0102      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.434      |\n",
      "|    explained_variance   | 0.0442      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.02e+03    |\n",
      "|    n_updates            | 16560       |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    value_loss           | 1.84e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1576         |\n",
      "|    iterations           | 1302         |\n",
      "|    time_elapsed         | 6764         |\n",
      "|    total_timesteps      | 10665984     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020228075 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.433       |\n",
      "|    explained_variance   | 0.0612       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 869          |\n",
      "|    n_updates            | 16570        |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 1303         |\n",
      "|    time_elapsed         | 6767         |\n",
      "|    total_timesteps      | 10674176     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023194312 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.43        |\n",
      "|    explained_variance   | 0.0507       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 16580        |\n",
      "|    policy_gradient_loss | -0.00388     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10680000, episode_reward=605.00 +/- 51.55\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 605          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10680000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022634289 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.427       |\n",
      "|    explained_variance   | 0.0486       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 627          |\n",
      "|    n_updates            | 16590        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1576     |\n",
      "|    iterations      | 1304     |\n",
      "|    time_elapsed    | 6777     |\n",
      "|    total_timesteps | 10682368 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1576         |\n",
      "|    iterations           | 1305         |\n",
      "|    time_elapsed         | 6781         |\n",
      "|    total_timesteps      | 10690560     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020029503 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.439       |\n",
      "|    explained_variance   | 0.0611       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 761          |\n",
      "|    n_updates            | 16600        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1576        |\n",
      "|    iterations           | 1306        |\n",
      "|    time_elapsed         | 6785        |\n",
      "|    total_timesteps      | 10698752    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002040158 |\n",
      "|    clip_fraction        | 0.0092      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.431      |\n",
      "|    explained_variance   | 0.052       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 838         |\n",
      "|    n_updates            | 16610       |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    value_loss           | 1.85e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1577        |\n",
      "|    iterations           | 1307        |\n",
      "|    time_elapsed         | 6788        |\n",
      "|    total_timesteps      | 10706944    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002341859 |\n",
      "|    clip_fraction        | 0.0161      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.443      |\n",
      "|    explained_variance   | 0.0848      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 865         |\n",
      "|    n_updates            | 16620       |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    value_loss           | 1.69e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 1308         |\n",
      "|    time_elapsed         | 6792         |\n",
      "|    total_timesteps      | 10715136     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021249105 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.438       |\n",
      "|    explained_variance   | 0.0562       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 922          |\n",
      "|    n_updates            | 16630        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10720000, episode_reward=620.20 +/- 61.53\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 620          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10720000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027120805 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.439       |\n",
      "|    explained_variance   | 0.0394       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 864          |\n",
      "|    n_updates            | 16640        |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1576     |\n",
      "|    iterations      | 1309     |\n",
      "|    time_elapsed    | 6802     |\n",
      "|    total_timesteps | 10723328 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1576         |\n",
      "|    iterations           | 1310         |\n",
      "|    time_elapsed         | 6806         |\n",
      "|    total_timesteps      | 10731520     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021069956 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.443       |\n",
      "|    explained_variance   | 0.0113       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.21e+03     |\n",
      "|    n_updates            | 16650        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1577        |\n",
      "|    iterations           | 1311        |\n",
      "|    time_elapsed         | 6810        |\n",
      "|    total_timesteps      | 10739712    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002428342 |\n",
      "|    clip_fraction        | 0.0161      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.45       |\n",
      "|    explained_variance   | 0.00078     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 679         |\n",
      "|    n_updates            | 16660       |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    value_loss           | 1.7e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 1312         |\n",
      "|    time_elapsed         | 6813         |\n",
      "|    total_timesteps      | 10747904     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023846554 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.447       |\n",
      "|    explained_variance   | 0.0213       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 828          |\n",
      "|    n_updates            | 16670        |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 1313         |\n",
      "|    time_elapsed         | 6817         |\n",
      "|    total_timesteps      | 10756096     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018760753 |\n",
      "|    clip_fraction        | 0.00914      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.457       |\n",
      "|    explained_variance   | 0.0242       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 16680        |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10760000, episode_reward=631.60 +/- 65.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 632          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10760000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024062337 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.0265       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 889          |\n",
      "|    n_updates            | 16690        |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1576     |\n",
      "|    iterations      | 1314     |\n",
      "|    time_elapsed    | 6827     |\n",
      "|    total_timesteps | 10764288 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1576         |\n",
      "|    iterations           | 1315         |\n",
      "|    time_elapsed         | 6831         |\n",
      "|    total_timesteps      | 10772480     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024791304 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.46        |\n",
      "|    explained_variance   | 0.0419       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 827          |\n",
      "|    n_updates            | 16700        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 1316         |\n",
      "|    time_elapsed         | 6835         |\n",
      "|    total_timesteps      | 10780672     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025605764 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.0252       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 793          |\n",
      "|    n_updates            | 16710        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 1317         |\n",
      "|    time_elapsed         | 6838         |\n",
      "|    total_timesteps      | 10788864     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027387524 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.455       |\n",
      "|    explained_variance   | 0.0215       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 634          |\n",
      "|    n_updates            | 16720        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 1318         |\n",
      "|    time_elapsed         | 6842         |\n",
      "|    total_timesteps      | 10797056     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025906595 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.453       |\n",
      "|    explained_variance   | 0.0405       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 751          |\n",
      "|    n_updates            | 16730        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10800000, episode_reward=624.60 +/- 61.85\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 625          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10800000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024002995 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.0541       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 670          |\n",
      "|    n_updates            | 16740        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1576     |\n",
      "|    iterations      | 1319     |\n",
      "|    time_elapsed    | 6852     |\n",
      "|    total_timesteps | 10805248 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 1320         |\n",
      "|    time_elapsed         | 6856         |\n",
      "|    total_timesteps      | 10813440     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016038122 |\n",
      "|    clip_fraction        | 0.00552      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.438       |\n",
      "|    explained_variance   | 0.045        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 708          |\n",
      "|    n_updates            | 16750        |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 1321         |\n",
      "|    time_elapsed         | 6860         |\n",
      "|    total_timesteps      | 10821632     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023473792 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.468       |\n",
      "|    explained_variance   | 0.0351       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 709          |\n",
      "|    n_updates            | 16760        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 1322         |\n",
      "|    time_elapsed         | 6864         |\n",
      "|    total_timesteps      | 10829824     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024616593 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.0501       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1e+03        |\n",
      "|    n_updates            | 16770        |\n",
      "|    policy_gradient_loss | -0.0042      |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 1323         |\n",
      "|    time_elapsed         | 6867         |\n",
      "|    total_timesteps      | 10838016     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020612993 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.436       |\n",
      "|    explained_variance   | 0.0615       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 812          |\n",
      "|    n_updates            | 16780        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10840000, episode_reward=621.60 +/- 57.46\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 622          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10840000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019293007 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.438       |\n",
      "|    explained_variance   | 0.0669       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 786          |\n",
      "|    n_updates            | 16790        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1577     |\n",
      "|    iterations      | 1324     |\n",
      "|    time_elapsed    | 6877     |\n",
      "|    total_timesteps | 10846208 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1577        |\n",
      "|    iterations           | 1325        |\n",
      "|    time_elapsed         | 6881        |\n",
      "|    total_timesteps      | 10854400    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002377822 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.434      |\n",
      "|    explained_variance   | 0.0337      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 817         |\n",
      "|    n_updates            | 16800       |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    value_loss           | 1.72e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1577        |\n",
      "|    iterations           | 1326        |\n",
      "|    time_elapsed         | 6885        |\n",
      "|    total_timesteps      | 10862592    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002062493 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.431      |\n",
      "|    explained_variance   | 0.039       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 803         |\n",
      "|    n_updates            | 16810       |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    value_loss           | 1.88e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 1327         |\n",
      "|    time_elapsed         | 6888         |\n",
      "|    total_timesteps      | 10870784     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021915105 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.00583      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 931          |\n",
      "|    n_updates            | 16820        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 1328         |\n",
      "|    time_elapsed         | 6892         |\n",
      "|    total_timesteps      | 10878976     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018519834 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.0173       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 16830        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10880000, episode_reward=629.40 +/- 58.84\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 629          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10880000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023490847 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.451       |\n",
      "|    explained_variance   | 0.0479       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 576          |\n",
      "|    n_updates            | 16840        |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1577     |\n",
      "|    iterations      | 1329     |\n",
      "|    time_elapsed    | 6902     |\n",
      "|    total_timesteps | 10887168 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1577        |\n",
      "|    iterations           | 1330        |\n",
      "|    time_elapsed         | 6906        |\n",
      "|    total_timesteps      | 10895360    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002443772 |\n",
      "|    clip_fraction        | 0.0123      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.452      |\n",
      "|    explained_variance   | 0.0122      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 762         |\n",
      "|    n_updates            | 16850       |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 1331         |\n",
      "|    time_elapsed         | 6910         |\n",
      "|    total_timesteps      | 10903552     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023682434 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.446       |\n",
      "|    explained_variance   | 0.0281       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 959          |\n",
      "|    n_updates            | 16860        |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 1332         |\n",
      "|    time_elapsed         | 6913         |\n",
      "|    total_timesteps      | 10911744     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025790958 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.0507       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 846          |\n",
      "|    n_updates            | 16870        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 1333         |\n",
      "|    time_elapsed         | 6917         |\n",
      "|    total_timesteps      | 10919936     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017253354 |\n",
      "|    clip_fraction        | 0.00737      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.438       |\n",
      "|    explained_variance   | 0.0685       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 831          |\n",
      "|    n_updates            | 16880        |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    value_loss           | 1.63e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10920000, episode_reward=624.40 +/- 62.58\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 624          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10920000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025153782 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.447       |\n",
      "|    explained_variance   | 0.0102       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 16890        |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1577     |\n",
      "|    iterations      | 1334     |\n",
      "|    time_elapsed    | 6927     |\n",
      "|    total_timesteps | 10928128 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 1335         |\n",
      "|    time_elapsed         | 6931         |\n",
      "|    total_timesteps      | 10936320     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019424071 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.45        |\n",
      "|    explained_variance   | 0.0309       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 784          |\n",
      "|    n_updates            | 16900        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 1336         |\n",
      "|    time_elapsed         | 6934         |\n",
      "|    total_timesteps      | 10944512     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022351618 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.435       |\n",
      "|    explained_variance   | 0.0204       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 864          |\n",
      "|    n_updates            | 16910        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 1337         |\n",
      "|    time_elapsed         | 6938         |\n",
      "|    total_timesteps      | 10952704     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020839141 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.437       |\n",
      "|    explained_variance   | 0.00259      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 718          |\n",
      "|    n_updates            | 16920        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10960000, episode_reward=624.20 +/- 58.18\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 624          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10960000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028126817 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.436       |\n",
      "|    explained_variance   | 0.0495       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 813          |\n",
      "|    n_updates            | 16930        |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1577     |\n",
      "|    iterations      | 1338     |\n",
      "|    time_elapsed    | 6948     |\n",
      "|    total_timesteps | 10960896 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1577         |\n",
      "|    iterations           | 1339         |\n",
      "|    time_elapsed         | 6952         |\n",
      "|    total_timesteps      | 10969088     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017136274 |\n",
      "|    clip_fraction        | 0.00854      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.412       |\n",
      "|    explained_variance   | 0.0544       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.24e+03     |\n",
      "|    n_updates            | 16940        |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 1340         |\n",
      "|    time_elapsed         | 6955         |\n",
      "|    total_timesteps      | 10977280     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021937126 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.422       |\n",
      "|    explained_variance   | 0.0247       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 16950        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1578        |\n",
      "|    iterations           | 1341        |\n",
      "|    time_elapsed         | 6959        |\n",
      "|    total_timesteps      | 10985472    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001927258 |\n",
      "|    clip_fraction        | 0.0084      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.424      |\n",
      "|    explained_variance   | 0.0269      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 850         |\n",
      "|    n_updates            | 16960       |\n",
      "|    policy_gradient_loss | -0.00289    |\n",
      "|    value_loss           | 1.7e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1578        |\n",
      "|    iterations           | 1342        |\n",
      "|    time_elapsed         | 6963        |\n",
      "|    total_timesteps      | 10993664    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002335604 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.422      |\n",
      "|    explained_variance   | 0.0229      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 16970       |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    value_loss           | 1.64e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=11000000, episode_reward=605.40 +/- 55.36\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 605          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11000000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028702258 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.414       |\n",
      "|    explained_variance   | 0.0184       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 735          |\n",
      "|    n_updates            | 16980        |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    value_loss           | 1.91e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1577     |\n",
      "|    iterations      | 1343     |\n",
      "|    time_elapsed    | 6973     |\n",
      "|    total_timesteps | 11001856 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 1344         |\n",
      "|    time_elapsed         | 6976         |\n",
      "|    total_timesteps      | 11010048     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022621113 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.407       |\n",
      "|    explained_variance   | 0.0716       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 865          |\n",
      "|    n_updates            | 16990        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 1345         |\n",
      "|    time_elapsed         | 6980         |\n",
      "|    total_timesteps      | 11018240     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020386297 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.0502       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 788          |\n",
      "|    n_updates            | 17000        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 1346         |\n",
      "|    time_elapsed         | 6984         |\n",
      "|    total_timesteps      | 11026432     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027134954 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.411       |\n",
      "|    explained_variance   | 0.0563       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 825          |\n",
      "|    n_updates            | 17010        |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1347         |\n",
      "|    time_elapsed         | 6988         |\n",
      "|    total_timesteps      | 11034624     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018230255 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.403       |\n",
      "|    explained_variance   | 0.0567       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 17020        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11040000, episode_reward=604.60 +/- 95.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 605          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11040000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022807026 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.412       |\n",
      "|    explained_variance   | 0.0223       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 873          |\n",
      "|    n_updates            | 17030        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1577     |\n",
      "|    iterations      | 1348     |\n",
      "|    time_elapsed    | 6998     |\n",
      "|    total_timesteps | 11042816 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 1349         |\n",
      "|    time_elapsed         | 7001         |\n",
      "|    total_timesteps      | 11051008     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022061393 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.417       |\n",
      "|    explained_variance   | 0.0478       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 792          |\n",
      "|    n_updates            | 17040        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 1350         |\n",
      "|    time_elapsed         | 7005         |\n",
      "|    total_timesteps      | 11059200     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019588063 |\n",
      "|    clip_fraction        | 0.00947      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.427       |\n",
      "|    explained_variance   | 0.0346       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 867          |\n",
      "|    n_updates            | 17050        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 1351         |\n",
      "|    time_elapsed         | 7009         |\n",
      "|    total_timesteps      | 11067392     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023893646 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.428       |\n",
      "|    explained_variance   | 0.0512       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.24e+03     |\n",
      "|    n_updates            | 17060        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1352         |\n",
      "|    time_elapsed         | 7013         |\n",
      "|    total_timesteps      | 11075584     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018328531 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.421       |\n",
      "|    explained_variance   | 0.0292       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 875          |\n",
      "|    n_updates            | 17070        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11080000, episode_reward=616.20 +/- 57.93\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 200        |\n",
      "|    mean_reward          | 616        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 11080000   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00275417 |\n",
      "|    clip_fraction        | 0.0221     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.417     |\n",
      "|    explained_variance   | 0.0105     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 743        |\n",
      "|    n_updates            | 17080      |\n",
      "|    policy_gradient_loss | -0.00389   |\n",
      "|    value_loss           | 1.73e+03   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1578     |\n",
      "|    iterations      | 1353     |\n",
      "|    time_elapsed    | 7023     |\n",
      "|    total_timesteps | 11083776 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 1354         |\n",
      "|    time_elapsed         | 7026         |\n",
      "|    total_timesteps      | 11091968     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024502631 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.409       |\n",
      "|    explained_variance   | 0.0334       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 987          |\n",
      "|    n_updates            | 17090        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 1578     |\n",
      "|    iterations           | 1355     |\n",
      "|    time_elapsed         | 7030     |\n",
      "|    total_timesteps      | 11100160 |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.001903 |\n",
      "|    clip_fraction        | 0.0137   |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.407   |\n",
      "|    explained_variance   | 0.0499   |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 1.09e+03 |\n",
      "|    n_updates            | 17100    |\n",
      "|    policy_gradient_loss | -0.00236 |\n",
      "|    value_loss           | 1.78e+03 |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1356         |\n",
      "|    time_elapsed         | 7034         |\n",
      "|    total_timesteps      | 11108352     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029392778 |\n",
      "|    clip_fraction        | 0.0243       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.418       |\n",
      "|    explained_variance   | 0.0804       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 952          |\n",
      "|    n_updates            | 17110        |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1579        |\n",
      "|    iterations           | 1357        |\n",
      "|    time_elapsed         | 7038        |\n",
      "|    total_timesteps      | 11116544    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002112796 |\n",
      "|    clip_fraction        | 0.0126      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.417      |\n",
      "|    explained_variance   | 0.0172      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 837         |\n",
      "|    n_updates            | 17120       |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    value_loss           | 1.71e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=11120000, episode_reward=623.40 +/- 49.10\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 623          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11120000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018649745 |\n",
      "|    clip_fraction        | 0.00919      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.419       |\n",
      "|    explained_variance   | 0.0352       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 642          |\n",
      "|    n_updates            | 17130        |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1578     |\n",
      "|    iterations      | 1358     |\n",
      "|    time_elapsed    | 7048     |\n",
      "|    total_timesteps | 11124736 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1578        |\n",
      "|    iterations           | 1359        |\n",
      "|    time_elapsed         | 7051        |\n",
      "|    total_timesteps      | 11132928    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002250752 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.423      |\n",
      "|    explained_variance   | 0.0129      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 745         |\n",
      "|    n_updates            | 17140       |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    value_loss           | 1.71e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1360         |\n",
      "|    time_elapsed         | 7055         |\n",
      "|    total_timesteps      | 11141120     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018309976 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.421       |\n",
      "|    explained_variance   | 0.0283       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 17150        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    value_loss           | 1.93e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1361         |\n",
      "|    time_elapsed         | 7059         |\n",
      "|    total_timesteps      | 11149312     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028949985 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.418       |\n",
      "|    explained_variance   | 0.0216       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 783          |\n",
      "|    n_updates            | 17160        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1362         |\n",
      "|    time_elapsed         | 7062         |\n",
      "|    total_timesteps      | 11157504     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019699114 |\n",
      "|    clip_fraction        | 0.00992      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.414       |\n",
      "|    explained_variance   | 0.0466       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 697          |\n",
      "|    n_updates            | 17170        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11160000, episode_reward=603.60 +/- 134.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 604          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11160000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026642128 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.425       |\n",
      "|    explained_variance   | 0.0297       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 589          |\n",
      "|    n_updates            | 17180        |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1578     |\n",
      "|    iterations      | 1363     |\n",
      "|    time_elapsed    | 7072     |\n",
      "|    total_timesteps | 11165696 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1364         |\n",
      "|    time_elapsed         | 7076         |\n",
      "|    total_timesteps      | 11173888     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018256108 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.407       |\n",
      "|    explained_variance   | 0.00111      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 812          |\n",
      "|    n_updates            | 17190        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1365         |\n",
      "|    time_elapsed         | 7079         |\n",
      "|    total_timesteps      | 11182080     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022606922 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.407       |\n",
      "|    explained_variance   | 0.0684       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 657          |\n",
      "|    n_updates            | 17200        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1579        |\n",
      "|    iterations           | 1366        |\n",
      "|    time_elapsed         | 7083        |\n",
      "|    total_timesteps      | 11190272    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002171962 |\n",
      "|    clip_fraction        | 0.0138      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.405      |\n",
      "|    explained_variance   | 0.0277      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 829         |\n",
      "|    n_updates            | 17210       |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    value_loss           | 1.72e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 1367         |\n",
      "|    time_elapsed         | 7087         |\n",
      "|    total_timesteps      | 11198464     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025704452 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.418       |\n",
      "|    explained_variance   | 0.0309       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 661          |\n",
      "|    n_updates            | 17220        |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11200000, episode_reward=638.60 +/- 54.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 639          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11200000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017664656 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.407       |\n",
      "|    explained_variance   | 0.0337       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 889          |\n",
      "|    n_updates            | 17230        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    value_loss           | 1.96e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1578     |\n",
      "|    iterations      | 1368     |\n",
      "|    time_elapsed    | 7097     |\n",
      "|    total_timesteps | 11206656 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1369         |\n",
      "|    time_elapsed         | 7101         |\n",
      "|    total_timesteps      | 11214848     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017666066 |\n",
      "|    clip_fraction        | 0.00898      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.402       |\n",
      "|    explained_variance   | 0.0104       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 958          |\n",
      "|    n_updates            | 17240        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1370         |\n",
      "|    time_elapsed         | 7105         |\n",
      "|    total_timesteps      | 11223040     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021878178 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.0182       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 897          |\n",
      "|    n_updates            | 17250        |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1579       |\n",
      "|    iterations           | 1371       |\n",
      "|    time_elapsed         | 7108       |\n",
      "|    total_timesteps      | 11231232   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00230882 |\n",
      "|    clip_fraction        | 0.0151     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.406     |\n",
      "|    explained_variance   | 0.0617     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.08e+03   |\n",
      "|    n_updates            | 17260      |\n",
      "|    policy_gradient_loss | -0.0034    |\n",
      "|    value_loss           | 1.74e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1580        |\n",
      "|    iterations           | 1372        |\n",
      "|    time_elapsed         | 7112        |\n",
      "|    total_timesteps      | 11239424    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002318222 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.402      |\n",
      "|    explained_variance   | 0.00164     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 833         |\n",
      "|    n_updates            | 17270       |\n",
      "|    policy_gradient_loss | -0.00326    |\n",
      "|    value_loss           | 1.92e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=11240000, episode_reward=611.60 +/- 56.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 612          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11240000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018316519 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.408       |\n",
      "|    explained_variance   | 0.0234       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 638          |\n",
      "|    n_updates            | 17280        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1579     |\n",
      "|    iterations      | 1373     |\n",
      "|    time_elapsed    | 7122     |\n",
      "|    total_timesteps | 11247616 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1579        |\n",
      "|    iterations           | 1374        |\n",
      "|    time_elapsed         | 7126        |\n",
      "|    total_timesteps      | 11255808    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002550836 |\n",
      "|    clip_fraction        | 0.0163      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.397      |\n",
      "|    explained_variance   | 0.0186      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 669         |\n",
      "|    n_updates            | 17290       |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    value_loss           | 1.73e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1375         |\n",
      "|    time_elapsed         | 7129         |\n",
      "|    total_timesteps      | 11264000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022503135 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.416       |\n",
      "|    explained_variance   | 0.0464       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 833          |\n",
      "|    n_updates            | 17300        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 1376         |\n",
      "|    time_elapsed         | 7133         |\n",
      "|    total_timesteps      | 11272192     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021181009 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.401       |\n",
      "|    explained_variance   | 0.0411       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 972          |\n",
      "|    n_updates            | 17310        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11280000, episode_reward=614.00 +/- 108.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 614          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11280000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020909598 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.404       |\n",
      "|    explained_variance   | 0.0649       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 725          |\n",
      "|    n_updates            | 17320        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1579     |\n",
      "|    iterations      | 1377     |\n",
      "|    time_elapsed    | 7143     |\n",
      "|    total_timesteps | 11280384 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1378         |\n",
      "|    time_elapsed         | 7147         |\n",
      "|    total_timesteps      | 11288576     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017908653 |\n",
      "|    clip_fraction        | 0.00907      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.409       |\n",
      "|    explained_variance   | 0.0123       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 889          |\n",
      "|    n_updates            | 17330        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1379         |\n",
      "|    time_elapsed         | 7150         |\n",
      "|    total_timesteps      | 11296768     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020465963 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.052        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 915          |\n",
      "|    n_updates            | 17340        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 1380         |\n",
      "|    time_elapsed         | 7154         |\n",
      "|    total_timesteps      | 11304960     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025363453 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.396       |\n",
      "|    explained_variance   | 0.0365       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 718          |\n",
      "|    n_updates            | 17350        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 1381         |\n",
      "|    time_elapsed         | 7158         |\n",
      "|    total_timesteps      | 11313152     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017566024 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.395       |\n",
      "|    explained_variance   | 0.0629       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 960          |\n",
      "|    n_updates            | 17360        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11320000, episode_reward=618.40 +/- 60.74\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 618          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11320000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023392742 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.396       |\n",
      "|    explained_variance   | 0.0235       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 880          |\n",
      "|    n_updates            | 17370        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1579     |\n",
      "|    iterations      | 1382     |\n",
      "|    time_elapsed    | 7168     |\n",
      "|    total_timesteps | 11321344 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1579        |\n",
      "|    iterations           | 1383        |\n",
      "|    time_elapsed         | 7172        |\n",
      "|    total_timesteps      | 11329536    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002270769 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.396      |\n",
      "|    explained_variance   | 0.0401      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 654         |\n",
      "|    n_updates            | 17380       |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    value_loss           | 1.74e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1384         |\n",
      "|    time_elapsed         | 7176         |\n",
      "|    total_timesteps      | 11337728     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016404818 |\n",
      "|    clip_fraction        | 0.00702      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.395       |\n",
      "|    explained_variance   | 0.0437       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 777          |\n",
      "|    n_updates            | 17390        |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 1385         |\n",
      "|    time_elapsed         | 7179         |\n",
      "|    total_timesteps      | 11345920     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019659996 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.402       |\n",
      "|    explained_variance   | 0.00243      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 796          |\n",
      "|    n_updates            | 17400        |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    value_loss           | 1.96e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 1386         |\n",
      "|    time_elapsed         | 7183         |\n",
      "|    total_timesteps      | 11354112     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018890359 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.394       |\n",
      "|    explained_variance   | 0.0134       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 17410        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11360000, episode_reward=622.40 +/- 68.78\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 622          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11360000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018508215 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.39        |\n",
      "|    explained_variance   | 0.0511       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 988          |\n",
      "|    n_updates            | 17420        |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1579     |\n",
      "|    iterations      | 1387     |\n",
      "|    time_elapsed    | 7193     |\n",
      "|    total_timesteps | 11362304 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1388         |\n",
      "|    time_elapsed         | 7196         |\n",
      "|    total_timesteps      | 11370496     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021757882 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.391       |\n",
      "|    explained_variance   | 0.0416       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 944          |\n",
      "|    n_updates            | 17430        |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 1389         |\n",
      "|    time_elapsed         | 7200         |\n",
      "|    total_timesteps      | 11378688     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023012927 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.409       |\n",
      "|    explained_variance   | 0.0273       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 920          |\n",
      "|    n_updates            | 17440        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 1390         |\n",
      "|    time_elapsed         | 7204         |\n",
      "|    total_timesteps      | 11386880     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021926798 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.397       |\n",
      "|    explained_variance   | 0.0383       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 800          |\n",
      "|    n_updates            | 17450        |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 1391         |\n",
      "|    time_elapsed         | 7207         |\n",
      "|    total_timesteps      | 11395072     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023085158 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.401       |\n",
      "|    explained_variance   | 0.0495       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 606          |\n",
      "|    n_updates            | 17460        |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11400000, episode_reward=613.80 +/- 67.17\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 614          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11400000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023879916 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.407       |\n",
      "|    explained_variance   | 0.0552       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 17470        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1579     |\n",
      "|    iterations      | 1392     |\n",
      "|    time_elapsed    | 7217     |\n",
      "|    total_timesteps | 11403264 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 1393         |\n",
      "|    time_elapsed         | 7221         |\n",
      "|    total_timesteps      | 11411456     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024784436 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.392       |\n",
      "|    explained_variance   | 0.0427       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 816          |\n",
      "|    n_updates            | 17480        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    value_loss           | 1.93e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 1394         |\n",
      "|    time_elapsed         | 7225         |\n",
      "|    total_timesteps      | 11419648     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024845968 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.396       |\n",
      "|    explained_variance   | 0.0135       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 931          |\n",
      "|    n_updates            | 17490        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 1395         |\n",
      "|    time_elapsed         | 7229         |\n",
      "|    total_timesteps      | 11427840     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017966891 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.393       |\n",
      "|    explained_variance   | 0.016        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 808          |\n",
      "|    n_updates            | 17500        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1581        |\n",
      "|    iterations           | 1396        |\n",
      "|    time_elapsed         | 7232        |\n",
      "|    total_timesteps      | 11436032    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002137472 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.384      |\n",
      "|    explained_variance   | 0.0228      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 615         |\n",
      "|    n_updates            | 17510       |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    value_loss           | 1.8e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=11440000, episode_reward=621.60 +/- 68.86\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 622          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11440000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026651218 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.381       |\n",
      "|    explained_variance   | 0.0379       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 876          |\n",
      "|    n_updates            | 17520        |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1580     |\n",
      "|    iterations      | 1397     |\n",
      "|    time_elapsed    | 7242     |\n",
      "|    total_timesteps | 11444224 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1580        |\n",
      "|    iterations           | 1398        |\n",
      "|    time_elapsed         | 7246        |\n",
      "|    total_timesteps      | 11452416    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001550775 |\n",
      "|    clip_fraction        | 0.0111      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.389      |\n",
      "|    explained_variance   | 0.0247      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 879         |\n",
      "|    n_updates            | 17530       |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    value_loss           | 1.69e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 1399         |\n",
      "|    time_elapsed         | 7249         |\n",
      "|    total_timesteps      | 11460608     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020097322 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.391       |\n",
      "|    explained_variance   | 0.027        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 574          |\n",
      "|    n_updates            | 17540        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1400         |\n",
      "|    time_elapsed         | 7253         |\n",
      "|    total_timesteps      | 11468800     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020866087 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.395       |\n",
      "|    explained_variance   | 0.0387       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 17550        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1581        |\n",
      "|    iterations           | 1401        |\n",
      "|    time_elapsed         | 7257        |\n",
      "|    total_timesteps      | 11476992    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002918589 |\n",
      "|    clip_fraction        | 0.0272      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.396      |\n",
      "|    explained_variance   | 0.0193      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 722         |\n",
      "|    n_updates            | 17560       |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    value_loss           | 1.9e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=11480000, episode_reward=626.40 +/- 55.49\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 626          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11480000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017677485 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.394       |\n",
      "|    explained_variance   | 0.0136       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 807          |\n",
      "|    n_updates            | 17570        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1580     |\n",
      "|    iterations      | 1402     |\n",
      "|    time_elapsed    | 7267     |\n",
      "|    total_timesteps | 11485184 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1580        |\n",
      "|    iterations           | 1403        |\n",
      "|    time_elapsed         | 7271        |\n",
      "|    total_timesteps      | 11493376    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003060334 |\n",
      "|    clip_fraction        | 0.0249      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.393      |\n",
      "|    explained_variance   | 0.0409      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 788         |\n",
      "|    n_updates            | 17580       |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    value_loss           | 1.76e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1404         |\n",
      "|    time_elapsed         | 7274         |\n",
      "|    total_timesteps      | 11501568     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013895002 |\n",
      "|    clip_fraction        | 0.00562      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.39        |\n",
      "|    explained_variance   | 0.0639       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 863          |\n",
      "|    n_updates            | 17590        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1405         |\n",
      "|    time_elapsed         | 7278         |\n",
      "|    total_timesteps      | 11509760     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017064641 |\n",
      "|    clip_fraction        | 0.00889      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.398       |\n",
      "|    explained_variance   | 0.0693       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 924          |\n",
      "|    n_updates            | 17600        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1406         |\n",
      "|    time_elapsed         | 7282         |\n",
      "|    total_timesteps      | 11517952     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020184738 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.402       |\n",
      "|    explained_variance   | 0.0358       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 17610        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11520000, episode_reward=609.60 +/- 58.21\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 610          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11520000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021324025 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.391       |\n",
      "|    explained_variance   | 0.0236       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 754          |\n",
      "|    n_updates            | 17620        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1580     |\n",
      "|    iterations      | 1407     |\n",
      "|    time_elapsed    | 7292     |\n",
      "|    total_timesteps | 11526144 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1580         |\n",
      "|    iterations           | 1408         |\n",
      "|    time_elapsed         | 7296         |\n",
      "|    total_timesteps      | 11534336     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020735306 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.4         |\n",
      "|    explained_variance   | 0.0413       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 17630        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1581       |\n",
      "|    iterations           | 1409       |\n",
      "|    time_elapsed         | 7300       |\n",
      "|    total_timesteps      | 11542528   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00208573 |\n",
      "|    clip_fraction        | 0.012      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.408     |\n",
      "|    explained_variance   | 0.0351     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 982        |\n",
      "|    n_updates            | 17640      |\n",
      "|    policy_gradient_loss | -0.00284   |\n",
      "|    value_loss           | 1.75e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1581        |\n",
      "|    iterations           | 1410        |\n",
      "|    time_elapsed         | 7303        |\n",
      "|    total_timesteps      | 11550720    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002592748 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.406      |\n",
      "|    explained_variance   | 0.0183      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 782         |\n",
      "|    n_updates            | 17650       |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    value_loss           | 1.91e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1411         |\n",
      "|    time_elapsed         | 7307         |\n",
      "|    total_timesteps      | 11558912     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027655973 |\n",
      "|    clip_fraction        | 0.0265       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.422       |\n",
      "|    explained_variance   | 0.0173       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 806          |\n",
      "|    n_updates            | 17660        |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11560000, episode_reward=613.60 +/- 56.31\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 614          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11560000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021326537 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.0375       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 927          |\n",
      "|    n_updates            | 17670        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1580     |\n",
      "|    iterations      | 1412     |\n",
      "|    time_elapsed    | 7317     |\n",
      "|    total_timesteps | 11567104 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1413         |\n",
      "|    time_elapsed         | 7321         |\n",
      "|    total_timesteps      | 11575296     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025698638 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.396       |\n",
      "|    explained_variance   | 0.0356       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 845          |\n",
      "|    n_updates            | 17680        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1414         |\n",
      "|    time_elapsed         | 7324         |\n",
      "|    total_timesteps      | 11583488     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026840656 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.407       |\n",
      "|    explained_variance   | 0.0142       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 17690        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1415         |\n",
      "|    time_elapsed         | 7328         |\n",
      "|    total_timesteps      | 11591680     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023809783 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.404       |\n",
      "|    explained_variance   | 0.0538       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 943          |\n",
      "|    n_updates            | 17700        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1416         |\n",
      "|    time_elapsed         | 7332         |\n",
      "|    total_timesteps      | 11599872     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020514587 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.399       |\n",
      "|    explained_variance   | 0.0246       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 713          |\n",
      "|    n_updates            | 17710        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11600000, episode_reward=597.40 +/- 40.09\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 597          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11600000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024073273 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.393       |\n",
      "|    explained_variance   | 0.0259       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 755          |\n",
      "|    n_updates            | 17720        |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1580     |\n",
      "|    iterations      | 1417     |\n",
      "|    time_elapsed    | 7342     |\n",
      "|    total_timesteps | 11608064 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1418         |\n",
      "|    time_elapsed         | 7346         |\n",
      "|    total_timesteps      | 11616256     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018180157 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.402       |\n",
      "|    explained_variance   | 0.0197       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 782          |\n",
      "|    n_updates            | 17730        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    value_loss           | 1.95e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1419         |\n",
      "|    time_elapsed         | 7350         |\n",
      "|    total_timesteps      | 11624448     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023932317 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.397       |\n",
      "|    explained_variance   | 0.0387       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 784          |\n",
      "|    n_updates            | 17740        |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1420         |\n",
      "|    time_elapsed         | 7353         |\n",
      "|    total_timesteps      | 11632640     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023208433 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.396       |\n",
      "|    explained_variance   | 0.0451       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 787          |\n",
      "|    n_updates            | 17750        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11640000, episode_reward=605.80 +/- 56.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 606          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11640000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021077811 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.409       |\n",
      "|    explained_variance   | 0.0122       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 806          |\n",
      "|    n_updates            | 17760        |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1580     |\n",
      "|    iterations      | 1421     |\n",
      "|    time_elapsed    | 7363     |\n",
      "|    total_timesteps | 11640832 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1422         |\n",
      "|    time_elapsed         | 7367         |\n",
      "|    total_timesteps      | 11649024     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022844612 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.401       |\n",
      "|    explained_variance   | 0.0523       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.18e+03     |\n",
      "|    n_updates            | 17770        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1423         |\n",
      "|    time_elapsed         | 7370         |\n",
      "|    total_timesteps      | 11657216     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021359841 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.407       |\n",
      "|    explained_variance   | 0.0332       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 579          |\n",
      "|    n_updates            | 17780        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1424         |\n",
      "|    time_elapsed         | 7374         |\n",
      "|    total_timesteps      | 11665408     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021709085 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.416       |\n",
      "|    explained_variance   | 0.0124       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.29e+03     |\n",
      "|    n_updates            | 17790        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1425         |\n",
      "|    time_elapsed         | 7378         |\n",
      "|    total_timesteps      | 11673600     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021005722 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.407       |\n",
      "|    explained_variance   | 0.023        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 762          |\n",
      "|    n_updates            | 17800        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11680000, episode_reward=613.80 +/- 64.21\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 614          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11680000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027956709 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.408       |\n",
      "|    explained_variance   | 0.0129       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 992          |\n",
      "|    n_updates            | 17810        |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    value_loss           | 1.94e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1581     |\n",
      "|    iterations      | 1426     |\n",
      "|    time_elapsed    | 7388     |\n",
      "|    total_timesteps | 11681792 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1427         |\n",
      "|    time_elapsed         | 7391         |\n",
      "|    total_timesteps      | 11689984     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021458296 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.406       |\n",
      "|    explained_variance   | 0.00515      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 795          |\n",
      "|    n_updates            | 17820        |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    value_loss           | 1.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1428         |\n",
      "|    time_elapsed         | 7395         |\n",
      "|    total_timesteps      | 11698176     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019492133 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.413       |\n",
      "|    explained_variance   | 0.0392       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 861          |\n",
      "|    n_updates            | 17830        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1582        |\n",
      "|    iterations           | 1429        |\n",
      "|    time_elapsed         | 7399        |\n",
      "|    total_timesteps      | 11706368    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002393991 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.401      |\n",
      "|    explained_variance   | 0.075       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 806         |\n",
      "|    n_updates            | 17840       |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    value_loss           | 1.72e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1430         |\n",
      "|    time_elapsed         | 7402         |\n",
      "|    total_timesteps      | 11714560     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016473318 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.0107       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 761          |\n",
      "|    n_updates            | 17850        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11720000, episode_reward=613.40 +/- 54.83\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 613          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11720000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019176742 |\n",
      "|    clip_fraction        | 0.00999      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.412       |\n",
      "|    explained_variance   | 0.0441       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 750          |\n",
      "|    n_updates            | 17860        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1581     |\n",
      "|    iterations      | 1431     |\n",
      "|    time_elapsed    | 7412     |\n",
      "|    total_timesteps | 11722752 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1581        |\n",
      "|    iterations           | 1432        |\n",
      "|    time_elapsed         | 7416        |\n",
      "|    total_timesteps      | 11730944    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001658258 |\n",
      "|    clip_fraction        | 0.00634     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.403      |\n",
      "|    explained_variance   | 0.0313      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 984         |\n",
      "|    n_updates            | 17870       |\n",
      "|    policy_gradient_loss | -0.00225    |\n",
      "|    value_loss           | 1.8e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1433         |\n",
      "|    time_elapsed         | 7420         |\n",
      "|    total_timesteps      | 11739136     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021593343 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.422       |\n",
      "|    explained_variance   | 0.0341       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 819          |\n",
      "|    n_updates            | 17880        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1434         |\n",
      "|    time_elapsed         | 7423         |\n",
      "|    total_timesteps      | 11747328     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027958131 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.417       |\n",
      "|    explained_variance   | 0.0293       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1e+03        |\n",
      "|    n_updates            | 17890        |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1435         |\n",
      "|    time_elapsed         | 7427         |\n",
      "|    total_timesteps      | 11755520     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022604987 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.424       |\n",
      "|    explained_variance   | 0.0332       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 475          |\n",
      "|    n_updates            | 17900        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11760000, episode_reward=617.60 +/- 48.56\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 618          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11760000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025780725 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.425       |\n",
      "|    explained_variance   | 0.0405       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 840          |\n",
      "|    n_updates            | 17910        |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1581     |\n",
      "|    iterations      | 1436     |\n",
      "|    time_elapsed    | 7437     |\n",
      "|    total_timesteps | 11763712 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1437         |\n",
      "|    time_elapsed         | 7441         |\n",
      "|    total_timesteps      | 11771904     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023301567 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.443       |\n",
      "|    explained_variance   | 0.0355       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 708          |\n",
      "|    n_updates            | 17920        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1438         |\n",
      "|    time_elapsed         | 7444         |\n",
      "|    total_timesteps      | 11780096     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024370642 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.433       |\n",
      "|    explained_variance   | 0.0291       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 736          |\n",
      "|    n_updates            | 17930        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1439         |\n",
      "|    time_elapsed         | 7448         |\n",
      "|    total_timesteps      | 11788288     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025388966 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.423       |\n",
      "|    explained_variance   | 0.0178       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 650          |\n",
      "|    n_updates            | 17940        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1440         |\n",
      "|    time_elapsed         | 7452         |\n",
      "|    total_timesteps      | 11796480     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020769243 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.0372       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 754          |\n",
      "|    n_updates            | 17950        |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11800000, episode_reward=612.40 +/- 54.50\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 612          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11800000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016095492 |\n",
      "|    clip_fraction        | 0.00903      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.419       |\n",
      "|    explained_variance   | 0.0469       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 871          |\n",
      "|    n_updates            | 17960        |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1581     |\n",
      "|    iterations      | 1441     |\n",
      "|    time_elapsed    | 7462     |\n",
      "|    total_timesteps | 11804672 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1442         |\n",
      "|    time_elapsed         | 7466         |\n",
      "|    total_timesteps      | 11812864     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023537418 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.417       |\n",
      "|    explained_variance   | -0.0136      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 898          |\n",
      "|    n_updates            | 17970        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1443         |\n",
      "|    time_elapsed         | 7469         |\n",
      "|    total_timesteps      | 11821056     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019522796 |\n",
      "|    clip_fraction        | 0.00991      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.408       |\n",
      "|    explained_variance   | 0.0145       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 830          |\n",
      "|    n_updates            | 17980        |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1444         |\n",
      "|    time_elapsed         | 7473         |\n",
      "|    total_timesteps      | 11829248     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021405132 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.404       |\n",
      "|    explained_variance   | 0.0108       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 746          |\n",
      "|    n_updates            | 17990        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1445         |\n",
      "|    time_elapsed         | 7477         |\n",
      "|    total_timesteps      | 11837440     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022565313 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.421       |\n",
      "|    explained_variance   | 0.027        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.24e+03     |\n",
      "|    n_updates            | 18000        |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11840000, episode_reward=626.80 +/- 50.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 627          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11840000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022877164 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.419       |\n",
      "|    explained_variance   | 0.0373       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 952          |\n",
      "|    n_updates            | 18010        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1446     |\n",
      "|    time_elapsed    | 7487     |\n",
      "|    total_timesteps | 11845632 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1447         |\n",
      "|    time_elapsed         | 7490         |\n",
      "|    total_timesteps      | 11853824     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025569203 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.417       |\n",
      "|    explained_variance   | 0.0584       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 945          |\n",
      "|    n_updates            | 18020        |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    value_loss           | 1.95e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1448         |\n",
      "|    time_elapsed         | 7494         |\n",
      "|    total_timesteps      | 11862016     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019849178 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.0578       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 778          |\n",
      "|    n_updates            | 18030        |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1449         |\n",
      "|    time_elapsed         | 7498         |\n",
      "|    total_timesteps      | 11870208     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029695858 |\n",
      "|    clip_fraction        | 0.024        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.419       |\n",
      "|    explained_variance   | 0.0371       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 18040        |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1450         |\n",
      "|    time_elapsed         | 7501         |\n",
      "|    total_timesteps      | 11878400     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018157011 |\n",
      "|    clip_fraction        | 0.00942      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.42        |\n",
      "|    explained_variance   | 0.0358       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 751          |\n",
      "|    n_updates            | 18050        |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11880000, episode_reward=614.00 +/- 57.48\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 614         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 11880000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002142786 |\n",
      "|    clip_fraction        | 0.0133      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.427      |\n",
      "|    explained_variance   | 0.0214      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 994         |\n",
      "|    n_updates            | 18060       |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    value_loss           | 1.8e+03     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1451     |\n",
      "|    time_elapsed    | 7511     |\n",
      "|    total_timesteps | 11886592 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1452         |\n",
      "|    time_elapsed         | 7515         |\n",
      "|    total_timesteps      | 11894784     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023139364 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.421       |\n",
      "|    explained_variance   | 0.0419       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 742          |\n",
      "|    n_updates            | 18070        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1453         |\n",
      "|    time_elapsed         | 7519         |\n",
      "|    total_timesteps      | 11902976     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020867027 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.428       |\n",
      "|    explained_variance   | 0.0263       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 899          |\n",
      "|    n_updates            | 18080        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1454         |\n",
      "|    time_elapsed         | 7522         |\n",
      "|    total_timesteps      | 11911168     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022334515 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.422       |\n",
      "|    explained_variance   | 0.0264       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 674          |\n",
      "|    n_updates            | 18090        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1583       |\n",
      "|    iterations           | 1455       |\n",
      "|    time_elapsed         | 7526       |\n",
      "|    total_timesteps      | 11919360   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00218686 |\n",
      "|    clip_fraction        | 0.0151     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.425     |\n",
      "|    explained_variance   | 0.0329     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.02e+03   |\n",
      "|    n_updates            | 18100      |\n",
      "|    policy_gradient_loss | -0.00321   |\n",
      "|    value_loss           | 1.63e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=11920000, episode_reward=593.80 +/- 56.25\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 594          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11920000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022202483 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.423       |\n",
      "|    explained_variance   | 0.0217       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 869          |\n",
      "|    n_updates            | 18110        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1456     |\n",
      "|    time_elapsed    | 7536     |\n",
      "|    total_timesteps | 11927552 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1457         |\n",
      "|    time_elapsed         | 7540         |\n",
      "|    total_timesteps      | 11935744     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022950994 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.423       |\n",
      "|    explained_variance   | 0.0137       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 792          |\n",
      "|    n_updates            | 18120        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1458        |\n",
      "|    time_elapsed         | 7544        |\n",
      "|    total_timesteps      | 11943936    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001575992 |\n",
      "|    clip_fraction        | 0.00804     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.431      |\n",
      "|    explained_variance   | 0.0339      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 757         |\n",
      "|    n_updates            | 18130       |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    value_loss           | 1.71e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1459         |\n",
      "|    time_elapsed         | 7547         |\n",
      "|    total_timesteps      | 11952128     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016154919 |\n",
      "|    clip_fraction        | 0.00771      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.428       |\n",
      "|    explained_variance   | 0.0348       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 919          |\n",
      "|    n_updates            | 18140        |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11960000, episode_reward=611.20 +/- 64.18\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 611         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 11960000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002256467 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.428      |\n",
      "|    explained_variance   | 0.0637      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 756         |\n",
      "|    n_updates            | 18150       |\n",
      "|    policy_gradient_loss | -0.00264    |\n",
      "|    value_loss           | 1.89e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1460     |\n",
      "|    time_elapsed    | 7557     |\n",
      "|    total_timesteps | 11960320 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1461         |\n",
      "|    time_elapsed         | 7560         |\n",
      "|    total_timesteps      | 11968512     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020699096 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.036        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 18160        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1462         |\n",
      "|    time_elapsed         | 7564         |\n",
      "|    total_timesteps      | 11976704     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021411218 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.422       |\n",
      "|    explained_variance   | 0.0379       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 863          |\n",
      "|    n_updates            | 18170        |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1463         |\n",
      "|    time_elapsed         | 7568         |\n",
      "|    total_timesteps      | 11984896     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023322725 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.414       |\n",
      "|    explained_variance   | 0.0256       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 993          |\n",
      "|    n_updates            | 18180        |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1464         |\n",
      "|    time_elapsed         | 7571         |\n",
      "|    total_timesteps      | 11993088     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020398432 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.427       |\n",
      "|    explained_variance   | 0.0262       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 953          |\n",
      "|    n_updates            | 18190        |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12000000, episode_reward=628.80 +/- 62.63\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 629          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12000000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023290098 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.429       |\n",
      "|    explained_variance   | 0.0355       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 702          |\n",
      "|    n_updates            | 18200        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1465     |\n",
      "|    time_elapsed    | 7581     |\n",
      "|    total_timesteps | 12001280 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1466         |\n",
      "|    time_elapsed         | 7585         |\n",
      "|    total_timesteps      | 12009472     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016990631 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.424       |\n",
      "|    explained_variance   | 0.0349       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 18210        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1467         |\n",
      "|    time_elapsed         | 7589         |\n",
      "|    total_timesteps      | 12017664     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022720727 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.423       |\n",
      "|    explained_variance   | -0.000299    |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 892          |\n",
      "|    n_updates            | 18220        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1468         |\n",
      "|    time_elapsed         | 7592         |\n",
      "|    total_timesteps      | 12025856     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022445116 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.403       |\n",
      "|    explained_variance   | 0.0466       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 18230        |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1469         |\n",
      "|    time_elapsed         | 7596         |\n",
      "|    total_timesteps      | 12034048     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018719261 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.413       |\n",
      "|    explained_variance   | 0.0359       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 18240        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12040000, episode_reward=614.80 +/- 57.35\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 615          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12040000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026400397 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.408       |\n",
      "|    explained_variance   | 0.0777       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 18250        |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1583     |\n",
      "|    iterations      | 1470     |\n",
      "|    time_elapsed    | 7606     |\n",
      "|    total_timesteps | 12042240 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1471        |\n",
      "|    time_elapsed         | 7610        |\n",
      "|    total_timesteps      | 12050432    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001971093 |\n",
      "|    clip_fraction        | 0.013       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.417      |\n",
      "|    explained_variance   | 0.0239      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 502         |\n",
      "|    n_updates            | 18260       |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    value_loss           | 1.63e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1583       |\n",
      "|    iterations           | 1472       |\n",
      "|    time_elapsed         | 7614       |\n",
      "|    total_timesteps      | 12058624   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00209128 |\n",
      "|    clip_fraction        | 0.012      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.412     |\n",
      "|    explained_variance   | 0.00973    |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 810        |\n",
      "|    n_updates            | 18270      |\n",
      "|    policy_gradient_loss | -0.00277   |\n",
      "|    value_loss           | 1.84e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1473         |\n",
      "|    time_elapsed         | 7618         |\n",
      "|    total_timesteps      | 12066816     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025232378 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.411       |\n",
      "|    explained_variance   | 0.0612       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 18280        |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1474         |\n",
      "|    time_elapsed         | 7622         |\n",
      "|    total_timesteps      | 12075008     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024433534 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.0411       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 857          |\n",
      "|    n_updates            | 18290        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12080000, episode_reward=622.60 +/- 69.56\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 623          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12080000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021781495 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.407       |\n",
      "|    explained_variance   | 0.0467       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 921          |\n",
      "|    n_updates            | 18300        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1583     |\n",
      "|    iterations      | 1475     |\n",
      "|    time_elapsed    | 7632     |\n",
      "|    total_timesteps | 12083200 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1476         |\n",
      "|    time_elapsed         | 7635         |\n",
      "|    total_timesteps      | 12091392     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018769397 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.404       |\n",
      "|    explained_variance   | 0.0335       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 882          |\n",
      "|    n_updates            | 18310        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 1.95e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1477        |\n",
      "|    time_elapsed         | 7639        |\n",
      "|    total_timesteps      | 12099584    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002206273 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.419      |\n",
      "|    explained_variance   | 0.0628      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 727         |\n",
      "|    n_updates            | 18320       |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    value_loss           | 1.76e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 1478        |\n",
      "|    time_elapsed         | 7643        |\n",
      "|    total_timesteps      | 12107776    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001866673 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.408      |\n",
      "|    explained_variance   | -0.00446    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 872         |\n",
      "|    n_updates            | 18330       |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 1479        |\n",
      "|    time_elapsed         | 7647        |\n",
      "|    total_timesteps      | 12115968    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002010774 |\n",
      "|    clip_fraction        | 0.0112      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.421      |\n",
      "|    explained_variance   | 0.0385      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 862         |\n",
      "|    n_updates            | 18340       |\n",
      "|    policy_gradient_loss | -0.00289    |\n",
      "|    value_loss           | 1.74e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=12120000, episode_reward=626.80 +/- 70.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 627         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 12120000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001984985 |\n",
      "|    clip_fraction        | 0.0118      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.42       |\n",
      "|    explained_variance   | 0.0489      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 690         |\n",
      "|    n_updates            | 18350       |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    value_loss           | 1.9e+03     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1480     |\n",
      "|    time_elapsed    | 7659     |\n",
      "|    total_timesteps | 12124160 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1481         |\n",
      "|    time_elapsed         | 7662         |\n",
      "|    total_timesteps      | 12132352     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020893132 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.418       |\n",
      "|    explained_variance   | 0.0474       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 838          |\n",
      "|    n_updates            | 18360        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1482         |\n",
      "|    time_elapsed         | 7666         |\n",
      "|    total_timesteps      | 12140544     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020340374 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.409       |\n",
      "|    explained_variance   | 0.0368       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 841          |\n",
      "|    n_updates            | 18370        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1483         |\n",
      "|    time_elapsed         | 7670         |\n",
      "|    total_timesteps      | 12148736     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026408476 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.423       |\n",
      "|    explained_variance   | 0.0265       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 18380        |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1484         |\n",
      "|    time_elapsed         | 7674         |\n",
      "|    total_timesteps      | 12156928     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022840346 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.418       |\n",
      "|    explained_variance   | 0.0626       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 688          |\n",
      "|    n_updates            | 18390        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12160000, episode_reward=629.20 +/- 70.79\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 629          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12160000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015147128 |\n",
      "|    clip_fraction        | 0.00771      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.415       |\n",
      "|    explained_variance   | 0.028        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 698          |\n",
      "|    n_updates            | 18400        |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    value_loss           | 1.92e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1583     |\n",
      "|    iterations      | 1485     |\n",
      "|    time_elapsed    | 7684     |\n",
      "|    total_timesteps | 12165120 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1486         |\n",
      "|    time_elapsed         | 7688         |\n",
      "|    total_timesteps      | 12173312     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019989386 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.411       |\n",
      "|    explained_variance   | 0.0365       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 18410        |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1487         |\n",
      "|    time_elapsed         | 7692         |\n",
      "|    total_timesteps      | 12181504     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020027417 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.422       |\n",
      "|    explained_variance   | 0.0437       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 794          |\n",
      "|    n_updates            | 18420        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1488         |\n",
      "|    time_elapsed         | 7695         |\n",
      "|    total_timesteps      | 12189696     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020141662 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.417       |\n",
      "|    explained_variance   | 0.0149       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 775          |\n",
      "|    n_updates            | 18430        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1489         |\n",
      "|    time_elapsed         | 7699         |\n",
      "|    total_timesteps      | 12197888     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018045944 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.428       |\n",
      "|    explained_variance   | 0.0359       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 760          |\n",
      "|    n_updates            | 18440        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12200000, episode_reward=626.40 +/- 54.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 626          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12200000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015045427 |\n",
      "|    clip_fraction        | 0.00851      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.413       |\n",
      "|    explained_variance   | 0.0385       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 800          |\n",
      "|    n_updates            | 18450        |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1583     |\n",
      "|    iterations      | 1490     |\n",
      "|    time_elapsed    | 7709     |\n",
      "|    total_timesteps | 12206080 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1491         |\n",
      "|    time_elapsed         | 7713         |\n",
      "|    total_timesteps      | 12214272     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022914978 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.426       |\n",
      "|    explained_variance   | 0.0456       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 687          |\n",
      "|    n_updates            | 18460        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1492         |\n",
      "|    time_elapsed         | 7717         |\n",
      "|    total_timesteps      | 12222464     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018735721 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.0201       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 885          |\n",
      "|    n_updates            | 18470        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1493         |\n",
      "|    time_elapsed         | 7720         |\n",
      "|    total_timesteps      | 12230656     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019720346 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.418       |\n",
      "|    explained_variance   | 0.046        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 564          |\n",
      "|    n_updates            | 18480        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    value_loss           | 1.92e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1494         |\n",
      "|    time_elapsed         | 7724         |\n",
      "|    total_timesteps      | 12238848     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025429754 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.408       |\n",
      "|    explained_variance   | 0.0985       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 915          |\n",
      "|    n_updates            | 18490        |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12240000, episode_reward=642.00 +/- 58.82\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 642          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12240000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022357926 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.418       |\n",
      "|    explained_variance   | 0.0504       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 657          |\n",
      "|    n_updates            | 18500        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1583     |\n",
      "|    iterations      | 1495     |\n",
      "|    time_elapsed    | 7734     |\n",
      "|    total_timesteps | 12247040 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1496         |\n",
      "|    time_elapsed         | 7738         |\n",
      "|    total_timesteps      | 12255232     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019805743 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.422       |\n",
      "|    explained_variance   | 0.083        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 821          |\n",
      "|    n_updates            | 18510        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1497         |\n",
      "|    time_elapsed         | 7742         |\n",
      "|    total_timesteps      | 12263424     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030584903 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.408       |\n",
      "|    explained_variance   | 0.0232       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 787          |\n",
      "|    n_updates            | 18520        |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    value_loss           | 2e+03        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 1498        |\n",
      "|    time_elapsed         | 7745        |\n",
      "|    total_timesteps      | 12271616    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001798545 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.401      |\n",
      "|    explained_variance   | 0.0214      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 721         |\n",
      "|    n_updates            | 18530       |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    value_loss           | 1.66e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 1499        |\n",
      "|    time_elapsed         | 7749        |\n",
      "|    total_timesteps      | 12279808    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002565405 |\n",
      "|    clip_fraction        | 0.0203      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.419      |\n",
      "|    explained_variance   | 0.0472      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.05e+03    |\n",
      "|    n_updates            | 18540       |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    value_loss           | 1.82e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=12280000, episode_reward=618.40 +/- 47.39\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 618          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12280000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019652748 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.414       |\n",
      "|    explained_variance   | 0.0218       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 18550        |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1583     |\n",
      "|    iterations      | 1500     |\n",
      "|    time_elapsed    | 7760     |\n",
      "|    total_timesteps | 12288000 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1583       |\n",
      "|    iterations           | 1501       |\n",
      "|    time_elapsed         | 7763       |\n",
      "|    total_timesteps      | 12296192   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00214917 |\n",
      "|    clip_fraction        | 0.0139     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.414     |\n",
      "|    explained_variance   | 0.0192     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.05e+03   |\n",
      "|    n_updates            | 18560      |\n",
      "|    policy_gradient_loss | -0.00294   |\n",
      "|    value_loss           | 1.94e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 1502        |\n",
      "|    time_elapsed         | 7767        |\n",
      "|    total_timesteps      | 12304384    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001891424 |\n",
      "|    clip_fraction        | 0.00991     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.405      |\n",
      "|    explained_variance   | 0.0202      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 645         |\n",
      "|    n_updates            | 18570       |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    value_loss           | 1.74e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1503         |\n",
      "|    time_elapsed         | 7771         |\n",
      "|    total_timesteps      | 12312576     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019522635 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.414       |\n",
      "|    explained_variance   | 0.0254       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 885          |\n",
      "|    n_updates            | 18580        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12320000, episode_reward=636.00 +/- 51.65\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 636         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 12320000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002527874 |\n",
      "|    clip_fraction        | 0.0191      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.419      |\n",
      "|    explained_variance   | 0.0626      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 631         |\n",
      "|    n_updates            | 18590       |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1583     |\n",
      "|    iterations      | 1504     |\n",
      "|    time_elapsed    | 7781     |\n",
      "|    total_timesteps | 12320768 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1505        |\n",
      "|    time_elapsed         | 7785        |\n",
      "|    total_timesteps      | 12328960    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002485773 |\n",
      "|    clip_fraction        | 0.0161      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.418      |\n",
      "|    explained_variance   | 0.0106      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 991         |\n",
      "|    n_updates            | 18600       |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    value_loss           | 1.74e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1506         |\n",
      "|    time_elapsed         | 7789         |\n",
      "|    total_timesteps      | 12337152     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022845254 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.419       |\n",
      "|    explained_variance   | 0.0688       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 779          |\n",
      "|    n_updates            | 18610        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1507         |\n",
      "|    time_elapsed         | 7792         |\n",
      "|    total_timesteps      | 12345344     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018802015 |\n",
      "|    clip_fraction        | 0.00891      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.409       |\n",
      "|    explained_variance   | 0.0658       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 892          |\n",
      "|    n_updates            | 18620        |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1508         |\n",
      "|    time_elapsed         | 7796         |\n",
      "|    total_timesteps      | 12353536     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019814046 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.413       |\n",
      "|    explained_variance   | 0.021        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 732          |\n",
      "|    n_updates            | 18630        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12360000, episode_reward=616.60 +/- 64.73\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 617          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12360000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017150103 |\n",
      "|    clip_fraction        | 0.00839      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.422       |\n",
      "|    explained_variance   | 0.0331       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 883          |\n",
      "|    n_updates            | 18640        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1583     |\n",
      "|    iterations      | 1509     |\n",
      "|    time_elapsed    | 7806     |\n",
      "|    total_timesteps | 12361728 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1510        |\n",
      "|    time_elapsed         | 7810        |\n",
      "|    total_timesteps      | 12369920    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001926582 |\n",
      "|    clip_fraction        | 0.00963     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.416      |\n",
      "|    explained_variance   | 0.0475      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 873         |\n",
      "|    n_updates            | 18650       |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    value_loss           | 1.85e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 1511        |\n",
      "|    time_elapsed         | 7814        |\n",
      "|    total_timesteps      | 12378112    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002291075 |\n",
      "|    clip_fraction        | 0.0154      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.415      |\n",
      "|    explained_variance   | 0.0504      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 849         |\n",
      "|    n_updates            | 18660       |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    value_loss           | 1.79e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 1512        |\n",
      "|    time_elapsed         | 7817        |\n",
      "|    total_timesteps      | 12386304    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002432415 |\n",
      "|    clip_fraction        | 0.013       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.441      |\n",
      "|    explained_variance   | 0.0613      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 770         |\n",
      "|    n_updates            | 18670       |\n",
      "|    policy_gradient_loss | -0.0032     |\n",
      "|    value_loss           | 1.75e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1513         |\n",
      "|    time_elapsed         | 7821         |\n",
      "|    total_timesteps      | 12394496     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018180794 |\n",
      "|    clip_fraction        | 0.00917      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.447       |\n",
      "|    explained_variance   | 0.0311       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 794          |\n",
      "|    n_updates            | 18680        |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12400000, episode_reward=637.20 +/- 58.86\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 637          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12400000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019723186 |\n",
      "|    clip_fraction        | 0.0095       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.43        |\n",
      "|    explained_variance   | 0.0114       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 866          |\n",
      "|    n_updates            | 18690        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    value_loss           | 1.92e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1583     |\n",
      "|    iterations      | 1514     |\n",
      "|    time_elapsed    | 7831     |\n",
      "|    total_timesteps | 12402688 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1515         |\n",
      "|    time_elapsed         | 7835         |\n",
      "|    total_timesteps      | 12410880     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020410148 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.431       |\n",
      "|    explained_variance   | 0.0272       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 18700        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1516         |\n",
      "|    time_elapsed         | 7839         |\n",
      "|    total_timesteps      | 12419072     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025175253 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.438       |\n",
      "|    explained_variance   | 0.00863      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 801          |\n",
      "|    n_updates            | 18710        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1517         |\n",
      "|    time_elapsed         | 7842         |\n",
      "|    total_timesteps      | 12427264     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023520165 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.429       |\n",
      "|    explained_variance   | 0.0339       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 688          |\n",
      "|    n_updates            | 18720        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1518         |\n",
      "|    time_elapsed         | 7846         |\n",
      "|    total_timesteps      | 12435456     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018117789 |\n",
      "|    clip_fraction        | 0.00914      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.434       |\n",
      "|    explained_variance   | 0.0471       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 942          |\n",
      "|    n_updates            | 18730        |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    value_loss           | 1.91e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12440000, episode_reward=618.60 +/- 41.62\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 619          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12440000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025051762 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.0598       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 773          |\n",
      "|    n_updates            | 18740        |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1583     |\n",
      "|    iterations      | 1519     |\n",
      "|    time_elapsed    | 7856     |\n",
      "|    total_timesteps | 12443648 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1520         |\n",
      "|    time_elapsed         | 7860         |\n",
      "|    total_timesteps      | 12451840     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029552886 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.442       |\n",
      "|    explained_variance   | 0.0143       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 18750        |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1521         |\n",
      "|    time_elapsed         | 7864         |\n",
      "|    total_timesteps      | 12460032     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018599095 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.431       |\n",
      "|    explained_variance   | 0.0658       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 527          |\n",
      "|    n_updates            | 18760        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1522         |\n",
      "|    time_elapsed         | 7868         |\n",
      "|    total_timesteps      | 12468224     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018238777 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.434       |\n",
      "|    explained_variance   | 0.0573       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 812          |\n",
      "|    n_updates            | 18770        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 1523        |\n",
      "|    time_elapsed         | 7873        |\n",
      "|    total_timesteps      | 12476416    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002757901 |\n",
      "|    clip_fraction        | 0.0219      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.429      |\n",
      "|    explained_variance   | 0.0095      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 677         |\n",
      "|    n_updates            | 18780       |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    value_loss           | 1.81e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=12480000, episode_reward=618.20 +/- 53.50\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 618          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12480000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021872828 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.428       |\n",
      "|    explained_variance   | 0.0411       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 824          |\n",
      "|    n_updates            | 18790        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1583     |\n",
      "|    iterations      | 1524     |\n",
      "|    time_elapsed    | 7883     |\n",
      "|    total_timesteps | 12484608 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1525         |\n",
      "|    time_elapsed         | 7887         |\n",
      "|    total_timesteps      | 12492800     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023247045 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.413       |\n",
      "|    explained_variance   | 0.00289      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 798          |\n",
      "|    n_updates            | 18800        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1526         |\n",
      "|    time_elapsed         | 7891         |\n",
      "|    total_timesteps      | 12500992     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019203038 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.427       |\n",
      "|    explained_variance   | 0.0212       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 873          |\n",
      "|    n_updates            | 18810        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    value_loss           | 1.97e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1527         |\n",
      "|    time_elapsed         | 7895         |\n",
      "|    total_timesteps      | 12509184     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023176423 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.424       |\n",
      "|    explained_variance   | 0.0782       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 971          |\n",
      "|    n_updates            | 18820        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1528         |\n",
      "|    time_elapsed         | 7898         |\n",
      "|    total_timesteps      | 12517376     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018171368 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.418       |\n",
      "|    explained_variance   | 0.00712      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 924          |\n",
      "|    n_updates            | 18830        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12520000, episode_reward=631.20 +/- 54.91\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 631         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 12520000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001696039 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.442      |\n",
      "|    explained_variance   | 0.0485      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 649         |\n",
      "|    n_updates            | 18840       |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    value_loss           | 1.82e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1583     |\n",
      "|    iterations      | 1529     |\n",
      "|    time_elapsed    | 7908     |\n",
      "|    total_timesteps | 12525568 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1530         |\n",
      "|    time_elapsed         | 7912         |\n",
      "|    total_timesteps      | 12533760     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019808607 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.427       |\n",
      "|    explained_variance   | 0.00496      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 18850        |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1531         |\n",
      "|    time_elapsed         | 7916         |\n",
      "|    total_timesteps      | 12541952     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021841298 |\n",
      "|    clip_fraction        | 0.0097       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.429       |\n",
      "|    explained_variance   | 0.0122       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 18860        |\n",
      "|    policy_gradient_loss | -0.00241     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1532         |\n",
      "|    time_elapsed         | 7919         |\n",
      "|    total_timesteps      | 12550144     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022750217 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.422       |\n",
      "|    explained_variance   | 0.0151       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 752          |\n",
      "|    n_updates            | 18870        |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1533         |\n",
      "|    time_elapsed         | 7923         |\n",
      "|    total_timesteps      | 12558336     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017815355 |\n",
      "|    clip_fraction        | 0.00972      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.418       |\n",
      "|    explained_variance   | 0.0386       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 618          |\n",
      "|    n_updates            | 18880        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12560000, episode_reward=654.40 +/- 57.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 654          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12560000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014593861 |\n",
      "|    clip_fraction        | 0.00701      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.426       |\n",
      "|    explained_variance   | 0.032        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 820          |\n",
      "|    n_updates            | 18890        |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1583     |\n",
      "|    iterations      | 1534     |\n",
      "|    time_elapsed    | 7933     |\n",
      "|    total_timesteps | 12566528 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1535         |\n",
      "|    time_elapsed         | 7937         |\n",
      "|    total_timesteps      | 12574720     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017305042 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.424       |\n",
      "|    explained_variance   | 0.0364       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 18900        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    value_loss           | 1.92e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1536         |\n",
      "|    time_elapsed         | 7940         |\n",
      "|    total_timesteps      | 12582912     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021698512 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.426       |\n",
      "|    explained_variance   | 0.0568       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 770          |\n",
      "|    n_updates            | 18910        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1537         |\n",
      "|    time_elapsed         | 7944         |\n",
      "|    total_timesteps      | 12591104     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019322613 |\n",
      "|    clip_fraction        | 0.00836      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.425       |\n",
      "|    explained_variance   | 0.0579       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 18920        |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 1538         |\n",
      "|    time_elapsed         | 7948         |\n",
      "|    total_timesteps      | 12599296     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027748162 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.408       |\n",
      "|    explained_variance   | 0.013        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 869          |\n",
      "|    n_updates            | 18930        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12600000, episode_reward=622.20 +/- 62.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 622         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 12600000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002119303 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.412      |\n",
      "|    explained_variance   | 0.0244      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 901         |\n",
      "|    n_updates            | 18940       |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    value_loss           | 1.89e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1584     |\n",
      "|    iterations      | 1539     |\n",
      "|    time_elapsed    | 7958     |\n",
      "|    total_timesteps | 12607488 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1540         |\n",
      "|    time_elapsed         | 7961         |\n",
      "|    total_timesteps      | 12615680     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019215033 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.0172       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 838          |\n",
      "|    n_updates            | 18950        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1541         |\n",
      "|    time_elapsed         | 7965         |\n",
      "|    total_timesteps      | 12623872     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021487684 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.412       |\n",
      "|    explained_variance   | 0.0327       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 18960        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 1542         |\n",
      "|    time_elapsed         | 7969         |\n",
      "|    total_timesteps      | 12632064     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021226539 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.408       |\n",
      "|    explained_variance   | 0.024        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 835          |\n",
      "|    n_updates            | 18970        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12640000, episode_reward=639.20 +/- 59.86\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 639          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12640000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021546304 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.00702      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 967          |\n",
      "|    n_updates            | 18980        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1584     |\n",
      "|    iterations      | 1543     |\n",
      "|    time_elapsed    | 7979     |\n",
      "|    total_timesteps | 12640256 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1544         |\n",
      "|    time_elapsed         | 7982         |\n",
      "|    total_timesteps      | 12648448     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019455269 |\n",
      "|    clip_fraction        | 0.00879      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.0288       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 524          |\n",
      "|    n_updates            | 18990        |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1545         |\n",
      "|    time_elapsed         | 7986         |\n",
      "|    total_timesteps      | 12656640     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025025005 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.398       |\n",
      "|    explained_variance   | 0.0298       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 925          |\n",
      "|    n_updates            | 19000        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 1546         |\n",
      "|    time_elapsed         | 7990         |\n",
      "|    total_timesteps      | 12664832     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018393667 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.0162       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 19010        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 1547         |\n",
      "|    time_elapsed         | 7994         |\n",
      "|    total_timesteps      | 12673024     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017941059 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.408       |\n",
      "|    explained_variance   | 0.038        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 882          |\n",
      "|    n_updates            | 19020        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12680000, episode_reward=631.00 +/- 51.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 631         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 12680000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001961404 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.408      |\n",
      "|    explained_variance   | 0.0219      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 884         |\n",
      "|    n_updates            | 19030       |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    value_loss           | 1.77e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1584     |\n",
      "|    iterations      | 1548     |\n",
      "|    time_elapsed    | 8003     |\n",
      "|    total_timesteps | 12681216 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 1549        |\n",
      "|    time_elapsed         | 8007        |\n",
      "|    total_timesteps      | 12689408    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002054488 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.409      |\n",
      "|    explained_variance   | 0.0429      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 885         |\n",
      "|    n_updates            | 19040       |\n",
      "|    policy_gradient_loss | -0.00284    |\n",
      "|    value_loss           | 1.66e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1585        |\n",
      "|    iterations           | 1550        |\n",
      "|    time_elapsed         | 8011        |\n",
      "|    total_timesteps      | 12697600    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002643237 |\n",
      "|    clip_fraction        | 0.015       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.397      |\n",
      "|    explained_variance   | 0.0566      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 863         |\n",
      "|    n_updates            | 19050       |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    value_loss           | 1.65e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 1551         |\n",
      "|    time_elapsed         | 8014         |\n",
      "|    total_timesteps      | 12705792     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025655415 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.4         |\n",
      "|    explained_variance   | 0.0437       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 724          |\n",
      "|    n_updates            | 19060        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 1552         |\n",
      "|    time_elapsed         | 8018         |\n",
      "|    total_timesteps      | 12713984     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019172449 |\n",
      "|    clip_fraction        | 0.00996      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.386       |\n",
      "|    explained_variance   | 0.0133       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.21e+03     |\n",
      "|    n_updates            | 19070        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12720000, episode_reward=610.40 +/- 44.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 610          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12720000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014584094 |\n",
      "|    clip_fraction        | 0.00916      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.398       |\n",
      "|    explained_variance   | 0.0417       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 813          |\n",
      "|    n_updates            | 19080        |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1584     |\n",
      "|    iterations      | 1553     |\n",
      "|    time_elapsed    | 8028     |\n",
      "|    total_timesteps | 12722176 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 1554        |\n",
      "|    time_elapsed         | 8032        |\n",
      "|    total_timesteps      | 12730368    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001911643 |\n",
      "|    clip_fraction        | 0.0126      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.408      |\n",
      "|    explained_variance   | 0.0306      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 796         |\n",
      "|    n_updates            | 19090       |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    value_loss           | 1.7e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 1555         |\n",
      "|    time_elapsed         | 8035         |\n",
      "|    total_timesteps      | 12738560     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023148586 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.383       |\n",
      "|    explained_variance   | 0.0574       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 816          |\n",
      "|    n_updates            | 19100        |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 1556         |\n",
      "|    time_elapsed         | 8040         |\n",
      "|    total_timesteps      | 12746752     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019426704 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.389       |\n",
      "|    explained_variance   | 0.0535       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 949          |\n",
      "|    n_updates            | 19110        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    value_loss           | 1.93e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 1557         |\n",
      "|    time_elapsed         | 8045         |\n",
      "|    total_timesteps      | 12754944     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022855662 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.379       |\n",
      "|    explained_variance   | 0.0329       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 19120        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 1.61e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12760000, episode_reward=607.60 +/- 48.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 608          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12760000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019357428 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.386       |\n",
      "|    explained_variance   | 0.0361       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 769          |\n",
      "|    n_updates            | 19130        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1584     |\n",
      "|    iterations      | 1558     |\n",
      "|    time_elapsed    | 8055     |\n",
      "|    total_timesteps | 12763136 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1559         |\n",
      "|    time_elapsed         | 8059         |\n",
      "|    total_timesteps      | 12771328     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019842796 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.392       |\n",
      "|    explained_variance   | 0.0604       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1e+03        |\n",
      "|    n_updates            | 19140        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1560         |\n",
      "|    time_elapsed         | 8063         |\n",
      "|    total_timesteps      | 12779520     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017286151 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.386       |\n",
      "|    explained_variance   | 0.0407       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 906          |\n",
      "|    n_updates            | 19150        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 1561        |\n",
      "|    time_elapsed         | 8068        |\n",
      "|    total_timesteps      | 12787712    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002245572 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.395      |\n",
      "|    explained_variance   | 0.0477      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 933         |\n",
      "|    n_updates            | 19160       |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    value_loss           | 1.69e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1585        |\n",
      "|    iterations           | 1562        |\n",
      "|    time_elapsed         | 8072        |\n",
      "|    total_timesteps      | 12795904    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002111596 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.393      |\n",
      "|    explained_variance   | 0.0285      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 860         |\n",
      "|    n_updates            | 19170       |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    value_loss           | 1.77e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=12800000, episode_reward=649.60 +/- 52.31\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 650         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 12800000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002738247 |\n",
      "|    clip_fraction        | 0.0214      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.403      |\n",
      "|    explained_variance   | 0.0574      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 709         |\n",
      "|    n_updates            | 19180       |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    value_loss           | 1.76e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1584     |\n",
      "|    iterations      | 1563     |\n",
      "|    time_elapsed    | 8082     |\n",
      "|    total_timesteps | 12804096 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1564         |\n",
      "|    time_elapsed         | 8086         |\n",
      "|    total_timesteps      | 12812288     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018860279 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.389       |\n",
      "|    explained_variance   | 0.0741       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 961          |\n",
      "|    n_updates            | 19190        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1565         |\n",
      "|    time_elapsed         | 8090         |\n",
      "|    total_timesteps      | 12820480     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026050494 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.393       |\n",
      "|    explained_variance   | 0.0347       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 906          |\n",
      "|    n_updates            | 19200        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1566         |\n",
      "|    time_elapsed         | 8094         |\n",
      "|    total_timesteps      | 12828672     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022366536 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.388       |\n",
      "|    explained_variance   | 0.0101       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 884          |\n",
      "|    n_updates            | 19210        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 1567         |\n",
      "|    time_elapsed         | 8097         |\n",
      "|    total_timesteps      | 12836864     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022044447 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.395       |\n",
      "|    explained_variance   | 0.0513       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 899          |\n",
      "|    n_updates            | 19220        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12840000, episode_reward=630.00 +/- 67.26\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 630          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12840000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021967196 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.402       |\n",
      "|    explained_variance   | 0.027        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 798          |\n",
      "|    n_updates            | 19230        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1584     |\n",
      "|    iterations      | 1568     |\n",
      "|    time_elapsed    | 8108     |\n",
      "|    total_timesteps | 12845056 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1584        |\n",
      "|    iterations           | 1569        |\n",
      "|    time_elapsed         | 8112        |\n",
      "|    total_timesteps      | 12853248    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002794305 |\n",
      "|    clip_fraction        | 0.0193      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.399      |\n",
      "|    explained_variance   | 0.0294      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 19240       |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    value_loss           | 1.82e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1570         |\n",
      "|    time_elapsed         | 8116         |\n",
      "|    total_timesteps      | 12861440     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020489653 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.383       |\n",
      "|    explained_variance   | 0.0516       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 999          |\n",
      "|    n_updates            | 19250        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1571         |\n",
      "|    time_elapsed         | 8119         |\n",
      "|    total_timesteps      | 12869632     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019706432 |\n",
      "|    clip_fraction        | 0.00906      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.393       |\n",
      "|    explained_variance   | 0.00408      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 920          |\n",
      "|    n_updates            | 19260        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 1572         |\n",
      "|    time_elapsed         | 8123         |\n",
      "|    total_timesteps      | 12877824     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018341593 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.395       |\n",
      "|    explained_variance   | 0.0338       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 871          |\n",
      "|    n_updates            | 19270        |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12880000, episode_reward=596.40 +/- 101.64\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 596          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12880000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025503796 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.386       |\n",
      "|    explained_variance   | 0.0613       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 579          |\n",
      "|    n_updates            | 19280        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1584     |\n",
      "|    iterations      | 1573     |\n",
      "|    time_elapsed    | 8134     |\n",
      "|    total_timesteps | 12886016 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1574         |\n",
      "|    time_elapsed         | 8138         |\n",
      "|    total_timesteps      | 12894208     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020378577 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.403       |\n",
      "|    explained_variance   | 0.0062       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 937          |\n",
      "|    n_updates            | 19290        |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1575         |\n",
      "|    time_elapsed         | 8142         |\n",
      "|    total_timesteps      | 12902400     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015646341 |\n",
      "|    clip_fraction        | 0.00903      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.39        |\n",
      "|    explained_variance   | 0.0202       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 660          |\n",
      "|    n_updates            | 19300        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1576         |\n",
      "|    time_elapsed         | 8146         |\n",
      "|    total_timesteps      | 12910592     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019887527 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.393       |\n",
      "|    explained_variance   | 0.0454       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 900          |\n",
      "|    n_updates            | 19310        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1585         |\n",
      "|    iterations           | 1577         |\n",
      "|    time_elapsed         | 8150         |\n",
      "|    total_timesteps      | 12918784     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022143507 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.387       |\n",
      "|    explained_variance   | 0.0473       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 779          |\n",
      "|    n_updates            | 19320        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12920000, episode_reward=613.20 +/- 52.06\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 613          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12920000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018792948 |\n",
      "|    clip_fraction        | 0.00947      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.396       |\n",
      "|    explained_variance   | 0.069        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 682          |\n",
      "|    n_updates            | 19330        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1584     |\n",
      "|    iterations      | 1578     |\n",
      "|    time_elapsed    | 8160     |\n",
      "|    total_timesteps | 12926976 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1579         |\n",
      "|    time_elapsed         | 8165         |\n",
      "|    total_timesteps      | 12935168     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022076226 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.382       |\n",
      "|    explained_variance   | 0.0323       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 917          |\n",
      "|    n_updates            | 19340        |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1580         |\n",
      "|    time_elapsed         | 8169         |\n",
      "|    total_timesteps      | 12943360     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021299003 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.39        |\n",
      "|    explained_variance   | 0.0225       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 845          |\n",
      "|    n_updates            | 19350        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1581         |\n",
      "|    time_elapsed         | 8173         |\n",
      "|    total_timesteps      | 12951552     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019845911 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.404       |\n",
      "|    explained_variance   | 0.035        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 725          |\n",
      "|    n_updates            | 19360        |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1582         |\n",
      "|    time_elapsed         | 8176         |\n",
      "|    total_timesteps      | 12959744     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018491799 |\n",
      "|    clip_fraction        | 0.00994      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.402       |\n",
      "|    explained_variance   | 0.0405       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 769          |\n",
      "|    n_updates            | 19370        |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12960000, episode_reward=629.00 +/- 54.85\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 629          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12960000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023336448 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.394       |\n",
      "|    explained_variance   | 0.0404       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 19380        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1583     |\n",
      "|    iterations      | 1583     |\n",
      "|    time_elapsed    | 8187     |\n",
      "|    total_timesteps | 12967936 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1584         |\n",
      "|    time_elapsed         | 8191         |\n",
      "|    total_timesteps      | 12976128     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024073238 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.408       |\n",
      "|    explained_variance   | 0.0622       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 19390        |\n",
      "|    policy_gradient_loss | -0.00414     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1585         |\n",
      "|    time_elapsed         | 8195         |\n",
      "|    total_timesteps      | 12984320     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021465137 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.396       |\n",
      "|    explained_variance   | 0.0335       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 573          |\n",
      "|    n_updates            | 19400        |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1586         |\n",
      "|    time_elapsed         | 8199         |\n",
      "|    total_timesteps      | 12992512     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023236421 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.406       |\n",
      "|    explained_variance   | 0.0486       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 829          |\n",
      "|    n_updates            | 19410        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13000000, episode_reward=629.00 +/- 58.59\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 629          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13000000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021469952 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.411       |\n",
      "|    explained_variance   | 0.0399       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 845          |\n",
      "|    n_updates            | 19420        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1583     |\n",
      "|    iterations      | 1587     |\n",
      "|    time_elapsed    | 8209     |\n",
      "|    total_timesteps | 13000704 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1588        |\n",
      "|    time_elapsed         | 8213        |\n",
      "|    total_timesteps      | 13008896    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001759486 |\n",
      "|    clip_fraction        | 0.00933     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.393      |\n",
      "|    explained_variance   | 0.0261      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 750         |\n",
      "|    n_updates            | 19430       |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    value_loss           | 1.76e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1589         |\n",
      "|    time_elapsed         | 8216         |\n",
      "|    total_timesteps      | 13017088     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024079825 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.0142       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 943          |\n",
      "|    n_updates            | 19440        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1584         |\n",
      "|    iterations           | 1590         |\n",
      "|    time_elapsed         | 8220         |\n",
      "|    total_timesteps      | 13025280     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022401875 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.4         |\n",
      "|    explained_variance   | 0.0436       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 709          |\n",
      "|    n_updates            | 19450        |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1591         |\n",
      "|    time_elapsed         | 8229         |\n",
      "|    total_timesteps      | 13033472     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024201907 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.394       |\n",
      "|    explained_variance   | 0.0293       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 847          |\n",
      "|    n_updates            | 19460        |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13040000, episode_reward=625.40 +/- 57.07\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 625          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13040000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025074237 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.4         |\n",
      "|    explained_variance   | 0.00496      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 722          |\n",
      "|    n_updates            | 19470        |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1592     |\n",
      "|    time_elapsed    | 8239     |\n",
      "|    total_timesteps | 13041664 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1593         |\n",
      "|    time_elapsed         | 8243         |\n",
      "|    total_timesteps      | 13049856     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020511188 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.406       |\n",
      "|    explained_variance   | 0.0376       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 955          |\n",
      "|    n_updates            | 19480        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    value_loss           | 1.96e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1594         |\n",
      "|    time_elapsed         | 8247         |\n",
      "|    total_timesteps      | 13058048     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021489589 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.0374       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 823          |\n",
      "|    n_updates            | 19490        |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1595        |\n",
      "|    time_elapsed         | 8251        |\n",
      "|    total_timesteps      | 13066240    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002445951 |\n",
      "|    clip_fraction        | 0.0198      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.403      |\n",
      "|    explained_variance   | 0.0592      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 949         |\n",
      "|    n_updates            | 19500       |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    value_loss           | 1.7e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1596        |\n",
      "|    time_elapsed         | 8255        |\n",
      "|    total_timesteps      | 13074432    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001924749 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.397      |\n",
      "|    explained_variance   | 0.0587      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 802         |\n",
      "|    n_updates            | 19510       |\n",
      "|    policy_gradient_loss | -0.0033     |\n",
      "|    value_loss           | 1.84e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=13080000, episode_reward=620.40 +/- 55.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 620          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13080000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017519064 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.398       |\n",
      "|    explained_variance   | 0.0527       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 19520        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 1.91e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1597     |\n",
      "|    time_elapsed    | 8265     |\n",
      "|    total_timesteps | 13082624 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1598         |\n",
      "|    time_elapsed         | 8269         |\n",
      "|    total_timesteps      | 13090816     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021274192 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.395       |\n",
      "|    explained_variance   | 0.0353       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 707          |\n",
      "|    n_updates            | 19530        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1599         |\n",
      "|    time_elapsed         | 8272         |\n",
      "|    total_timesteps      | 13099008     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021369732 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.39        |\n",
      "|    explained_variance   | 0.0404       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 19540        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1600         |\n",
      "|    time_elapsed         | 8276         |\n",
      "|    total_timesteps      | 13107200     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021304192 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.391       |\n",
      "|    explained_variance   | 0.0501       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 892          |\n",
      "|    n_updates            | 19550        |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1601         |\n",
      "|    time_elapsed         | 8280         |\n",
      "|    total_timesteps      | 13115392     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018438029 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.402       |\n",
      "|    explained_variance   | 0.0182       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 804          |\n",
      "|    n_updates            | 19560        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13120000, episode_reward=609.00 +/- 58.15\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 609          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13120000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013257167 |\n",
      "|    clip_fraction        | 0.00597      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.394       |\n",
      "|    explained_variance   | 0.000855     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 859          |\n",
      "|    n_updates            | 19570        |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1602     |\n",
      "|    time_elapsed    | 8290     |\n",
      "|    total_timesteps | 13123584 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1603         |\n",
      "|    time_elapsed         | 8294         |\n",
      "|    total_timesteps      | 13131776     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022862055 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.387       |\n",
      "|    explained_variance   | 0.028        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 863          |\n",
      "|    n_updates            | 19580        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1604         |\n",
      "|    time_elapsed         | 8298         |\n",
      "|    total_timesteps      | 13139968     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019315397 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.391       |\n",
      "|    explained_variance   | 0.0423       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 19590        |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1605        |\n",
      "|    time_elapsed         | 8302        |\n",
      "|    total_timesteps      | 13148160    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002004397 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.385      |\n",
      "|    explained_variance   | 0.0466      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 949         |\n",
      "|    n_updates            | 19600       |\n",
      "|    policy_gradient_loss | -0.00259    |\n",
      "|    value_loss           | 1.74e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1606         |\n",
      "|    time_elapsed         | 8305         |\n",
      "|    total_timesteps      | 13156352     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020141085 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.373       |\n",
      "|    explained_variance   | 0.0384       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.24e+03     |\n",
      "|    n_updates            | 19610        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    value_loss           | 1.91e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13160000, episode_reward=631.60 +/- 53.90\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 632          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13160000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013870863 |\n",
      "|    clip_fraction        | 0.00792      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.399       |\n",
      "|    explained_variance   | 0.0373       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 944          |\n",
      "|    n_updates            | 19620        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1583     |\n",
      "|    iterations      | 1607     |\n",
      "|    time_elapsed    | 8315     |\n",
      "|    total_timesteps | 13164544 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1608         |\n",
      "|    time_elapsed         | 8319         |\n",
      "|    total_timesteps      | 13172736     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024950532 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.396       |\n",
      "|    explained_variance   | 0.0359       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 653          |\n",
      "|    n_updates            | 19630        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1609         |\n",
      "|    time_elapsed         | 8323         |\n",
      "|    total_timesteps      | 13180928     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021193377 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.397       |\n",
      "|    explained_variance   | 0.0631       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 555          |\n",
      "|    n_updates            | 19640        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1610        |\n",
      "|    time_elapsed         | 8327        |\n",
      "|    total_timesteps      | 13189120    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002108009 |\n",
      "|    clip_fraction        | 0.015       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.396      |\n",
      "|    explained_variance   | 0.0632      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 833         |\n",
      "|    n_updates            | 19650       |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    value_loss           | 1.85e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1611        |\n",
      "|    time_elapsed         | 8331        |\n",
      "|    total_timesteps      | 13197312    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002131887 |\n",
      "|    clip_fraction        | 0.0143      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.386      |\n",
      "|    explained_variance   | 0.0529      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 750         |\n",
      "|    n_updates            | 19660       |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    value_loss           | 1.84e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=13200000, episode_reward=639.60 +/- 55.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 640          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13200000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026951444 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.384       |\n",
      "|    explained_variance   | 0.0464       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.08e+03     |\n",
      "|    n_updates            | 19670        |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1612     |\n",
      "|    time_elapsed    | 8342     |\n",
      "|    total_timesteps | 13205504 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1613         |\n",
      "|    time_elapsed         | 8346         |\n",
      "|    total_timesteps      | 13213696     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020474803 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.376       |\n",
      "|    explained_variance   | 0.0181       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 19680        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1614        |\n",
      "|    time_elapsed         | 8349        |\n",
      "|    total_timesteps      | 13221888    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002107236 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.372      |\n",
      "|    explained_variance   | 0.0101      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 934         |\n",
      "|    n_updates            | 19690       |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    value_loss           | 1.9e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1615        |\n",
      "|    time_elapsed         | 8353        |\n",
      "|    total_timesteps      | 13230080    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002206217 |\n",
      "|    clip_fraction        | 0.0152      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.386      |\n",
      "|    explained_variance   | 0.0317      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.29e+03    |\n",
      "|    n_updates            | 19700       |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    value_loss           | 1.73e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1616        |\n",
      "|    time_elapsed         | 8358        |\n",
      "|    total_timesteps      | 13238272    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001885888 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.357      |\n",
      "|    explained_variance   | 0.0577      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 955         |\n",
      "|    n_updates            | 19710       |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    value_loss           | 1.83e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=13240000, episode_reward=612.20 +/- 62.46\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 612          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13240000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022797815 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.366       |\n",
      "|    explained_variance   | 0.041        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 653          |\n",
      "|    n_updates            | 19720        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1617     |\n",
      "|    time_elapsed    | 8368     |\n",
      "|    total_timesteps | 13246464 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1618         |\n",
      "|    time_elapsed         | 8372         |\n",
      "|    total_timesteps      | 13254656     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017831102 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.369       |\n",
      "|    explained_variance   | 0.0205       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 966          |\n",
      "|    n_updates            | 19730        |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1619         |\n",
      "|    time_elapsed         | 8376         |\n",
      "|    total_timesteps      | 13262848     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015943536 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.365       |\n",
      "|    explained_variance   | 0.0424       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 19740        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1620         |\n",
      "|    time_elapsed         | 8380         |\n",
      "|    total_timesteps      | 13271040     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021173954 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.368       |\n",
      "|    explained_variance   | 0.0516       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 801          |\n",
      "|    n_updates            | 19750        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1621         |\n",
      "|    time_elapsed         | 8384         |\n",
      "|    total_timesteps      | 13279232     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022791103 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.376       |\n",
      "|    explained_variance   | -0.0158      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 896          |\n",
      "|    n_updates            | 19760        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13280000, episode_reward=615.40 +/- 48.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 615          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13280000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013842435 |\n",
      "|    clip_fraction        | 0.00697      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.365       |\n",
      "|    explained_variance   | 0.023        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 993          |\n",
      "|    n_updates            | 19770        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1622     |\n",
      "|    time_elapsed    | 8394     |\n",
      "|    total_timesteps | 13287424 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1623         |\n",
      "|    time_elapsed         | 8397         |\n",
      "|    total_timesteps      | 13295616     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014436152 |\n",
      "|    clip_fraction        | 0.00758      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.364       |\n",
      "|    explained_variance   | 0.033        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 822          |\n",
      "|    n_updates            | 19780        |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1624         |\n",
      "|    time_elapsed         | 8401         |\n",
      "|    total_timesteps      | 13303808     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024071073 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.362       |\n",
      "|    explained_variance   | 0.0235       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 908          |\n",
      "|    n_updates            | 19790        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1625        |\n",
      "|    time_elapsed         | 8405        |\n",
      "|    total_timesteps      | 13312000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002277468 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.347      |\n",
      "|    explained_variance   | 0.0112      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.13e+03    |\n",
      "|    n_updates            | 19800       |\n",
      "|    policy_gradient_loss | -0.00267    |\n",
      "|    value_loss           | 1.79e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=13320000, episode_reward=620.80 +/- 62.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 621          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13320000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015085728 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.358       |\n",
      "|    explained_variance   | 0.0271       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 855          |\n",
      "|    n_updates            | 19810        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1626     |\n",
      "|    time_elapsed    | 8415     |\n",
      "|    total_timesteps | 13320192 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1627         |\n",
      "|    time_elapsed         | 8419         |\n",
      "|    total_timesteps      | 13328384     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018177414 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.362       |\n",
      "|    explained_variance   | 0.0297       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 987          |\n",
      "|    n_updates            | 19820        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1628         |\n",
      "|    time_elapsed         | 8423         |\n",
      "|    total_timesteps      | 13336576     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021986272 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.358       |\n",
      "|    explained_variance   | 0.0384       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 759          |\n",
      "|    n_updates            | 19830        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1629         |\n",
      "|    time_elapsed         | 8427         |\n",
      "|    total_timesteps      | 13344768     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018423586 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.356       |\n",
      "|    explained_variance   | 0.0469       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 789          |\n",
      "|    n_updates            | 19840        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1630        |\n",
      "|    time_elapsed         | 8431        |\n",
      "|    total_timesteps      | 13352960    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002544671 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.361      |\n",
      "|    explained_variance   | 0.0313      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 756         |\n",
      "|    n_updates            | 19850       |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    value_loss           | 1.77e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=13360000, episode_reward=618.40 +/- 67.60\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 618         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 13360000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001780982 |\n",
      "|    clip_fraction        | 0.0115      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.367      |\n",
      "|    explained_variance   | 0.0501      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 825         |\n",
      "|    n_updates            | 19860       |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    value_loss           | 1.81e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1631     |\n",
      "|    time_elapsed    | 8441     |\n",
      "|    total_timesteps | 13361152 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1632         |\n",
      "|    time_elapsed         | 8445         |\n",
      "|    total_timesteps      | 13369344     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018967646 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.365       |\n",
      "|    explained_variance   | -0.00506     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 19870        |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1633         |\n",
      "|    time_elapsed         | 8449         |\n",
      "|    total_timesteps      | 13377536     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015349694 |\n",
      "|    clip_fraction        | 0.00868      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.37        |\n",
      "|    explained_variance   | 0.0314       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 19880        |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1634         |\n",
      "|    time_elapsed         | 8453         |\n",
      "|    total_timesteps      | 13385728     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020621428 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.362       |\n",
      "|    explained_variance   | 0.0185       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 940          |\n",
      "|    n_updates            | 19890        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1635         |\n",
      "|    time_elapsed         | 8457         |\n",
      "|    total_timesteps      | 13393920     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019036683 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.363       |\n",
      "|    explained_variance   | 0.0376       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 19900        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 1.98e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13400000, episode_reward=612.00 +/- 58.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 612          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13400000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022540935 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.364       |\n",
      "|    explained_variance   | 0.0384       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 818          |\n",
      "|    n_updates            | 19910        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1636     |\n",
      "|    time_elapsed    | 8467     |\n",
      "|    total_timesteps | 13402112 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1637         |\n",
      "|    time_elapsed         | 8471         |\n",
      "|    total_timesteps      | 13410304     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021104936 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.363       |\n",
      "|    explained_variance   | 0.0191       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 762          |\n",
      "|    n_updates            | 19920        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1638        |\n",
      "|    time_elapsed         | 8475        |\n",
      "|    total_timesteps      | 13418496    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001738596 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.376      |\n",
      "|    explained_variance   | 0.0176      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 956         |\n",
      "|    n_updates            | 19930       |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    value_loss           | 1.76e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1639        |\n",
      "|    time_elapsed         | 8479        |\n",
      "|    total_timesteps      | 13426688    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002495492 |\n",
      "|    clip_fraction        | 0.019       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.367      |\n",
      "|    explained_variance   | 0.0347      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 773         |\n",
      "|    n_updates            | 19940       |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    value_loss           | 1.9e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1640         |\n",
      "|    time_elapsed         | 8483         |\n",
      "|    total_timesteps      | 13434880     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023023272 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.381       |\n",
      "|    explained_variance   | 0.0143       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 904          |\n",
      "|    n_updates            | 19950        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13440000, episode_reward=629.80 +/- 63.29\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 630          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13440000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017830334 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.365       |\n",
      "|    explained_variance   | 0.019        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 441          |\n",
      "|    n_updates            | 19960        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1641     |\n",
      "|    time_elapsed    | 8493     |\n",
      "|    total_timesteps | 13443072 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1642         |\n",
      "|    time_elapsed         | 8497         |\n",
      "|    total_timesteps      | 13451264     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017473653 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.375       |\n",
      "|    explained_variance   | 0.0365       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 754          |\n",
      "|    n_updates            | 19970        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1643         |\n",
      "|    time_elapsed         | 8501         |\n",
      "|    total_timesteps      | 13459456     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020085261 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.374       |\n",
      "|    explained_variance   | 0.0407       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 19980        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1644         |\n",
      "|    time_elapsed         | 8505         |\n",
      "|    total_timesteps      | 13467648     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019425962 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.365       |\n",
      "|    explained_variance   | 0.0503       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 696          |\n",
      "|    n_updates            | 19990        |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1645         |\n",
      "|    time_elapsed         | 8509         |\n",
      "|    total_timesteps      | 13475840     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018724187 |\n",
      "|    clip_fraction        | 0.00935      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.367       |\n",
      "|    explained_variance   | 0.0107       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 691          |\n",
      "|    n_updates            | 20000        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13480000, episode_reward=622.20 +/- 70.80\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 622          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13480000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022197324 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.359       |\n",
      "|    explained_variance   | 0.0421       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 943          |\n",
      "|    n_updates            | 20010        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1646     |\n",
      "|    time_elapsed    | 8519     |\n",
      "|    total_timesteps | 13484032 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1647         |\n",
      "|    time_elapsed         | 8523         |\n",
      "|    total_timesteps      | 13492224     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016740994 |\n",
      "|    clip_fraction        | 0.00828      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.361       |\n",
      "|    explained_variance   | 0.0244       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 942          |\n",
      "|    n_updates            | 20020        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1648        |\n",
      "|    time_elapsed         | 8527        |\n",
      "|    total_timesteps      | 13500416    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002031406 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.375      |\n",
      "|    explained_variance   | 0.0419      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 796         |\n",
      "|    n_updates            | 20030       |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1649         |\n",
      "|    time_elapsed         | 8531         |\n",
      "|    total_timesteps      | 13508608     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019546177 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.372       |\n",
      "|    explained_variance   | 0.0349       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.18e+03     |\n",
      "|    n_updates            | 20040        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1650         |\n",
      "|    time_elapsed         | 8535         |\n",
      "|    total_timesteps      | 13516800     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017289461 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.37        |\n",
      "|    explained_variance   | 0.0357       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 839          |\n",
      "|    n_updates            | 20050        |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13520000, episode_reward=620.60 +/- 55.58\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 621          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13520000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021429462 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.369       |\n",
      "|    explained_variance   | 0.0348       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 20060        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1651     |\n",
      "|    time_elapsed    | 8545     |\n",
      "|    total_timesteps | 13524992 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1652         |\n",
      "|    time_elapsed         | 8549         |\n",
      "|    total_timesteps      | 13533184     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023450085 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.382       |\n",
      "|    explained_variance   | 0.0258       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 812          |\n",
      "|    n_updates            | 20070        |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1653         |\n",
      "|    time_elapsed         | 8553         |\n",
      "|    total_timesteps      | 13541376     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020451425 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.374       |\n",
      "|    explained_variance   | 0.0226       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 706          |\n",
      "|    n_updates            | 20080        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1654        |\n",
      "|    time_elapsed         | 8557        |\n",
      "|    total_timesteps      | 13549568    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001588413 |\n",
      "|    clip_fraction        | 0.00627     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.378      |\n",
      "|    explained_variance   | -0.0108     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 599         |\n",
      "|    n_updates            | 20090       |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    value_loss           | 1.72e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1655         |\n",
      "|    time_elapsed         | 8562         |\n",
      "|    total_timesteps      | 13557760     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020212177 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.368       |\n",
      "|    explained_variance   | 0.0241       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 684          |\n",
      "|    n_updates            | 20100        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13560000, episode_reward=614.40 +/- 68.36\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 614         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 13560000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001967805 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.373      |\n",
      "|    explained_variance   | 0.0344      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 892         |\n",
      "|    n_updates            | 20110       |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    value_loss           | 1.85e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1656     |\n",
      "|    time_elapsed    | 8573     |\n",
      "|    total_timesteps | 13565952 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1657         |\n",
      "|    time_elapsed         | 8576         |\n",
      "|    total_timesteps      | 13574144     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017526592 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.383       |\n",
      "|    explained_variance   | 0.0307       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 728          |\n",
      "|    n_updates            | 20120        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1582       |\n",
      "|    iterations           | 1658       |\n",
      "|    time_elapsed         | 8580       |\n",
      "|    total_timesteps      | 13582336   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00189443 |\n",
      "|    clip_fraction        | 0.0128     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.381     |\n",
      "|    explained_variance   | 0.023      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 849        |\n",
      "|    n_updates            | 20130      |\n",
      "|    policy_gradient_loss | -0.00302   |\n",
      "|    value_loss           | 1.62e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1659        |\n",
      "|    time_elapsed         | 8584        |\n",
      "|    total_timesteps      | 13590528    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002109258 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.384      |\n",
      "|    explained_variance   | 0.0381      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 20140       |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    value_loss           | 1.74e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1660         |\n",
      "|    time_elapsed         | 8588         |\n",
      "|    total_timesteps      | 13598720     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024044001 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.376       |\n",
      "|    explained_variance   | 0.0344       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 862          |\n",
      "|    n_updates            | 20150        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13600000, episode_reward=618.20 +/- 46.03\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 618          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13600000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014558671 |\n",
      "|    clip_fraction        | 0.00994      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.375       |\n",
      "|    explained_variance   | 0.0366       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 920          |\n",
      "|    n_updates            | 20160        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1661     |\n",
      "|    time_elapsed    | 8598     |\n",
      "|    total_timesteps | 13606912 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1662         |\n",
      "|    time_elapsed         | 8602         |\n",
      "|    total_timesteps      | 13615104     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012827117 |\n",
      "|    clip_fraction        | 0.00599      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.376       |\n",
      "|    explained_variance   | 0.0389       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 975          |\n",
      "|    n_updates            | 20170        |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1663         |\n",
      "|    time_elapsed         | 8606         |\n",
      "|    total_timesteps      | 13623296     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016560201 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.38        |\n",
      "|    explained_variance   | 0.0177       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 832          |\n",
      "|    n_updates            | 20180        |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1664         |\n",
      "|    time_elapsed         | 8610         |\n",
      "|    total_timesteps      | 13631488     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025830101 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.378       |\n",
      "|    explained_variance   | 0.0104       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 830          |\n",
      "|    n_updates            | 20190        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1583       |\n",
      "|    iterations           | 1665       |\n",
      "|    time_elapsed         | 8613       |\n",
      "|    total_timesteps      | 13639680   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00222826 |\n",
      "|    clip_fraction        | 0.0134     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.366     |\n",
      "|    explained_variance   | 0.0456     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 888        |\n",
      "|    n_updates            | 20200      |\n",
      "|    policy_gradient_loss | -0.00319   |\n",
      "|    value_loss           | 1.72e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=13640000, episode_reward=625.20 +/- 56.12\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 625          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13640000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017530196 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.381       |\n",
      "|    explained_variance   | 0.0356       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 983          |\n",
      "|    n_updates            | 20210        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1666     |\n",
      "|    time_elapsed    | 8623     |\n",
      "|    total_timesteps | 13647872 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1667         |\n",
      "|    time_elapsed         | 8627         |\n",
      "|    total_timesteps      | 13656064     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021424945 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.376       |\n",
      "|    explained_variance   | 0.0249       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 973          |\n",
      "|    n_updates            | 20220        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1668         |\n",
      "|    time_elapsed         | 8631         |\n",
      "|    total_timesteps      | 13664256     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021395746 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.365       |\n",
      "|    explained_variance   | 0.0216       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.08e+03     |\n",
      "|    n_updates            | 20230        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1669         |\n",
      "|    time_elapsed         | 8635         |\n",
      "|    total_timesteps      | 13672448     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025647646 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.38        |\n",
      "|    explained_variance   | 0.0366       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 810          |\n",
      "|    n_updates            | 20240        |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13680000, episode_reward=625.80 +/- 67.38\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 626          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13680000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017458926 |\n",
      "|    clip_fraction        | 0.00933      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.367       |\n",
      "|    explained_variance   | 0.0732       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 918          |\n",
      "|    n_updates            | 20250        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1670     |\n",
      "|    time_elapsed    | 8644     |\n",
      "|    total_timesteps | 13680640 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1582        |\n",
      "|    iterations           | 1671        |\n",
      "|    time_elapsed         | 8648        |\n",
      "|    total_timesteps      | 13688832    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001906293 |\n",
      "|    clip_fraction        | 0.0106      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.376      |\n",
      "|    explained_variance   | 0.0949      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 808         |\n",
      "|    n_updates            | 20260       |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    value_loss           | 1.78e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1672         |\n",
      "|    time_elapsed         | 8652         |\n",
      "|    total_timesteps      | 13697024     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022077658 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.355       |\n",
      "|    explained_variance   | 0.0992       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 857          |\n",
      "|    n_updates            | 20270        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1673        |\n",
      "|    time_elapsed         | 8656        |\n",
      "|    total_timesteps      | 13705216    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002158152 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.365      |\n",
      "|    explained_variance   | 0.0165      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 697         |\n",
      "|    n_updates            | 20280       |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    value_loss           | 1.71e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1674         |\n",
      "|    time_elapsed         | 8660         |\n",
      "|    total_timesteps      | 13713408     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014993848 |\n",
      "|    clip_fraction        | 0.0087       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.367       |\n",
      "|    explained_variance   | 0.0237       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 20290        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13720000, episode_reward=627.00 +/- 52.81\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 627         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 13720000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002202183 |\n",
      "|    clip_fraction        | 0.0146      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.371      |\n",
      "|    explained_variance   | 0.0514      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 779         |\n",
      "|    n_updates            | 20300       |\n",
      "|    policy_gradient_loss | -0.00281    |\n",
      "|    value_loss           | 1.76e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1675     |\n",
      "|    time_elapsed    | 8670     |\n",
      "|    total_timesteps | 13721600 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1676         |\n",
      "|    time_elapsed         | 8674         |\n",
      "|    total_timesteps      | 13729792     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016745313 |\n",
      "|    clip_fraction        | 0.00695      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.375       |\n",
      "|    explained_variance   | 0.0345       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 20310        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    value_loss           | 1.93e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1677         |\n",
      "|    time_elapsed         | 8677         |\n",
      "|    total_timesteps      | 13737984     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020746794 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.379       |\n",
      "|    explained_variance   | 0.0337       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 978          |\n",
      "|    n_updates            | 20320        |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1583       |\n",
      "|    iterations           | 1678       |\n",
      "|    time_elapsed         | 8681       |\n",
      "|    total_timesteps      | 13746176   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00204885 |\n",
      "|    clip_fraction        | 0.0116     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.364     |\n",
      "|    explained_variance   | 0.027      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 703        |\n",
      "|    n_updates            | 20330      |\n",
      "|    policy_gradient_loss | -0.00277   |\n",
      "|    value_loss           | 1.75e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1679         |\n",
      "|    time_elapsed         | 8685         |\n",
      "|    total_timesteps      | 13754368     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017772357 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.368       |\n",
      "|    explained_variance   | 0.0226       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 923          |\n",
      "|    n_updates            | 20340        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13760000, episode_reward=636.40 +/- 68.08\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 636          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13760000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026897506 |\n",
      "|    clip_fraction        | 0.0279       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.366       |\n",
      "|    explained_variance   | 0.037        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 911          |\n",
      "|    n_updates            | 20350        |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1680     |\n",
      "|    time_elapsed    | 8695     |\n",
      "|    total_timesteps | 13762560 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1681         |\n",
      "|    time_elapsed         | 8699         |\n",
      "|    total_timesteps      | 13770752     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022257413 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.35        |\n",
      "|    explained_variance   | 0.0833       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 859          |\n",
      "|    n_updates            | 20360        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1682         |\n",
      "|    time_elapsed         | 8703         |\n",
      "|    total_timesteps      | 13778944     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021862069 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.374       |\n",
      "|    explained_variance   | 0.00598      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 863          |\n",
      "|    n_updates            | 20370        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1683         |\n",
      "|    time_elapsed         | 8707         |\n",
      "|    total_timesteps      | 13787136     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017593452 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.365       |\n",
      "|    explained_variance   | 0.0562       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 965          |\n",
      "|    n_updates            | 20380        |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1684         |\n",
      "|    time_elapsed         | 8710         |\n",
      "|    total_timesteps      | 13795328     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018450262 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.366       |\n",
      "|    explained_variance   | 0.0251       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 770          |\n",
      "|    n_updates            | 20390        |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13800000, episode_reward=638.40 +/- 56.23\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 638          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13800000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019070511 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.374       |\n",
      "|    explained_variance   | 0.047        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 709          |\n",
      "|    n_updates            | 20400        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1685     |\n",
      "|    time_elapsed    | 8721     |\n",
      "|    total_timesteps | 13803520 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1582        |\n",
      "|    iterations           | 1686        |\n",
      "|    time_elapsed         | 8725        |\n",
      "|    total_timesteps      | 13811712    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001790121 |\n",
      "|    clip_fraction        | 0.0121      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.382      |\n",
      "|    explained_variance   | 0.0318      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 20410       |\n",
      "|    policy_gradient_loss | -0.00243    |\n",
      "|    value_loss           | 1.86e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1687         |\n",
      "|    time_elapsed         | 8729         |\n",
      "|    total_timesteps      | 13819904     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018695571 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.396       |\n",
      "|    explained_variance   | 0.0289       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 904          |\n",
      "|    n_updates            | 20420        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1688         |\n",
      "|    time_elapsed         | 8733         |\n",
      "|    total_timesteps      | 13828096     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014616607 |\n",
      "|    clip_fraction        | 0.0059       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.384       |\n",
      "|    explained_variance   | 0.0273       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 878          |\n",
      "|    n_updates            | 20430        |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1689         |\n",
      "|    time_elapsed         | 8737         |\n",
      "|    total_timesteps      | 13836288     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018380752 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.378       |\n",
      "|    explained_variance   | 0.0254       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 786          |\n",
      "|    n_updates            | 20440        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13840000, episode_reward=616.60 +/- 66.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 617          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13840000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026641046 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.388       |\n",
      "|    explained_variance   | 0.045        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 755          |\n",
      "|    n_updates            | 20450        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1690     |\n",
      "|    time_elapsed    | 8748     |\n",
      "|    total_timesteps | 13844480 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1582        |\n",
      "|    iterations           | 1691        |\n",
      "|    time_elapsed         | 8752        |\n",
      "|    total_timesteps      | 13852672    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002283685 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.389      |\n",
      "|    explained_variance   | 0.0289      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 834         |\n",
      "|    n_updates            | 20460       |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    value_loss           | 1.75e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1692         |\n",
      "|    time_elapsed         | 8756         |\n",
      "|    total_timesteps      | 13860864     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015470214 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.38        |\n",
      "|    explained_variance   | 0.0672       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 20470        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1693         |\n",
      "|    time_elapsed         | 8760         |\n",
      "|    total_timesteps      | 13869056     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015682842 |\n",
      "|    clip_fraction        | 0.00879      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.376       |\n",
      "|    explained_variance   | 0.00767      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 20480        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    value_loss           | 2.01e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1694        |\n",
      "|    time_elapsed         | 8764        |\n",
      "|    total_timesteps      | 13877248    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002591938 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.386      |\n",
      "|    explained_variance   | 0.0474      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 639         |\n",
      "|    n_updates            | 20490       |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    value_loss           | 1.77e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=13880000, episode_reward=608.60 +/- 54.52\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 609          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13880000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023051738 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.371       |\n",
      "|    explained_variance   | 0.0338       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 875          |\n",
      "|    n_updates            | 20500        |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    value_loss           | 1.68e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1695     |\n",
      "|    time_elapsed    | 8774     |\n",
      "|    total_timesteps | 13885440 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1696         |\n",
      "|    time_elapsed         | 8778         |\n",
      "|    total_timesteps      | 13893632     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018661855 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.384       |\n",
      "|    explained_variance   | 0.0609       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 809          |\n",
      "|    n_updates            | 20510        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1697         |\n",
      "|    time_elapsed         | 8781         |\n",
      "|    total_timesteps      | 13901824     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020087946 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.381       |\n",
      "|    explained_variance   | 0.016        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 20520        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1698         |\n",
      "|    time_elapsed         | 8785         |\n",
      "|    total_timesteps      | 13910016     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022988985 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.373       |\n",
      "|    explained_variance   | 0.0442       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 858          |\n",
      "|    n_updates            | 20530        |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1699         |\n",
      "|    time_elapsed         | 8789         |\n",
      "|    total_timesteps      | 13918208     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020029396 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.372       |\n",
      "|    explained_variance   | 0.0256       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 734          |\n",
      "|    n_updates            | 20540        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13920000, episode_reward=615.60 +/- 60.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 616         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 13920000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002288891 |\n",
      "|    clip_fraction        | 0.0152      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.382      |\n",
      "|    explained_variance   | 0.0424      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 958         |\n",
      "|    n_updates            | 20550       |\n",
      "|    policy_gradient_loss | -0.00314    |\n",
      "|    value_loss           | 1.75e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1700     |\n",
      "|    time_elapsed    | 8800     |\n",
      "|    total_timesteps | 13926400 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1701         |\n",
      "|    time_elapsed         | 8804         |\n",
      "|    total_timesteps      | 13934592     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015998557 |\n",
      "|    clip_fraction        | 0.0075       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.364       |\n",
      "|    explained_variance   | -0.00203     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 867          |\n",
      "|    n_updates            | 20560        |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1702         |\n",
      "|    time_elapsed         | 8808         |\n",
      "|    total_timesteps      | 13942784     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015395143 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.367       |\n",
      "|    explained_variance   | 0.0201       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 750          |\n",
      "|    n_updates            | 20570        |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1703        |\n",
      "|    time_elapsed         | 8812        |\n",
      "|    total_timesteps      | 13950976    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002399969 |\n",
      "|    clip_fraction        | 0.0159      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.38       |\n",
      "|    explained_variance   | 0.0322      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 637         |\n",
      "|    n_updates            | 20580       |\n",
      "|    policy_gradient_loss | -0.00345    |\n",
      "|    value_loss           | 1.69e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1704        |\n",
      "|    time_elapsed         | 8816        |\n",
      "|    total_timesteps      | 13959168    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002261552 |\n",
      "|    clip_fraction        | 0.0114      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.377      |\n",
      "|    explained_variance   | 0.0281      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.05e+03    |\n",
      "|    n_updates            | 20590       |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=13960000, episode_reward=634.00 +/- 62.93\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 634          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13960000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015001883 |\n",
      "|    clip_fraction        | 0.00663      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.38        |\n",
      "|    explained_variance   | 0.0312       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 909          |\n",
      "|    n_updates            | 20600        |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1705     |\n",
      "|    time_elapsed    | 8826     |\n",
      "|    total_timesteps | 13967360 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1582        |\n",
      "|    iterations           | 1706        |\n",
      "|    time_elapsed         | 8830        |\n",
      "|    total_timesteps      | 13975552    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001815941 |\n",
      "|    clip_fraction        | 0.0114      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.375      |\n",
      "|    explained_variance   | 0.0466      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 933         |\n",
      "|    n_updates            | 20610       |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    value_loss           | 1.86e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1707         |\n",
      "|    time_elapsed         | 8833         |\n",
      "|    total_timesteps      | 13983744     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014566518 |\n",
      "|    clip_fraction        | 0.00868      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.375       |\n",
      "|    explained_variance   | 0.0112       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 948          |\n",
      "|    n_updates            | 20620        |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1708         |\n",
      "|    time_elapsed         | 8837         |\n",
      "|    total_timesteps      | 13991936     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023040264 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.37        |\n",
      "|    explained_variance   | 0.0442       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 814          |\n",
      "|    n_updates            | 20630        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14000000, episode_reward=632.40 +/- 62.40\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 632          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14000000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021051865 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.377       |\n",
      "|    explained_variance   | 0.0344       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 939          |\n",
      "|    n_updates            | 20640        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1709     |\n",
      "|    time_elapsed    | 8847     |\n",
      "|    total_timesteps | 14000128 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1710         |\n",
      "|    time_elapsed         | 8851         |\n",
      "|    total_timesteps      | 14008320     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024828392 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.387       |\n",
      "|    explained_variance   | 0.0223       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 904          |\n",
      "|    n_updates            | 20650        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1711         |\n",
      "|    time_elapsed         | 8855         |\n",
      "|    total_timesteps      | 14016512     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018596963 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.374       |\n",
      "|    explained_variance   | 0.0372       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 749          |\n",
      "|    n_updates            | 20660        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1712        |\n",
      "|    time_elapsed         | 8858        |\n",
      "|    total_timesteps      | 14024704    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002537426 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.382      |\n",
      "|    explained_variance   | 0.0548      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 814         |\n",
      "|    n_updates            | 20670       |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1713        |\n",
      "|    time_elapsed         | 8862        |\n",
      "|    total_timesteps      | 14032896    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001710706 |\n",
      "|    clip_fraction        | 0.00983     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.377      |\n",
      "|    explained_variance   | 0.0429      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 984         |\n",
      "|    n_updates            | 20680       |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    value_loss           | 1.73e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=14040000, episode_reward=651.80 +/- 62.31\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 652          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14040000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019028495 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.366       |\n",
      "|    explained_variance   | 0.0492       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 20690        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1714     |\n",
      "|    time_elapsed    | 8872     |\n",
      "|    total_timesteps | 14041088 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1582        |\n",
      "|    iterations           | 1715        |\n",
      "|    time_elapsed         | 8876        |\n",
      "|    total_timesteps      | 14049280    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002813429 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.372      |\n",
      "|    explained_variance   | 0.0581      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 788         |\n",
      "|    n_updates            | 20700       |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    value_loss           | 1.73e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1716         |\n",
      "|    time_elapsed         | 8880         |\n",
      "|    total_timesteps      | 14057472     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026246202 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.378       |\n",
      "|    explained_variance   | 0.0213       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 932          |\n",
      "|    n_updates            | 20710        |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1717         |\n",
      "|    time_elapsed         | 8884         |\n",
      "|    total_timesteps      | 14065664     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017949905 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.363       |\n",
      "|    explained_variance   | 0.031        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 955          |\n",
      "|    n_updates            | 20720        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1718        |\n",
      "|    time_elapsed         | 8888        |\n",
      "|    total_timesteps      | 14073856    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002090457 |\n",
      "|    clip_fraction        | 0.0126      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.386      |\n",
      "|    explained_variance   | -0.0067     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 689         |\n",
      "|    n_updates            | 20730       |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    value_loss           | 1.89e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=14080000, episode_reward=629.40 +/- 63.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 629          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14080000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021340463 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.378       |\n",
      "|    explained_variance   | 0.0173       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 20740        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1719     |\n",
      "|    time_elapsed    | 8898     |\n",
      "|    total_timesteps | 14082048 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1720         |\n",
      "|    time_elapsed         | 8902         |\n",
      "|    total_timesteps      | 14090240     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019991565 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.374       |\n",
      "|    explained_variance   | 0.013        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 800          |\n",
      "|    n_updates            | 20750        |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1582        |\n",
      "|    iterations           | 1721        |\n",
      "|    time_elapsed         | 8906        |\n",
      "|    total_timesteps      | 14098432    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001980651 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.385      |\n",
      "|    explained_variance   | 0.0259      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 814         |\n",
      "|    n_updates            | 20760       |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    value_loss           | 1.72e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1722         |\n",
      "|    time_elapsed         | 8910         |\n",
      "|    total_timesteps      | 14106624     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019698432 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.383       |\n",
      "|    explained_variance   | 0.0131       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 970          |\n",
      "|    n_updates            | 20770        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1723         |\n",
      "|    time_elapsed         | 8914         |\n",
      "|    total_timesteps      | 14114816     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022272319 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.39        |\n",
      "|    explained_variance   | 0.0217       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 892          |\n",
      "|    n_updates            | 20780        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14120000, episode_reward=635.40 +/- 59.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 635          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14120000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022235508 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.393       |\n",
      "|    explained_variance   | 0.0195       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 853          |\n",
      "|    n_updates            | 20790        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1724     |\n",
      "|    time_elapsed    | 8924     |\n",
      "|    total_timesteps | 14123008 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1725         |\n",
      "|    time_elapsed         | 8929         |\n",
      "|    total_timesteps      | 14131200     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022191643 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.394       |\n",
      "|    explained_variance   | 0.0397       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.25e+03     |\n",
      "|    n_updates            | 20800        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1582        |\n",
      "|    iterations           | 1726        |\n",
      "|    time_elapsed         | 8932        |\n",
      "|    total_timesteps      | 14139392    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002291502 |\n",
      "|    clip_fraction        | 0.016       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.389      |\n",
      "|    explained_variance   | 0.0223      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.2e+03     |\n",
      "|    n_updates            | 20810       |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    value_loss           | 1.98e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1727         |\n",
      "|    time_elapsed         | 8936         |\n",
      "|    total_timesteps      | 14147584     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015744452 |\n",
      "|    clip_fraction        | 0.00995      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.392       |\n",
      "|    explained_variance   | 0.0267       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 833          |\n",
      "|    n_updates            | 20820        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1728         |\n",
      "|    time_elapsed         | 8940         |\n",
      "|    total_timesteps      | 14155776     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020823998 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.395       |\n",
      "|    explained_variance   | 0.0203       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 704          |\n",
      "|    n_updates            | 20830        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14160000, episode_reward=620.00 +/- 105.01\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 620          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14160000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026836782 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.386       |\n",
      "|    explained_variance   | 0.0253       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 951          |\n",
      "|    n_updates            | 20840        |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1729     |\n",
      "|    time_elapsed    | 8951     |\n",
      "|    total_timesteps | 14163968 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1730         |\n",
      "|    time_elapsed         | 8954         |\n",
      "|    total_timesteps      | 14172160     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021545924 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.399       |\n",
      "|    explained_variance   | 0.0428       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 871          |\n",
      "|    n_updates            | 20850        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1731         |\n",
      "|    time_elapsed         | 8958         |\n",
      "|    total_timesteps      | 14180352     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018829771 |\n",
      "|    clip_fraction        | 0.00997      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.401       |\n",
      "|    explained_variance   | 0.0187       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 20860        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    value_loss           | 2.02e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1732         |\n",
      "|    time_elapsed         | 8962         |\n",
      "|    total_timesteps      | 14188544     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020987946 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.395       |\n",
      "|    explained_variance   | 0.0275       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 689          |\n",
      "|    n_updates            | 20870        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1733         |\n",
      "|    time_elapsed         | 8966         |\n",
      "|    total_timesteps      | 14196736     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025172215 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.411       |\n",
      "|    explained_variance   | 0.03         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1e+03        |\n",
      "|    n_updates            | 20880        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14200000, episode_reward=622.80 +/- 73.43\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 200        |\n",
      "|    mean_reward          | 623        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 14200000   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00219227 |\n",
      "|    clip_fraction        | 0.0152     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.396     |\n",
      "|    explained_variance   | 0.0217     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 869        |\n",
      "|    n_updates            | 20890      |\n",
      "|    policy_gradient_loss | -0.00341   |\n",
      "|    value_loss           | 1.83e+03   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1734     |\n",
      "|    time_elapsed    | 8976     |\n",
      "|    total_timesteps | 14204928 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1735         |\n",
      "|    time_elapsed         | 8980         |\n",
      "|    total_timesteps      | 14213120     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026708134 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.4         |\n",
      "|    explained_variance   | 0.0299       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.32e+03     |\n",
      "|    n_updates            | 20900        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1736         |\n",
      "|    time_elapsed         | 8984         |\n",
      "|    total_timesteps      | 14221312     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020527728 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.404       |\n",
      "|    explained_variance   | 0.0545       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 554          |\n",
      "|    n_updates            | 20910        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    value_loss           | 1.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1737         |\n",
      "|    time_elapsed         | 8988         |\n",
      "|    total_timesteps      | 14229504     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017393618 |\n",
      "|    clip_fraction        | 0.0085       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.398       |\n",
      "|    explained_variance   | 0.0359       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 20920        |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1583        |\n",
      "|    iterations           | 1738        |\n",
      "|    time_elapsed         | 8992        |\n",
      "|    total_timesteps      | 14237696    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002339853 |\n",
      "|    clip_fraction        | 0.0184      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.417      |\n",
      "|    explained_variance   | 0.00733     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 772         |\n",
      "|    n_updates            | 20930       |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=14240000, episode_reward=637.40 +/- 54.73\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 637          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14240000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017697759 |\n",
      "|    clip_fraction        | 0.00842      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.409       |\n",
      "|    explained_variance   | 0.0245       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 975          |\n",
      "|    n_updates            | 20940        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1739     |\n",
      "|    time_elapsed    | 9002     |\n",
      "|    total_timesteps | 14245888 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1740         |\n",
      "|    time_elapsed         | 9006         |\n",
      "|    total_timesteps      | 14254080     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018533011 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.419       |\n",
      "|    explained_variance   | 0.0396       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 820          |\n",
      "|    n_updates            | 20950        |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1741         |\n",
      "|    time_elapsed         | 9010         |\n",
      "|    total_timesteps      | 14262272     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018899811 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.398       |\n",
      "|    explained_variance   | 0.046        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 789          |\n",
      "|    n_updates            | 20960        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1742         |\n",
      "|    time_elapsed         | 9014         |\n",
      "|    total_timesteps      | 14270464     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024101208 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.4         |\n",
      "|    explained_variance   | 0.0453       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 648          |\n",
      "|    n_updates            | 20970        |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1743         |\n",
      "|    time_elapsed         | 9018         |\n",
      "|    total_timesteps      | 14278656     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021184944 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.396       |\n",
      "|    explained_variance   | 0.0363       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 20980        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    value_loss           | 1.98e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14280000, episode_reward=619.20 +/- 65.60\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 619          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14280000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019774453 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.411       |\n",
      "|    explained_variance   | 0.0356       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 745          |\n",
      "|    n_updates            | 20990        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1744     |\n",
      "|    time_elapsed    | 9028     |\n",
      "|    total_timesteps | 14286848 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1745         |\n",
      "|    time_elapsed         | 9032         |\n",
      "|    total_timesteps      | 14295040     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023563649 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.399       |\n",
      "|    explained_variance   | 0.0539       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 21000        |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1746         |\n",
      "|    time_elapsed         | 9036         |\n",
      "|    total_timesteps      | 14303232     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015486212 |\n",
      "|    clip_fraction        | 0.00896      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.388       |\n",
      "|    explained_variance   | 0.00477      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 716          |\n",
      "|    n_updates            | 21010        |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1747         |\n",
      "|    time_elapsed         | 9040         |\n",
      "|    total_timesteps      | 14311424     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024563961 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.383       |\n",
      "|    explained_variance   | 0.0293       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 863          |\n",
      "|    n_updates            | 21020        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    value_loss           | 1.94e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1748         |\n",
      "|    time_elapsed         | 9044         |\n",
      "|    total_timesteps      | 14319616     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021423902 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.393       |\n",
      "|    explained_variance   | 0.0509       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 907          |\n",
      "|    n_updates            | 21030        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14320000, episode_reward=628.60 +/- 52.65\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 629          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14320000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021341126 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.384       |\n",
      "|    explained_variance   | 0.036        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 984          |\n",
      "|    n_updates            | 21040        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1749     |\n",
      "|    time_elapsed    | 9054     |\n",
      "|    total_timesteps | 14327808 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1750         |\n",
      "|    time_elapsed         | 9058         |\n",
      "|    total_timesteps      | 14336000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019335486 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.382       |\n",
      "|    explained_variance   | 0.0257       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 910          |\n",
      "|    n_updates            | 21050        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1751         |\n",
      "|    time_elapsed         | 9062         |\n",
      "|    total_timesteps      | 14344192     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019618927 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.394       |\n",
      "|    explained_variance   | 0.0104       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 21060        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1752         |\n",
      "|    time_elapsed         | 9066         |\n",
      "|    total_timesteps      | 14352384     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018191084 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.381       |\n",
      "|    explained_variance   | 0.0286       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 954          |\n",
      "|    n_updates            | 21070        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14360000, episode_reward=658.80 +/- 46.46\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 659          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14360000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016885109 |\n",
      "|    clip_fraction        | 0.00868      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.389       |\n",
      "|    explained_variance   | 0.0293       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 975          |\n",
      "|    n_updates            | 21080        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1753     |\n",
      "|    time_elapsed    | 9076     |\n",
      "|    total_timesteps | 14360576 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1754         |\n",
      "|    time_elapsed         | 9080         |\n",
      "|    total_timesteps      | 14368768     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014630586 |\n",
      "|    clip_fraction        | 0.0067       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.393       |\n",
      "|    explained_variance   | 0.0292       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 719          |\n",
      "|    n_updates            | 21090        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1582        |\n",
      "|    iterations           | 1755        |\n",
      "|    time_elapsed         | 9084        |\n",
      "|    total_timesteps      | 14376960    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001910357 |\n",
      "|    clip_fraction        | 0.0143      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.392      |\n",
      "|    explained_variance   | 0.0211      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 21100       |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    value_loss           | 1.77e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1756         |\n",
      "|    time_elapsed         | 9088         |\n",
      "|    total_timesteps      | 14385152     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022956892 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.38        |\n",
      "|    explained_variance   | 0.0245       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 769          |\n",
      "|    n_updates            | 21110        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1757         |\n",
      "|    time_elapsed         | 9092         |\n",
      "|    total_timesteps      | 14393344     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026310235 |\n",
      "|    clip_fraction        | 0.0237       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.381       |\n",
      "|    explained_variance   | 0.0275       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 896          |\n",
      "|    n_updates            | 21120        |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14400000, episode_reward=640.00 +/- 58.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 640          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14400000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019369648 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.397       |\n",
      "|    explained_variance   | 0.0283       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 705          |\n",
      "|    n_updates            | 21130        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1758     |\n",
      "|    time_elapsed    | 9101     |\n",
      "|    total_timesteps | 14401536 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1759         |\n",
      "|    time_elapsed         | 9105         |\n",
      "|    total_timesteps      | 14409728     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020558923 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.389       |\n",
      "|    explained_variance   | 0.0433       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 835          |\n",
      "|    n_updates            | 21140        |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1760         |\n",
      "|    time_elapsed         | 9109         |\n",
      "|    total_timesteps      | 14417920     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015987316 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.392       |\n",
      "|    explained_variance   | 0.0289       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 21150        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1761         |\n",
      "|    time_elapsed         | 9112         |\n",
      "|    total_timesteps      | 14426112     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023697098 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.393       |\n",
      "|    explained_variance   | 0.0581       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 783          |\n",
      "|    n_updates            | 21160        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1762         |\n",
      "|    time_elapsed         | 9116         |\n",
      "|    total_timesteps      | 14434304     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020903954 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.392       |\n",
      "|    explained_variance   | 0.0558       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 906          |\n",
      "|    n_updates            | 21170        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14440000, episode_reward=641.80 +/- 65.90\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 642          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14440000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025715996 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.391       |\n",
      "|    explained_variance   | -0.00704     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 651          |\n",
      "|    n_updates            | 21180        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1763     |\n",
      "|    time_elapsed    | 9127     |\n",
      "|    total_timesteps | 14442496 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1764         |\n",
      "|    time_elapsed         | 9130         |\n",
      "|    total_timesteps      | 14450688     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020447401 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.383       |\n",
      "|    explained_variance   | 0.0187       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 869          |\n",
      "|    n_updates            | 21190        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    value_loss           | 1.98e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1765         |\n",
      "|    time_elapsed         | 9134         |\n",
      "|    total_timesteps      | 14458880     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024612788 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.0365       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.08e+03     |\n",
      "|    n_updates            | 21200        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1766         |\n",
      "|    time_elapsed         | 9138         |\n",
      "|    total_timesteps      | 14467072     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020359522 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | -0.0127      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 598          |\n",
      "|    n_updates            | 21210        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1767         |\n",
      "|    time_elapsed         | 9142         |\n",
      "|    total_timesteps      | 14475264     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018970292 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.393       |\n",
      "|    explained_variance   | 0.0314       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 986          |\n",
      "|    n_updates            | 21220        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14480000, episode_reward=632.40 +/- 52.52\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 632          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14480000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023108248 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.0424       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.08e+03     |\n",
      "|    n_updates            | 21230        |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    value_loss           | 1.97e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1768     |\n",
      "|    time_elapsed    | 9152     |\n",
      "|    total_timesteps | 14483456 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1769         |\n",
      "|    time_elapsed         | 9156         |\n",
      "|    total_timesteps      | 14491648     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014955569 |\n",
      "|    clip_fraction        | 0.00745      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.408       |\n",
      "|    explained_variance   | 0.0155       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 852          |\n",
      "|    n_updates            | 21240        |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1770         |\n",
      "|    time_elapsed         | 9160         |\n",
      "|    total_timesteps      | 14499840     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020418137 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.397       |\n",
      "|    explained_variance   | 0.0309       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 771          |\n",
      "|    n_updates            | 21250        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1771         |\n",
      "|    time_elapsed         | 9164         |\n",
      "|    total_timesteps      | 14508032     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032533212 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.398       |\n",
      "|    explained_variance   | 0.0203       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 678          |\n",
      "|    n_updates            | 21260        |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1772         |\n",
      "|    time_elapsed         | 9168         |\n",
      "|    total_timesteps      | 14516224     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020717054 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.412       |\n",
      "|    explained_variance   | 0.0219       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 21270        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    value_loss           | 1.93e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14520000, episode_reward=623.80 +/- 55.24\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 624          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14520000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024397613 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.0194       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 21280        |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    value_loss           | 1.7e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1773     |\n",
      "|    time_elapsed    | 9178     |\n",
      "|    total_timesteps | 14524416 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1774         |\n",
      "|    time_elapsed         | 9182         |\n",
      "|    total_timesteps      | 14532608     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021698063 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.0414       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 746          |\n",
      "|    n_updates            | 21290        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1775         |\n",
      "|    time_elapsed         | 9186         |\n",
      "|    total_timesteps      | 14540800     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022727153 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.0356       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 887          |\n",
      "|    n_updates            | 21300        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1776         |\n",
      "|    time_elapsed         | 9190         |\n",
      "|    total_timesteps      | 14548992     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026163578 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.416       |\n",
      "|    explained_variance   | 0.0269       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 21310        |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1777         |\n",
      "|    time_elapsed         | 9194         |\n",
      "|    total_timesteps      | 14557184     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016688445 |\n",
      "|    clip_fraction        | 0.00918      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.406       |\n",
      "|    explained_variance   | 0.0335       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 882          |\n",
      "|    n_updates            | 21320        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14560000, episode_reward=636.20 +/- 69.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 636          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14560000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020205532 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.408       |\n",
      "|    explained_variance   | 0.0378       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 541          |\n",
      "|    n_updates            | 21330        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    value_loss           | 1.67e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1778     |\n",
      "|    time_elapsed    | 9204     |\n",
      "|    total_timesteps | 14565376 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1582        |\n",
      "|    iterations           | 1779        |\n",
      "|    time_elapsed         | 9208        |\n",
      "|    total_timesteps      | 14573568    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001814107 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.408      |\n",
      "|    explained_variance   | 0.0478      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 849         |\n",
      "|    n_updates            | 21340       |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    value_loss           | 1.71e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1780         |\n",
      "|    time_elapsed         | 9212         |\n",
      "|    total_timesteps      | 14581760     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027352287 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.412       |\n",
      "|    explained_variance   | 0.0296       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 962          |\n",
      "|    n_updates            | 21350        |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1781         |\n",
      "|    time_elapsed         | 9216         |\n",
      "|    total_timesteps      | 14589952     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026407838 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.398       |\n",
      "|    explained_variance   | 0.0298       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 985          |\n",
      "|    n_updates            | 21360        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    value_loss           | 1.97e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1583         |\n",
      "|    iterations           | 1782         |\n",
      "|    time_elapsed         | 9220         |\n",
      "|    total_timesteps      | 14598144     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028274301 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.4         |\n",
      "|    explained_variance   | 0.0138       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 679          |\n",
      "|    n_updates            | 21370        |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14600000, episode_reward=638.80 +/- 56.06\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 639          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14600000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016777224 |\n",
      "|    clip_fraction        | 0.00697      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.406       |\n",
      "|    explained_variance   | 0.00617      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 512          |\n",
      "|    n_updates            | 21380        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    value_loss           | 1.74e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1582     |\n",
      "|    iterations      | 1783     |\n",
      "|    time_elapsed    | 9230     |\n",
      "|    total_timesteps | 14606336 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1784         |\n",
      "|    time_elapsed         | 9234         |\n",
      "|    total_timesteps      | 14614528     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019966566 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.399       |\n",
      "|    explained_variance   | 0.0593       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 978          |\n",
      "|    n_updates            | 21390        |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1785         |\n",
      "|    time_elapsed         | 9238         |\n",
      "|    total_timesteps      | 14622720     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023251506 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.403       |\n",
      "|    explained_variance   | 0.0499       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 768          |\n",
      "|    n_updates            | 21400        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    value_loss           | 1.91e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1582        |\n",
      "|    iterations           | 1786        |\n",
      "|    time_elapsed         | 9242        |\n",
      "|    total_timesteps      | 14630912    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002014859 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.404      |\n",
      "|    explained_variance   | 0.0444      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 822         |\n",
      "|    n_updates            | 21410       |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    value_loss           | 1.73e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1787         |\n",
      "|    time_elapsed         | 9248         |\n",
      "|    total_timesteps      | 14639104     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025764606 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.404       |\n",
      "|    explained_variance   | 0.057        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 21420        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14640000, episode_reward=635.40 +/- 53.19\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 635          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14640000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024828247 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.404       |\n",
      "|    explained_variance   | 0.0624       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 684          |\n",
      "|    n_updates            | 21430        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1581     |\n",
      "|    iterations      | 1788     |\n",
      "|    time_elapsed    | 9259     |\n",
      "|    total_timesteps | 14647296 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1789         |\n",
      "|    time_elapsed         | 9263         |\n",
      "|    total_timesteps      | 14655488     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018459543 |\n",
      "|    clip_fraction        | 0.00925      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.42        |\n",
      "|    explained_variance   | -0.00669     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 21440        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1790         |\n",
      "|    time_elapsed         | 9267         |\n",
      "|    total_timesteps      | 14663680     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025588865 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.414       |\n",
      "|    explained_variance   | 0.0467       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 845          |\n",
      "|    n_updates            | 21450        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1791         |\n",
      "|    time_elapsed         | 9271         |\n",
      "|    total_timesteps      | 14671872     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026861392 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.411       |\n",
      "|    explained_variance   | 0.0125       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 21460        |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14680000, episode_reward=633.60 +/- 62.25\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 634          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14680000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020221197 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.0204       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 878          |\n",
      "|    n_updates            | 21470        |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1581     |\n",
      "|    iterations      | 1792     |\n",
      "|    time_elapsed    | 9282     |\n",
      "|    total_timesteps | 14680064 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1793         |\n",
      "|    time_elapsed         | 9286         |\n",
      "|    total_timesteps      | 14688256     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017342825 |\n",
      "|    clip_fraction        | 0.00886      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.427       |\n",
      "|    explained_variance   | 0.0254       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 21480        |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    value_loss           | 1.96e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1581        |\n",
      "|    iterations           | 1794        |\n",
      "|    time_elapsed         | 9290        |\n",
      "|    total_timesteps      | 14696448    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002194555 |\n",
      "|    clip_fraction        | 0.0151      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.428      |\n",
      "|    explained_variance   | 0.0406      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 749         |\n",
      "|    n_updates            | 21490       |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    value_loss           | 1.84e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1582        |\n",
      "|    iterations           | 1795        |\n",
      "|    time_elapsed         | 9294        |\n",
      "|    total_timesteps      | 14704640    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002204177 |\n",
      "|    clip_fraction        | 0.0144      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.415      |\n",
      "|    explained_variance   | 0.0449      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 685         |\n",
      "|    n_updates            | 21500       |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    value_loss           | 1.75e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1796         |\n",
      "|    time_elapsed         | 9298         |\n",
      "|    total_timesteps      | 14712832     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022304992 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.421       |\n",
      "|    explained_variance   | 0.0145       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 948          |\n",
      "|    n_updates            | 21510        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14720000, episode_reward=651.00 +/- 68.56\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 651          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14720000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027328895 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.42        |\n",
      "|    explained_variance   | 0.0268       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 918          |\n",
      "|    n_updates            | 21520        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1581     |\n",
      "|    iterations      | 1797     |\n",
      "|    time_elapsed    | 9308     |\n",
      "|    total_timesteps | 14721024 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1798         |\n",
      "|    time_elapsed         | 9312         |\n",
      "|    total_timesteps      | 14729216     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020414463 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.42        |\n",
      "|    explained_variance   | 0.04         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.47e+03     |\n",
      "|    n_updates            | 21530        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1799         |\n",
      "|    time_elapsed         | 9316         |\n",
      "|    total_timesteps      | 14737408     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022970703 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.416       |\n",
      "|    explained_variance   | 0.0204       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.19e+03     |\n",
      "|    n_updates            | 21540        |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1582        |\n",
      "|    iterations           | 1800        |\n",
      "|    time_elapsed         | 9320        |\n",
      "|    total_timesteps      | 14745600    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002511845 |\n",
      "|    clip_fraction        | 0.0177      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.418      |\n",
      "|    explained_variance   | 0.0282      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 874         |\n",
      "|    n_updates            | 21550       |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    value_loss           | 1.75e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1801         |\n",
      "|    time_elapsed         | 9324         |\n",
      "|    total_timesteps      | 14753792     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025276204 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.422       |\n",
      "|    explained_variance   | 0.0406       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.08e+03     |\n",
      "|    n_updates            | 21560        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    value_loss           | 2.02e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14760000, episode_reward=641.40 +/- 54.26\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 641          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14760000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024285642 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.0403       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 899          |\n",
      "|    n_updates            | 21570        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1581     |\n",
      "|    iterations      | 1802     |\n",
      "|    time_elapsed    | 9334     |\n",
      "|    total_timesteps | 14761984 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1803         |\n",
      "|    time_elapsed         | 9338         |\n",
      "|    total_timesteps      | 14770176     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026741843 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.0479       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 884          |\n",
      "|    n_updates            | 21580        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1804         |\n",
      "|    time_elapsed         | 9342         |\n",
      "|    total_timesteps      | 14778368     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024053457 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.415       |\n",
      "|    explained_variance   | 0.0304       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 775          |\n",
      "|    n_updates            | 21590        |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1805         |\n",
      "|    time_elapsed         | 9346         |\n",
      "|    total_timesteps      | 14786560     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022435996 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.0334       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 21600        |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    value_loss           | 1.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1806         |\n",
      "|    time_elapsed         | 9350         |\n",
      "|    total_timesteps      | 14794752     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020522885 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.0512       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 963          |\n",
      "|    n_updates            | 21610        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    value_loss           | 1.94e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14800000, episode_reward=634.40 +/- 70.15\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 634         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 14800000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002166897 |\n",
      "|    clip_fraction        | 0.0151      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.412      |\n",
      "|    explained_variance   | 0.00986     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 21620       |\n",
      "|    policy_gradient_loss | -0.0036     |\n",
      "|    value_loss           | 1.81e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1581     |\n",
      "|    iterations      | 1807     |\n",
      "|    time_elapsed    | 9360     |\n",
      "|    total_timesteps | 14802944 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1581        |\n",
      "|    iterations           | 1808        |\n",
      "|    time_elapsed         | 9364        |\n",
      "|    total_timesteps      | 14811136    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002492503 |\n",
      "|    clip_fraction        | 0.02        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.417      |\n",
      "|    explained_variance   | 0.0348      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.12e+03    |\n",
      "|    n_updates            | 21630       |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    value_loss           | 1.87e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1809         |\n",
      "|    time_elapsed         | 9368         |\n",
      "|    total_timesteps      | 14819328     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020168808 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.422       |\n",
      "|    explained_variance   | 0.0438       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 709          |\n",
      "|    n_updates            | 21640        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1581        |\n",
      "|    iterations           | 1810        |\n",
      "|    time_elapsed         | 9372        |\n",
      "|    total_timesteps      | 14827520    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002440358 |\n",
      "|    clip_fraction        | 0.0165      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.418      |\n",
      "|    explained_variance   | 0.0839      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 743         |\n",
      "|    n_updates            | 21650       |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    value_loss           | 1.84e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1582         |\n",
      "|    iterations           | 1811         |\n",
      "|    time_elapsed         | 9376         |\n",
      "|    total_timesteps      | 14835712     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022793738 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.42        |\n",
      "|    explained_variance   | 0.0516       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 497          |\n",
      "|    n_updates            | 21660        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    value_loss           | 1.71e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14840000, episode_reward=636.60 +/- 56.41\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 637          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14840000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029807272 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.427       |\n",
      "|    explained_variance   | 0.0266       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 957          |\n",
      "|    n_updates            | 21670        |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1581     |\n",
      "|    iterations      | 1812     |\n",
      "|    time_elapsed    | 9386     |\n",
      "|    total_timesteps | 14843904 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1581        |\n",
      "|    iterations           | 1813        |\n",
      "|    time_elapsed         | 9391        |\n",
      "|    total_timesteps      | 14852096    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002417008 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.421      |\n",
      "|    explained_variance   | 0.0437      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 733         |\n",
      "|    n_updates            | 21680       |\n",
      "|    policy_gradient_loss | -0.00378    |\n",
      "|    value_loss           | 1.76e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 1581       |\n",
      "|    iterations           | 1814       |\n",
      "|    time_elapsed         | 9395       |\n",
      "|    total_timesteps      | 14860288   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00193768 |\n",
      "|    clip_fraction        | 0.00995    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.42      |\n",
      "|    explained_variance   | 0.0326     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.03e+03   |\n",
      "|    n_updates            | 21690      |\n",
      "|    policy_gradient_loss | -0.00296   |\n",
      "|    value_loss           | 1.92e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1581        |\n",
      "|    iterations           | 1815        |\n",
      "|    time_elapsed         | 9400        |\n",
      "|    total_timesteps      | 14868480    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002067406 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.428      |\n",
      "|    explained_variance   | 0.0454      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 641         |\n",
      "|    n_updates            | 21700       |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    value_loss           | 1.78e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1581         |\n",
      "|    iterations           | 1816         |\n",
      "|    time_elapsed         | 9405         |\n",
      "|    total_timesteps      | 14876672     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024061012 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.431       |\n",
      "|    explained_variance   | 0.0426       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 715          |\n",
      "|    n_updates            | 21710        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14880000, episode_reward=645.60 +/- 61.75\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 646          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14880000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020149874 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.433       |\n",
      "|    explained_variance   | 0.0459       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 695          |\n",
      "|    n_updates            | 21720        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1580     |\n",
      "|    iterations      | 1817     |\n",
      "|    time_elapsed    | 9417     |\n",
      "|    total_timesteps | 14884864 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1818         |\n",
      "|    time_elapsed         | 9428         |\n",
      "|    total_timesteps      | 14893056     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023015763 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.424       |\n",
      "|    explained_variance   | -0.00514     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1e+03        |\n",
      "|    n_updates            | 21730        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    value_loss           | 1.97e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1819         |\n",
      "|    time_elapsed         | 9432         |\n",
      "|    total_timesteps      | 14901248     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018568605 |\n",
      "|    clip_fraction        | 0.00834      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.421       |\n",
      "|    explained_variance   | 0.0317       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 674          |\n",
      "|    n_updates            | 21740        |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1820         |\n",
      "|    time_elapsed         | 9437         |\n",
      "|    total_timesteps      | 14909440     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019223462 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.414       |\n",
      "|    explained_variance   | 0.00937      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 911          |\n",
      "|    n_updates            | 21750        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    value_loss           | 1.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1821         |\n",
      "|    time_elapsed         | 9441         |\n",
      "|    total_timesteps      | 14917632     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017758533 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.42        |\n",
      "|    explained_variance   | 0.0292       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 910          |\n",
      "|    n_updates            | 21760        |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14920000, episode_reward=639.00 +/- 58.35\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 639          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14920000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018424751 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.416       |\n",
      "|    explained_variance   | 0.028        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 749          |\n",
      "|    n_updates            | 21770        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1578     |\n",
      "|    iterations      | 1822     |\n",
      "|    time_elapsed    | 9452     |\n",
      "|    total_timesteps | 14925824 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1823         |\n",
      "|    time_elapsed         | 9457         |\n",
      "|    total_timesteps      | 14934016     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026227224 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.425       |\n",
      "|    explained_variance   | 0.025        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 679          |\n",
      "|    n_updates            | 21780        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1824         |\n",
      "|    time_elapsed         | 9462         |\n",
      "|    total_timesteps      | 14942208     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019447051 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.419       |\n",
      "|    explained_variance   | 0.0371       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 695          |\n",
      "|    n_updates            | 21790        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1579        |\n",
      "|    iterations           | 1825        |\n",
      "|    time_elapsed         | 9466        |\n",
      "|    total_timesteps      | 14950400    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002049676 |\n",
      "|    clip_fraction        | 0.0146      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.421      |\n",
      "|    explained_variance   | 0.0438      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 737         |\n",
      "|    n_updates            | 21800       |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    value_loss           | 1.74e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1826         |\n",
      "|    time_elapsed         | 9470         |\n",
      "|    total_timesteps      | 14958592     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025652696 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.427       |\n",
      "|    explained_variance   | 0.0271       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 800          |\n",
      "|    n_updates            | 21810        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    value_loss           | 1.92e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14960000, episode_reward=627.40 +/- 51.99\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 627          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14960000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031082362 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.419       |\n",
      "|    explained_variance   | 0.0117       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 751          |\n",
      "|    n_updates            | 21820        |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1578     |\n",
      "|    iterations      | 1827     |\n",
      "|    time_elapsed    | 9480     |\n",
      "|    total_timesteps | 14966784 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 1828         |\n",
      "|    time_elapsed         | 9484         |\n",
      "|    total_timesteps      | 14974976     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026598377 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.431       |\n",
      "|    explained_variance   | 0.0271       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 669          |\n",
      "|    n_updates            | 21830        |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1829         |\n",
      "|    time_elapsed         | 9488         |\n",
      "|    total_timesteps      | 14983168     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021732026 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.43        |\n",
      "|    explained_variance   | 0.0428       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 21840        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1830         |\n",
      "|    time_elapsed         | 9493         |\n",
      "|    total_timesteps      | 14991360     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021232334 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.425       |\n",
      "|    explained_variance   | 0.0674       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 904          |\n",
      "|    n_updates            | 21850        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    value_loss           | 1.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1579         |\n",
      "|    iterations           | 1831         |\n",
      "|    time_elapsed         | 9497         |\n",
      "|    total_timesteps      | 14999552     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018201567 |\n",
      "|    clip_fraction        | 0.00925      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.414       |\n",
      "|    explained_variance   | 0.0887       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 890          |\n",
      "|    n_updates            | 21860        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15000000, episode_reward=651.20 +/- 45.19\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 651          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 15000000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025608256 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.418       |\n",
      "|    explained_variance   | 0.0561       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 890          |\n",
      "|    n_updates            | 21870        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1578     |\n",
      "|    iterations      | 1832     |\n",
      "|    time_elapsed    | 9509     |\n",
      "|    total_timesteps | 15007744 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1578         |\n",
      "|    iterations           | 1833         |\n",
      "|    time_elapsed         | 9513         |\n",
      "|    total_timesteps      | 15015936     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.038601e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.414       |\n",
      "|    explained_variance   | -0.00925     |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 697          |\n",
      "|    n_updates            | 21880        |\n",
      "|    policy_gradient_loss | -0.000412    |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1578          |\n",
      "|    iterations           | 1834          |\n",
      "|    time_elapsed         | 9517          |\n",
      "|    total_timesteps      | 15024128      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013320675 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.424        |\n",
      "|    explained_variance   | 0.0361        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 784           |\n",
      "|    n_updates            | 21890         |\n",
      "|    policy_gradient_loss | -0.000572     |\n",
      "|    value_loss           | 1.93e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1578          |\n",
      "|    iterations           | 1835          |\n",
      "|    time_elapsed         | 9521          |\n",
      "|    total_timesteps      | 15032320      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019383623 |\n",
      "|    clip_fraction        | 7.32e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.418        |\n",
      "|    explained_variance   | 0.0148        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.28e+03      |\n",
      "|    n_updates            | 21900         |\n",
      "|    policy_gradient_loss | -0.000526     |\n",
      "|    value_loss           | 2.02e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=15040000, episode_reward=642.00 +/- 48.66\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 642           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15040000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028275372 |\n",
      "|    clip_fraction        | 0.000171      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.431        |\n",
      "|    explained_variance   | 0.0376        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.05e+03      |\n",
      "|    n_updates            | 21910         |\n",
      "|    policy_gradient_loss | -0.000734     |\n",
      "|    value_loss           | 1.79e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1577     |\n",
      "|    iterations      | 1836     |\n",
      "|    time_elapsed    | 9532     |\n",
      "|    total_timesteps | 15040512 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1577          |\n",
      "|    iterations           | 1837          |\n",
      "|    time_elapsed         | 9537          |\n",
      "|    total_timesteps      | 15048704      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012505797 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.411        |\n",
      "|    explained_variance   | 0.0696        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.4e+03       |\n",
      "|    n_updates            | 21920         |\n",
      "|    policy_gradient_loss | -0.000481     |\n",
      "|    value_loss           | 1.94e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1577          |\n",
      "|    iterations           | 1838          |\n",
      "|    time_elapsed         | 9546          |\n",
      "|    total_timesteps      | 15056896      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014469078 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.406        |\n",
      "|    explained_variance   | 0.0408        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 796           |\n",
      "|    n_updates            | 21930         |\n",
      "|    policy_gradient_loss | -0.000475     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1577          |\n",
      "|    iterations           | 1839          |\n",
      "|    time_elapsed         | 9551          |\n",
      "|    total_timesteps      | 15065088      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010958051 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.417        |\n",
      "|    explained_variance   | 0.0556        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 943           |\n",
      "|    n_updates            | 21940         |\n",
      "|    policy_gradient_loss | -0.000403     |\n",
      "|    value_loss           | 2.06e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1577          |\n",
      "|    iterations           | 1840          |\n",
      "|    time_elapsed         | 9555          |\n",
      "|    total_timesteps      | 15073280      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014123751 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.419        |\n",
      "|    explained_variance   | 0.0298        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 700           |\n",
      "|    n_updates            | 21950         |\n",
      "|    policy_gradient_loss | -0.000584     |\n",
      "|    value_loss           | 1.79e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=15080000, episode_reward=634.40 +/- 61.10\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 634          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 15080000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.924615e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.402       |\n",
      "|    explained_variance   | 0.0691       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 611          |\n",
      "|    n_updates            | 21960        |\n",
      "|    policy_gradient_loss | -0.000432    |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1576     |\n",
      "|    iterations      | 1841     |\n",
      "|    time_elapsed    | 9566     |\n",
      "|    total_timesteps | 15081472 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1576         |\n",
      "|    iterations           | 1842         |\n",
      "|    time_elapsed         | 9571         |\n",
      "|    total_timesteps      | 15089664     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.460925e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.418       |\n",
      "|    explained_variance   | 0.0253       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 744          |\n",
      "|    n_updates            | 21970        |\n",
      "|    policy_gradient_loss | -0.000447    |\n",
      "|    value_loss           | 1.94e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1576          |\n",
      "|    iterations           | 1843          |\n",
      "|    time_elapsed         | 9575          |\n",
      "|    total_timesteps      | 15097856      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023205872 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.406        |\n",
      "|    explained_variance   | 0.0513        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.32e+03      |\n",
      "|    n_updates            | 21980         |\n",
      "|    policy_gradient_loss | -0.000661     |\n",
      "|    value_loss           | 2.04e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1576          |\n",
      "|    iterations           | 1844          |\n",
      "|    time_elapsed         | 9580          |\n",
      "|    total_timesteps      | 15106048      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012770965 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.408        |\n",
      "|    explained_variance   | 0.0453        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 733           |\n",
      "|    n_updates            | 21990         |\n",
      "|    policy_gradient_loss | -0.000465     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1576         |\n",
      "|    iterations           | 1845         |\n",
      "|    time_elapsed         | 9584         |\n",
      "|    total_timesteps      | 15114240     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.612515e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.417       |\n",
      "|    explained_variance   | 0.0294       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 772          |\n",
      "|    n_updates            | 22000        |\n",
      "|    policy_gradient_loss | -0.000412    |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15120000, episode_reward=665.40 +/- 53.64\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 665           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15120000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011495202 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.409        |\n",
      "|    explained_variance   | 0.0108        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 914           |\n",
      "|    n_updates            | 22010         |\n",
      "|    policy_gradient_loss | -0.00044      |\n",
      "|    value_loss           | 1.98e+03      |\n",
      "-------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1575     |\n",
      "|    iterations      | 1846     |\n",
      "|    time_elapsed    | 9596     |\n",
      "|    total_timesteps | 15122432 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1575          |\n",
      "|    iterations           | 1847          |\n",
      "|    time_elapsed         | 9603          |\n",
      "|    total_timesteps      | 15130624      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7661193e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.411        |\n",
      "|    explained_variance   | 0.0535        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 934           |\n",
      "|    n_updates            | 22020         |\n",
      "|    policy_gradient_loss | -0.000228     |\n",
      "|    value_loss           | 1.94e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1575          |\n",
      "|    iterations           | 1848          |\n",
      "|    time_elapsed         | 9607          |\n",
      "|    total_timesteps      | 15138816      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.2094295e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.41         |\n",
      "|    explained_variance   | 0.0309        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 802           |\n",
      "|    n_updates            | 22030         |\n",
      "|    policy_gradient_loss | -0.000397     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 1572           |\n",
      "|    iterations           | 1849           |\n",
      "|    time_elapsed         | 9632           |\n",
      "|    total_timesteps      | 15147008       |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000109386165 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.412         |\n",
      "|    explained_variance   | 0.0292         |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 1.03e+03       |\n",
      "|    n_updates            | 22040          |\n",
      "|    policy_gradient_loss | -0.000552      |\n",
      "|    value_loss           | 1.83e+03       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1572          |\n",
      "|    iterations           | 1850          |\n",
      "|    time_elapsed         | 9637          |\n",
      "|    total_timesteps      | 15155200      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025288135 |\n",
      "|    clip_fraction        | 0.000208      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.398        |\n",
      "|    explained_variance   | 0.0696        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 801           |\n",
      "|    n_updates            | 22050         |\n",
      "|    policy_gradient_loss | -0.000816     |\n",
      "|    value_loss           | 1.82e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=15160000, episode_reward=647.40 +/- 55.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 647           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15160000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010683684 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.406        |\n",
      "|    explained_variance   | 0.0464        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.02e+03      |\n",
      "|    n_updates            | 22060         |\n",
      "|    policy_gradient_loss | -0.000483     |\n",
      "|    value_loss           | 2.04e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1571     |\n",
      "|    iterations      | 1851     |\n",
      "|    time_elapsed    | 9648     |\n",
      "|    total_timesteps | 15163392 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1571          |\n",
      "|    iterations           | 1852          |\n",
      "|    time_elapsed         | 9652          |\n",
      "|    total_timesteps      | 15171584      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011131227 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.414        |\n",
      "|    explained_variance   | 0.0373        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.19e+03      |\n",
      "|    n_updates            | 22070         |\n",
      "|    policy_gradient_loss | -0.000463     |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1571          |\n",
      "|    iterations           | 1853          |\n",
      "|    time_elapsed         | 9657          |\n",
      "|    total_timesteps      | 15179776      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013950004 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.407        |\n",
      "|    explained_variance   | 0.0486        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.27e+03      |\n",
      "|    n_updates            | 22080         |\n",
      "|    policy_gradient_loss | -0.000551     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1572         |\n",
      "|    iterations           | 1854         |\n",
      "|    time_elapsed         | 9661         |\n",
      "|    total_timesteps      | 15187968     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.523254e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.412       |\n",
      "|    explained_variance   | 0.0447       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 873          |\n",
      "|    n_updates            | 22090        |\n",
      "|    policy_gradient_loss | -0.000375    |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1572         |\n",
      "|    iterations           | 1855         |\n",
      "|    time_elapsed         | 9666         |\n",
      "|    total_timesteps      | 15196160     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.579945e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.404       |\n",
      "|    explained_variance   | 0.0676       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 22100        |\n",
      "|    policy_gradient_loss | -0.00041     |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15200000, episode_reward=645.60 +/- 64.53\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 646           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15200000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010891786 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.409        |\n",
      "|    explained_variance   | 0.0238        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 639           |\n",
      "|    n_updates            | 22110         |\n",
      "|    policy_gradient_loss | -0.000569     |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1571     |\n",
      "|    iterations      | 1856     |\n",
      "|    time_elapsed    | 9677     |\n",
      "|    total_timesteps | 15204352 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1571          |\n",
      "|    iterations           | 1857          |\n",
      "|    time_elapsed         | 9681          |\n",
      "|    total_timesteps      | 15212544      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033355757 |\n",
      "|    clip_fraction        | 0.000122      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.407        |\n",
      "|    explained_variance   | 0.0502        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 712           |\n",
      "|    n_updates            | 22120         |\n",
      "|    policy_gradient_loss | -0.000893     |\n",
      "|    value_loss           | 1.82e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1571          |\n",
      "|    iterations           | 1858          |\n",
      "|    time_elapsed         | 9686          |\n",
      "|    total_timesteps      | 15220736      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015704449 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.402        |\n",
      "|    explained_variance   | 0.0468        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 667           |\n",
      "|    n_updates            | 22130         |\n",
      "|    policy_gradient_loss | -0.000522     |\n",
      "|    value_loss           | 1.79e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1571          |\n",
      "|    iterations           | 1859          |\n",
      "|    time_elapsed         | 9690          |\n",
      "|    total_timesteps      | 15228928      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016228855 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.401        |\n",
      "|    explained_variance   | 0.0428        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 775           |\n",
      "|    n_updates            | 22140         |\n",
      "|    policy_gradient_loss | -0.000682     |\n",
      "|    value_loss           | 1.82e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1571          |\n",
      "|    iterations           | 1860          |\n",
      "|    time_elapsed         | 9696          |\n",
      "|    total_timesteps      | 15237120      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021798731 |\n",
      "|    clip_fraction        | 3.66e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.413        |\n",
      "|    explained_variance   | 0.0253        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.48e+03      |\n",
      "|    n_updates            | 22150         |\n",
      "|    policy_gradient_loss | -0.000678     |\n",
      "|    value_loss           | 2.03e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=15240000, episode_reward=638.00 +/- 52.99\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 638           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15240000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013524253 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.408        |\n",
      "|    explained_variance   | 0.0306        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 811           |\n",
      "|    n_updates            | 22160         |\n",
      "|    policy_gradient_loss | -0.00056      |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1570     |\n",
      "|    iterations      | 1861     |\n",
      "|    time_elapsed    | 9709     |\n",
      "|    total_timesteps | 15245312 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1570          |\n",
      "|    iterations           | 1862          |\n",
      "|    time_elapsed         | 9713          |\n",
      "|    total_timesteps      | 15253504      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018037028 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.401        |\n",
      "|    explained_variance   | 0.0561        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 816           |\n",
      "|    n_updates            | 22170         |\n",
      "|    policy_gradient_loss | -0.000602     |\n",
      "|    value_loss           | 1.87e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1570         |\n",
      "|    iterations           | 1863         |\n",
      "|    time_elapsed         | 9718         |\n",
      "|    total_timesteps      | 15261696     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.180203e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.406       |\n",
      "|    explained_variance   | 0.03         |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 22180        |\n",
      "|    policy_gradient_loss | -0.000402    |\n",
      "|    value_loss           | 1.92e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1570          |\n",
      "|    iterations           | 1864          |\n",
      "|    time_elapsed         | 9723          |\n",
      "|    total_timesteps      | 15269888      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022532439 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.405        |\n",
      "|    explained_variance   | 0.0289        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 884           |\n",
      "|    n_updates            | 22190         |\n",
      "|    policy_gradient_loss | -0.000674     |\n",
      "|    value_loss           | 1.96e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1570          |\n",
      "|    iterations           | 1865          |\n",
      "|    time_elapsed         | 9727          |\n",
      "|    total_timesteps      | 15278080      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.9429705e-05 |\n",
      "|    clip_fraction        | 3.66e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.422        |\n",
      "|    explained_variance   | 0.0512        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 951           |\n",
      "|    n_updates            | 22200         |\n",
      "|    policy_gradient_loss | -0.00036      |\n",
      "|    value_loss           | 1.81e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=15280000, episode_reward=651.60 +/- 58.29\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 652           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15280000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.3338895e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.407        |\n",
      "|    explained_variance   | 0.0714        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 654           |\n",
      "|    n_updates            | 22210         |\n",
      "|    policy_gradient_loss | -0.000415     |\n",
      "|    value_loss           | 1.76e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1569     |\n",
      "|    iterations      | 1866     |\n",
      "|    time_elapsed    | 9738     |\n",
      "|    total_timesteps | 15286272 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1569          |\n",
      "|    iterations           | 1867          |\n",
      "|    time_elapsed         | 9743          |\n",
      "|    total_timesteps      | 15294464      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012873762 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.412        |\n",
      "|    explained_variance   | 0.0139        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.05e+03      |\n",
      "|    n_updates            | 22220         |\n",
      "|    policy_gradient_loss | -0.000443     |\n",
      "|    value_loss           | 1.97e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 1868         |\n",
      "|    time_elapsed         | 9747         |\n",
      "|    total_timesteps      | 15302656     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001078229 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.411       |\n",
      "|    explained_variance   | 0.0416       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 890          |\n",
      "|    n_updates            | 22230        |\n",
      "|    policy_gradient_loss | -0.000511    |\n",
      "|    value_loss           | 1.96e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1570          |\n",
      "|    iterations           | 1869          |\n",
      "|    time_elapsed         | 9751          |\n",
      "|    total_timesteps      | 15310848      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021913873 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.404        |\n",
      "|    explained_variance   | 0.0593        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.23e+03      |\n",
      "|    n_updates            | 22240         |\n",
      "|    policy_gradient_loss | -0.000763     |\n",
      "|    value_loss           | 1.95e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1570          |\n",
      "|    iterations           | 1870          |\n",
      "|    time_elapsed         | 9755          |\n",
      "|    total_timesteps      | 15319040      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016697023 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.409        |\n",
      "|    explained_variance   | -0.0105       |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 941           |\n",
      "|    n_updates            | 22250         |\n",
      "|    policy_gradient_loss | -0.000573     |\n",
      "|    value_loss           | 1.78e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=15320000, episode_reward=641.60 +/- 62.46\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 642           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15320000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018628541 |\n",
      "|    clip_fraction        | 3.66e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.4          |\n",
      "|    explained_variance   | 0.0354        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 716           |\n",
      "|    n_updates            | 22260         |\n",
      "|    policy_gradient_loss | -0.000606     |\n",
      "|    value_loss           | 1.81e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1569     |\n",
      "|    iterations      | 1871     |\n",
      "|    time_elapsed    | 9767     |\n",
      "|    total_timesteps | 15327232 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1569          |\n",
      "|    iterations           | 1872          |\n",
      "|    time_elapsed         | 9771          |\n",
      "|    total_timesteps      | 15335424      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016398256 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.41         |\n",
      "|    explained_variance   | 0.0336        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 940           |\n",
      "|    n_updates            | 22270         |\n",
      "|    policy_gradient_loss | -0.000662     |\n",
      "|    value_loss           | 2.09e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1569        |\n",
      "|    iterations           | 1873        |\n",
      "|    time_elapsed         | 9775        |\n",
      "|    total_timesteps      | 15343616    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 8.05755e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.425      |\n",
      "|    explained_variance   | 0.0483      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 921         |\n",
      "|    n_updates            | 22280       |\n",
      "|    policy_gradient_loss | -0.000406   |\n",
      "|    value_loss           | 1.84e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 1569           |\n",
      "|    iterations           | 1874           |\n",
      "|    time_elapsed         | 9779           |\n",
      "|    total_timesteps      | 15351808       |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000113438815 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.413         |\n",
      "|    explained_variance   | 0.0679         |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 856            |\n",
      "|    n_updates            | 22290          |\n",
      "|    policy_gradient_loss | -0.000506      |\n",
      "|    value_loss           | 1.83e+03       |\n",
      "--------------------------------------------\n",
      "Eval num_timesteps=15360000, episode_reward=632.20 +/- 59.47\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 632           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15360000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012693141 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.409        |\n",
      "|    explained_variance   | 0.0187        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 873           |\n",
      "|    n_updates            | 22300         |\n",
      "|    policy_gradient_loss | -0.000496     |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1568     |\n",
      "|    iterations      | 1875     |\n",
      "|    time_elapsed    | 9790     |\n",
      "|    total_timesteps | 15360000 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1568          |\n",
      "|    iterations           | 1876          |\n",
      "|    time_elapsed         | 9795          |\n",
      "|    total_timesteps      | 15368192      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022410548 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.414        |\n",
      "|    explained_variance   | 0.0405        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.07e+03      |\n",
      "|    n_updates            | 22310         |\n",
      "|    policy_gradient_loss | -0.000689     |\n",
      "|    value_loss           | 2.06e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1568          |\n",
      "|    iterations           | 1877          |\n",
      "|    time_elapsed         | 9800          |\n",
      "|    total_timesteps      | 15376384      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013120801 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.411        |\n",
      "|    explained_variance   | 0.0358        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.1e+03       |\n",
      "|    n_updates            | 22320         |\n",
      "|    policy_gradient_loss | -0.000588     |\n",
      "|    value_loss           | 1.96e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1569          |\n",
      "|    iterations           | 1878          |\n",
      "|    time_elapsed         | 9805          |\n",
      "|    total_timesteps      | 15384576      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015078281 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.415        |\n",
      "|    explained_variance   | 0.0387        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.1e+03       |\n",
      "|    n_updates            | 22330         |\n",
      "|    policy_gradient_loss | -0.000584     |\n",
      "|    value_loss           | 1.84e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1569         |\n",
      "|    iterations           | 1879         |\n",
      "|    time_elapsed         | 9810         |\n",
      "|    total_timesteps      | 15392768     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.219363e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.409       |\n",
      "|    explained_variance   | 0.0296       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 925          |\n",
      "|    n_updates            | 22340        |\n",
      "|    policy_gradient_loss | -0.000434    |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15400000, episode_reward=641.60 +/- 60.74\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 642           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15400000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035872567 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.412        |\n",
      "|    explained_variance   | 0.0568        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.03e+03      |\n",
      "|    n_updates            | 22350         |\n",
      "|    policy_gradient_loss | -0.000896     |\n",
      "|    value_loss           | 1.94e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1567     |\n",
      "|    iterations      | 1880     |\n",
      "|    time_elapsed    | 9822     |\n",
      "|    total_timesteps | 15400960 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1568          |\n",
      "|    iterations           | 1881          |\n",
      "|    time_elapsed         | 9827          |\n",
      "|    total_timesteps      | 15409152      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011763954 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.406        |\n",
      "|    explained_variance   | 0.0269        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.07e+03      |\n",
      "|    n_updates            | 22360         |\n",
      "|    policy_gradient_loss | -0.000489     |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1566          |\n",
      "|    iterations           | 1882          |\n",
      "|    time_elapsed         | 9843          |\n",
      "|    total_timesteps      | 15417344      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011518582 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.404        |\n",
      "|    explained_variance   | 0.0419        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 753           |\n",
      "|    n_updates            | 22370         |\n",
      "|    policy_gradient_loss | -0.000514     |\n",
      "|    value_loss           | 1.84e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1565          |\n",
      "|    iterations           | 1883          |\n",
      "|    time_elapsed         | 9852          |\n",
      "|    total_timesteps      | 15425536      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016764292 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.42         |\n",
      "|    explained_variance   | 0.0339        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 523           |\n",
      "|    n_updates            | 22380         |\n",
      "|    policy_gradient_loss | -0.000507     |\n",
      "|    value_loss           | 1.8e+03       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1565         |\n",
      "|    iterations           | 1884         |\n",
      "|    time_elapsed         | 9858         |\n",
      "|    total_timesteps      | 15433728     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.786525e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.417       |\n",
      "|    explained_variance   | 0.0557       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 22390        |\n",
      "|    policy_gradient_loss | -0.000496    |\n",
      "|    value_loss           | 1.93e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15440000, episode_reward=637.60 +/- 63.67\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 638           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15440000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.3071896e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.407        |\n",
      "|    explained_variance   | 0.0247        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.03e+03      |\n",
      "|    n_updates            | 22400         |\n",
      "|    policy_gradient_loss | -0.000404     |\n",
      "|    value_loss           | 1.98e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1564     |\n",
      "|    iterations      | 1885     |\n",
      "|    time_elapsed    | 9872     |\n",
      "|    total_timesteps | 15441920 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1564          |\n",
      "|    iterations           | 1886          |\n",
      "|    time_elapsed         | 9877          |\n",
      "|    total_timesteps      | 15450112      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023972889 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.412        |\n",
      "|    explained_variance   | 0.0412        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.12e+03      |\n",
      "|    n_updates            | 22410         |\n",
      "|    policy_gradient_loss | -0.000849     |\n",
      "|    value_loss           | 1.8e+03       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1564         |\n",
      "|    iterations           | 1887         |\n",
      "|    time_elapsed         | 9882         |\n",
      "|    total_timesteps      | 15458304     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.833224e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.422       |\n",
      "|    explained_variance   | 0.00894      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.21e+03     |\n",
      "|    n_updates            | 22420        |\n",
      "|    policy_gradient_loss | -0.000411    |\n",
      "|    value_loss           | 1.92e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1562          |\n",
      "|    iterations           | 1888          |\n",
      "|    time_elapsed         | 9895          |\n",
      "|    total_timesteps      | 15466496      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021575521 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.419        |\n",
      "|    explained_variance   | 0.0187        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 803           |\n",
      "|    n_updates            | 22430         |\n",
      "|    policy_gradient_loss | -0.000572     |\n",
      "|    value_loss           | 1.82e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1562          |\n",
      "|    iterations           | 1889          |\n",
      "|    time_elapsed         | 9903          |\n",
      "|    total_timesteps      | 15474688      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027349117 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.412        |\n",
      "|    explained_variance   | 0.0633        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.29e+03      |\n",
      "|    n_updates            | 22440         |\n",
      "|    policy_gradient_loss | -0.000744     |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=15480000, episode_reward=638.80 +/- 61.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 639           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15480000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012770406 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.413        |\n",
      "|    explained_variance   | 0.0546        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.05e+03      |\n",
      "|    n_updates            | 22450         |\n",
      "|    policy_gradient_loss | -0.000492     |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1561     |\n",
      "|    iterations      | 1890     |\n",
      "|    time_elapsed    | 9915     |\n",
      "|    total_timesteps | 15482880 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1561          |\n",
      "|    iterations           | 1891          |\n",
      "|    time_elapsed         | 9921          |\n",
      "|    total_timesteps      | 15491072      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017374597 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.399        |\n",
      "|    explained_variance   | 0.0558        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 775           |\n",
      "|    n_updates            | 22460         |\n",
      "|    policy_gradient_loss | -0.000651     |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1560          |\n",
      "|    iterations           | 1892          |\n",
      "|    time_elapsed         | 9929          |\n",
      "|    total_timesteps      | 15499264      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012449143 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.404        |\n",
      "|    explained_variance   | 0.068         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 847           |\n",
      "|    n_updates            | 22470         |\n",
      "|    policy_gradient_loss | -0.000488     |\n",
      "|    value_loss           | 1.81e+03      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 1560           |\n",
      "|    iterations           | 1893           |\n",
      "|    time_elapsed         | 9939           |\n",
      "|    total_timesteps      | 15507456       |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000104168284 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.408         |\n",
      "|    explained_variance   | 0.041          |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 1.09e+03       |\n",
      "|    n_updates            | 22480          |\n",
      "|    policy_gradient_loss | -0.000443      |\n",
      "|    value_loss           | 1.97e+03       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1560          |\n",
      "|    iterations           | 1894          |\n",
      "|    time_elapsed         | 9944          |\n",
      "|    total_timesteps      | 15515648      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016744048 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.401        |\n",
      "|    explained_variance   | 0.066         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.13e+03      |\n",
      "|    n_updates            | 22490         |\n",
      "|    policy_gradient_loss | -0.00064      |\n",
      "|    value_loss           | 1.85e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=15520000, episode_reward=645.20 +/- 54.08\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 645           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15520000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012419504 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.421        |\n",
      "|    explained_variance   | 0.0479        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 764           |\n",
      "|    n_updates            | 22500         |\n",
      "|    policy_gradient_loss | -0.000433     |\n",
      "|    value_loss           | 1.84e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1558     |\n",
      "|    iterations      | 1895     |\n",
      "|    time_elapsed    | 9958     |\n",
      "|    total_timesteps | 15523840 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1559         |\n",
      "|    iterations           | 1896         |\n",
      "|    time_elapsed         | 9962         |\n",
      "|    total_timesteps      | 15532032     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.440438e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.4         |\n",
      "|    explained_variance   | 0.0142       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 783          |\n",
      "|    n_updates            | 22510        |\n",
      "|    policy_gradient_loss | -0.000452    |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1559          |\n",
      "|    iterations           | 1897          |\n",
      "|    time_elapsed         | 9967          |\n",
      "|    total_timesteps      | 15540224      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013451272 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.405        |\n",
      "|    explained_variance   | 0.0518        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.04e+03      |\n",
      "|    n_updates            | 22520         |\n",
      "|    policy_gradient_loss | -0.000465     |\n",
      "|    value_loss           | 1.98e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1559          |\n",
      "|    iterations           | 1898          |\n",
      "|    time_elapsed         | 9972          |\n",
      "|    total_timesteps      | 15548416      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010990587 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.405        |\n",
      "|    explained_variance   | 0.0394        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 733           |\n",
      "|    n_updates            | 22530         |\n",
      "|    policy_gradient_loss | -0.000555     |\n",
      "|    value_loss           | 1.83e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1559          |\n",
      "|    iterations           | 1899          |\n",
      "|    time_elapsed         | 9977          |\n",
      "|    total_timesteps      | 15556608      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010917878 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.4          |\n",
      "|    explained_variance   | 0.00712       |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 735           |\n",
      "|    n_updates            | 22540         |\n",
      "|    policy_gradient_loss | -0.000499     |\n",
      "|    value_loss           | 1.85e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=15560000, episode_reward=644.80 +/- 56.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 645           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15560000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011403259 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.399        |\n",
      "|    explained_variance   | 0.0633        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 934           |\n",
      "|    n_updates            | 22550         |\n",
      "|    policy_gradient_loss | -0.000481     |\n",
      "|    value_loss           | 1.82e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1558     |\n",
      "|    iterations      | 1900     |\n",
      "|    time_elapsed    | 9989     |\n",
      "|    total_timesteps | 15564800 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1558         |\n",
      "|    iterations           | 1901         |\n",
      "|    time_elapsed         | 9994         |\n",
      "|    total_timesteps      | 15572992     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.557643e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.408       |\n",
      "|    explained_variance   | 0.0266       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 22560        |\n",
      "|    policy_gradient_loss | -0.000387    |\n",
      "|    value_loss           | 2.02e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1558          |\n",
      "|    iterations           | 1902          |\n",
      "|    time_elapsed         | 9999          |\n",
      "|    total_timesteps      | 15581184      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018265555 |\n",
      "|    clip_fraction        | 3.66e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.413        |\n",
      "|    explained_variance   | 0.0611        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.01e+03      |\n",
      "|    n_updates            | 22570         |\n",
      "|    policy_gradient_loss | -0.000625     |\n",
      "|    value_loss           | 1.81e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1558          |\n",
      "|    iterations           | 1903          |\n",
      "|    time_elapsed         | 10004         |\n",
      "|    total_timesteps      | 15589376      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015715175 |\n",
      "|    clip_fraction        | 0.000122      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.412        |\n",
      "|    explained_variance   | 0.00166       |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.08e+03      |\n",
      "|    n_updates            | 22580         |\n",
      "|    policy_gradient_loss | -0.000747     |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1558          |\n",
      "|    iterations           | 1904          |\n",
      "|    time_elapsed         | 10009         |\n",
      "|    total_timesteps      | 15597568      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023670903 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.413        |\n",
      "|    explained_variance   | 0.0323        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.07e+03      |\n",
      "|    n_updates            | 22590         |\n",
      "|    policy_gradient_loss | -0.000706     |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=15600000, episode_reward=632.80 +/- 54.52\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 633           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15600000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015048278 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.396        |\n",
      "|    explained_variance   | 0.0187        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 957           |\n",
      "|    n_updates            | 22600         |\n",
      "|    policy_gradient_loss | -0.000613     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1557     |\n",
      "|    iterations      | 1905     |\n",
      "|    time_elapsed    | 10022    |\n",
      "|    total_timesteps | 15605760 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1557         |\n",
      "|    iterations           | 1906         |\n",
      "|    time_elapsed         | 10027        |\n",
      "|    total_timesteps      | 15613952     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.849158e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.393       |\n",
      "|    explained_variance   | 0.0624       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 22610        |\n",
      "|    policy_gradient_loss | -0.000472    |\n",
      "|    value_loss           | 2.1e+03      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1557          |\n",
      "|    iterations           | 1907          |\n",
      "|    time_elapsed         | 10032         |\n",
      "|    total_timesteps      | 15622144      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021287563 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.414        |\n",
      "|    explained_variance   | 0.0432        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 865           |\n",
      "|    n_updates            | 22620         |\n",
      "|    policy_gradient_loss | -0.000688     |\n",
      "|    value_loss           | 1.77e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1557         |\n",
      "|    iterations           | 1908         |\n",
      "|    time_elapsed         | 10037        |\n",
      "|    total_timesteps      | 15630336     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.735817e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.411       |\n",
      "|    explained_variance   | 0.0346       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 673          |\n",
      "|    n_updates            | 22630        |\n",
      "|    policy_gradient_loss | -0.000396    |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1557          |\n",
      "|    iterations           | 1909          |\n",
      "|    time_elapsed         | 10042         |\n",
      "|    total_timesteps      | 15638528      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.6141417e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.411        |\n",
      "|    explained_variance   | 0.101         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 853           |\n",
      "|    n_updates            | 22640         |\n",
      "|    policy_gradient_loss | -0.000281     |\n",
      "|    value_loss           | 1.81e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=15640000, episode_reward=665.20 +/- 53.38\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 665           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15640000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.1814724e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.403        |\n",
      "|    explained_variance   | 0.0151        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 694           |\n",
      "|    n_updates            | 22650         |\n",
      "|    policy_gradient_loss | -0.000312     |\n",
      "|    value_loss           | 1.93e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1555     |\n",
      "|    iterations      | 1910     |\n",
      "|    time_elapsed    | 10056    |\n",
      "|    total_timesteps | 15646720 |\n",
      "---------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 1555           |\n",
      "|    iterations           | 1911           |\n",
      "|    time_elapsed         | 10061          |\n",
      "|    total_timesteps      | 15654912       |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000118031465 |\n",
      "|    clip_fraction        | 3.66e-05       |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.408         |\n",
      "|    explained_variance   | 0.056          |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 858            |\n",
      "|    n_updates            | 22660          |\n",
      "|    policy_gradient_loss | -0.000485      |\n",
      "|    value_loss           | 1.86e+03       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1556          |\n",
      "|    iterations           | 1912          |\n",
      "|    time_elapsed         | 10065         |\n",
      "|    total_timesteps      | 15663104      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.5264575e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.408        |\n",
      "|    explained_variance   | 0.0577        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 906           |\n",
      "|    n_updates            | 22670         |\n",
      "|    policy_gradient_loss | -0.000351     |\n",
      "|    value_loss           | 1.82e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1556          |\n",
      "|    iterations           | 1913          |\n",
      "|    time_elapsed         | 10069         |\n",
      "|    total_timesteps      | 15671296      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016793268 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.413        |\n",
      "|    explained_variance   | 0.0541        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 942           |\n",
      "|    n_updates            | 22680         |\n",
      "|    policy_gradient_loss | -0.000498     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1556          |\n",
      "|    iterations           | 1914          |\n",
      "|    time_elapsed         | 10076         |\n",
      "|    total_timesteps      | 15679488      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017211077 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.411        |\n",
      "|    explained_variance   | 0.0162        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.18e+03      |\n",
      "|    n_updates            | 22690         |\n",
      "|    policy_gradient_loss | -0.000698     |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=15680000, episode_reward=653.40 +/- 63.83\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 653           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15680000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012900778 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.404        |\n",
      "|    explained_variance   | 0.00201       |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 848           |\n",
      "|    n_updates            | 22700         |\n",
      "|    policy_gradient_loss | -0.000544     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1554     |\n",
      "|    iterations      | 1915     |\n",
      "|    time_elapsed    | 10088    |\n",
      "|    total_timesteps | 15687680 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1555          |\n",
      "|    iterations           | 1916          |\n",
      "|    time_elapsed         | 10093         |\n",
      "|    total_timesteps      | 15695872      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010760186 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.406        |\n",
      "|    explained_variance   | 0.0388        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 867           |\n",
      "|    n_updates            | 22710         |\n",
      "|    policy_gradient_loss | -0.000401     |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1555          |\n",
      "|    iterations           | 1917          |\n",
      "|    time_elapsed         | 10098         |\n",
      "|    total_timesteps      | 15704064      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018217179 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.403        |\n",
      "|    explained_variance   | 0.0475        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 774           |\n",
      "|    n_updates            | 22720         |\n",
      "|    policy_gradient_loss | -0.000614     |\n",
      "|    value_loss           | 1.82e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1554         |\n",
      "|    iterations           | 1918         |\n",
      "|    time_elapsed         | 10106        |\n",
      "|    total_timesteps      | 15712256     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001452771 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.417       |\n",
      "|    explained_variance   | 0.0321       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 22730        |\n",
      "|    policy_gradient_loss | -0.00053     |\n",
      "|    value_loss           | 2.02e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15720000, episode_reward=650.40 +/- 58.21\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 650           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15720000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.0298425e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.417        |\n",
      "|    explained_variance   | 0.0432        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.11e+03      |\n",
      "|    n_updates            | 22740         |\n",
      "|    policy_gradient_loss | -0.000381     |\n",
      "|    value_loss           | 1.95e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1553     |\n",
      "|    iterations      | 1919     |\n",
      "|    time_elapsed    | 10118    |\n",
      "|    total_timesteps | 15720448 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1553        |\n",
      "|    iterations           | 1920        |\n",
      "|    time_elapsed         | 10122       |\n",
      "|    total_timesteps      | 15728640    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 7.06457e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.413      |\n",
      "|    explained_variance   | 0.0566      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 788         |\n",
      "|    n_updates            | 22750       |\n",
      "|    policy_gradient_loss | -0.000433   |\n",
      "|    value_loss           | 1.78e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1553         |\n",
      "|    iterations           | 1921         |\n",
      "|    time_elapsed         | 10129        |\n",
      "|    total_timesteps      | 15736832     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002904713 |\n",
      "|    clip_fraction        | 0.00011      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.409       |\n",
      "|    explained_variance   | 0.0124       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 654          |\n",
      "|    n_updates            | 22760        |\n",
      "|    policy_gradient_loss | -0.000645    |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1553         |\n",
      "|    iterations           | 1922         |\n",
      "|    time_elapsed         | 10136        |\n",
      "|    total_timesteps      | 15745024     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.066124e-05 |\n",
      "|    clip_fraction        | 1.22e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.402       |\n",
      "|    explained_variance   | 0.0257       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 22770        |\n",
      "|    policy_gradient_loss | -0.000442    |\n",
      "|    value_loss           | 2.11e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1553         |\n",
      "|    iterations           | 1923         |\n",
      "|    time_elapsed         | 10141        |\n",
      "|    total_timesteps      | 15753216     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.898832e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.416       |\n",
      "|    explained_variance   | 0.0334       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 856          |\n",
      "|    n_updates            | 22780        |\n",
      "|    policy_gradient_loss | -0.000348    |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15760000, episode_reward=637.40 +/- 56.06\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 637          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 15760000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.766994e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.41        |\n",
      "|    explained_variance   | 0.0271       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 873          |\n",
      "|    n_updates            | 22790        |\n",
      "|    policy_gradient_loss | -0.000305    |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1552     |\n",
      "|    iterations      | 1924     |\n",
      "|    time_elapsed    | 10153    |\n",
      "|    total_timesteps | 15761408 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1552          |\n",
      "|    iterations           | 1925          |\n",
      "|    time_elapsed         | 10157         |\n",
      "|    total_timesteps      | 15769600      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013874078 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.399        |\n",
      "|    explained_variance   | 0.0337        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.15e+03      |\n",
      "|    n_updates            | 22800         |\n",
      "|    policy_gradient_loss | -0.000429     |\n",
      "|    value_loss           | 1.83e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1552          |\n",
      "|    iterations           | 1926          |\n",
      "|    time_elapsed         | 10162         |\n",
      "|    total_timesteps      | 15777792      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012114857 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.411        |\n",
      "|    explained_variance   | 0.0478        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.12e+03      |\n",
      "|    n_updates            | 22810         |\n",
      "|    policy_gradient_loss | -0.000468     |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1552         |\n",
      "|    iterations           | 1927         |\n",
      "|    time_elapsed         | 10167        |\n",
      "|    total_timesteps      | 15785984     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002208378 |\n",
      "|    clip_fraction        | 3.66e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.4         |\n",
      "|    explained_variance   | 0.0256       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 901          |\n",
      "|    n_updates            | 22820        |\n",
      "|    policy_gradient_loss | -0.000726    |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 1552           |\n",
      "|    iterations           | 1928           |\n",
      "|    time_elapsed         | 10172          |\n",
      "|    total_timesteps      | 15794176       |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000117647556 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.404         |\n",
      "|    explained_variance   | 0.0513         |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 1.08e+03       |\n",
      "|    n_updates            | 22830          |\n",
      "|    policy_gradient_loss | -0.000479      |\n",
      "|    value_loss           | 1.82e+03       |\n",
      "--------------------------------------------\n",
      "Eval num_timesteps=15800000, episode_reward=660.20 +/- 57.11\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 660           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15800000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3148826e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.406        |\n",
      "|    explained_variance   | 0.0433        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 972           |\n",
      "|    n_updates            | 22840         |\n",
      "|    policy_gradient_loss | -0.00029      |\n",
      "|    value_loss           | 1.87e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1549     |\n",
      "|    iterations      | 1929     |\n",
      "|    time_elapsed    | 10197    |\n",
      "|    total_timesteps | 15802368 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1549          |\n",
      "|    iterations           | 1930          |\n",
      "|    time_elapsed         | 10201         |\n",
      "|    total_timesteps      | 15810560      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.9927192e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.392        |\n",
      "|    explained_variance   | 0.0449        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.07e+03      |\n",
      "|    n_updates            | 22850         |\n",
      "|    policy_gradient_loss | -0.000348     |\n",
      "|    value_loss           | 1.87e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1549          |\n",
      "|    iterations           | 1931          |\n",
      "|    time_elapsed         | 10206         |\n",
      "|    total_timesteps      | 15818752      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012076351 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.408        |\n",
      "|    explained_variance   | 0.0293        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.01e+03      |\n",
      "|    n_updates            | 22860         |\n",
      "|    policy_gradient_loss | -0.00055      |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1549          |\n",
      "|    iterations           | 1932          |\n",
      "|    time_elapsed         | 10212         |\n",
      "|    total_timesteps      | 15826944      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.5667886e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.388        |\n",
      "|    explained_variance   | 0.0363        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 719           |\n",
      "|    n_updates            | 22870         |\n",
      "|    policy_gradient_loss | -0.000386     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1549          |\n",
      "|    iterations           | 1933          |\n",
      "|    time_elapsed         | 10219         |\n",
      "|    total_timesteps      | 15835136      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037117652 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.401        |\n",
      "|    explained_variance   | 0.0386        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.27e+03      |\n",
      "|    n_updates            | 22880         |\n",
      "|    policy_gradient_loss | -0.00087      |\n",
      "|    value_loss           | 1.76e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=15840000, episode_reward=651.20 +/- 48.15\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 651           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15840000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010059703 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.399        |\n",
      "|    explained_variance   | 0.00495       |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 667           |\n",
      "|    n_updates            | 22890         |\n",
      "|    policy_gradient_loss | -0.000534     |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1548     |\n",
      "|    iterations      | 1934     |\n",
      "|    time_elapsed    | 10231    |\n",
      "|    total_timesteps | 15843328 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1548          |\n",
      "|    iterations           | 1935          |\n",
      "|    time_elapsed         | 10238         |\n",
      "|    total_timesteps      | 15851520      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043425284 |\n",
      "|    clip_fraction        | 0.000159      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.409        |\n",
      "|    explained_variance   | 0.0191        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.01e+03      |\n",
      "|    n_updates            | 22900         |\n",
      "|    policy_gradient_loss | -0.00102      |\n",
      "|    value_loss           | 1.97e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1548          |\n",
      "|    iterations           | 1936          |\n",
      "|    time_elapsed         | 10242         |\n",
      "|    total_timesteps      | 15859712      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011931218 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.407        |\n",
      "|    explained_variance   | 0.045         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 756           |\n",
      "|    n_updates            | 22910         |\n",
      "|    policy_gradient_loss | -0.000582     |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1548         |\n",
      "|    iterations           | 1937         |\n",
      "|    time_elapsed         | 10246        |\n",
      "|    total_timesteps      | 15867904     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001038875 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.406       |\n",
      "|    explained_variance   | 0.0253       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 22920        |\n",
      "|    policy_gradient_loss | -0.000493    |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1548         |\n",
      "|    iterations           | 1938         |\n",
      "|    time_elapsed         | 10252        |\n",
      "|    total_timesteps      | 15876096     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.500942e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.408       |\n",
      "|    explained_variance   | 0.0382       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.08e+03     |\n",
      "|    n_updates            | 22930        |\n",
      "|    policy_gradient_loss | -0.000345    |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15880000, episode_reward=635.80 +/- 59.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 636          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 15880000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.438147e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.408       |\n",
      "|    explained_variance   | 0.0413       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 22940        |\n",
      "|    policy_gradient_loss | -0.000448    |\n",
      "|    value_loss           | 1.99e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1547     |\n",
      "|    iterations      | 1939     |\n",
      "|    time_elapsed    | 10264    |\n",
      "|    total_timesteps | 15884288 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1547         |\n",
      "|    iterations           | 1940         |\n",
      "|    time_elapsed         | 10269        |\n",
      "|    total_timesteps      | 15892480     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002248972 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.406       |\n",
      "|    explained_variance   | 0.062        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 908          |\n",
      "|    n_updates            | 22950        |\n",
      "|    policy_gradient_loss | -0.000768    |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1547          |\n",
      "|    iterations           | 1941          |\n",
      "|    time_elapsed         | 10274         |\n",
      "|    total_timesteps      | 15900672      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011979614 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.408        |\n",
      "|    explained_variance   | 0.0539        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 887           |\n",
      "|    n_updates            | 22960         |\n",
      "|    policy_gradient_loss | -0.000493     |\n",
      "|    value_loss           | 1.76e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1547          |\n",
      "|    iterations           | 1942          |\n",
      "|    time_elapsed         | 10280         |\n",
      "|    total_timesteps      | 15908864      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.7715886e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.413        |\n",
      "|    explained_variance   | 0.0217        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 836           |\n",
      "|    n_updates            | 22970         |\n",
      "|    policy_gradient_loss | -0.000368     |\n",
      "|    value_loss           | 1.8e+03       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1547          |\n",
      "|    iterations           | 1943          |\n",
      "|    time_elapsed         | 10288         |\n",
      "|    total_timesteps      | 15917056      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012948105 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.403        |\n",
      "|    explained_variance   | 0.0455        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 832           |\n",
      "|    n_updates            | 22980         |\n",
      "|    policy_gradient_loss | -0.00053      |\n",
      "|    value_loss           | 2.03e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=15920000, episode_reward=647.60 +/- 48.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 648           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15920000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033647183 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.389        |\n",
      "|    explained_variance   | 0.0295        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.14e+03      |\n",
      "|    n_updates            | 22990         |\n",
      "|    policy_gradient_loss | -0.00085      |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1545     |\n",
      "|    iterations      | 1944     |\n",
      "|    time_elapsed    | 10302    |\n",
      "|    total_timesteps | 15925248 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1545          |\n",
      "|    iterations           | 1945          |\n",
      "|    time_elapsed         | 10307         |\n",
      "|    total_timesteps      | 15933440      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.5266656e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.413        |\n",
      "|    explained_variance   | 0.0472        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 610           |\n",
      "|    n_updates            | 23000         |\n",
      "|    policy_gradient_loss | -0.000414     |\n",
      "|    value_loss           | 1.81e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1545          |\n",
      "|    iterations           | 1946          |\n",
      "|    time_elapsed         | 10312         |\n",
      "|    total_timesteps      | 15941632      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022802882 |\n",
      "|    clip_fraction        | 0.00011       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.4          |\n",
      "|    explained_variance   | 0.0244        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.08e+03      |\n",
      "|    n_updates            | 23010         |\n",
      "|    policy_gradient_loss | -0.000663     |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1545          |\n",
      "|    iterations           | 1947          |\n",
      "|    time_elapsed         | 10317         |\n",
      "|    total_timesteps      | 15949824      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016475415 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.399        |\n",
      "|    explained_variance   | 0.0477        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.52e+03      |\n",
      "|    n_updates            | 23020         |\n",
      "|    policy_gradient_loss | -0.000437     |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1545          |\n",
      "|    iterations           | 1948          |\n",
      "|    time_elapsed         | 10325         |\n",
      "|    total_timesteps      | 15958016      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014030073 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.408        |\n",
      "|    explained_variance   | 0.0339        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 829           |\n",
      "|    n_updates            | 23030         |\n",
      "|    policy_gradient_loss | -0.000469     |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=15960000, episode_reward=654.00 +/- 55.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 654           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15960000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014328652 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.414        |\n",
      "|    explained_variance   | 0.0398        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 941           |\n",
      "|    n_updates            | 23040         |\n",
      "|    policy_gradient_loss | -0.000513     |\n",
      "|    value_loss           | 1.84e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1544     |\n",
      "|    iterations      | 1949     |\n",
      "|    time_elapsed    | 10339    |\n",
      "|    total_timesteps | 15966208 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1544          |\n",
      "|    iterations           | 1950          |\n",
      "|    time_elapsed         | 10343         |\n",
      "|    total_timesteps      | 15974400      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019427929 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.4          |\n",
      "|    explained_variance   | 0.0439        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.04e+03      |\n",
      "|    n_updates            | 23050         |\n",
      "|    policy_gradient_loss | -0.000732     |\n",
      "|    value_loss           | 1.84e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1543         |\n",
      "|    iterations           | 1951         |\n",
      "|    time_elapsed         | 10352        |\n",
      "|    total_timesteps      | 15982592     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001528516 |\n",
      "|    clip_fraction        | 1.22e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.407       |\n",
      "|    explained_variance   | 0.0586       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 23060        |\n",
      "|    policy_gradient_loss | -0.000754    |\n",
      "|    value_loss           | 2.04e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1543          |\n",
      "|    iterations           | 1952          |\n",
      "|    time_elapsed         | 10359         |\n",
      "|    total_timesteps      | 15990784      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015817485 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.39         |\n",
      "|    explained_variance   | 0.0457        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.08e+03      |\n",
      "|    n_updates            | 23070         |\n",
      "|    policy_gradient_loss | -0.000567     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1543          |\n",
      "|    iterations           | 1953          |\n",
      "|    time_elapsed         | 10364         |\n",
      "|    total_timesteps      | 15998976      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013546852 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.408        |\n",
      "|    explained_variance   | 0.0747        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 779           |\n",
      "|    n_updates            | 23080         |\n",
      "|    policy_gradient_loss | -0.000534     |\n",
      "|    value_loss           | 1.8e+03       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=16000000, episode_reward=664.60 +/- 52.85\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 665           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 16000000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.8619636e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.407        |\n",
      "|    explained_variance   | 0.071         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.08e+03      |\n",
      "|    n_updates            | 23090         |\n",
      "|    policy_gradient_loss | -0.000269     |\n",
      "|    value_loss           | 2e+03         |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1542     |\n",
      "|    iterations      | 1954     |\n",
      "|    time_elapsed    | 10379    |\n",
      "|    total_timesteps | 16007168 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1541         |\n",
      "|    iterations           | 1955         |\n",
      "|    time_elapsed         | 10387        |\n",
      "|    total_timesteps      | 16015360     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.710698e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.396       |\n",
      "|    explained_variance   | 0.0643       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 714          |\n",
      "|    n_updates            | 23100        |\n",
      "|    policy_gradient_loss | -0.00034     |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1541          |\n",
      "|    iterations           | 1956          |\n",
      "|    time_elapsed         | 10396         |\n",
      "|    total_timesteps      | 16023552      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018026847 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.412        |\n",
      "|    explained_variance   | 0.0529        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 940           |\n",
      "|    n_updates            | 23110         |\n",
      "|    policy_gradient_loss | -0.000603     |\n",
      "|    value_loss           | 2.01e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1541        |\n",
      "|    iterations           | 1957        |\n",
      "|    time_elapsed         | 10401       |\n",
      "|    total_timesteps      | 16031744    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 6.61679e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.401      |\n",
      "|    explained_variance   | 0.0468      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 930         |\n",
      "|    n_updates            | 23120       |\n",
      "|    policy_gradient_loss | -0.000339   |\n",
      "|    value_loss           | 1.85e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1538         |\n",
      "|    iterations           | 1958         |\n",
      "|    time_elapsed         | 10425        |\n",
      "|    total_timesteps      | 16039936     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.429231e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.0551       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.21e+03     |\n",
      "|    n_updates            | 23130        |\n",
      "|    policy_gradient_loss | -0.000421    |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=16040000, episode_reward=658.80 +/- 58.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 659           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 16040000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021912875 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.407        |\n",
      "|    explained_variance   | 0.0642        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 894           |\n",
      "|    n_updates            | 23140         |\n",
      "|    policy_gradient_loss | -0.000667     |\n",
      "|    value_loss           | 1.78e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1537     |\n",
      "|    iterations      | 1959     |\n",
      "|    time_elapsed    | 10439    |\n",
      "|    total_timesteps | 16048128 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1537         |\n",
      "|    iterations           | 1960         |\n",
      "|    time_elapsed         | 10444        |\n",
      "|    total_timesteps      | 16056320     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.228198e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.403       |\n",
      "|    explained_variance   | 0.0521       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 758          |\n",
      "|    n_updates            | 23150        |\n",
      "|    policy_gradient_loss | -0.000434    |\n",
      "|    value_loss           | 2.06e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 1536           |\n",
      "|    iterations           | 1961           |\n",
      "|    time_elapsed         | 10452          |\n",
      "|    total_timesteps      | 16064512       |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000103968516 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.399         |\n",
      "|    explained_variance   | 0.0532         |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 933            |\n",
      "|    n_updates            | 23160          |\n",
      "|    policy_gradient_loss | -0.000494      |\n",
      "|    value_loss           | 1.92e+03       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1536         |\n",
      "|    iterations           | 1962         |\n",
      "|    time_elapsed         | 10457        |\n",
      "|    total_timesteps      | 16072704     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.807816e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.4         |\n",
      "|    explained_variance   | 0.0467       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 23170        |\n",
      "|    policy_gradient_loss | -0.000324    |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=16080000, episode_reward=653.20 +/- 51.24\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 653          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16080000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.662285e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.392       |\n",
      "|    explained_variance   | 0.069        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 840          |\n",
      "|    n_updates            | 23180        |\n",
      "|    policy_gradient_loss | -0.000352    |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1535     |\n",
      "|    iterations      | 1963     |\n",
      "|    time_elapsed    | 10470    |\n",
      "|    total_timesteps | 16080896 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1533         |\n",
      "|    iterations           | 1964         |\n",
      "|    time_elapsed         | 10490        |\n",
      "|    total_timesteps      | 16089088     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002685889 |\n",
      "|    clip_fraction        | 2.44e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.409       |\n",
      "|    explained_variance   | 0.0217       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 23190        |\n",
      "|    policy_gradient_loss | -0.000729    |\n",
      "|    value_loss           | 2.04e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1533          |\n",
      "|    iterations           | 1965          |\n",
      "|    time_elapsed         | 10496         |\n",
      "|    total_timesteps      | 16097280      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011562879 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.401        |\n",
      "|    explained_variance   | 0.01          |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.07e+03      |\n",
      "|    n_updates            | 23200         |\n",
      "|    policy_gradient_loss | -0.000462     |\n",
      "|    value_loss           | 1.83e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1533          |\n",
      "|    iterations           | 1966          |\n",
      "|    time_elapsed         | 10501         |\n",
      "|    total_timesteps      | 16105472      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012703075 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.383        |\n",
      "|    explained_variance   | 0.049         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.05e+03      |\n",
      "|    n_updates            | 23210         |\n",
      "|    policy_gradient_loss | -0.000611     |\n",
      "|    value_loss           | 1.93e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1533         |\n",
      "|    iterations           | 1967         |\n",
      "|    time_elapsed         | 10509        |\n",
      "|    total_timesteps      | 16113664     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.895091e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.402       |\n",
      "|    explained_variance   | 0.0416       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 873          |\n",
      "|    n_updates            | 23220        |\n",
      "|    policy_gradient_loss | -0.000372    |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=16120000, episode_reward=666.60 +/- 57.57\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 667           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 16120000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011181369 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.403        |\n",
      "|    explained_variance   | 0.0261        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.07e+03      |\n",
      "|    n_updates            | 23230         |\n",
      "|    policy_gradient_loss | -0.000468     |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1532     |\n",
      "|    iterations      | 1968     |\n",
      "|    time_elapsed    | 10522    |\n",
      "|    total_timesteps | 16121856 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1531         |\n",
      "|    iterations           | 1969         |\n",
      "|    time_elapsed         | 10533        |\n",
      "|    total_timesteps      | 16130048     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.324535e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.398       |\n",
      "|    explained_variance   | 0.0328       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 786          |\n",
      "|    n_updates            | 23240        |\n",
      "|    policy_gradient_loss | -0.000449    |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1529          |\n",
      "|    iterations           | 1970          |\n",
      "|    time_elapsed         | 10552         |\n",
      "|    total_timesteps      | 16138240      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017997655 |\n",
      "|    clip_fraction        | 0.000134      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.391        |\n",
      "|    explained_variance   | -0.00833      |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 838           |\n",
      "|    n_updates            | 23250         |\n",
      "|    policy_gradient_loss | -0.000524     |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1529        |\n",
      "|    iterations           | 1971        |\n",
      "|    time_elapsed         | 10557       |\n",
      "|    total_timesteps      | 16146432    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 7.58574e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.399      |\n",
      "|    explained_variance   | 0.0449      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 930         |\n",
      "|    n_updates            | 23260       |\n",
      "|    policy_gradient_loss | -0.000398   |\n",
      "|    value_loss           | 2e+03       |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1529          |\n",
      "|    iterations           | 1972          |\n",
      "|    time_elapsed         | 10562         |\n",
      "|    total_timesteps      | 16154624      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013106273 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.389        |\n",
      "|    explained_variance   | 0.0395        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 965           |\n",
      "|    n_updates            | 23270         |\n",
      "|    policy_gradient_loss | -0.00051      |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=16160000, episode_reward=642.20 +/- 52.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 642           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 16160000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011165426 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.393        |\n",
      "|    explained_variance   | 0.0259        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 851           |\n",
      "|    n_updates            | 23280         |\n",
      "|    policy_gradient_loss | -0.000532     |\n",
      "|    value_loss           | 1.98e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1523     |\n",
      "|    iterations      | 1973     |\n",
      "|    time_elapsed    | 10606    |\n",
      "|    total_timesteps | 16162816 |\n",
      "---------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 1523           |\n",
      "|    iterations           | 1974           |\n",
      "|    time_elapsed         | 10612          |\n",
      "|    total_timesteps      | 16171008       |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000121722296 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.405         |\n",
      "|    explained_variance   | 0.0718         |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 970            |\n",
      "|    n_updates            | 23290          |\n",
      "|    policy_gradient_loss | -0.000404      |\n",
      "|    value_loss           | 1.9e+03        |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1523          |\n",
      "|    iterations           | 1975          |\n",
      "|    time_elapsed         | 10617         |\n",
      "|    total_timesteps      | 16179200      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017948105 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.388        |\n",
      "|    explained_variance   | 0.0495        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.04e+03      |\n",
      "|    n_updates            | 23300         |\n",
      "|    policy_gradient_loss | -0.000573     |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1521         |\n",
      "|    iterations           | 1976         |\n",
      "|    time_elapsed         | 10636        |\n",
      "|    total_timesteps      | 16187392     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.333661e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.391       |\n",
      "|    explained_variance   | 0.0517       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 959          |\n",
      "|    n_updates            | 23310        |\n",
      "|    policy_gradient_loss | -0.000424    |\n",
      "|    value_loss           | 2.09e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1521         |\n",
      "|    iterations           | 1977         |\n",
      "|    time_elapsed         | 10641        |\n",
      "|    total_timesteps      | 16195584     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.070627e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.393       |\n",
      "|    explained_variance   | 0.0285       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 864          |\n",
      "|    n_updates            | 23320        |\n",
      "|    policy_gradient_loss | -0.000381    |\n",
      "|    value_loss           | 1.96e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=16200000, episode_reward=664.00 +/- 63.25\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 664           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 16200000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011723863 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.406        |\n",
      "|    explained_variance   | 0.0227        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1e+03         |\n",
      "|    n_updates            | 23330         |\n",
      "|    policy_gradient_loss | -0.000506     |\n",
      "|    value_loss           | 1.87e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1520     |\n",
      "|    iterations      | 1978     |\n",
      "|    time_elapsed    | 10653    |\n",
      "|    total_timesteps | 16203776 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1521         |\n",
      "|    iterations           | 1979         |\n",
      "|    time_elapsed         | 10658        |\n",
      "|    total_timesteps      | 16211968     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.273552e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.392       |\n",
      "|    explained_variance   | 0.0128       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 979          |\n",
      "|    n_updates            | 23340        |\n",
      "|    policy_gradient_loss | -0.000404    |\n",
      "|    value_loss           | 1.91e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1520          |\n",
      "|    iterations           | 1980          |\n",
      "|    time_elapsed         | 10668         |\n",
      "|    total_timesteps      | 16220160      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018358266 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.399        |\n",
      "|    explained_variance   | 0.0332        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.14e+03      |\n",
      "|    n_updates            | 23350         |\n",
      "|    policy_gradient_loss | -0.000761     |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1519          |\n",
      "|    iterations           | 1981          |\n",
      "|    time_elapsed         | 10681         |\n",
      "|    total_timesteps      | 16228352      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020427744 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.399        |\n",
      "|    explained_variance   | 0.0378        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 846           |\n",
      "|    n_updates            | 23360         |\n",
      "|    policy_gradient_loss | -0.000677     |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1519          |\n",
      "|    iterations           | 1982          |\n",
      "|    time_elapsed         | 10685         |\n",
      "|    total_timesteps      | 16236544      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015880287 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.392        |\n",
      "|    explained_variance   | 0.0132        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1e+03         |\n",
      "|    n_updates            | 23370         |\n",
      "|    policy_gradient_loss | -0.000556     |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=16240000, episode_reward=656.20 +/- 47.37\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 656          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16240000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.289599e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.394       |\n",
      "|    explained_variance   | 0.0241       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 23380        |\n",
      "|    policy_gradient_loss | -0.000407    |\n",
      "|    value_loss           | 1.97e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1516     |\n",
      "|    iterations      | 1983     |\n",
      "|    time_elapsed    | 10708    |\n",
      "|    total_timesteps | 16244736 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1517         |\n",
      "|    iterations           | 1984         |\n",
      "|    time_elapsed         | 10713        |\n",
      "|    total_timesteps      | 16252928     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001590357 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.406       |\n",
      "|    explained_variance   | 0.048        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 849          |\n",
      "|    n_updates            | 23390        |\n",
      "|    policy_gradient_loss | -0.00059     |\n",
      "|    value_loss           | 1.97e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1517         |\n",
      "|    iterations           | 1985         |\n",
      "|    time_elapsed         | 10718        |\n",
      "|    total_timesteps      | 16261120     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001691044 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.399       |\n",
      "|    explained_variance   | 0.0382       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 858          |\n",
      "|    n_updates            | 23400        |\n",
      "|    policy_gradient_loss | -0.000576    |\n",
      "|    value_loss           | 2.01e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1516          |\n",
      "|    iterations           | 1986          |\n",
      "|    time_elapsed         | 10729         |\n",
      "|    total_timesteps      | 16269312      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015781997 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.391        |\n",
      "|    explained_variance   | 0.0258        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 666           |\n",
      "|    n_updates            | 23410         |\n",
      "|    policy_gradient_loss | -0.000605     |\n",
      "|    value_loss           | 1.97e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1516          |\n",
      "|    iterations           | 1987          |\n",
      "|    time_elapsed         | 10733         |\n",
      "|    total_timesteps      | 16277504      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021217657 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.406        |\n",
      "|    explained_variance   | 0.0465        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.26e+03      |\n",
      "|    n_updates            | 23420         |\n",
      "|    policy_gradient_loss | -0.000589     |\n",
      "|    value_loss           | 1.81e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=16280000, episode_reward=667.40 +/- 58.68\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 667           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 16280000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023192642 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.4          |\n",
      "|    explained_variance   | 0.0194        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 915           |\n",
      "|    n_updates            | 23430         |\n",
      "|    policy_gradient_loss | -0.000649     |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1513     |\n",
      "|    iterations      | 1988     |\n",
      "|    time_elapsed    | 10756    |\n",
      "|    total_timesteps | 16285696 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1512          |\n",
      "|    iterations           | 1989          |\n",
      "|    time_elapsed         | 10772         |\n",
      "|    total_timesteps      | 16293888      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017456454 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.4          |\n",
      "|    explained_variance   | 0.0256        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 969           |\n",
      "|    n_updates            | 23440         |\n",
      "|    policy_gradient_loss | -0.000521     |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1500          |\n",
      "|    iterations           | 1990          |\n",
      "|    time_elapsed         | 10862         |\n",
      "|    total_timesteps      | 16302080      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020063146 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.391        |\n",
      "|    explained_variance   | 0.0275        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.04e+03      |\n",
      "|    n_updates            | 23450         |\n",
      "|    policy_gradient_loss | -0.000694     |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1500          |\n",
      "|    iterations           | 1991          |\n",
      "|    time_elapsed         | 10866         |\n",
      "|    total_timesteps      | 16310272      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018995997 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.402        |\n",
      "|    explained_variance   | 0.0645        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 681           |\n",
      "|    n_updates            | 23460         |\n",
      "|    policy_gradient_loss | -0.000569     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1501          |\n",
      "|    iterations           | 1992          |\n",
      "|    time_elapsed         | 10871         |\n",
      "|    total_timesteps      | 16318464      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021238902 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.4          |\n",
      "|    explained_variance   | 0.0472        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 970           |\n",
      "|    n_updates            | 23470         |\n",
      "|    policy_gradient_loss | -0.000662     |\n",
      "|    value_loss           | 1.93e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=16320000, episode_reward=669.20 +/- 57.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 669           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 16320000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014558359 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.39         |\n",
      "|    explained_variance   | 0.0435        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.16e+03      |\n",
      "|    n_updates            | 23480         |\n",
      "|    policy_gradient_loss | -0.000486     |\n",
      "|    value_loss           | 2.13e+03      |\n",
      "-------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1497     |\n",
      "|    iterations      | 1993     |\n",
      "|    time_elapsed    | 10904    |\n",
      "|    total_timesteps | 16326656 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1497          |\n",
      "|    iterations           | 1994          |\n",
      "|    time_elapsed         | 10908         |\n",
      "|    total_timesteps      | 16334848      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011829338 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.395        |\n",
      "|    explained_variance   | 0.0318        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 665           |\n",
      "|    n_updates            | 23490         |\n",
      "|    policy_gradient_loss | -0.000617     |\n",
      "|    value_loss           | 1.82e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1497          |\n",
      "|    iterations           | 1995          |\n",
      "|    time_elapsed         | 10913         |\n",
      "|    total_timesteps      | 16343040      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015457798 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.394        |\n",
      "|    explained_variance   | 0.0389        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.04e+03      |\n",
      "|    n_updates            | 23500         |\n",
      "|    policy_gradient_loss | -0.000666     |\n",
      "|    value_loss           | 1.94e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1492         |\n",
      "|    iterations           | 1996         |\n",
      "|    time_elapsed         | 10955        |\n",
      "|    total_timesteps      | 16351232     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.496434e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.398       |\n",
      "|    explained_variance   | 0.0268       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 791          |\n",
      "|    n_updates            | 23510        |\n",
      "|    policy_gradient_loss | -0.000329    |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1489          |\n",
      "|    iterations           | 1997          |\n",
      "|    time_elapsed         | 10983         |\n",
      "|    total_timesteps      | 16359424      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017744728 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.39         |\n",
      "|    explained_variance   | 0.0412        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.03e+03      |\n",
      "|    n_updates            | 23520         |\n",
      "|    policy_gradient_loss | -0.000606     |\n",
      "|    value_loss           | 2.07e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=16360000, episode_reward=658.80 +/- 57.64\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 659          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16360000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001920423 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.392       |\n",
      "|    explained_variance   | 0.0582       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 23530        |\n",
      "|    policy_gradient_loss | -0.000514    |\n",
      "|    value_loss           | 1.93e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1485     |\n",
      "|    iterations      | 1998     |\n",
      "|    time_elapsed    | 11020    |\n",
      "|    total_timesteps | 16367616 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1485          |\n",
      "|    iterations           | 1999          |\n",
      "|    time_elapsed         | 11025         |\n",
      "|    total_timesteps      | 16375808      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013457159 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.383        |\n",
      "|    explained_variance   | 0.0237        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.15e+03      |\n",
      "|    n_updates            | 23540         |\n",
      "|    policy_gradient_loss | -0.000561     |\n",
      "|    value_loss           | 1.93e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1484          |\n",
      "|    iterations           | 2000          |\n",
      "|    time_elapsed         | 11036         |\n",
      "|    total_timesteps      | 16384000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.9595764e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.394        |\n",
      "|    explained_variance   | 0.00985       |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.16e+03      |\n",
      "|    n_updates            | 23550         |\n",
      "|    policy_gradient_loss | -0.000391     |\n",
      "|    value_loss           | 1.76e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1484          |\n",
      "|    iterations           | 2001          |\n",
      "|    time_elapsed         | 11040         |\n",
      "|    total_timesteps      | 16392192      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015131099 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.389        |\n",
      "|    explained_variance   | 0.0554        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 969           |\n",
      "|    n_updates            | 23560         |\n",
      "|    policy_gradient_loss | -0.000502     |\n",
      "|    value_loss           | 2e+03         |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=16400000, episode_reward=657.20 +/- 52.65\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 657           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 16400000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013093656 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.401        |\n",
      "|    explained_variance   | 0.0202        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 972           |\n",
      "|    n_updates            | 23570         |\n",
      "|    policy_gradient_loss | -0.000451     |\n",
      "|    value_loss           | 1.85e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1483     |\n",
      "|    iterations      | 2002     |\n",
      "|    time_elapsed    | 11051    |\n",
      "|    total_timesteps | 16400384 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1484         |\n",
      "|    iterations           | 2003         |\n",
      "|    time_elapsed         | 11056        |\n",
      "|    total_timesteps      | 16408576     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.060601e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.393       |\n",
      "|    explained_variance   | 0.0515       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 883          |\n",
      "|    n_updates            | 23580        |\n",
      "|    policy_gradient_loss | -0.000465    |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1482          |\n",
      "|    iterations           | 2004          |\n",
      "|    time_elapsed         | 11071         |\n",
      "|    total_timesteps      | 16416768      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017911299 |\n",
      "|    clip_fraction        | 6.1e-05       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.395        |\n",
      "|    explained_variance   | 0.0383        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.04e+03      |\n",
      "|    n_updates            | 23590         |\n",
      "|    policy_gradient_loss | -0.000591     |\n",
      "|    value_loss           | 1.84e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1482          |\n",
      "|    iterations           | 2005          |\n",
      "|    time_elapsed         | 11078         |\n",
      "|    total_timesteps      | 16424960      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.9348574e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.383        |\n",
      "|    explained_variance   | 0.0355        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 710           |\n",
      "|    n_updates            | 23600         |\n",
      "|    policy_gradient_loss | -0.000364     |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1482          |\n",
      "|    iterations           | 2006          |\n",
      "|    time_elapsed         | 11083         |\n",
      "|    total_timesteps      | 16433152      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.2230905e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.4          |\n",
      "|    explained_variance   | 0.0468        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.3e+03       |\n",
      "|    n_updates            | 23610         |\n",
      "|    policy_gradient_loss | -0.000397     |\n",
      "|    value_loss           | 1.98e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=16440000, episode_reward=646.80 +/- 42.16\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 647           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 16440000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013271035 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.391        |\n",
      "|    explained_variance   | 0.0336        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 893           |\n",
      "|    n_updates            | 23620         |\n",
      "|    policy_gradient_loss | -0.000504     |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1481     |\n",
      "|    iterations      | 2007     |\n",
      "|    time_elapsed    | 11094    |\n",
      "|    total_timesteps | 16441344 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1482          |\n",
      "|    iterations           | 2008          |\n",
      "|    time_elapsed         | 11098         |\n",
      "|    total_timesteps      | 16449536      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013081639 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.395        |\n",
      "|    explained_variance   | 0.0375        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 984           |\n",
      "|    n_updates            | 23630         |\n",
      "|    policy_gradient_loss | -0.000459     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1468         |\n",
      "|    iterations           | 2009         |\n",
      "|    time_elapsed         | 11208        |\n",
      "|    total_timesteps      | 16457728     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002422217 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.387       |\n",
      "|    explained_variance   | 0.0548       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 23640        |\n",
      "|    policy_gradient_loss | -0.000761    |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1468         |\n",
      "|    iterations           | 2010         |\n",
      "|    time_elapsed         | 11212        |\n",
      "|    total_timesteps      | 16465920     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.992532e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.399       |\n",
      "|    explained_variance   | 0.0275       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 684          |\n",
      "|    n_updates            | 23650        |\n",
      "|    policy_gradient_loss | -0.000442    |\n",
      "|    value_loss           | 2.01e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1468          |\n",
      "|    iterations           | 2011          |\n",
      "|    time_elapsed         | 11217         |\n",
      "|    total_timesteps      | 16474112      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029319868 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.39         |\n",
      "|    explained_variance   | 0.036         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 752           |\n",
      "|    n_updates            | 23660         |\n",
      "|    policy_gradient_loss | -0.000846     |\n",
      "|    value_loss           | 1.79e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=16480000, episode_reward=652.40 +/- 46.02\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 652          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16480000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.610369e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.38        |\n",
      "|    explained_variance   | 0.0714       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 777          |\n",
      "|    n_updates            | 23670        |\n",
      "|    policy_gradient_loss | -0.000398    |\n",
      "|    value_loss           | 1.92e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1459     |\n",
      "|    iterations      | 2012     |\n",
      "|    time_elapsed    | 11292    |\n",
      "|    total_timesteps | 16482304 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1459          |\n",
      "|    iterations           | 2013          |\n",
      "|    time_elapsed         | 11297         |\n",
      "|    total_timesteps      | 16490496      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015187453 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.386        |\n",
      "|    explained_variance   | 0.0212        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 811           |\n",
      "|    n_updates            | 23680         |\n",
      "|    policy_gradient_loss | -0.000492     |\n",
      "|    value_loss           | 1.84e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1459         |\n",
      "|    iterations           | 2014         |\n",
      "|    time_elapsed         | 11301        |\n",
      "|    total_timesteps      | 16498688     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.809277e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.378       |\n",
      "|    explained_variance   | 0.0355       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.24e+03     |\n",
      "|    n_updates            | 23690        |\n",
      "|    policy_gradient_loss | -0.000378    |\n",
      "|    value_loss           | 2.07e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1459         |\n",
      "|    iterations           | 2015         |\n",
      "|    time_elapsed         | 11306        |\n",
      "|    total_timesteps      | 16506880     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.659385e-05 |\n",
      "|    clip_fraction        | 1.22e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.388       |\n",
      "|    explained_variance   | 0.0283       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 809          |\n",
      "|    n_updates            | 23700        |\n",
      "|    policy_gradient_loss | -0.000468    |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1458          |\n",
      "|    iterations           | 2016          |\n",
      "|    time_elapsed         | 11321         |\n",
      "|    total_timesteps      | 16515072      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010143365 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.376        |\n",
      "|    explained_variance   | 0.0269        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.19e+03      |\n",
      "|    n_updates            | 23710         |\n",
      "|    policy_gradient_loss | -0.000467     |\n",
      "|    value_loss           | 1.84e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=16520000, episode_reward=652.20 +/- 64.01\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 652           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 16520000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013482643 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.383        |\n",
      "|    explained_variance   | 0.041         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.01e+03      |\n",
      "|    n_updates            | 23720         |\n",
      "|    policy_gradient_loss | -0.000474     |\n",
      "|    value_loss           | 1.82e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1455     |\n",
      "|    iterations      | 2017     |\n",
      "|    time_elapsed    | 11351    |\n",
      "|    total_timesteps | 16523264 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1455          |\n",
      "|    iterations           | 2018          |\n",
      "|    time_elapsed         | 11356         |\n",
      "|    total_timesteps      | 16531456      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012956688 |\n",
      "|    clip_fraction        | 3.66e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.392        |\n",
      "|    explained_variance   | 0.036         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 883           |\n",
      "|    n_updates            | 23730         |\n",
      "|    policy_gradient_loss | -0.000541     |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1455          |\n",
      "|    iterations           | 2019          |\n",
      "|    time_elapsed         | 11361         |\n",
      "|    total_timesteps      | 16539648      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012871543 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.391        |\n",
      "|    explained_variance   | 0.0595        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1e+03         |\n",
      "|    n_updates            | 23740         |\n",
      "|    policy_gradient_loss | -0.000449     |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1452         |\n",
      "|    iterations           | 2020         |\n",
      "|    time_elapsed         | 11395        |\n",
      "|    total_timesteps      | 16547840     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.701314e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.386       |\n",
      "|    explained_variance   | 0.0482       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 23750        |\n",
      "|    policy_gradient_loss | -0.00051     |\n",
      "|    value_loss           | 1.98e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1452         |\n",
      "|    iterations           | 2021         |\n",
      "|    time_elapsed         | 11400        |\n",
      "|    total_timesteps      | 16556032     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001105321 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.393       |\n",
      "|    explained_variance   | 0.0403       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 993          |\n",
      "|    n_updates            | 23760        |\n",
      "|    policy_gradient_loss | -0.000518    |\n",
      "|    value_loss           | 1.78e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=16560000, episode_reward=646.40 +/- 51.49\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 646           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 16560000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.6314045e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.38         |\n",
      "|    explained_variance   | 0.0274        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 987           |\n",
      "|    n_updates            | 23770         |\n",
      "|    policy_gradient_loss | -0.000412     |\n",
      "|    value_loss           | 2.09e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1451     |\n",
      "|    iterations      | 2022     |\n",
      "|    time_elapsed    | 11414    |\n",
      "|    total_timesteps | 16564224 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1446          |\n",
      "|    iterations           | 2023          |\n",
      "|    time_elapsed         | 11454         |\n",
      "|    total_timesteps      | 16572416      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017410242 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.388        |\n",
      "|    explained_variance   | 0.0837        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 857           |\n",
      "|    n_updates            | 23780         |\n",
      "|    policy_gradient_loss | -0.000558     |\n",
      "|    value_loss           | 1.84e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1446         |\n",
      "|    iterations           | 2024         |\n",
      "|    time_elapsed         | 11459        |\n",
      "|    total_timesteps      | 16580608     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.319115e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.389       |\n",
      "|    explained_variance   | 0.0741       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 23790        |\n",
      "|    policy_gradient_loss | -0.000414    |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1447          |\n",
      "|    iterations           | 2025          |\n",
      "|    time_elapsed         | 11463         |\n",
      "|    total_timesteps      | 16588800      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018691007 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.385        |\n",
      "|    explained_variance   | 0.0495        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.02e+03      |\n",
      "|    n_updates            | 23800         |\n",
      "|    policy_gradient_loss | -0.000613     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1435          |\n",
      "|    iterations           | 2026          |\n",
      "|    time_elapsed         | 11563         |\n",
      "|    total_timesteps      | 16596992      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015286023 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.392        |\n",
      "|    explained_variance   | 0.0311        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.02e+03      |\n",
      "|    n_updates            | 23810         |\n",
      "|    policy_gradient_loss | -0.000621     |\n",
      "|    value_loss           | 2.01e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=16600000, episode_reward=656.40 +/- 65.51\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 656          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16600000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.586683e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.384       |\n",
      "|    explained_variance   | 0.0597       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 785          |\n",
      "|    n_updates            | 23820        |\n",
      "|    policy_gradient_loss | -0.000411    |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1434     |\n",
      "|    iterations      | 2027     |\n",
      "|    time_elapsed    | 11577    |\n",
      "|    total_timesteps | 16605184 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1433         |\n",
      "|    iterations           | 2028         |\n",
      "|    time_elapsed         | 11588        |\n",
      "|    total_timesteps      | 16613376     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.356174e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.395       |\n",
      "|    explained_variance   | 0.0471       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 972          |\n",
      "|    n_updates            | 23830        |\n",
      "|    policy_gradient_loss | -0.000354    |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 1429           |\n",
      "|    iterations           | 2029           |\n",
      "|    time_elapsed         | 11628          |\n",
      "|    total_timesteps      | 16621568       |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000114807895 |\n",
      "|    clip_fraction        | 3.66e-05       |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.39          |\n",
      "|    explained_variance   | 0.0301         |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 822            |\n",
      "|    n_updates            | 23840          |\n",
      "|    policy_gradient_loss | -0.000489      |\n",
      "|    value_loss           | 1.9e+03        |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1429          |\n",
      "|    iterations           | 2030          |\n",
      "|    time_elapsed         | 11633         |\n",
      "|    total_timesteps      | 16629760      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014651546 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.403        |\n",
      "|    explained_variance   | 0.0333        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 799           |\n",
      "|    n_updates            | 23850         |\n",
      "|    policy_gradient_loss | -0.000567     |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1429          |\n",
      "|    iterations           | 2031          |\n",
      "|    time_elapsed         | 11638         |\n",
      "|    total_timesteps      | 16637952      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017190883 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.384        |\n",
      "|    explained_variance   | 0.0273        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.42e+03      |\n",
      "|    n_updates            | 23860         |\n",
      "|    policy_gradient_loss | -0.000594     |\n",
      "|    value_loss           | 1.96e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=16640000, episode_reward=634.80 +/- 68.80\n",
      "Episode length: 200.00 +/- 0.00\n",
      "--------------------------------------------\n",
      "| eval/                   |                |\n",
      "|    mean_ep_length       | 200            |\n",
      "|    mean_reward          | 635            |\n",
      "| time/                   |                |\n",
      "|    total_timesteps      | 16640000       |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000118791126 |\n",
      "|    clip_fraction        | 3.66e-05       |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.382         |\n",
      "|    explained_variance   | 0.026          |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 943            |\n",
      "|    n_updates            | 23870          |\n",
      "|    policy_gradient_loss | -0.000451      |\n",
      "|    value_loss           | 1.83e+03       |\n",
      "--------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1428     |\n",
      "|    iterations      | 2032     |\n",
      "|    time_elapsed    | 11650    |\n",
      "|    total_timesteps | 16646144 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1428          |\n",
      "|    iterations           | 2033          |\n",
      "|    time_elapsed         | 11662         |\n",
      "|    total_timesteps      | 16654336      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019670189 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.384        |\n",
      "|    explained_variance   | 0.0557        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.23e+03      |\n",
      "|    n_updates            | 23880         |\n",
      "|    policy_gradient_loss | -0.000684     |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1427         |\n",
      "|    iterations           | 2034         |\n",
      "|    time_elapsed         | 11671        |\n",
      "|    total_timesteps      | 16662528     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.551281e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.381       |\n",
      "|    explained_variance   | 0.0437       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 895          |\n",
      "|    n_updates            | 23890        |\n",
      "|    policy_gradient_loss | -0.000362    |\n",
      "|    value_loss           | 1.86e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1426         |\n",
      "|    iterations           | 2035         |\n",
      "|    time_elapsed         | 11688        |\n",
      "|    total_timesteps      | 16670720     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001769429 |\n",
      "|    clip_fraction        | 1.22e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.389       |\n",
      "|    explained_variance   | 0.00398      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 875          |\n",
      "|    n_updates            | 23900        |\n",
      "|    policy_gradient_loss | -0.000659    |\n",
      "|    value_loss           | 2.06e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1426          |\n",
      "|    iterations           | 2036          |\n",
      "|    time_elapsed         | 11692         |\n",
      "|    total_timesteps      | 16678912      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011025762 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.386        |\n",
      "|    explained_variance   | 0.0375        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 995           |\n",
      "|    n_updates            | 23910         |\n",
      "|    policy_gradient_loss | -0.000466     |\n",
      "|    value_loss           | 1.83e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=16680000, episode_reward=659.20 +/- 56.81\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 659          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16680000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.851551e-05 |\n",
      "|    clip_fraction        | 2.44e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.388       |\n",
      "|    explained_variance   | 0.0417       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 904          |\n",
      "|    n_updates            | 23920        |\n",
      "|    policy_gradient_loss | -0.000507    |\n",
      "|    value_loss           | 1.98e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1424     |\n",
      "|    iterations      | 2037     |\n",
      "|    time_elapsed    | 11712    |\n",
      "|    total_timesteps | 16687104 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1422         |\n",
      "|    iterations           | 2038         |\n",
      "|    time_elapsed         | 11734        |\n",
      "|    total_timesteps      | 16695296     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.901016e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.383       |\n",
      "|    explained_variance   | 0.0438       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 928          |\n",
      "|    n_updates            | 23930        |\n",
      "|    policy_gradient_loss | -0.000382    |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1420          |\n",
      "|    iterations           | 2039          |\n",
      "|    time_elapsed         | 11760         |\n",
      "|    total_timesteps      | 16703488      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024512448 |\n",
      "|    clip_fraction        | 0.000159      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.393        |\n",
      "|    explained_variance   | 0.0421        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 866           |\n",
      "|    n_updates            | 23940         |\n",
      "|    policy_gradient_loss | -0.000664     |\n",
      "|    value_loss           | 2.06e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1414          |\n",
      "|    iterations           | 2040          |\n",
      "|    time_elapsed         | 11813         |\n",
      "|    total_timesteps      | 16711680      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012613506 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.396        |\n",
      "|    explained_variance   | 0.0402        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.03e+03      |\n",
      "|    n_updates            | 23950         |\n",
      "|    policy_gradient_loss | -0.000496     |\n",
      "|    value_loss           | 1.8e+03       |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 1414           |\n",
      "|    iterations           | 2041           |\n",
      "|    time_elapsed         | 11817          |\n",
      "|    total_timesteps      | 16719872       |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000121826735 |\n",
      "|    clip_fraction        | 3.66e-05       |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.377         |\n",
      "|    explained_variance   | 0.0522         |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 728            |\n",
      "|    n_updates            | 23960          |\n",
      "|    policy_gradient_loss | -0.000538      |\n",
      "|    value_loss           | 1.9e+03        |\n",
      "--------------------------------------------\n",
      "Eval num_timesteps=16720000, episode_reward=650.20 +/- 52.90\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 650           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 16720000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020118844 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.381        |\n",
      "|    explained_variance   | 0.037         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.13e+03      |\n",
      "|    n_updates            | 23970         |\n",
      "|    policy_gradient_loss | -0.00055      |\n",
      "|    value_loss           | 1.87e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1413     |\n",
      "|    iterations      | 2042     |\n",
      "|    time_elapsed    | 11837    |\n",
      "|    total_timesteps | 16728064 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1401          |\n",
      "|    iterations           | 2043          |\n",
      "|    time_elapsed         | 11942         |\n",
      "|    total_timesteps      | 16736256      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012650949 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.395        |\n",
      "|    explained_variance   | 0.032         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.23e+03      |\n",
      "|    n_updates            | 23980         |\n",
      "|    policy_gradient_loss | -0.000488     |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1401          |\n",
      "|    iterations           | 2044          |\n",
      "|    time_elapsed         | 11946         |\n",
      "|    total_timesteps      | 16744448      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011930444 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.395        |\n",
      "|    explained_variance   | 0.0425        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 937           |\n",
      "|    n_updates            | 23990         |\n",
      "|    policy_gradient_loss | -0.000448     |\n",
      "|    value_loss           | 1.87e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1399          |\n",
      "|    iterations           | 2045          |\n",
      "|    time_elapsed         | 11970         |\n",
      "|    total_timesteps      | 16752640      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013153566 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.387        |\n",
      "|    explained_variance   | 0.0337        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 995           |\n",
      "|    n_updates            | 24000         |\n",
      "|    policy_gradient_loss | -0.000502     |\n",
      "|    value_loss           | 1.93e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=16760000, episode_reward=636.20 +/- 66.63\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 636           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 16760000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022567954 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.395        |\n",
      "|    explained_variance   | 0.0443        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 657           |\n",
      "|    n_updates            | 24010         |\n",
      "|    policy_gradient_loss | -0.000655     |\n",
      "|    value_loss           | 1.87e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1389     |\n",
      "|    iterations      | 2046     |\n",
      "|    time_elapsed    | 12061    |\n",
      "|    total_timesteps | 16760832 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1389         |\n",
      "|    iterations           | 2047         |\n",
      "|    time_elapsed         | 12067        |\n",
      "|    total_timesteps      | 16769024     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001726314 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.391       |\n",
      "|    explained_variance   | 0.0353       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 899          |\n",
      "|    n_updates            | 24020        |\n",
      "|    policy_gradient_loss | -0.000634    |\n",
      "|    value_loss           | 2.08e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1381          |\n",
      "|    iterations           | 2048          |\n",
      "|    time_elapsed         | 12141         |\n",
      "|    total_timesteps      | 16777216      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.3979834e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.403        |\n",
      "|    explained_variance   | 0.0576        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.3e+03       |\n",
      "|    n_updates            | 24030         |\n",
      "|    policy_gradient_loss | -0.000422     |\n",
      "|    value_loss           | 1.85e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1378          |\n",
      "|    iterations           | 2049          |\n",
      "|    time_elapsed         | 12172         |\n",
      "|    total_timesteps      | 16785408      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022086686 |\n",
      "|    clip_fraction        | 0.000134      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.399        |\n",
      "|    explained_variance   | 0.0609        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 751           |\n",
      "|    n_updates            | 24040         |\n",
      "|    policy_gradient_loss | -0.000641     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1379          |\n",
      "|    iterations           | 2050          |\n",
      "|    time_elapsed         | 12177         |\n",
      "|    total_timesteps      | 16793600      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012354943 |\n",
      "|    clip_fraction        | 3.66e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.393        |\n",
      "|    explained_variance   | 0.0549        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 989           |\n",
      "|    n_updates            | 24050         |\n",
      "|    policy_gradient_loss | -0.000581     |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=16800000, episode_reward=660.80 +/- 62.51\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 661          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16800000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.228982e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.386       |\n",
      "|    explained_variance   | 0.024        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 837          |\n",
      "|    n_updates            | 24060        |\n",
      "|    policy_gradient_loss | -0.000397    |\n",
      "|    value_loss           | 1.98e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1376     |\n",
      "|    iterations      | 2051     |\n",
      "|    time_elapsed    | 12205    |\n",
      "|    total_timesteps | 16801792 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1370          |\n",
      "|    iterations           | 2052          |\n",
      "|    time_elapsed         | 12266         |\n",
      "|    total_timesteps      | 16809984      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019367028 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.391        |\n",
      "|    explained_variance   | 0.0453        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.01e+03      |\n",
      "|    n_updates            | 24070         |\n",
      "|    policy_gradient_loss | -0.000619     |\n",
      "|    value_loss           | 1.94e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1369          |\n",
      "|    iterations           | 2053          |\n",
      "|    time_elapsed         | 12276         |\n",
      "|    total_timesteps      | 16818176      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014627542 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.392        |\n",
      "|    explained_variance   | 0.0491        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.08e+03      |\n",
      "|    n_updates            | 24080         |\n",
      "|    policy_gradient_loss | -0.000587     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1367         |\n",
      "|    iterations           | 2054         |\n",
      "|    time_elapsed         | 12308        |\n",
      "|    total_timesteps      | 16826368     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.225511e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.383       |\n",
      "|    explained_variance   | 0.0479       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 886          |\n",
      "|    n_updates            | 24090        |\n",
      "|    policy_gradient_loss | -0.000414    |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1365          |\n",
      "|    iterations           | 2055          |\n",
      "|    time_elapsed         | 12327         |\n",
      "|    total_timesteps      | 16834560      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015736243 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.392        |\n",
      "|    explained_variance   | 0.0316        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.18e+03      |\n",
      "|    n_updates            | 24100         |\n",
      "|    policy_gradient_loss | -0.000557     |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=16840000, episode_reward=656.40 +/- 56.21\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 656           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 16840000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030418544 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.394        |\n",
      "|    explained_variance   | 0.0315        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 965           |\n",
      "|    n_updates            | 24110         |\n",
      "|    policy_gradient_loss | -0.000979     |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1363     |\n",
      "|    iterations      | 2056     |\n",
      "|    time_elapsed    | 12354    |\n",
      "|    total_timesteps | 16842752 |\n",
      "---------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 1356           |\n",
      "|    iterations           | 2057           |\n",
      "|    time_elapsed         | 12422          |\n",
      "|    total_timesteps      | 16850944       |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000101440884 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.391         |\n",
      "|    explained_variance   | 0.0234         |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 797            |\n",
      "|    n_updates            | 24120          |\n",
      "|    policy_gradient_loss | -0.000422      |\n",
      "|    value_loss           | 1.82e+03       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2058          |\n",
      "|    time_elapsed         | 12427         |\n",
      "|    total_timesteps      | 16859136      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011522919 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.387        |\n",
      "|    explained_variance   | 0.0423        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 694           |\n",
      "|    n_updates            | 24130         |\n",
      "|    policy_gradient_loss | -0.000423     |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1356         |\n",
      "|    iterations           | 2059         |\n",
      "|    time_elapsed         | 12431        |\n",
      "|    total_timesteps      | 16867328     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.472012e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.396       |\n",
      "|    explained_variance   | 0.0392       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 24140        |\n",
      "|    policy_gradient_loss | -0.000408    |\n",
      "|    value_loss           | 1.94e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2060          |\n",
      "|    time_elapsed         | 12436         |\n",
      "|    total_timesteps      | 16875520      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012512476 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.377        |\n",
      "|    explained_variance   | 0.037         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.15e+03      |\n",
      "|    n_updates            | 24150         |\n",
      "|    policy_gradient_loss | -0.000444     |\n",
      "|    value_loss           | 2.1e+03       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=16880000, episode_reward=632.20 +/- 61.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 632           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 16880000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.9621434e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.387        |\n",
      "|    explained_variance   | 0.0281        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 633           |\n",
      "|    n_updates            | 24160         |\n",
      "|    policy_gradient_loss | -0.000395     |\n",
      "|    value_loss           | 1.85e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1356     |\n",
      "|    iterations      | 2061     |\n",
      "|    time_elapsed    | 12448    |\n",
      "|    total_timesteps | 16883712 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1356         |\n",
      "|    iterations           | 2062         |\n",
      "|    time_elapsed         | 12453        |\n",
      "|    total_timesteps      | 16891904     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.779205e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.386       |\n",
      "|    explained_variance   | 0.045        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 973          |\n",
      "|    n_updates            | 24170        |\n",
      "|    policy_gradient_loss | -0.00041     |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1356        |\n",
      "|    iterations           | 2063        |\n",
      "|    time_elapsed         | 12458       |\n",
      "|    total_timesteps      | 16900096    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000140992 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.375      |\n",
      "|    explained_variance   | 0.0622      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 779         |\n",
      "|    n_updates            | 24180       |\n",
      "|    policy_gradient_loss | -0.000516   |\n",
      "|    value_loss           | 1.83e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2064          |\n",
      "|    time_elapsed         | 12462         |\n",
      "|    total_timesteps      | 16908288      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012093613 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.38         |\n",
      "|    explained_variance   | 0.00599       |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 976           |\n",
      "|    n_updates            | 24190         |\n",
      "|    policy_gradient_loss | -0.000475     |\n",
      "|    value_loss           | 2.03e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1356         |\n",
      "|    iterations           | 2065         |\n",
      "|    time_elapsed         | 12467        |\n",
      "|    total_timesteps      | 16916480     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001894868 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.38        |\n",
      "|    explained_variance   | 0.0452       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 24200        |\n",
      "|    policy_gradient_loss | -0.000593    |\n",
      "|    value_loss           | 1.8e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=16920000, episode_reward=641.00 +/- 49.49\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 641           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 16920000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010490155 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.382        |\n",
      "|    explained_variance   | 0.0366        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.02e+03      |\n",
      "|    n_updates            | 24210         |\n",
      "|    policy_gradient_loss | -0.000427     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1356     |\n",
      "|    iterations      | 2066     |\n",
      "|    time_elapsed    | 12479    |\n",
      "|    total_timesteps | 16924672 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2067          |\n",
      "|    time_elapsed         | 12484         |\n",
      "|    total_timesteps      | 16932864      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013414628 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.391        |\n",
      "|    explained_variance   | 0.0429        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.16e+03      |\n",
      "|    n_updates            | 24220         |\n",
      "|    policy_gradient_loss | -0.000455     |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2068          |\n",
      "|    time_elapsed         | 12489         |\n",
      "|    total_timesteps      | 16941056      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013628122 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.383        |\n",
      "|    explained_variance   | 0.0639        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 979           |\n",
      "|    n_updates            | 24230         |\n",
      "|    policy_gradient_loss | -0.000617     |\n",
      "|    value_loss           | 2.09e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2069          |\n",
      "|    time_elapsed         | 12493         |\n",
      "|    total_timesteps      | 16949248      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014937334 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.387        |\n",
      "|    explained_variance   | 0.0404        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.03e+03      |\n",
      "|    n_updates            | 24240         |\n",
      "|    policy_gradient_loss | -0.00053      |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2070          |\n",
      "|    time_elapsed         | 12498         |\n",
      "|    total_timesteps      | 16957440      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016807861 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.387        |\n",
      "|    explained_variance   | 0.0444        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 808           |\n",
      "|    n_updates            | 24250         |\n",
      "|    policy_gradient_loss | -0.000487     |\n",
      "|    value_loss           | 1.87e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=16960000, episode_reward=660.20 +/- 56.87\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 660           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 16960000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016931945 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.386        |\n",
      "|    explained_variance   | 0.0329        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.08e+03      |\n",
      "|    n_updates            | 24260         |\n",
      "|    policy_gradient_loss | -0.000533     |\n",
      "|    value_loss           | 1.85e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1356     |\n",
      "|    iterations      | 2071     |\n",
      "|    time_elapsed    | 12510    |\n",
      "|    total_timesteps | 16965632 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2072          |\n",
      "|    time_elapsed         | 12515         |\n",
      "|    total_timesteps      | 16973824      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013431878 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.385        |\n",
      "|    explained_variance   | 0.052         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.02e+03      |\n",
      "|    n_updates            | 24270         |\n",
      "|    policy_gradient_loss | -0.000588     |\n",
      "|    value_loss           | 2.07e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2073          |\n",
      "|    time_elapsed         | 12519         |\n",
      "|    total_timesteps      | 16982016      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016341274 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.375        |\n",
      "|    explained_variance   | 0.0473        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.06e+03      |\n",
      "|    n_updates            | 24280         |\n",
      "|    policy_gradient_loss | -0.000589     |\n",
      "|    value_loss           | 1.96e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2074          |\n",
      "|    time_elapsed         | 12524         |\n",
      "|    total_timesteps      | 16990208      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015527513 |\n",
      "|    clip_fraction        | 6.1e-05       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.379        |\n",
      "|    explained_variance   | 0.0372        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 886           |\n",
      "|    n_updates            | 24290         |\n",
      "|    policy_gradient_loss | -0.000489     |\n",
      "|    value_loss           | 1.95e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2075          |\n",
      "|    time_elapsed         | 12529         |\n",
      "|    total_timesteps      | 16998400      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012598922 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.385        |\n",
      "|    explained_variance   | 0.046         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 959           |\n",
      "|    n_updates            | 24300         |\n",
      "|    policy_gradient_loss | -0.000428     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=17000000, episode_reward=657.20 +/- 49.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 657          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 17000000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.873038e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.378       |\n",
      "|    explained_variance   | 0.0574       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 794          |\n",
      "|    n_updates            | 24310        |\n",
      "|    policy_gradient_loss | -0.000357    |\n",
      "|    value_loss           | 2.11e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1356     |\n",
      "|    iterations      | 2076     |\n",
      "|    time_elapsed    | 12541    |\n",
      "|    total_timesteps | 17006592 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1356         |\n",
      "|    iterations           | 2077         |\n",
      "|    time_elapsed         | 12545        |\n",
      "|    total_timesteps      | 17014784     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003469802 |\n",
      "|    clip_fraction        | 0.000354     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.377       |\n",
      "|    explained_variance   | 0.0256       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 912          |\n",
      "|    n_updates            | 24320        |\n",
      "|    policy_gradient_loss | -0.000791    |\n",
      "|    value_loss           | 1.93e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2078          |\n",
      "|    time_elapsed         | 12550         |\n",
      "|    total_timesteps      | 17022976      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012074363 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.377        |\n",
      "|    explained_variance   | 0.0331        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 918           |\n",
      "|    n_updates            | 24330         |\n",
      "|    policy_gradient_loss | -0.000523     |\n",
      "|    value_loss           | 1.95e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1356         |\n",
      "|    iterations           | 2079         |\n",
      "|    time_elapsed         | 12554        |\n",
      "|    total_timesteps      | 17031168     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.861996e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.37        |\n",
      "|    explained_variance   | 0.0402       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 977          |\n",
      "|    n_updates            | 24340        |\n",
      "|    policy_gradient_loss | -0.000308    |\n",
      "|    value_loss           | 1.98e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2080          |\n",
      "|    time_elapsed         | 12559         |\n",
      "|    total_timesteps      | 17039360      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012458157 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.375        |\n",
      "|    explained_variance   | 0.0459        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 830           |\n",
      "|    n_updates            | 24350         |\n",
      "|    policy_gradient_loss | -0.000494     |\n",
      "|    value_loss           | 1.83e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=17040000, episode_reward=650.20 +/- 52.55\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 650          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 17040000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003312647 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.379       |\n",
      "|    explained_variance   | 0.0321       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 969          |\n",
      "|    n_updates            | 24360        |\n",
      "|    policy_gradient_loss | -0.000978    |\n",
      "|    value_loss           | 2.08e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1356     |\n",
      "|    iterations      | 2081     |\n",
      "|    time_elapsed    | 12571    |\n",
      "|    total_timesteps | 17047552 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2082          |\n",
      "|    time_elapsed         | 12575         |\n",
      "|    total_timesteps      | 17055744      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00033436966 |\n",
      "|    clip_fraction        | 8.54e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.371        |\n",
      "|    explained_variance   | 0.0613        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 940           |\n",
      "|    n_updates            | 24370         |\n",
      "|    policy_gradient_loss | -0.000785     |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1356         |\n",
      "|    iterations           | 2083         |\n",
      "|    time_elapsed         | 12580        |\n",
      "|    total_timesteps      | 17063936     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.550158e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.373       |\n",
      "|    explained_variance   | 0.0223       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 929          |\n",
      "|    n_updates            | 24380        |\n",
      "|    policy_gradient_loss | -0.000467    |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2084          |\n",
      "|    time_elapsed         | 12585         |\n",
      "|    total_timesteps      | 17072128      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013325771 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.38         |\n",
      "|    explained_variance   | 0.0433        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 790           |\n",
      "|    n_updates            | 24390         |\n",
      "|    policy_gradient_loss | -0.000478     |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=17080000, episode_reward=653.80 +/- 58.75\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 654           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 17080000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016964955 |\n",
      "|    clip_fraction        | 8.54e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.378        |\n",
      "|    explained_variance   | 0.0384        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 686           |\n",
      "|    n_updates            | 24400         |\n",
      "|    policy_gradient_loss | -0.000546     |\n",
      "|    value_loss           | 2.04e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1355     |\n",
      "|    iterations      | 2085     |\n",
      "|    time_elapsed    | 12596    |\n",
      "|    total_timesteps | 17080320 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1356         |\n",
      "|    iterations           | 2086         |\n",
      "|    time_elapsed         | 12601        |\n",
      "|    total_timesteps      | 17088512     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.249306e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.385       |\n",
      "|    explained_variance   | 0.021        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 24410        |\n",
      "|    policy_gradient_loss | -0.00031     |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2087          |\n",
      "|    time_elapsed         | 12606         |\n",
      "|    total_timesteps      | 17096704      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012021462 |\n",
      "|    clip_fraction        | 3.66e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.389        |\n",
      "|    explained_variance   | 0.0505        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 824           |\n",
      "|    n_updates            | 24420         |\n",
      "|    policy_gradient_loss | -0.000551     |\n",
      "|    value_loss           | 1.94e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2088          |\n",
      "|    time_elapsed         | 12610         |\n",
      "|    total_timesteps      | 17104896      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.8853668e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.388        |\n",
      "|    explained_variance   | 0.0531        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 782           |\n",
      "|    n_updates            | 24430         |\n",
      "|    policy_gradient_loss | -0.000256     |\n",
      "|    value_loss           | 1.97e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1356         |\n",
      "|    iterations           | 2089         |\n",
      "|    time_elapsed         | 12615        |\n",
      "|    total_timesteps      | 17113088     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001551621 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.387       |\n",
      "|    explained_variance   | 0.0423       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 24440        |\n",
      "|    policy_gradient_loss | -0.00063     |\n",
      "|    value_loss           | 2.06e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=17120000, episode_reward=647.40 +/- 64.21\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 647           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 17120000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.0667476e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.377        |\n",
      "|    explained_variance   | 0.0221        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 747           |\n",
      "|    n_updates            | 24450         |\n",
      "|    policy_gradient_loss | -0.000444     |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1355     |\n",
      "|    iterations      | 2090     |\n",
      "|    time_elapsed    | 12627    |\n",
      "|    total_timesteps | 17121280 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2091          |\n",
      "|    time_elapsed         | 12631         |\n",
      "|    total_timesteps      | 17129472      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017396951 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.381        |\n",
      "|    explained_variance   | 0.0444        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.36e+03      |\n",
      "|    n_updates            | 24460         |\n",
      "|    policy_gradient_loss | -0.000693     |\n",
      "|    value_loss           | 1.85e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2092          |\n",
      "|    time_elapsed         | 12636         |\n",
      "|    total_timesteps      | 17137664      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019144354 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.384        |\n",
      "|    explained_variance   | 0.0585        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.01e+03      |\n",
      "|    n_updates            | 24470         |\n",
      "|    policy_gradient_loss | -0.000601     |\n",
      "|    value_loss           | 1.87e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2093          |\n",
      "|    time_elapsed         | 12640         |\n",
      "|    total_timesteps      | 17145856      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012621113 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.39         |\n",
      "|    explained_variance   | 0.0395        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 831           |\n",
      "|    n_updates            | 24480         |\n",
      "|    policy_gradient_loss | -0.000435     |\n",
      "|    value_loss           | 2.04e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1356         |\n",
      "|    iterations           | 2094         |\n",
      "|    time_elapsed         | 12645        |\n",
      "|    total_timesteps      | 17154048     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.033309e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.382       |\n",
      "|    explained_variance   | 0.0405       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.24e+03     |\n",
      "|    n_updates            | 24490        |\n",
      "|    policy_gradient_loss | -0.000409    |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=17160000, episode_reward=649.00 +/- 52.89\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 649          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 17160000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.489406e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.382       |\n",
      "|    explained_variance   | 0.0181       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 913          |\n",
      "|    n_updates            | 24500        |\n",
      "|    policy_gradient_loss | -0.00039     |\n",
      "|    value_loss           | 1.97e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1355     |\n",
      "|    iterations      | 2095     |\n",
      "|    time_elapsed    | 12657    |\n",
      "|    total_timesteps | 17162240 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2096          |\n",
      "|    time_elapsed         | 12661         |\n",
      "|    total_timesteps      | 17170432      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022968951 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.381        |\n",
      "|    explained_variance   | 0.000287      |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 958           |\n",
      "|    n_updates            | 24510         |\n",
      "|    policy_gradient_loss | -0.000543     |\n",
      "|    value_loss           | 1.93e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1356         |\n",
      "|    iterations           | 2097         |\n",
      "|    time_elapsed         | 12666        |\n",
      "|    total_timesteps      | 17178624     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.617418e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.387       |\n",
      "|    explained_variance   | 0.0258       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 747          |\n",
      "|    n_updates            | 24520        |\n",
      "|    policy_gradient_loss | -0.000469    |\n",
      "|    value_loss           | 2.04e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2098          |\n",
      "|    time_elapsed         | 12671         |\n",
      "|    total_timesteps      | 17186816      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.2862876e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.387        |\n",
      "|    explained_variance   | 0.0442        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 785           |\n",
      "|    n_updates            | 24530         |\n",
      "|    policy_gradient_loss | -0.000366     |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1356         |\n",
      "|    iterations           | 2099         |\n",
      "|    time_elapsed         | 12675        |\n",
      "|    total_timesteps      | 17195008     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003357167 |\n",
      "|    clip_fraction        | 3.66e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.393       |\n",
      "|    explained_variance   | 0.0469       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 958          |\n",
      "|    n_updates            | 24540        |\n",
      "|    policy_gradient_loss | -0.000835    |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=17200000, episode_reward=666.20 +/- 64.56\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 666           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 17200000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014671733 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.383        |\n",
      "|    explained_variance   | 0.0343        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 968           |\n",
      "|    n_updates            | 24550         |\n",
      "|    policy_gradient_loss | -0.000582     |\n",
      "|    value_loss           | 1.83e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1355     |\n",
      "|    iterations      | 2100     |\n",
      "|    time_elapsed    | 12687    |\n",
      "|    total_timesteps | 17203200 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1356         |\n",
      "|    iterations           | 2101         |\n",
      "|    time_elapsed         | 12692        |\n",
      "|    total_timesteps      | 17211392     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.413164e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.376       |\n",
      "|    explained_variance   | 0.0274       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 24560        |\n",
      "|    policy_gradient_loss | -0.000441    |\n",
      "|    value_loss           | 2.06e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2102          |\n",
      "|    time_elapsed         | 12697         |\n",
      "|    total_timesteps      | 17219584      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018163904 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.379        |\n",
      "|    explained_variance   | 0.0353        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.23e+03      |\n",
      "|    n_updates            | 24570         |\n",
      "|    policy_gradient_loss | -0.00067      |\n",
      "|    value_loss           | 1.84e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2103          |\n",
      "|    time_elapsed         | 12702         |\n",
      "|    total_timesteps      | 17227776      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015039055 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.395        |\n",
      "|    explained_variance   | 0.0291        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.19e+03      |\n",
      "|    n_updates            | 24580         |\n",
      "|    policy_gradient_loss | -0.00058      |\n",
      "|    value_loss           | 2.01e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1356         |\n",
      "|    iterations           | 2104         |\n",
      "|    time_elapsed         | 12707        |\n",
      "|    total_timesteps      | 17235968     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.706447e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.381       |\n",
      "|    explained_variance   | 0.0411       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 884          |\n",
      "|    n_updates            | 24590        |\n",
      "|    policy_gradient_loss | -0.000402    |\n",
      "|    value_loss           | 1.92e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=17240000, episode_reward=664.20 +/- 58.65\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 664           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 17240000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.7220414e-05 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.379        |\n",
      "|    explained_variance   | 0.0433        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 796           |\n",
      "|    n_updates            | 24600         |\n",
      "|    policy_gradient_loss | -0.000418     |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1355     |\n",
      "|    iterations      | 2105     |\n",
      "|    time_elapsed    | 12719    |\n",
      "|    total_timesteps | 17244160 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1355          |\n",
      "|    iterations           | 2106          |\n",
      "|    time_elapsed         | 12723         |\n",
      "|    total_timesteps      | 17252352      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010420045 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.391        |\n",
      "|    explained_variance   | 0.0498        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.04e+03      |\n",
      "|    n_updates            | 24610         |\n",
      "|    policy_gradient_loss | -0.000515     |\n",
      "|    value_loss           | 1.98e+03      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 1356           |\n",
      "|    iterations           | 2107           |\n",
      "|    time_elapsed         | 12728          |\n",
      "|    total_timesteps      | 17260544       |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000114861956 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.381         |\n",
      "|    explained_variance   | 0.0172         |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 808            |\n",
      "|    n_updates            | 24620          |\n",
      "|    policy_gradient_loss | -0.000442      |\n",
      "|    value_loss           | 1.85e+03       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1356         |\n",
      "|    iterations           | 2108         |\n",
      "|    time_elapsed         | 12734        |\n",
      "|    total_timesteps      | 17268736     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001323305 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.385       |\n",
      "|    explained_variance   | 0.0393       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 931          |\n",
      "|    n_updates            | 24630        |\n",
      "|    policy_gradient_loss | -0.00051     |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 1356           |\n",
      "|    iterations           | 2109           |\n",
      "|    time_elapsed         | 12738          |\n",
      "|    total_timesteps      | 17276928       |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000106615014 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.385         |\n",
      "|    explained_variance   | 0.0441         |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 969            |\n",
      "|    n_updates            | 24640          |\n",
      "|    policy_gradient_loss | -0.00044       |\n",
      "|    value_loss           | 1.92e+03       |\n",
      "--------------------------------------------\n",
      "Eval num_timesteps=17280000, episode_reward=651.60 +/- 62.01\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 652          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 17280000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.810742e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.399       |\n",
      "|    explained_variance   | 0.0579       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 24650        |\n",
      "|    policy_gradient_loss | -0.000325    |\n",
      "|    value_loss           | 2.02e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1355     |\n",
      "|    iterations      | 2110     |\n",
      "|    time_elapsed    | 12750    |\n",
      "|    total_timesteps | 17285120 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1355          |\n",
      "|    iterations           | 2111          |\n",
      "|    time_elapsed         | 12755         |\n",
      "|    total_timesteps      | 17293312      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4081007e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.366        |\n",
      "|    explained_variance   | 0.0372        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.45e+03      |\n",
      "|    n_updates            | 24660         |\n",
      "|    policy_gradient_loss | -0.000256     |\n",
      "|    value_loss           | 1.94e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1355          |\n",
      "|    iterations           | 2112          |\n",
      "|    time_elapsed         | 12760         |\n",
      "|    total_timesteps      | 17301504      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011613399 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.374        |\n",
      "|    explained_variance   | 0.0149        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.1e+03       |\n",
      "|    n_updates            | 24670         |\n",
      "|    policy_gradient_loss | -0.000421     |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2113          |\n",
      "|    time_elapsed         | 12764         |\n",
      "|    total_timesteps      | 17309696      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010793554 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.383        |\n",
      "|    explained_variance   | 0.0458        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 764           |\n",
      "|    n_updates            | 24680         |\n",
      "|    policy_gradient_loss | -0.000494     |\n",
      "|    value_loss           | 1.96e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2114          |\n",
      "|    time_elapsed         | 12770         |\n",
      "|    total_timesteps      | 17317888      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019133037 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.387        |\n",
      "|    explained_variance   | 0.0322        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.04e+03      |\n",
      "|    n_updates            | 24690         |\n",
      "|    policy_gradient_loss | -0.000599     |\n",
      "|    value_loss           | 1.97e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=17320000, episode_reward=664.60 +/- 55.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 665           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 17320000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028425077 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.396        |\n",
      "|    explained_variance   | 0.0368        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 882           |\n",
      "|    n_updates            | 24700         |\n",
      "|    policy_gradient_loss | -0.000882     |\n",
      "|    value_loss           | 1.83e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1355     |\n",
      "|    iterations      | 2115     |\n",
      "|    time_elapsed    | 12781    |\n",
      "|    total_timesteps | 17326080 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1355         |\n",
      "|    iterations           | 2116         |\n",
      "|    time_elapsed         | 12785        |\n",
      "|    total_timesteps      | 17334272     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.722024e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.39        |\n",
      "|    explained_variance   | 0.0365       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 24710        |\n",
      "|    policy_gradient_loss | -0.000498    |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 1355           |\n",
      "|    iterations           | 2117           |\n",
      "|    time_elapsed         | 12789          |\n",
      "|    total_timesteps      | 17342464       |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000105009625 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.389         |\n",
      "|    explained_variance   | 0.0556         |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 820            |\n",
      "|    n_updates            | 24720          |\n",
      "|    policy_gradient_loss | -0.000378      |\n",
      "|    value_loss           | 1.79e+03       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2118          |\n",
      "|    time_elapsed         | 12793         |\n",
      "|    total_timesteps      | 17350656      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011250188 |\n",
      "|    clip_fraction        | 7.32e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.384        |\n",
      "|    explained_variance   | 0.0351        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.24e+03      |\n",
      "|    n_updates            | 24730         |\n",
      "|    policy_gradient_loss | -0.000465     |\n",
      "|    value_loss           | 2.12e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2119          |\n",
      "|    time_elapsed         | 12797         |\n",
      "|    total_timesteps      | 17358848      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013282141 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.381        |\n",
      "|    explained_variance   | 0.0493        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.07e+03      |\n",
      "|    n_updates            | 24740         |\n",
      "|    policy_gradient_loss | -0.000574     |\n",
      "|    value_loss           | 1.96e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=17360000, episode_reward=650.20 +/- 57.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 650           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 17360000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024824627 |\n",
      "|    clip_fraction        | 6.1e-05       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.396        |\n",
      "|    explained_variance   | 0.0407        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.05e+03      |\n",
      "|    n_updates            | 24750         |\n",
      "|    policy_gradient_loss | -0.000694     |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1355     |\n",
      "|    iterations      | 2120     |\n",
      "|    time_elapsed    | 12807    |\n",
      "|    total_timesteps | 17367040 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2121          |\n",
      "|    time_elapsed         | 12811         |\n",
      "|    total_timesteps      | 17375232      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014080312 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.395        |\n",
      "|    explained_variance   | 0.0383        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 941           |\n",
      "|    n_updates            | 24760         |\n",
      "|    policy_gradient_loss | -0.000488     |\n",
      "|    value_loss           | 1.94e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1356         |\n",
      "|    iterations           | 2122         |\n",
      "|    time_elapsed         | 12815        |\n",
      "|    total_timesteps      | 17383424     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.213532e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.389       |\n",
      "|    explained_variance   | -0.00821     |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.08e+03     |\n",
      "|    n_updates            | 24770        |\n",
      "|    policy_gradient_loss | -0.000469    |\n",
      "|    value_loss           | 2e+03        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1356         |\n",
      "|    iterations           | 2123         |\n",
      "|    time_elapsed         | 12819        |\n",
      "|    total_timesteps      | 17391616     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003362965 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.386       |\n",
      "|    explained_variance   | 0.0298       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 777          |\n",
      "|    n_updates            | 24780        |\n",
      "|    policy_gradient_loss | -0.00093     |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1356         |\n",
      "|    iterations           | 2124         |\n",
      "|    time_elapsed         | 12823        |\n",
      "|    total_timesteps      | 17399808     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001637383 |\n",
      "|    clip_fraction        | 1.22e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.393       |\n",
      "|    explained_variance   | 0.0254       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 24790        |\n",
      "|    policy_gradient_loss | -0.000633    |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=17400000, episode_reward=647.60 +/- 63.01\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 648           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 17400000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013936579 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.393        |\n",
      "|    explained_variance   | 0.0449        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.08e+03      |\n",
      "|    n_updates            | 24800         |\n",
      "|    policy_gradient_loss | -0.00054      |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1356     |\n",
      "|    iterations      | 2125     |\n",
      "|    time_elapsed    | 12834    |\n",
      "|    total_timesteps | 17408000 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2126          |\n",
      "|    time_elapsed         | 12838         |\n",
      "|    total_timesteps      | 17416192      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014887948 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.383        |\n",
      "|    explained_variance   | 0.0283        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.36e+03      |\n",
      "|    n_updates            | 24810         |\n",
      "|    policy_gradient_loss | -0.000518     |\n",
      "|    value_loss           | 2.08e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2127          |\n",
      "|    time_elapsed         | 12842         |\n",
      "|    total_timesteps      | 17424384      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014317344 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.389        |\n",
      "|    explained_variance   | 0.0401        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.09e+03      |\n",
      "|    n_updates            | 24820         |\n",
      "|    policy_gradient_loss | -0.000578     |\n",
      "|    value_loss           | 1.94e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1357          |\n",
      "|    iterations           | 2128          |\n",
      "|    time_elapsed         | 12846         |\n",
      "|    total_timesteps      | 17432576      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021715462 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.382        |\n",
      "|    explained_variance   | 0.0461        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 668           |\n",
      "|    n_updates            | 24830         |\n",
      "|    policy_gradient_loss | -0.000623     |\n",
      "|    value_loss           | 1.84e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=17440000, episode_reward=632.60 +/- 47.11\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 633           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 17440000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027494898 |\n",
      "|    clip_fraction        | 0.00011       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.385        |\n",
      "|    explained_variance   | 0.0463        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.05e+03      |\n",
      "|    n_updates            | 24840         |\n",
      "|    policy_gradient_loss | -0.000914     |\n",
      "|    value_loss           | 1.84e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1356     |\n",
      "|    iterations      | 2129     |\n",
      "|    time_elapsed    | 12856    |\n",
      "|    total_timesteps | 17440768 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1356          |\n",
      "|    iterations           | 2130          |\n",
      "|    time_elapsed         | 12860         |\n",
      "|    total_timesteps      | 17448960      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015046983 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.399        |\n",
      "|    explained_variance   | 0.0355        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 992           |\n",
      "|    n_updates            | 24850         |\n",
      "|    policy_gradient_loss | -0.000517     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1357          |\n",
      "|    iterations           | 2131          |\n",
      "|    time_elapsed         | 12864         |\n",
      "|    total_timesteps      | 17457152      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.3139744e-05 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.382        |\n",
      "|    explained_variance   | 0.0426        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 875           |\n",
      "|    n_updates            | 24860         |\n",
      "|    policy_gradient_loss | -0.000378     |\n",
      "|    value_loss           | 2e+03         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1357         |\n",
      "|    iterations           | 2132         |\n",
      "|    time_elapsed         | 12868        |\n",
      "|    total_timesteps      | 17465344     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001419538 |\n",
      "|    clip_fraction        | 2.44e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.386       |\n",
      "|    explained_variance   | 0.0429       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 653          |\n",
      "|    n_updates            | 24870        |\n",
      "|    policy_gradient_loss | -0.000516    |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1357          |\n",
      "|    iterations           | 2133          |\n",
      "|    time_elapsed         | 12871         |\n",
      "|    total_timesteps      | 17473536      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013307857 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.377        |\n",
      "|    explained_variance   | 0.0623        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 838           |\n",
      "|    n_updates            | 24880         |\n",
      "|    policy_gradient_loss | -0.000436     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=17480000, episode_reward=650.80 +/- 50.75\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 651           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 17480000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012490498 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.391        |\n",
      "|    explained_variance   | 0.0155        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 795           |\n",
      "|    n_updates            | 24890         |\n",
      "|    policy_gradient_loss | -0.000476     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1357     |\n",
      "|    iterations      | 2134     |\n",
      "|    time_elapsed    | 12882    |\n",
      "|    total_timesteps | 17481728 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1357          |\n",
      "|    iterations           | 2135          |\n",
      "|    time_elapsed         | 12885         |\n",
      "|    total_timesteps      | 17489920      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.6443135e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.386        |\n",
      "|    explained_variance   | 0.016         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.04e+03      |\n",
      "|    n_updates            | 24900         |\n",
      "|    policy_gradient_loss | -0.000382     |\n",
      "|    value_loss           | 2.07e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1357          |\n",
      "|    iterations           | 2136          |\n",
      "|    time_elapsed         | 12889         |\n",
      "|    total_timesteps      | 17498112      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021048222 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.398        |\n",
      "|    explained_variance   | 0.0171        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.07e+03      |\n",
      "|    n_updates            | 24910         |\n",
      "|    policy_gradient_loss | -0.000649     |\n",
      "|    value_loss           | 1.87e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1357          |\n",
      "|    iterations           | 2137          |\n",
      "|    time_elapsed         | 12893         |\n",
      "|    total_timesteps      | 17506304      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011055121 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.401        |\n",
      "|    explained_variance   | 0.0393        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 918           |\n",
      "|    n_updates            | 24920         |\n",
      "|    policy_gradient_loss | -0.000352     |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1358         |\n",
      "|    iterations           | 2138         |\n",
      "|    time_elapsed         | 12897        |\n",
      "|    total_timesteps      | 17514496     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002534694 |\n",
      "|    clip_fraction        | 0.00011      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.383       |\n",
      "|    explained_variance   | 0.0419       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 940          |\n",
      "|    n_updates            | 24930        |\n",
      "|    policy_gradient_loss | -0.000684    |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=17520000, episode_reward=652.60 +/- 54.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 653          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 17520000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.984434e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.384       |\n",
      "|    explained_variance   | 0.0375       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 24940        |\n",
      "|    policy_gradient_loss | -0.000367    |\n",
      "|    value_loss           | 1.99e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1357     |\n",
      "|    iterations      | 2139     |\n",
      "|    time_elapsed    | 12908    |\n",
      "|    total_timesteps | 17522688 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1357          |\n",
      "|    iterations           | 2140          |\n",
      "|    time_elapsed         | 12912         |\n",
      "|    total_timesteps      | 17530880      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.9908976e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.396        |\n",
      "|    explained_variance   | 0.0396        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 678           |\n",
      "|    n_updates            | 24950         |\n",
      "|    policy_gradient_loss | -0.000358     |\n",
      "|    value_loss           | 1.94e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1357          |\n",
      "|    iterations           | 2141          |\n",
      "|    time_elapsed         | 12916         |\n",
      "|    total_timesteps      | 17539072      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013352942 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.384        |\n",
      "|    explained_variance   | 0.00678       |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 773           |\n",
      "|    n_updates            | 24960         |\n",
      "|    policy_gradient_loss | -0.00049      |\n",
      "|    value_loss           | 1.95e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1358          |\n",
      "|    iterations           | 2142          |\n",
      "|    time_elapsed         | 12920         |\n",
      "|    total_timesteps      | 17547264      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029163482 |\n",
      "|    clip_fraction        | 8.54e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.387        |\n",
      "|    explained_variance   | 0.0427        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.15e+03      |\n",
      "|    n_updates            | 24970         |\n",
      "|    policy_gradient_loss | -0.000826     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1358         |\n",
      "|    iterations           | 2143         |\n",
      "|    time_elapsed         | 12924        |\n",
      "|    total_timesteps      | 17555456     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.480107e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.375       |\n",
      "|    explained_variance   | 0.0504       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 24980        |\n",
      "|    policy_gradient_loss | -0.000395    |\n",
      "|    value_loss           | 2.11e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=17560000, episode_reward=668.20 +/- 60.16\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 668           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 17560000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020260636 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.387        |\n",
      "|    explained_variance   | 0.0524        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 767           |\n",
      "|    n_updates            | 24990         |\n",
      "|    policy_gradient_loss | -0.000696     |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1357     |\n",
      "|    iterations      | 2144     |\n",
      "|    time_elapsed    | 12934    |\n",
      "|    total_timesteps | 17563648 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1358          |\n",
      "|    iterations           | 2145          |\n",
      "|    time_elapsed         | 12938         |\n",
      "|    total_timesteps      | 17571840      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.9129895e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.374        |\n",
      "|    explained_variance   | 0.0308        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 825           |\n",
      "|    n_updates            | 25000         |\n",
      "|    policy_gradient_loss | -0.000452     |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1358         |\n",
      "|    iterations           | 2146         |\n",
      "|    time_elapsed         | 12942        |\n",
      "|    total_timesteps      | 17580032     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.830743e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.389       |\n",
      "|    explained_variance   | 0.0371       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 25010        |\n",
      "|    policy_gradient_loss | -0.000489    |\n",
      "|    value_loss           | 1.93e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1358          |\n",
      "|    iterations           | 2147          |\n",
      "|    time_elapsed         | 12945         |\n",
      "|    total_timesteps      | 17588224      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.2661886e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.385        |\n",
      "|    explained_variance   | 0.0294        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 787           |\n",
      "|    n_updates            | 25020         |\n",
      "|    policy_gradient_loss | -0.000371     |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1358          |\n",
      "|    iterations           | 2148          |\n",
      "|    time_elapsed         | 12949         |\n",
      "|    total_timesteps      | 17596416      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024661908 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.382        |\n",
      "|    explained_variance   | 0.0462        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.19e+03      |\n",
      "|    n_updates            | 25030         |\n",
      "|    policy_gradient_loss | -0.000759     |\n",
      "|    value_loss           | 2.01e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=17600000, episode_reward=653.20 +/- 48.76\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 653           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 17600000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019736245 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.383        |\n",
      "|    explained_variance   | 0.0282        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 873           |\n",
      "|    n_updates            | 25040         |\n",
      "|    policy_gradient_loss | -0.000711     |\n",
      "|    value_loss           | 1.81e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1358     |\n",
      "|    iterations      | 2149     |\n",
      "|    time_elapsed    | 12959    |\n",
      "|    total_timesteps | 17604608 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1358         |\n",
      "|    iterations           | 2150         |\n",
      "|    time_elapsed         | 12963        |\n",
      "|    total_timesteps      | 17612800     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.198094e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.385       |\n",
      "|    explained_variance   | 0.017        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 896          |\n",
      "|    n_updates            | 25050        |\n",
      "|    policy_gradient_loss | -0.000491    |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1358          |\n",
      "|    iterations           | 2151          |\n",
      "|    time_elapsed         | 12968         |\n",
      "|    total_timesteps      | 17620992      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.1155846e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.382        |\n",
      "|    explained_variance   | 0.0633        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 898           |\n",
      "|    n_updates            | 25060         |\n",
      "|    policy_gradient_loss | -0.000281     |\n",
      "|    value_loss           | 2.03e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1359          |\n",
      "|    iterations           | 2152          |\n",
      "|    time_elapsed         | 12971         |\n",
      "|    total_timesteps      | 17629184      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016674542 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.386        |\n",
      "|    explained_variance   | 0.00901       |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 754           |\n",
      "|    n_updates            | 25070         |\n",
      "|    policy_gradient_loss | -0.000585     |\n",
      "|    value_loss           | 1.82e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1359          |\n",
      "|    iterations           | 2153          |\n",
      "|    time_elapsed         | 12975         |\n",
      "|    total_timesteps      | 17637376      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024700933 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.391        |\n",
      "|    explained_variance   | 0.0356        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.16e+03      |\n",
      "|    n_updates            | 25080         |\n",
      "|    policy_gradient_loss | -0.00068      |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=17640000, episode_reward=651.80 +/- 51.72\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 652          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 17640000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.889872e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.393       |\n",
      "|    explained_variance   | 0.0217       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.33e+03     |\n",
      "|    n_updates            | 25090        |\n",
      "|    policy_gradient_loss | -0.000419    |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1358     |\n",
      "|    iterations      | 2154     |\n",
      "|    time_elapsed    | 12985    |\n",
      "|    total_timesteps | 17645568 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1359          |\n",
      "|    iterations           | 2155          |\n",
      "|    time_elapsed         | 12989         |\n",
      "|    total_timesteps      | 17653760      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012000005 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.379        |\n",
      "|    explained_variance   | 0.0306        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 936           |\n",
      "|    n_updates            | 25100         |\n",
      "|    policy_gradient_loss | -0.000464     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1359          |\n",
      "|    iterations           | 2156          |\n",
      "|    time_elapsed         | 12993         |\n",
      "|    total_timesteps      | 17661952      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027549377 |\n",
      "|    clip_fraction        | 7.32e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.404        |\n",
      "|    explained_variance   | 0.0314        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 787           |\n",
      "|    n_updates            | 25110         |\n",
      "|    policy_gradient_loss | -0.000734     |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1359          |\n",
      "|    iterations           | 2157          |\n",
      "|    time_elapsed         | 12997         |\n",
      "|    total_timesteps      | 17670144      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014655504 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.372        |\n",
      "|    explained_variance   | 0.0217        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 685           |\n",
      "|    n_updates            | 25120         |\n",
      "|    policy_gradient_loss | -0.000552     |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1359         |\n",
      "|    iterations           | 2158         |\n",
      "|    time_elapsed         | 13000        |\n",
      "|    total_timesteps      | 17678336     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002654387 |\n",
      "|    clip_fraction        | 3.66e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.385       |\n",
      "|    explained_variance   | 0.0372       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 940          |\n",
      "|    n_updates            | 25130        |\n",
      "|    policy_gradient_loss | -0.000694    |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=17680000, episode_reward=660.80 +/- 46.51\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 661           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 17680000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011153381 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.382        |\n",
      "|    explained_variance   | 0.033         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.24e+03      |\n",
      "|    n_updates            | 25140         |\n",
      "|    policy_gradient_loss | -0.000532     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1359     |\n",
      "|    iterations      | 2159     |\n",
      "|    time_elapsed    | 13011    |\n",
      "|    total_timesteps | 17686528 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1359         |\n",
      "|    iterations           | 2160         |\n",
      "|    time_elapsed         | 13015        |\n",
      "|    total_timesteps      | 17694720     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.850083e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.39        |\n",
      "|    explained_variance   | 0.0199       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 891          |\n",
      "|    n_updates            | 25150        |\n",
      "|    policy_gradient_loss | -0.000399    |\n",
      "|    value_loss           | 2.09e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1359          |\n",
      "|    iterations           | 2161          |\n",
      "|    time_elapsed         | 13018         |\n",
      "|    total_timesteps      | 17702912      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026016845 |\n",
      "|    clip_fraction        | 0.000134      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.374        |\n",
      "|    explained_variance   | 0.0464        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 802           |\n",
      "|    n_updates            | 25160         |\n",
      "|    policy_gradient_loss | -0.000843     |\n",
      "|    value_loss           | 1.97e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1360          |\n",
      "|    iterations           | 2162          |\n",
      "|    time_elapsed         | 13022         |\n",
      "|    total_timesteps      | 17711104      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037793687 |\n",
      "|    clip_fraction        | 0.00022       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.375        |\n",
      "|    explained_variance   | 0.0479        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 672           |\n",
      "|    n_updates            | 25170         |\n",
      "|    policy_gradient_loss | -0.00105      |\n",
      "|    value_loss           | 1.85e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1360          |\n",
      "|    iterations           | 2163          |\n",
      "|    time_elapsed         | 13027         |\n",
      "|    total_timesteps      | 17719296      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018749849 |\n",
      "|    clip_fraction        | 8.54e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.385        |\n",
      "|    explained_variance   | 0.0448        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 929           |\n",
      "|    n_updates            | 25180         |\n",
      "|    policy_gradient_loss | -0.000753     |\n",
      "|    value_loss           | 1.85e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=17720000, episode_reward=660.80 +/- 46.68\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 661           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 17720000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010067368 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.38         |\n",
      "|    explained_variance   | 0.0372        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.09e+03      |\n",
      "|    n_updates            | 25190         |\n",
      "|    policy_gradient_loss | -0.000464     |\n",
      "|    value_loss           | 1.97e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1359     |\n",
      "|    iterations      | 2164     |\n",
      "|    time_elapsed    | 13037    |\n",
      "|    total_timesteps | 17727488 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1359          |\n",
      "|    iterations           | 2165          |\n",
      "|    time_elapsed         | 13041         |\n",
      "|    total_timesteps      | 17735680      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2710206e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.4          |\n",
      "|    explained_variance   | 0.0378        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.29e+03      |\n",
      "|    n_updates            | 25200         |\n",
      "|    policy_gradient_loss | -0.000351     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1360          |\n",
      "|    iterations           | 2166          |\n",
      "|    time_elapsed         | 13044         |\n",
      "|    total_timesteps      | 17743872      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020545692 |\n",
      "|    clip_fraction        | 0.000269      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.385        |\n",
      "|    explained_variance   | 0.0297        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.07e+03      |\n",
      "|    n_updates            | 25210         |\n",
      "|    policy_gradient_loss | -0.000685     |\n",
      "|    value_loss           | 1.93e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1360          |\n",
      "|    iterations           | 2167          |\n",
      "|    time_elapsed         | 13048         |\n",
      "|    total_timesteps      | 17752064      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.2276915e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.381        |\n",
      "|    explained_variance   | 0.04          |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 822           |\n",
      "|    n_updates            | 25220         |\n",
      "|    policy_gradient_loss | -0.00039      |\n",
      "|    value_loss           | 1.94e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=17760000, episode_reward=657.40 +/- 51.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 657           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 17760000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.9353605e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.386        |\n",
      "|    explained_variance   | 0.0668        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 800           |\n",
      "|    n_updates            | 25230         |\n",
      "|    policy_gradient_loss | -0.000382     |\n",
      "|    value_loss           | 2.13e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1359     |\n",
      "|    iterations      | 2168     |\n",
      "|    time_elapsed    | 13059    |\n",
      "|    total_timesteps | 17760256 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1360         |\n",
      "|    iterations           | 2169         |\n",
      "|    time_elapsed         | 13063        |\n",
      "|    total_timesteps      | 17768448     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.401431e-05 |\n",
      "|    clip_fraction        | 1.22e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.393       |\n",
      "|    explained_variance   | 0.0142       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 991          |\n",
      "|    n_updates            | 25240        |\n",
      "|    policy_gradient_loss | -0.000378    |\n",
      "|    value_loss           | 1.96e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1360          |\n",
      "|    iterations           | 2170          |\n",
      "|    time_elapsed         | 13066         |\n",
      "|    total_timesteps      | 17776640      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034592586 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.403        |\n",
      "|    explained_variance   | 0.031         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 979           |\n",
      "|    n_updates            | 25250         |\n",
      "|    policy_gradient_loss | -0.000948     |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1360          |\n",
      "|    iterations           | 2171          |\n",
      "|    time_elapsed         | 13070         |\n",
      "|    total_timesteps      | 17784832      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021223148 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.393        |\n",
      "|    explained_variance   | 0.0374        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 965           |\n",
      "|    n_updates            | 25260         |\n",
      "|    policy_gradient_loss | -0.000677     |\n",
      "|    value_loss           | 1.97e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1360          |\n",
      "|    iterations           | 2172          |\n",
      "|    time_elapsed         | 13074         |\n",
      "|    total_timesteps      | 17793024      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.7829256e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.39         |\n",
      "|    explained_variance   | 0.0232        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.05e+03      |\n",
      "|    n_updates            | 25270         |\n",
      "|    policy_gradient_loss | -0.000444     |\n",
      "|    value_loss           | 2.14e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=17800000, episode_reward=637.80 +/- 71.65\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 638           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 17800000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015234848 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.404        |\n",
      "|    explained_variance   | 0.0369        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 880           |\n",
      "|    n_updates            | 25280         |\n",
      "|    policy_gradient_loss | -0.000439     |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1360     |\n",
      "|    iterations      | 2173     |\n",
      "|    time_elapsed    | 13085    |\n",
      "|    total_timesteps | 17801216 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1360         |\n",
      "|    iterations           | 2174         |\n",
      "|    time_elapsed         | 13089        |\n",
      "|    total_timesteps      | 17809408     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.977654e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.404       |\n",
      "|    explained_variance   | 0.042        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 765          |\n",
      "|    n_updates            | 25290        |\n",
      "|    policy_gradient_loss | -0.000407    |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1360         |\n",
      "|    iterations           | 2175         |\n",
      "|    time_elapsed         | 13093        |\n",
      "|    total_timesteps      | 17817600     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002068119 |\n",
      "|    clip_fraction        | 6.1e-05      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.395       |\n",
      "|    explained_variance   | 0.0437       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 918          |\n",
      "|    n_updates            | 25300        |\n",
      "|    policy_gradient_loss | -0.000561    |\n",
      "|    value_loss           | 1.93e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1361         |\n",
      "|    iterations           | 2176         |\n",
      "|    time_elapsed         | 13097        |\n",
      "|    total_timesteps      | 17825792     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.902249e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.392       |\n",
      "|    explained_variance   | 0.0441       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.29e+03     |\n",
      "|    n_updates            | 25310        |\n",
      "|    policy_gradient_loss | -0.000342    |\n",
      "|    value_loss           | 2.08e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1361          |\n",
      "|    iterations           | 2177          |\n",
      "|    time_elapsed         | 13101         |\n",
      "|    total_timesteps      | 17833984      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012752238 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.405        |\n",
      "|    explained_variance   | 0.0561        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 631           |\n",
      "|    n_updates            | 25320         |\n",
      "|    policy_gradient_loss | -0.00064      |\n",
      "|    value_loss           | 1.83e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=17840000, episode_reward=641.40 +/- 46.35\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 641           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 17840000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010046717 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.385        |\n",
      "|    explained_variance   | 0.0443        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 697           |\n",
      "|    n_updates            | 25330         |\n",
      "|    policy_gradient_loss | -0.000442     |\n",
      "|    value_loss           | 1.83e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1360     |\n",
      "|    iterations      | 2178     |\n",
      "|    time_elapsed    | 13111    |\n",
      "|    total_timesteps | 17842176 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1361          |\n",
      "|    iterations           | 2179          |\n",
      "|    time_elapsed         | 13114         |\n",
      "|    total_timesteps      | 17850368      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.5942674e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.394        |\n",
      "|    explained_variance   | 0.0398        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 991           |\n",
      "|    n_updates            | 25340         |\n",
      "|    policy_gradient_loss | -0.000311     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1361         |\n",
      "|    iterations           | 2180         |\n",
      "|    time_elapsed         | 13118        |\n",
      "|    total_timesteps      | 17858560     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001275726 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.382       |\n",
      "|    explained_variance   | 0.0314       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 824          |\n",
      "|    n_updates            | 25350        |\n",
      "|    policy_gradient_loss | -0.000499    |\n",
      "|    value_loss           | 1.88e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1361          |\n",
      "|    iterations           | 2181          |\n",
      "|    time_elapsed         | 13122         |\n",
      "|    total_timesteps      | 17866752      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010890557 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.384        |\n",
      "|    explained_variance   | 0.0428        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 589           |\n",
      "|    n_updates            | 25360         |\n",
      "|    policy_gradient_loss | -0.000497     |\n",
      "|    value_loss           | 2.05e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1361          |\n",
      "|    iterations           | 2182          |\n",
      "|    time_elapsed         | 13125         |\n",
      "|    total_timesteps      | 17874944      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010838496 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.392        |\n",
      "|    explained_variance   | 0.0309        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.11e+03      |\n",
      "|    n_updates            | 25370         |\n",
      "|    policy_gradient_loss | -0.000454     |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=17880000, episode_reward=639.40 +/- 60.64\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 639           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 17880000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011290554 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.389        |\n",
      "|    explained_variance   | 0.0372        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.09e+03      |\n",
      "|    n_updates            | 25380         |\n",
      "|    policy_gradient_loss | -0.000501     |\n",
      "|    value_loss           | 1.87e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1361     |\n",
      "|    iterations      | 2183     |\n",
      "|    time_elapsed    | 13135    |\n",
      "|    total_timesteps | 17883136 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1361         |\n",
      "|    iterations           | 2184         |\n",
      "|    time_elapsed         | 13138        |\n",
      "|    total_timesteps      | 17891328     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001888226 |\n",
      "|    clip_fraction        | 1.22e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.383       |\n",
      "|    explained_variance   | 0.0467       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 779          |\n",
      "|    n_updates            | 25390        |\n",
      "|    policy_gradient_loss | -0.000645    |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1361         |\n",
      "|    iterations           | 2185         |\n",
      "|    time_elapsed         | 13142        |\n",
      "|    total_timesteps      | 17899520     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.634021e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.391       |\n",
      "|    explained_variance   | 0.0376       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 25400        |\n",
      "|    policy_gradient_loss | -0.000404    |\n",
      "|    value_loss           | 2.05e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 1362           |\n",
      "|    iterations           | 2186           |\n",
      "|    time_elapsed         | 13147          |\n",
      "|    total_timesteps      | 17907712       |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000102887316 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.398         |\n",
      "|    explained_variance   | 0.0622         |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 856            |\n",
      "|    n_updates            | 25410          |\n",
      "|    policy_gradient_loss | -0.000419      |\n",
      "|    value_loss           | 1.91e+03       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1362          |\n",
      "|    iterations           | 2187          |\n",
      "|    time_elapsed         | 13151         |\n",
      "|    total_timesteps      | 17915904      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013276769 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.385        |\n",
      "|    explained_variance   | 0.0258        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.02e+03      |\n",
      "|    n_updates            | 25420         |\n",
      "|    policy_gradient_loss | -0.000543     |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=17920000, episode_reward=648.00 +/- 64.06\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 648           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 17920000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018912161 |\n",
      "|    clip_fraction        | 0.000171      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.387        |\n",
      "|    explained_variance   | 0.05          |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.1e+03       |\n",
      "|    n_updates            | 25430         |\n",
      "|    policy_gradient_loss | -0.000551     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1361     |\n",
      "|    iterations      | 2188     |\n",
      "|    time_elapsed    | 13161    |\n",
      "|    total_timesteps | 17924096 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1362         |\n",
      "|    iterations           | 2189         |\n",
      "|    time_elapsed         | 13165        |\n",
      "|    total_timesteps      | 17932288     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.845371e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.383       |\n",
      "|    explained_variance   | 0.0464       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 25440        |\n",
      "|    policy_gradient_loss | -0.000295    |\n",
      "|    value_loss           | 2.04e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1362         |\n",
      "|    iterations           | 2190         |\n",
      "|    time_elapsed         | 13169        |\n",
      "|    total_timesteps      | 17940480     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001467058 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.395       |\n",
      "|    explained_variance   | 0.00167      |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 855          |\n",
      "|    n_updates            | 25450        |\n",
      "|    policy_gradient_loss | -0.000563    |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1362          |\n",
      "|    iterations           | 2191          |\n",
      "|    time_elapsed         | 13173         |\n",
      "|    total_timesteps      | 17948672      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2196836e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.39         |\n",
      "|    explained_variance   | 0.023         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 863           |\n",
      "|    n_updates            | 25460         |\n",
      "|    policy_gradient_loss | -0.000273     |\n",
      "|    value_loss           | 1.85e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1362          |\n",
      "|    iterations           | 2192          |\n",
      "|    time_elapsed         | 13176         |\n",
      "|    total_timesteps      | 17956864      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014635903 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.381        |\n",
      "|    explained_variance   | 0.0258        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 797           |\n",
      "|    n_updates            | 25470         |\n",
      "|    policy_gradient_loss | -0.000499     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=17960000, episode_reward=655.00 +/- 55.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 655          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 17960000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.831039e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.374       |\n",
      "|    explained_variance   | 0.0528       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 25480        |\n",
      "|    policy_gradient_loss | -0.000315    |\n",
      "|    value_loss           | 2.08e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1362     |\n",
      "|    iterations      | 2193     |\n",
      "|    time_elapsed    | 13187    |\n",
      "|    total_timesteps | 17965056 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1362         |\n",
      "|    iterations           | 2194         |\n",
      "|    time_elapsed         | 13191        |\n",
      "|    total_timesteps      | 17973248     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.780213e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.379       |\n",
      "|    explained_variance   | 0.0275       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 25490        |\n",
      "|    policy_gradient_loss | -0.00041     |\n",
      "|    value_loss           | 1.97e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1362         |\n",
      "|    iterations           | 2195         |\n",
      "|    time_elapsed         | 13195        |\n",
      "|    total_timesteps      | 17981440     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001013074 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.383       |\n",
      "|    explained_variance   | 0.0272       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 25500        |\n",
      "|    policy_gradient_loss | -0.000345    |\n",
      "|    value_loss           | 1.92e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 1362           |\n",
      "|    iterations           | 2196           |\n",
      "|    time_elapsed         | 13199          |\n",
      "|    total_timesteps      | 17989632       |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000109975554 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.385         |\n",
      "|    explained_variance   | 0.0364         |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 887            |\n",
      "|    n_updates            | 25510          |\n",
      "|    policy_gradient_loss | -0.00043       |\n",
      "|    value_loss           | 1.92e+03       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1363          |\n",
      "|    iterations           | 2197          |\n",
      "|    time_elapsed         | 13203         |\n",
      "|    total_timesteps      | 17997824      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011708085 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.391        |\n",
      "|    explained_variance   | 0.0437        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 888           |\n",
      "|    n_updates            | 25520         |\n",
      "|    policy_gradient_loss | -0.000454     |\n",
      "|    value_loss           | 2.08e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=18000000, episode_reward=642.60 +/- 62.48\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 643           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 18000000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023681263 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.392        |\n",
      "|    explained_variance   | 0.0417        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.08e+03      |\n",
      "|    n_updates            | 25530         |\n",
      "|    policy_gradient_loss | -0.000652     |\n",
      "|    value_loss           | 1.98e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1362     |\n",
      "|    iterations      | 2198     |\n",
      "|    time_elapsed    | 13214    |\n",
      "|    total_timesteps | 18006016 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1362          |\n",
      "|    iterations           | 2199          |\n",
      "|    time_elapsed         | 13218         |\n",
      "|    total_timesteps      | 18014208      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024809333 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.384        |\n",
      "|    explained_variance   | 0.051         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 874           |\n",
      "|    n_updates            | 25540         |\n",
      "|    policy_gradient_loss | -0.000602     |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1363          |\n",
      "|    iterations           | 2200          |\n",
      "|    time_elapsed         | 13221         |\n",
      "|    total_timesteps      | 18022400      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011353712 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.389        |\n",
      "|    explained_variance   | 0.0436        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.07e+03      |\n",
      "|    n_updates            | 25550         |\n",
      "|    policy_gradient_loss | -0.000412     |\n",
      "|    value_loss           | 1.94e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1363          |\n",
      "|    iterations           | 2201          |\n",
      "|    time_elapsed         | 13225         |\n",
      "|    total_timesteps      | 18030592      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011616593 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.383        |\n",
      "|    explained_variance   | 0.0408        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.05e+03      |\n",
      "|    n_updates            | 25560         |\n",
      "|    policy_gradient_loss | -0.000482     |\n",
      "|    value_loss           | 2e+03         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1363          |\n",
      "|    iterations           | 2202          |\n",
      "|    time_elapsed         | 13229         |\n",
      "|    total_timesteps      | 18038784      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032658316 |\n",
      "|    clip_fraction        | 0.000366      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.388        |\n",
      "|    explained_variance   | 0.0339        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.03e+03      |\n",
      "|    n_updates            | 25570         |\n",
      "|    policy_gradient_loss | -0.000825     |\n",
      "|    value_loss           | 1.82e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=18040000, episode_reward=656.00 +/- 55.39\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 656           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 18040000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011377261 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.392        |\n",
      "|    explained_variance   | 0.0668        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.01e+03      |\n",
      "|    n_updates            | 25580         |\n",
      "|    policy_gradient_loss | -0.000545     |\n",
      "|    value_loss           | 1.84e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1363     |\n",
      "|    iterations      | 2203     |\n",
      "|    time_elapsed    | 13239    |\n",
      "|    total_timesteps | 18046976 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1363          |\n",
      "|    iterations           | 2204          |\n",
      "|    time_elapsed         | 13243         |\n",
      "|    total_timesteps      | 18055168      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.9999504e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.393        |\n",
      "|    explained_variance   | 0.0397        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.02e+03      |\n",
      "|    n_updates            | 25590         |\n",
      "|    policy_gradient_loss | -0.000307     |\n",
      "|    value_loss           | 1.87e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1363          |\n",
      "|    iterations           | 2205          |\n",
      "|    time_elapsed         | 13247         |\n",
      "|    total_timesteps      | 18063360      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027646846 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.374        |\n",
      "|    explained_variance   | 0.0144        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.04e+03      |\n",
      "|    n_updates            | 25600         |\n",
      "|    policy_gradient_loss | -0.000692     |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1363          |\n",
      "|    iterations           | 2206          |\n",
      "|    time_elapsed         | 13251         |\n",
      "|    total_timesteps      | 18071552      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015339607 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.384        |\n",
      "|    explained_variance   | 0.0505        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 897           |\n",
      "|    n_updates            | 25610         |\n",
      "|    policy_gradient_loss | -0.000693     |\n",
      "|    value_loss           | 2.02e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1363          |\n",
      "|    iterations           | 2207          |\n",
      "|    time_elapsed         | 13255         |\n",
      "|    total_timesteps      | 18079744      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011567867 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.381        |\n",
      "|    explained_variance   | 0.034         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.08e+03      |\n",
      "|    n_updates            | 25620         |\n",
      "|    policy_gradient_loss | -0.000455     |\n",
      "|    value_loss           | 1.87e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=18080000, episode_reward=661.40 +/- 56.21\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 661          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18080000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001964648 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.38        |\n",
      "|    explained_variance   | 0.0131       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 737          |\n",
      "|    n_updates            | 25630        |\n",
      "|    policy_gradient_loss | -0.000613    |\n",
      "|    value_loss           | 1.95e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1363     |\n",
      "|    iterations      | 2208     |\n",
      "|    time_elapsed    | 13265    |\n",
      "|    total_timesteps | 18087936 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1363          |\n",
      "|    iterations           | 2209          |\n",
      "|    time_elapsed         | 13269         |\n",
      "|    total_timesteps      | 18096128      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019919203 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.381        |\n",
      "|    explained_variance   | 0.0464        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 683           |\n",
      "|    n_updates            | 25640         |\n",
      "|    policy_gradient_loss | -0.000586     |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1363          |\n",
      "|    iterations           | 2210          |\n",
      "|    time_elapsed         | 13273         |\n",
      "|    total_timesteps      | 18104320      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029324554 |\n",
      "|    clip_fraction        | 0.000281      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.389        |\n",
      "|    explained_variance   | 0.0406        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.18e+03      |\n",
      "|    n_updates            | 25650         |\n",
      "|    policy_gradient_loss | -0.000576     |\n",
      "|    value_loss           | 2.08e+03      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 1364           |\n",
      "|    iterations           | 2211           |\n",
      "|    time_elapsed         | 13277          |\n",
      "|    total_timesteps      | 18112512       |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000100869336 |\n",
      "|    clip_fraction        | 2.44e-05       |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.393         |\n",
      "|    explained_variance   | 0.0266         |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 1.03e+03       |\n",
      "|    n_updates            | 25660          |\n",
      "|    policy_gradient_loss | -0.000522      |\n",
      "|    value_loss           | 1.86e+03       |\n",
      "--------------------------------------------\n",
      "Eval num_timesteps=18120000, episode_reward=643.80 +/- 62.83\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 644          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18120000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.361054e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.385       |\n",
      "|    explained_variance   | 0.0178       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.33e+03     |\n",
      "|    n_updates            | 25670        |\n",
      "|    policy_gradient_loss | -0.00036     |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1363     |\n",
      "|    iterations      | 2212     |\n",
      "|    time_elapsed    | 13287    |\n",
      "|    total_timesteps | 18120704 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1363        |\n",
      "|    iterations           | 2213        |\n",
      "|    time_elapsed         | 13291       |\n",
      "|    total_timesteps      | 18128896    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 7.41098e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.382      |\n",
      "|    explained_variance   | 0.0394      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 481         |\n",
      "|    n_updates            | 25680       |\n",
      "|    policy_gradient_loss | -0.000399   |\n",
      "|    value_loss           | 1.81e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1364          |\n",
      "|    iterations           | 2214          |\n",
      "|    time_elapsed         | 13295         |\n",
      "|    total_timesteps      | 18137088      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027811967 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.399        |\n",
      "|    explained_variance   | 0.033         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.04e+03      |\n",
      "|    n_updates            | 25690         |\n",
      "|    policy_gradient_loss | -0.000783     |\n",
      "|    value_loss           | 2.04e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1364          |\n",
      "|    iterations           | 2215          |\n",
      "|    time_elapsed         | 13299         |\n",
      "|    total_timesteps      | 18145280      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011181834 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.393        |\n",
      "|    explained_variance   | 0.0423        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 643           |\n",
      "|    n_updates            | 25700         |\n",
      "|    policy_gradient_loss | -0.000505     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1364          |\n",
      "|    iterations           | 2216          |\n",
      "|    time_elapsed         | 13303         |\n",
      "|    total_timesteps      | 18153472      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019291053 |\n",
      "|    clip_fraction        | 7.32e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.395        |\n",
      "|    explained_variance   | 0.044         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.13e+03      |\n",
      "|    n_updates            | 25710         |\n",
      "|    policy_gradient_loss | -0.000617     |\n",
      "|    value_loss           | 1.81e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=18160000, episode_reward=650.60 +/- 58.32\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 651           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 18160000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018437028 |\n",
      "|    clip_fraction        | 3.66e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.394        |\n",
      "|    explained_variance   | 0.0417        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 909           |\n",
      "|    n_updates            | 25720         |\n",
      "|    policy_gradient_loss | -0.000739     |\n",
      "|    value_loss           | 1.95e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1364     |\n",
      "|    iterations      | 2217     |\n",
      "|    time_elapsed    | 13313    |\n",
      "|    total_timesteps | 18161664 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1364        |\n",
      "|    iterations           | 2218        |\n",
      "|    time_elapsed         | 13317       |\n",
      "|    total_timesteps      | 18169856    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000184417 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.392      |\n",
      "|    explained_variance   | 0.0306      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 775         |\n",
      "|    n_updates            | 25730       |\n",
      "|    policy_gradient_loss | -0.000519   |\n",
      "|    value_loss           | 1.99e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1364          |\n",
      "|    iterations           | 2219          |\n",
      "|    time_elapsed         | 13321         |\n",
      "|    total_timesteps      | 18178048      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016805733 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.381        |\n",
      "|    explained_variance   | 0.0398        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 739           |\n",
      "|    n_updates            | 25740         |\n",
      "|    policy_gradient_loss | -0.000654     |\n",
      "|    value_loss           | 1.85e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1364          |\n",
      "|    iterations           | 2220          |\n",
      "|    time_elapsed         | 13325         |\n",
      "|    total_timesteps      | 18186240      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012461172 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.371        |\n",
      "|    explained_variance   | 0.0338        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 781           |\n",
      "|    n_updates            | 25750         |\n",
      "|    policy_gradient_loss | -0.000473     |\n",
      "|    value_loss           | 1.94e+03      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 1363           |\n",
      "|    iterations           | 2221           |\n",
      "|    time_elapsed         | 13346          |\n",
      "|    total_timesteps      | 18194432       |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000100176505 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.388         |\n",
      "|    explained_variance   | 0.0323         |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 1.28e+03       |\n",
      "|    n_updates            | 25760          |\n",
      "|    policy_gradient_loss | -0.000452      |\n",
      "|    value_loss           | 1.83e+03       |\n",
      "--------------------------------------------\n",
      "Eval num_timesteps=18200000, episode_reward=652.20 +/- 61.17\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 652          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18200000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001052439 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.393       |\n",
      "|    explained_variance   | 0.0104       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 785          |\n",
      "|    n_updates            | 25770        |\n",
      "|    policy_gradient_loss | -0.000447    |\n",
      "|    value_loss           | 2.06e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1362     |\n",
      "|    iterations      | 2222     |\n",
      "|    time_elapsed    | 13356    |\n",
      "|    total_timesteps | 18202624 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1363          |\n",
      "|    iterations           | 2223          |\n",
      "|    time_elapsed         | 13360         |\n",
      "|    total_timesteps      | 18210816      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015415344 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.383        |\n",
      "|    explained_variance   | 0.0152        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 681           |\n",
      "|    n_updates            | 25780         |\n",
      "|    policy_gradient_loss | -0.000504     |\n",
      "|    value_loss           | 1.84e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1363          |\n",
      "|    iterations           | 2224          |\n",
      "|    time_elapsed         | 13364         |\n",
      "|    total_timesteps      | 18219008      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010442449 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.385        |\n",
      "|    explained_variance   | 0.045         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.07e+03      |\n",
      "|    n_updates            | 25790         |\n",
      "|    policy_gradient_loss | -0.00044      |\n",
      "|    value_loss           | 1.81e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1363          |\n",
      "|    iterations           | 2225          |\n",
      "|    time_elapsed         | 13368         |\n",
      "|    total_timesteps      | 18227200      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020870513 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.386        |\n",
      "|    explained_variance   | 0.0396        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.14e+03      |\n",
      "|    n_updates            | 25800         |\n",
      "|    policy_gradient_loss | -0.000591     |\n",
      "|    value_loss           | 1.87e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1363          |\n",
      "|    iterations           | 2226          |\n",
      "|    time_elapsed         | 13371         |\n",
      "|    total_timesteps      | 18235392      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016879308 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.397        |\n",
      "|    explained_variance   | 0.0446        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 911           |\n",
      "|    n_updates            | 25810         |\n",
      "|    policy_gradient_loss | -0.000548     |\n",
      "|    value_loss           | 2.08e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=18240000, episode_reward=643.20 +/- 64.14\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 643           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 18240000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011692677 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.387        |\n",
      "|    explained_variance   | 0.0522        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.05e+03      |\n",
      "|    n_updates            | 25820         |\n",
      "|    policy_gradient_loss | -0.000515     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1363     |\n",
      "|    iterations      | 2227     |\n",
      "|    time_elapsed    | 13382    |\n",
      "|    total_timesteps | 18243584 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1363         |\n",
      "|    iterations           | 2228         |\n",
      "|    time_elapsed         | 13386        |\n",
      "|    total_timesteps      | 18251776     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002470972 |\n",
      "|    clip_fraction        | 7.32e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.389       |\n",
      "|    explained_variance   | 0.0634       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 898          |\n",
      "|    n_updates            | 25830        |\n",
      "|    policy_gradient_loss | -0.000607    |\n",
      "|    value_loss           | 1.95e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1363          |\n",
      "|    iterations           | 2229          |\n",
      "|    time_elapsed         | 13390         |\n",
      "|    total_timesteps      | 18259968      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024971907 |\n",
      "|    clip_fraction        | 7.32e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.389        |\n",
      "|    explained_variance   | 0.0321        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 978           |\n",
      "|    n_updates            | 25840         |\n",
      "|    policy_gradient_loss | -0.000757     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1363          |\n",
      "|    iterations           | 2230          |\n",
      "|    time_elapsed         | 13394         |\n",
      "|    total_timesteps      | 18268160      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021136076 |\n",
      "|    clip_fraction        | 6.1e-05       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.391        |\n",
      "|    explained_variance   | 0.026         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 923           |\n",
      "|    n_updates            | 25850         |\n",
      "|    policy_gradient_loss | -0.000733     |\n",
      "|    value_loss           | 1.94e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1364          |\n",
      "|    iterations           | 2231          |\n",
      "|    time_elapsed         | 13398         |\n",
      "|    total_timesteps      | 18276352      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018318181 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.402        |\n",
      "|    explained_variance   | 0.0412        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.04e+03      |\n",
      "|    n_updates            | 25860         |\n",
      "|    policy_gradient_loss | -0.000514     |\n",
      "|    value_loss           | 1.98e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=18280000, episode_reward=673.20 +/- 54.16\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 673          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18280000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.702735e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.395       |\n",
      "|    explained_variance   | 0.0571       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 724          |\n",
      "|    n_updates            | 25870        |\n",
      "|    policy_gradient_loss | -0.000434    |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1363     |\n",
      "|    iterations      | 2232     |\n",
      "|    time_elapsed    | 13409    |\n",
      "|    total_timesteps | 18284544 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1363          |\n",
      "|    iterations           | 2233          |\n",
      "|    time_elapsed         | 13413         |\n",
      "|    total_timesteps      | 18292736      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012924598 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.385        |\n",
      "|    explained_variance   | 0.0429        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 984           |\n",
      "|    n_updates            | 25880         |\n",
      "|    policy_gradient_loss | -0.000511     |\n",
      "|    value_loss           | 1.78e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1364          |\n",
      "|    iterations           | 2234          |\n",
      "|    time_elapsed         | 13417         |\n",
      "|    total_timesteps      | 18300928      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027906796 |\n",
      "|    clip_fraction        | 0.000659      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.388        |\n",
      "|    explained_variance   | 0.0577        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.08e+03      |\n",
      "|    n_updates            | 25890         |\n",
      "|    policy_gradient_loss | -0.00069      |\n",
      "|    value_loss           | 1.84e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1364         |\n",
      "|    iterations           | 2235         |\n",
      "|    time_elapsed         | 13420        |\n",
      "|    total_timesteps      | 18309120     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.034647e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.39        |\n",
      "|    explained_variance   | 0.0695       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 923          |\n",
      "|    n_updates            | 25900        |\n",
      "|    policy_gradient_loss | -0.000348    |\n",
      "|    value_loss           | 2e+03        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1364         |\n",
      "|    iterations           | 2236         |\n",
      "|    time_elapsed         | 13424        |\n",
      "|    total_timesteps      | 18317312     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002467638 |\n",
      "|    clip_fraction        | 8.54e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.387       |\n",
      "|    explained_variance   | 0.0353       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 515          |\n",
      "|    n_updates            | 25910        |\n",
      "|    policy_gradient_loss | -0.000705    |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=18320000, episode_reward=650.80 +/- 60.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 651           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 18320000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022444318 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.371        |\n",
      "|    explained_variance   | 0.0641        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 963           |\n",
      "|    n_updates            | 25920         |\n",
      "|    policy_gradient_loss | -0.000751     |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1364     |\n",
      "|    iterations      | 2237     |\n",
      "|    time_elapsed    | 13435    |\n",
      "|    total_timesteps | 18325504 |\n",
      "---------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 1364           |\n",
      "|    iterations           | 2238           |\n",
      "|    time_elapsed         | 13438          |\n",
      "|    total_timesteps      | 18333696       |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000100373174 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.39          |\n",
      "|    explained_variance   | 0.0411         |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 1.26e+03       |\n",
      "|    n_updates            | 25930          |\n",
      "|    policy_gradient_loss | -0.000418      |\n",
      "|    value_loss           | 1.93e+03       |\n",
      "--------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1364         |\n",
      "|    iterations           | 2239         |\n",
      "|    time_elapsed         | 13442        |\n",
      "|    total_timesteps      | 18341888     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.414549e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.39        |\n",
      "|    explained_variance   | 0.0523       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 914          |\n",
      "|    n_updates            | 25940        |\n",
      "|    policy_gradient_loss | -0.000382    |\n",
      "|    value_loss           | 2.07e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1364          |\n",
      "|    iterations           | 2240          |\n",
      "|    time_elapsed         | 13447         |\n",
      "|    total_timesteps      | 18350080      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.6112464e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.392        |\n",
      "|    explained_variance   | 0.0359        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 863           |\n",
      "|    n_updates            | 25950         |\n",
      "|    policy_gradient_loss | -0.000431     |\n",
      "|    value_loss           | 1.95e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1364          |\n",
      "|    iterations           | 2241          |\n",
      "|    time_elapsed         | 13458         |\n",
      "|    total_timesteps      | 18358272      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013433222 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.384        |\n",
      "|    explained_variance   | -0.00509      |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 966           |\n",
      "|    n_updates            | 25960         |\n",
      "|    policy_gradient_loss | -0.000476     |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=18360000, episode_reward=646.00 +/- 64.78\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 646           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 18360000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020515017 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.388        |\n",
      "|    explained_variance   | 0.00641       |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 775           |\n",
      "|    n_updates            | 25970         |\n",
      "|    policy_gradient_loss | -0.000596     |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1363     |\n",
      "|    iterations      | 2242     |\n",
      "|    time_elapsed    | 13469    |\n",
      "|    total_timesteps | 18366464 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1363          |\n",
      "|    iterations           | 2243          |\n",
      "|    time_elapsed         | 13472         |\n",
      "|    total_timesteps      | 18374656      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020197147 |\n",
      "|    clip_fraction        | 3.66e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.392        |\n",
      "|    explained_variance   | 0.04          |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 692           |\n",
      "|    n_updates            | 25980         |\n",
      "|    policy_gradient_loss | -0.000629     |\n",
      "|    value_loss           | 2.06e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1364          |\n",
      "|    iterations           | 2244          |\n",
      "|    time_elapsed         | 13476         |\n",
      "|    total_timesteps      | 18382848      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.7488258e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.391        |\n",
      "|    explained_variance   | 0.0584        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 982           |\n",
      "|    n_updates            | 25990         |\n",
      "|    policy_gradient_loss | -0.000318     |\n",
      "|    value_loss           | 1.84e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1364          |\n",
      "|    iterations           | 2245          |\n",
      "|    time_elapsed         | 13480         |\n",
      "|    total_timesteps      | 18391040      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017456495 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.387        |\n",
      "|    explained_variance   | 0.0174        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 999           |\n",
      "|    n_updates            | 26000         |\n",
      "|    policy_gradient_loss | -0.000453     |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1364          |\n",
      "|    iterations           | 2246          |\n",
      "|    time_elapsed         | 13484         |\n",
      "|    total_timesteps      | 18399232      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020425231 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.377        |\n",
      "|    explained_variance   | 0.0519        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.16e+03      |\n",
      "|    n_updates            | 26010         |\n",
      "|    policy_gradient_loss | -0.000665     |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=18400000, episode_reward=665.60 +/- 55.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 666           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 18400000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010951242 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.391        |\n",
      "|    explained_variance   | 0.0615        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 968           |\n",
      "|    n_updates            | 26020         |\n",
      "|    policy_gradient_loss | -0.000476     |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1364     |\n",
      "|    iterations      | 2247     |\n",
      "|    time_elapsed    | 13494    |\n",
      "|    total_timesteps | 18407424 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1364          |\n",
      "|    iterations           | 2248          |\n",
      "|    time_elapsed         | 13498         |\n",
      "|    total_timesteps      | 18415616      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017528859 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.395        |\n",
      "|    explained_variance   | 0.021         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 566           |\n",
      "|    n_updates            | 26030         |\n",
      "|    policy_gradient_loss | -0.000592     |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1364         |\n",
      "|    iterations           | 2249         |\n",
      "|    time_elapsed         | 13501        |\n",
      "|    total_timesteps      | 18423808     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001282975 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.389       |\n",
      "|    explained_variance   | 0.0177       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 995          |\n",
      "|    n_updates            | 26040        |\n",
      "|    policy_gradient_loss | -0.00048     |\n",
      "|    value_loss           | 1.91e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1364          |\n",
      "|    iterations           | 2250          |\n",
      "|    time_elapsed         | 13506         |\n",
      "|    total_timesteps      | 18432000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013510532 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.397        |\n",
      "|    explained_variance   | 0.0382        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.05e+03      |\n",
      "|    n_updates            | 26050         |\n",
      "|    policy_gradient_loss | -0.000479     |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=18440000, episode_reward=652.80 +/- 45.52\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 653           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 18440000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010858355 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.384        |\n",
      "|    explained_variance   | 0.0588        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.01e+03      |\n",
      "|    n_updates            | 26060         |\n",
      "|    policy_gradient_loss | -0.000495     |\n",
      "|    value_loss           | 2.05e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1364     |\n",
      "|    iterations      | 2251     |\n",
      "|    time_elapsed    | 13516    |\n",
      "|    total_timesteps | 18440192 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1364          |\n",
      "|    iterations           | 2252          |\n",
      "|    time_elapsed         | 13520         |\n",
      "|    total_timesteps      | 18448384      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.5055956e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.386        |\n",
      "|    explained_variance   | 0.0444        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.01e+03      |\n",
      "|    n_updates            | 26070         |\n",
      "|    policy_gradient_loss | -0.000368     |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1364        |\n",
      "|    iterations           | 2253        |\n",
      "|    time_elapsed         | 13523       |\n",
      "|    total_timesteps      | 18456576    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 8.42508e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.383      |\n",
      "|    explained_variance   | 0.0376      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 908         |\n",
      "|    n_updates            | 26080       |\n",
      "|    policy_gradient_loss | -0.000411   |\n",
      "|    value_loss           | 1.86e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1364          |\n",
      "|    iterations           | 2254          |\n",
      "|    time_elapsed         | 13527         |\n",
      "|    total_timesteps      | 18464768      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022691506 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.39         |\n",
      "|    explained_variance   | 0.0345        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 927           |\n",
      "|    n_updates            | 26090         |\n",
      "|    policy_gradient_loss | -0.000716     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1365          |\n",
      "|    iterations           | 2255          |\n",
      "|    time_elapsed         | 13531         |\n",
      "|    total_timesteps      | 18472960      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015069131 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.382        |\n",
      "|    explained_variance   | 0.031         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.07e+03      |\n",
      "|    n_updates            | 26100         |\n",
      "|    policy_gradient_loss | -0.000543     |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=18480000, episode_reward=660.80 +/- 77.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 661           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 18480000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.3773052e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.396        |\n",
      "|    explained_variance   | 0.0412        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.02e+03      |\n",
      "|    n_updates            | 26110         |\n",
      "|    policy_gradient_loss | -0.00029      |\n",
      "|    value_loss           | 2.07e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1364     |\n",
      "|    iterations      | 2256     |\n",
      "|    time_elapsed    | 13541    |\n",
      "|    total_timesteps | 18481152 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1364          |\n",
      "|    iterations           | 2257          |\n",
      "|    time_elapsed         | 13545         |\n",
      "|    total_timesteps      | 18489344      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017079533 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.391        |\n",
      "|    explained_variance   | 0.0374        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.05e+03      |\n",
      "|    n_updates            | 26120         |\n",
      "|    policy_gradient_loss | -0.000503     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1365          |\n",
      "|    iterations           | 2258          |\n",
      "|    time_elapsed         | 13549         |\n",
      "|    total_timesteps      | 18497536      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026900112 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.389        |\n",
      "|    explained_variance   | 0.0715        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 818           |\n",
      "|    n_updates            | 26130         |\n",
      "|    policy_gradient_loss | -0.000888     |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1365          |\n",
      "|    iterations           | 2259          |\n",
      "|    time_elapsed         | 13552         |\n",
      "|    total_timesteps      | 18505728      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.1421895e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.386        |\n",
      "|    explained_variance   | 0.0195        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 897           |\n",
      "|    n_updates            | 26140         |\n",
      "|    policy_gradient_loss | -0.000386     |\n",
      "|    value_loss           | 1.97e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1365          |\n",
      "|    iterations           | 2260          |\n",
      "|    time_elapsed         | 13556         |\n",
      "|    total_timesteps      | 18513920      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032310665 |\n",
      "|    clip_fraction        | 8.54e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.39         |\n",
      "|    explained_variance   | 0.0329        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 862           |\n",
      "|    n_updates            | 26150         |\n",
      "|    policy_gradient_loss | -0.000829     |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=18520000, episode_reward=652.20 +/- 64.63\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 652           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 18520000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022747152 |\n",
      "|    clip_fraction        | 0.000122      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.387        |\n",
      "|    explained_variance   | 0.0197        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.3e+03       |\n",
      "|    n_updates            | 26160         |\n",
      "|    policy_gradient_loss | -0.000946     |\n",
      "|    value_loss           | 1.96e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1362     |\n",
      "|    iterations      | 2261     |\n",
      "|    time_elapsed    | 13598    |\n",
      "|    total_timesteps | 18522112 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1362          |\n",
      "|    iterations           | 2262          |\n",
      "|    time_elapsed         | 13602         |\n",
      "|    total_timesteps      | 18530304      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015361211 |\n",
      "|    clip_fraction        | 0.000183      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.381        |\n",
      "|    explained_variance   | 0.0439        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 828           |\n",
      "|    n_updates            | 26170         |\n",
      "|    policy_gradient_loss | -0.000529     |\n",
      "|    value_loss           | 1.85e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1362         |\n",
      "|    iterations           | 2263         |\n",
      "|    time_elapsed         | 13606        |\n",
      "|    total_timesteps      | 18538496     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.683154e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.387       |\n",
      "|    explained_variance   | 0.053        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 944          |\n",
      "|    n_updates            | 26180        |\n",
      "|    policy_gradient_loss | -0.000383    |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1362         |\n",
      "|    iterations           | 2264         |\n",
      "|    time_elapsed         | 13610        |\n",
      "|    total_timesteps      | 18546688     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.131798e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.392       |\n",
      "|    explained_variance   | 0.0374       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.37e+03     |\n",
      "|    n_updates            | 26190        |\n",
      "|    policy_gradient_loss | -0.000276    |\n",
      "|    value_loss           | 2.02e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1362          |\n",
      "|    iterations           | 2265          |\n",
      "|    time_elapsed         | 13614         |\n",
      "|    total_timesteps      | 18554880      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023749904 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.386        |\n",
      "|    explained_variance   | 0.0475        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 891           |\n",
      "|    n_updates            | 26200         |\n",
      "|    policy_gradient_loss | -0.000659     |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=18560000, episode_reward=657.00 +/- 58.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 657          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18560000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002354417 |\n",
      "|    clip_fraction        | 2.44e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.39        |\n",
      "|    explained_variance   | 0.0397       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 832          |\n",
      "|    n_updates            | 26210        |\n",
      "|    policy_gradient_loss | -0.000715    |\n",
      "|    value_loss           | 1.95e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1362     |\n",
      "|    iterations      | 2266     |\n",
      "|    time_elapsed    | 13624    |\n",
      "|    total_timesteps | 18563072 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1357          |\n",
      "|    iterations           | 2267          |\n",
      "|    time_elapsed         | 13683         |\n",
      "|    total_timesteps      | 18571264      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018054625 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.393        |\n",
      "|    explained_variance   | 0.0547        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.33e+03      |\n",
      "|    n_updates            | 26220         |\n",
      "|    policy_gradient_loss | -0.000566     |\n",
      "|    value_loss           | 1.94e+03      |\n",
      "-------------------------------------------\n",
      "--------------------------------------------\n",
      "| time/                   |                |\n",
      "|    fps                  | 1351           |\n",
      "|    iterations           | 2268           |\n",
      "|    time_elapsed         | 13751          |\n",
      "|    total_timesteps      | 18579456       |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000108819484 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -0.399         |\n",
      "|    explained_variance   | 0.0398         |\n",
      "|    learning_rate        | 1e-05          |\n",
      "|    loss                 | 1.15e+03       |\n",
      "|    n_updates            | 26230          |\n",
      "|    policy_gradient_loss | -0.000516      |\n",
      "|    value_loss           | 1.94e+03       |\n",
      "--------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1351          |\n",
      "|    iterations           | 2269          |\n",
      "|    time_elapsed         | 13755         |\n",
      "|    total_timesteps      | 18587648      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012672355 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.39         |\n",
      "|    explained_variance   | 0.0509        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1e+03         |\n",
      "|    n_updates            | 26240         |\n",
      "|    policy_gradient_loss | -0.000525     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1351          |\n",
      "|    iterations           | 2270          |\n",
      "|    time_elapsed         | 13759         |\n",
      "|    total_timesteps      | 18595840      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026323393 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.388        |\n",
      "|    explained_variance   | 0.02          |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 872           |\n",
      "|    n_updates            | 26250         |\n",
      "|    policy_gradient_loss | -0.000756     |\n",
      "|    value_loss           | 1.85e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=18600000, episode_reward=646.80 +/- 68.19\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 647           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 18600000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019486729 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.393        |\n",
      "|    explained_variance   | 0.0356        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 797           |\n",
      "|    n_updates            | 26260         |\n",
      "|    policy_gradient_loss | -0.000665     |\n",
      "|    value_loss           | 1.85e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1351     |\n",
      "|    iterations      | 2271     |\n",
      "|    time_elapsed    | 13770    |\n",
      "|    total_timesteps | 18604032 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1351         |\n",
      "|    iterations           | 2272         |\n",
      "|    time_elapsed         | 13774        |\n",
      "|    total_timesteps      | 18612224     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.731618e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.384       |\n",
      "|    explained_variance   | 0.0501       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 797          |\n",
      "|    n_updates            | 26270        |\n",
      "|    policy_gradient_loss | -0.00036     |\n",
      "|    value_loss           | 1.94e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1351          |\n",
      "|    iterations           | 2273          |\n",
      "|    time_elapsed         | 13777         |\n",
      "|    total_timesteps      | 18620416      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016945333 |\n",
      "|    clip_fraction        | 8.54e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.396        |\n",
      "|    explained_variance   | 0.0689        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 888           |\n",
      "|    n_updates            | 26280         |\n",
      "|    policy_gradient_loss | -0.00063      |\n",
      "|    value_loss           | 1.84e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1351         |\n",
      "|    iterations           | 2274         |\n",
      "|    time_elapsed         | 13781        |\n",
      "|    total_timesteps      | 18628608     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.656447e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.389       |\n",
      "|    explained_variance   | 0.0145       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 850          |\n",
      "|    n_updates            | 26290        |\n",
      "|    policy_gradient_loss | -0.000469    |\n",
      "|    value_loss           | 1.91e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1351         |\n",
      "|    iterations           | 2275         |\n",
      "|    time_elapsed         | 13785        |\n",
      "|    total_timesteps      | 18636800     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002780782 |\n",
      "|    clip_fraction        | 0.00022      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.395       |\n",
      "|    explained_variance   | 0.0281       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 694          |\n",
      "|    n_updates            | 26300        |\n",
      "|    policy_gradient_loss | -0.000709    |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=18640000, episode_reward=649.40 +/- 58.01\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 649           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 18640000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012874714 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.38         |\n",
      "|    explained_variance   | 0.0434        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.07e+03      |\n",
      "|    n_updates            | 26310         |\n",
      "|    policy_gradient_loss | -0.000512     |\n",
      "|    value_loss           | 2.05e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1351     |\n",
      "|    iterations      | 2276     |\n",
      "|    time_elapsed    | 13796    |\n",
      "|    total_timesteps | 18644992 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1351         |\n",
      "|    iterations           | 2277         |\n",
      "|    time_elapsed         | 13799        |\n",
      "|    total_timesteps      | 18653184     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.563889e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.395       |\n",
      "|    explained_variance   | 0.047        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 915          |\n",
      "|    n_updates            | 26320        |\n",
      "|    policy_gradient_loss | -0.000365    |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1351          |\n",
      "|    iterations           | 2278          |\n",
      "|    time_elapsed         | 13803         |\n",
      "|    total_timesteps      | 18661376      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019285158 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.39         |\n",
      "|    explained_variance   | 0.0376        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 710           |\n",
      "|    n_updates            | 26330         |\n",
      "|    policy_gradient_loss | -0.000653     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1349          |\n",
      "|    iterations           | 2279          |\n",
      "|    time_elapsed         | 13838         |\n",
      "|    total_timesteps      | 18669568      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011959156 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.394        |\n",
      "|    explained_variance   | 0.0456        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 904           |\n",
      "|    n_updates            | 26340         |\n",
      "|    policy_gradient_loss | -0.000511     |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1349         |\n",
      "|    iterations           | 2280         |\n",
      "|    time_elapsed         | 13842        |\n",
      "|    total_timesteps      | 18677760     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.955956e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.387       |\n",
      "|    explained_variance   | 0.0706       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 26350        |\n",
      "|    policy_gradient_loss | -0.000427    |\n",
      "|    value_loss           | 1.94e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=18680000, episode_reward=653.40 +/- 49.74\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 653           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 18680000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018239956 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.39         |\n",
      "|    explained_variance   | 0.0588        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 951           |\n",
      "|    n_updates            | 26360         |\n",
      "|    policy_gradient_loss | -0.000763     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1348     |\n",
      "|    iterations      | 2281     |\n",
      "|    time_elapsed    | 13853    |\n",
      "|    total_timesteps | 18685952 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1349          |\n",
      "|    iterations           | 2282          |\n",
      "|    time_elapsed         | 13856         |\n",
      "|    total_timesteps      | 18694144      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010299107 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.38         |\n",
      "|    explained_variance   | 0.041         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 783           |\n",
      "|    n_updates            | 26370         |\n",
      "|    policy_gradient_loss | -0.000486     |\n",
      "|    value_loss           | 2.01e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1349          |\n",
      "|    iterations           | 2283          |\n",
      "|    time_elapsed         | 13860         |\n",
      "|    total_timesteps      | 18702336      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020412132 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.387        |\n",
      "|    explained_variance   | 0.0643        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 654           |\n",
      "|    n_updates            | 26380         |\n",
      "|    policy_gradient_loss | -0.000593     |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1349          |\n",
      "|    iterations           | 2284          |\n",
      "|    time_elapsed         | 13864         |\n",
      "|    total_timesteps      | 18710528      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017486003 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.39         |\n",
      "|    explained_variance   | 0.0178        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 894           |\n",
      "|    n_updates            | 26390         |\n",
      "|    policy_gradient_loss | -0.000537     |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1349          |\n",
      "|    iterations           | 2285          |\n",
      "|    time_elapsed         | 13870         |\n",
      "|    total_timesteps      | 18718720      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026555872 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.383        |\n",
      "|    explained_variance   | 0.0563        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 999           |\n",
      "|    n_updates            | 26400         |\n",
      "|    policy_gradient_loss | -0.000823     |\n",
      "|    value_loss           | 2.03e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=18720000, episode_reward=649.00 +/- 55.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 649           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 18720000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.7950936e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.385        |\n",
      "|    explained_variance   | 0.0567        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.01e+03      |\n",
      "|    n_updates            | 26410         |\n",
      "|    policy_gradient_loss | -0.000431     |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1349     |\n",
      "|    iterations      | 2286     |\n",
      "|    time_elapsed    | 13881    |\n",
      "|    total_timesteps | 18726912 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1349        |\n",
      "|    iterations           | 2287        |\n",
      "|    time_elapsed         | 13885       |\n",
      "|    total_timesteps      | 18735104    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 8.60431e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.379      |\n",
      "|    explained_variance   | 0.0384      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 968         |\n",
      "|    n_updates            | 26420       |\n",
      "|    policy_gradient_loss | -0.000381   |\n",
      "|    value_loss           | 1.87e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1349          |\n",
      "|    iterations           | 2288          |\n",
      "|    time_elapsed         | 13888         |\n",
      "|    total_timesteps      | 18743296      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017849437 |\n",
      "|    clip_fraction        | 0.00011       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.378        |\n",
      "|    explained_variance   | 0.0395        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 890           |\n",
      "|    n_updates            | 26430         |\n",
      "|    policy_gradient_loss | -0.000604     |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1349          |\n",
      "|    iterations           | 2289          |\n",
      "|    time_elapsed         | 13892         |\n",
      "|    total_timesteps      | 18751488      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.0019716e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.386        |\n",
      "|    explained_variance   | 0.0508        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 825           |\n",
      "|    n_updates            | 26440         |\n",
      "|    policy_gradient_loss | -0.00042      |\n",
      "|    value_loss           | 2.03e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1349          |\n",
      "|    iterations           | 2290          |\n",
      "|    time_elapsed         | 13896         |\n",
      "|    total_timesteps      | 18759680      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020470418 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.38         |\n",
      "|    explained_variance   | 0.045         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 767           |\n",
      "|    n_updates            | 26450         |\n",
      "|    policy_gradient_loss | -0.00069      |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=18760000, episode_reward=658.80 +/- 54.91\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 659          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18760000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.653447e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.403       |\n",
      "|    explained_variance   | 0.0303       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 26460        |\n",
      "|    policy_gradient_loss | -0.000412    |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1349     |\n",
      "|    iterations      | 2291     |\n",
      "|    time_elapsed    | 13907    |\n",
      "|    total_timesteps | 18767872 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1349          |\n",
      "|    iterations           | 2292          |\n",
      "|    time_elapsed         | 13911         |\n",
      "|    total_timesteps      | 18776064      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016658942 |\n",
      "|    clip_fraction        | 0.00011       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.386        |\n",
      "|    explained_variance   | 0.0585        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 919           |\n",
      "|    n_updates            | 26470         |\n",
      "|    policy_gradient_loss | -0.000555     |\n",
      "|    value_loss           | 1.96e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1349          |\n",
      "|    iterations           | 2293          |\n",
      "|    time_elapsed         | 13915         |\n",
      "|    total_timesteps      | 18784256      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.9064434e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.376        |\n",
      "|    explained_variance   | 0.0113        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.06e+03      |\n",
      "|    n_updates            | 26480         |\n",
      "|    policy_gradient_loss | -0.000366     |\n",
      "|    value_loss           | 2.03e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1350          |\n",
      "|    iterations           | 2294          |\n",
      "|    time_elapsed         | 13918         |\n",
      "|    total_timesteps      | 18792448      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017035671 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.38         |\n",
      "|    explained_variance   | 0.03          |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.12e+03      |\n",
      "|    n_updates            | 26490         |\n",
      "|    policy_gradient_loss | -0.000607     |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=18800000, episode_reward=668.80 +/- 59.99\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 669           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 18800000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014191918 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.371        |\n",
      "|    explained_variance   | 0.0409        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.1e+03       |\n",
      "|    n_updates            | 26500         |\n",
      "|    policy_gradient_loss | -0.00056      |\n",
      "|    value_loss           | 1.82e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1348     |\n",
      "|    iterations      | 2295     |\n",
      "|    time_elapsed    | 13942    |\n",
      "|    total_timesteps | 18800640 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1348          |\n",
      "|    iterations           | 2296          |\n",
      "|    time_elapsed         | 13946         |\n",
      "|    total_timesteps      | 18808832      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012014725 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.378        |\n",
      "|    explained_variance   | 0.05          |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 855           |\n",
      "|    n_updates            | 26510         |\n",
      "|    policy_gradient_loss | -0.000631     |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1348          |\n",
      "|    iterations           | 2297          |\n",
      "|    time_elapsed         | 13950         |\n",
      "|    total_timesteps      | 18817024      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.3631033e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.384        |\n",
      "|    explained_variance   | 0.0372        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 974           |\n",
      "|    n_updates            | 26520         |\n",
      "|    policy_gradient_loss | -0.000301     |\n",
      "|    value_loss           | 2.07e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1349          |\n",
      "|    iterations           | 2298          |\n",
      "|    time_elapsed         | 13954         |\n",
      "|    total_timesteps      | 18825216      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015299962 |\n",
      "|    clip_fraction        | 3.66e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.371        |\n",
      "|    explained_variance   | 0.022         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 827           |\n",
      "|    n_updates            | 26530         |\n",
      "|    policy_gradient_loss | -0.000538     |\n",
      "|    value_loss           | 1.82e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1349          |\n",
      "|    iterations           | 2299          |\n",
      "|    time_elapsed         | 13957         |\n",
      "|    total_timesteps      | 18833408      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015311546 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.373        |\n",
      "|    explained_variance   | 0.0359        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.08e+03      |\n",
      "|    n_updates            | 26540         |\n",
      "|    policy_gradient_loss | -0.000635     |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=18840000, episode_reward=657.40 +/- 56.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 657           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 18840000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020755088 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.377        |\n",
      "|    explained_variance   | 0.0602        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 873           |\n",
      "|    n_updates            | 26550         |\n",
      "|    policy_gradient_loss | -0.000644     |\n",
      "|    value_loss           | 1.83e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1348     |\n",
      "|    iterations      | 2300     |\n",
      "|    time_elapsed    | 13967    |\n",
      "|    total_timesteps | 18841600 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1349          |\n",
      "|    iterations           | 2301          |\n",
      "|    time_elapsed         | 13971         |\n",
      "|    total_timesteps      | 18849792      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011034936 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.378        |\n",
      "|    explained_variance   | 0.0308        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.1e+03       |\n",
      "|    n_updates            | 26560         |\n",
      "|    policy_gradient_loss | -0.000492     |\n",
      "|    value_loss           | 2.09e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1349          |\n",
      "|    iterations           | 2302          |\n",
      "|    time_elapsed         | 13975         |\n",
      "|    total_timesteps      | 18857984      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022382548 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.38         |\n",
      "|    explained_variance   | 0.047         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 926           |\n",
      "|    n_updates            | 26570         |\n",
      "|    policy_gradient_loss | -0.000652     |\n",
      "|    value_loss           | 2.07e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1349         |\n",
      "|    iterations           | 2303         |\n",
      "|    time_elapsed         | 13979        |\n",
      "|    total_timesteps      | 18866176     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.515038e-05 |\n",
      "|    clip_fraction        | 1.22e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.372       |\n",
      "|    explained_variance   | 0.0295       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 979          |\n",
      "|    n_updates            | 26580        |\n",
      "|    policy_gradient_loss | -0.000449    |\n",
      "|    value_loss           | 1.94e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1349          |\n",
      "|    iterations           | 2304          |\n",
      "|    time_elapsed         | 13983         |\n",
      "|    total_timesteps      | 18874368      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013951075 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.381        |\n",
      "|    explained_variance   | 0.0485        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 719           |\n",
      "|    n_updates            | 26590         |\n",
      "|    policy_gradient_loss | -0.000538     |\n",
      "|    value_loss           | 1.8e+03       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=18880000, episode_reward=656.20 +/- 64.90\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 656          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18880000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.055146e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.373       |\n",
      "|    explained_variance   | 0.0435       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 997          |\n",
      "|    n_updates            | 26600        |\n",
      "|    policy_gradient_loss | -0.000354    |\n",
      "|    value_loss           | 1.99e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1346     |\n",
      "|    iterations      | 2305     |\n",
      "|    time_elapsed    | 14023    |\n",
      "|    total_timesteps | 18882560 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1346          |\n",
      "|    iterations           | 2306          |\n",
      "|    time_elapsed         | 14027         |\n",
      "|    total_timesteps      | 18890752      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012017145 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.377        |\n",
      "|    explained_variance   | 0.0438        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 953           |\n",
      "|    n_updates            | 26610         |\n",
      "|    policy_gradient_loss | -0.000409     |\n",
      "|    value_loss           | 2.03e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1346          |\n",
      "|    iterations           | 2307          |\n",
      "|    time_elapsed         | 14030         |\n",
      "|    total_timesteps      | 18898944      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013245773 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.383        |\n",
      "|    explained_variance   | 0.0193        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 851           |\n",
      "|    n_updates            | 26620         |\n",
      "|    policy_gradient_loss | -0.000488     |\n",
      "|    value_loss           | 1.82e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1347          |\n",
      "|    iterations           | 2308          |\n",
      "|    time_elapsed         | 14034         |\n",
      "|    total_timesteps      | 18907136      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013963846 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.381        |\n",
      "|    explained_variance   | 0.039         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 801           |\n",
      "|    n_updates            | 26630         |\n",
      "|    policy_gradient_loss | -0.000537     |\n",
      "|    value_loss           | 1.86e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1347          |\n",
      "|    iterations           | 2309          |\n",
      "|    time_elapsed         | 14038         |\n",
      "|    total_timesteps      | 18915328      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012543818 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.379        |\n",
      "|    explained_variance   | 0.0504        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 895           |\n",
      "|    n_updates            | 26640         |\n",
      "|    policy_gradient_loss | -0.000451     |\n",
      "|    value_loss           | 2.01e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=18920000, episode_reward=647.60 +/- 63.10\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 648           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 18920000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021156584 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.368        |\n",
      "|    explained_variance   | 0.0467        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 970           |\n",
      "|    n_updates            | 26650         |\n",
      "|    policy_gradient_loss | -0.000591     |\n",
      "|    value_loss           | 2.01e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1340     |\n",
      "|    iterations      | 2310     |\n",
      "|    time_elapsed    | 14121    |\n",
      "|    total_timesteps | 18923520 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1340         |\n",
      "|    iterations           | 2311         |\n",
      "|    time_elapsed         | 14126        |\n",
      "|    total_timesteps      | 18931712     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001273767 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.38        |\n",
      "|    explained_variance   | 0.0478       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 996          |\n",
      "|    n_updates            | 26660        |\n",
      "|    policy_gradient_loss | -0.000626    |\n",
      "|    value_loss           | 1.91e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1340          |\n",
      "|    iterations           | 2312          |\n",
      "|    time_elapsed         | 14130         |\n",
      "|    total_timesteps      | 18939904      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 8.2534636e-05 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.38         |\n",
      "|    explained_variance   | 0.0363        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.17e+03      |\n",
      "|    n_updates            | 26670         |\n",
      "|    policy_gradient_loss | -0.000437     |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1339          |\n",
      "|    iterations           | 2313          |\n",
      "|    time_elapsed         | 14145         |\n",
      "|    total_timesteps      | 18948096      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011774619 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.379        |\n",
      "|    explained_variance   | 0.0496        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1e+03         |\n",
      "|    n_updates            | 26680         |\n",
      "|    policy_gradient_loss | -0.00047      |\n",
      "|    value_loss           | 1.85e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1339          |\n",
      "|    iterations           | 2314          |\n",
      "|    time_elapsed         | 14150         |\n",
      "|    total_timesteps      | 18956288      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015359133 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.382        |\n",
      "|    explained_variance   | 0.08          |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.37e+03      |\n",
      "|    n_updates            | 26690         |\n",
      "|    policy_gradient_loss | -0.000564     |\n",
      "|    value_loss           | 2.08e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=18960000, episode_reward=639.20 +/- 105.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 639           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 18960000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011237418 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.374        |\n",
      "|    explained_variance   | 0.0436        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.45e+03      |\n",
      "|    n_updates            | 26700         |\n",
      "|    policy_gradient_loss | -0.000396     |\n",
      "|    value_loss           | 1.95e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1339     |\n",
      "|    iterations      | 2315     |\n",
      "|    time_elapsed    | 14160    |\n",
      "|    total_timesteps | 18964480 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1339          |\n",
      "|    iterations           | 2316          |\n",
      "|    time_elapsed         | 14165         |\n",
      "|    total_timesteps      | 18972672      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013155301 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.37         |\n",
      "|    explained_variance   | 0.0413        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.21e+03      |\n",
      "|    n_updates            | 26710         |\n",
      "|    policy_gradient_loss | -0.000519     |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1339          |\n",
      "|    iterations           | 2317          |\n",
      "|    time_elapsed         | 14171         |\n",
      "|    total_timesteps      | 18980864      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026708032 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.375        |\n",
      "|    explained_variance   | 0.0374        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 955           |\n",
      "|    n_updates            | 26720         |\n",
      "|    policy_gradient_loss | -0.000752     |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1339        |\n",
      "|    iterations           | 2318        |\n",
      "|    time_elapsed         | 14178       |\n",
      "|    total_timesteps      | 18989056    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 6.41783e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.38       |\n",
      "|    explained_variance   | 0.0638      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 904         |\n",
      "|    n_updates            | 26730       |\n",
      "|    policy_gradient_loss | -0.000383   |\n",
      "|    value_loss           | 2.1e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1339         |\n",
      "|    iterations           | 2319         |\n",
      "|    time_elapsed         | 14182        |\n",
      "|    total_timesteps      | 18997248     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001221309 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.379       |\n",
      "|    explained_variance   | 0.0451       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 26740        |\n",
      "|    policy_gradient_loss | -0.000543    |\n",
      "|    value_loss           | 1.97e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19000000, episode_reward=656.00 +/- 56.57\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 656           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 19000000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013260785 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.384        |\n",
      "|    explained_variance   | 0.0333        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 821           |\n",
      "|    n_updates            | 26750         |\n",
      "|    policy_gradient_loss | -0.000575     |\n",
      "|    value_loss           | 1.87e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1338     |\n",
      "|    iterations      | 2320     |\n",
      "|    time_elapsed    | 14197    |\n",
      "|    total_timesteps | 19005440 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1338         |\n",
      "|    iterations           | 2321         |\n",
      "|    time_elapsed         | 14208        |\n",
      "|    total_timesteps      | 19013632     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.830695e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.368       |\n",
      "|    explained_variance   | 0.0289       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 901          |\n",
      "|    n_updates            | 26760        |\n",
      "|    policy_gradient_loss | -0.000428    |\n",
      "|    value_loss           | 1.99e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1338         |\n",
      "|    iterations           | 2322         |\n",
      "|    time_elapsed         | 14212        |\n",
      "|    total_timesteps      | 19021824     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.762971e-05 |\n",
      "|    clip_fraction        | 1.22e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.377       |\n",
      "|    explained_variance   | 0.0573       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 26770        |\n",
      "|    policy_gradient_loss | -0.000516    |\n",
      "|    value_loss           | 2.03e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1338          |\n",
      "|    iterations           | 2323          |\n",
      "|    time_elapsed         | 14216         |\n",
      "|    total_timesteps      | 19030016      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011890027 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.385        |\n",
      "|    explained_variance   | 0.0462        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.26e+03      |\n",
      "|    n_updates            | 26780         |\n",
      "|    policy_gradient_loss | -0.000449     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1338          |\n",
      "|    iterations           | 2324          |\n",
      "|    time_elapsed         | 14221         |\n",
      "|    total_timesteps      | 19038208      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013970629 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.372        |\n",
      "|    explained_variance   | 0.0505        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.27e+03      |\n",
      "|    n_updates            | 26790         |\n",
      "|    policy_gradient_loss | -0.000594     |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=19040000, episode_reward=670.80 +/- 69.59\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 671           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 19040000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024253648 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.374        |\n",
      "|    explained_variance   | 0.0459        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 901           |\n",
      "|    n_updates            | 26800         |\n",
      "|    policy_gradient_loss | -0.000749     |\n",
      "|    value_loss           | 1.95e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1330     |\n",
      "|    iterations      | 2325     |\n",
      "|    time_elapsed    | 14317    |\n",
      "|    total_timesteps | 19046400 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1330          |\n",
      "|    iterations           | 2326          |\n",
      "|    time_elapsed         | 14321         |\n",
      "|    total_timesteps      | 19054592      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.0695013e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.381        |\n",
      "|    explained_variance   | 0.0435        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 927           |\n",
      "|    n_updates            | 26810         |\n",
      "|    policy_gradient_loss | -0.000328     |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1330          |\n",
      "|    iterations           | 2327          |\n",
      "|    time_elapsed         | 14326         |\n",
      "|    total_timesteps      | 19062784      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.3847615e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.383        |\n",
      "|    explained_variance   | -0.00364      |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.06e+03      |\n",
      "|    n_updates            | 26820         |\n",
      "|    policy_gradient_loss | -0.000537     |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1329          |\n",
      "|    iterations           | 2328          |\n",
      "|    time_elapsed         | 14346         |\n",
      "|    total_timesteps      | 19070976      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.7906145e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.369        |\n",
      "|    explained_variance   | 0.041         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 850           |\n",
      "|    n_updates            | 26830         |\n",
      "|    policy_gradient_loss | -0.000332     |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1329          |\n",
      "|    iterations           | 2329          |\n",
      "|    time_elapsed         | 14353         |\n",
      "|    total_timesteps      | 19079168      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020887765 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.37         |\n",
      "|    explained_variance   | 0.0125        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.02e+03      |\n",
      "|    n_updates            | 26840         |\n",
      "|    policy_gradient_loss | -0.000548     |\n",
      "|    value_loss           | 1.93e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=19080000, episode_reward=660.20 +/- 57.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 660           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 19080000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024539474 |\n",
      "|    clip_fraction        | 0.000232      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.387        |\n",
      "|    explained_variance   | 0.0406        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 978           |\n",
      "|    n_updates            | 26850         |\n",
      "|    policy_gradient_loss | -0.000761     |\n",
      "|    value_loss           | 1.93e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1328     |\n",
      "|    iterations      | 2330     |\n",
      "|    time_elapsed    | 14363    |\n",
      "|    total_timesteps | 19087360 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1329          |\n",
      "|    iterations           | 2331          |\n",
      "|    time_elapsed         | 14367         |\n",
      "|    total_timesteps      | 19095552      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012933242 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.378        |\n",
      "|    explained_variance   | 0.0306        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.22e+03      |\n",
      "|    n_updates            | 26860         |\n",
      "|    policy_gradient_loss | -0.000462     |\n",
      "|    value_loss           | 2.04e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1329          |\n",
      "|    iterations           | 2332          |\n",
      "|    time_elapsed         | 14371         |\n",
      "|    total_timesteps      | 19103744      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010927653 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.38         |\n",
      "|    explained_variance   | 0.0517        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 853           |\n",
      "|    n_updates            | 26870         |\n",
      "|    policy_gradient_loss | -0.000455     |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1329         |\n",
      "|    iterations           | 2333         |\n",
      "|    time_elapsed         | 14375        |\n",
      "|    total_timesteps      | 19111936     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002178222 |\n",
      "|    clip_fraction        | 2.44e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.376       |\n",
      "|    explained_variance   | 0.0509       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 859          |\n",
      "|    n_updates            | 26880        |\n",
      "|    policy_gradient_loss | -0.000682    |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19120000, episode_reward=636.00 +/- 60.63\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 636           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 19120000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018158034 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.379        |\n",
      "|    explained_variance   | 0.047         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 971           |\n",
      "|    n_updates            | 26890         |\n",
      "|    policy_gradient_loss | -0.000527     |\n",
      "|    value_loss           | 1.87e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1329     |\n",
      "|    iterations      | 2334     |\n",
      "|    time_elapsed    | 14386    |\n",
      "|    total_timesteps | 19120128 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1329          |\n",
      "|    iterations           | 2335          |\n",
      "|    time_elapsed         | 14390         |\n",
      "|    total_timesteps      | 19128320      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014867133 |\n",
      "|    clip_fraction        | 6.1e-05       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.372        |\n",
      "|    explained_variance   | -0.000874     |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 706           |\n",
      "|    n_updates            | 26900         |\n",
      "|    policy_gradient_loss | -0.00057      |\n",
      "|    value_loss           | 2.09e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1329          |\n",
      "|    iterations           | 2336          |\n",
      "|    time_elapsed         | 14394         |\n",
      "|    total_timesteps      | 19136512      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018758299 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.377        |\n",
      "|    explained_variance   | 0.0182        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 735           |\n",
      "|    n_updates            | 26910         |\n",
      "|    policy_gradient_loss | -0.000681     |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1329          |\n",
      "|    iterations           | 2337          |\n",
      "|    time_elapsed         | 14400         |\n",
      "|    total_timesteps      | 19144704      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010633403 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.376        |\n",
      "|    explained_variance   | 0.0556        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 942           |\n",
      "|    n_updates            | 26920         |\n",
      "|    policy_gradient_loss | -0.000462     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1321          |\n",
      "|    iterations           | 2338          |\n",
      "|    time_elapsed         | 14498         |\n",
      "|    total_timesteps      | 19152896      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014416117 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.383        |\n",
      "|    explained_variance   | 0.027         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 674           |\n",
      "|    n_updates            | 26930         |\n",
      "|    policy_gradient_loss | -0.000459     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=19160000, episode_reward=658.60 +/- 58.34\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 659           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 19160000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.7153695e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.369        |\n",
      "|    explained_variance   | 0.0444        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.12e+03      |\n",
      "|    n_updates            | 26940         |\n",
      "|    policy_gradient_loss | -0.000314     |\n",
      "|    value_loss           | 2.1e+03       |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1320     |\n",
      "|    iterations      | 2339     |\n",
      "|    time_elapsed    | 14508    |\n",
      "|    total_timesteps | 19161088 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1320         |\n",
      "|    iterations           | 2340         |\n",
      "|    time_elapsed         | 14512        |\n",
      "|    total_timesteps      | 19169280     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001465184 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.379       |\n",
      "|    explained_variance   | 0.021        |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 778          |\n",
      "|    n_updates            | 26950        |\n",
      "|    policy_gradient_loss | -0.000529    |\n",
      "|    value_loss           | 1.92e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1321         |\n",
      "|    iterations           | 2341         |\n",
      "|    time_elapsed         | 14516        |\n",
      "|    total_timesteps      | 19177472     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001402467 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.372       |\n",
      "|    explained_variance   | 0.0322       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 953          |\n",
      "|    n_updates            | 26960        |\n",
      "|    policy_gradient_loss | -0.000489    |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1319         |\n",
      "|    iterations           | 2342         |\n",
      "|    time_elapsed         | 14539        |\n",
      "|    total_timesteps      | 19185664     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002092501 |\n",
      "|    clip_fraction        | 6.1e-05      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.374       |\n",
      "|    explained_variance   | 0.0347       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.08e+03     |\n",
      "|    n_updates            | 26970        |\n",
      "|    policy_gradient_loss | -0.000768    |\n",
      "|    value_loss           | 2e+03        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1318          |\n",
      "|    iterations           | 2343          |\n",
      "|    time_elapsed         | 14561         |\n",
      "|    total_timesteps      | 19193856      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011039133 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.372        |\n",
      "|    explained_variance   | 0.0414        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 821           |\n",
      "|    n_updates            | 26980         |\n",
      "|    policy_gradient_loss | -0.000465     |\n",
      "|    value_loss           | 2.08e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=19200000, episode_reward=668.40 +/- 50.25\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 668           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 19200000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010784444 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.388        |\n",
      "|    explained_variance   | 0.0285        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 975           |\n",
      "|    n_updates            | 26990         |\n",
      "|    policy_gradient_loss | -0.000536     |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1317     |\n",
      "|    iterations      | 2344     |\n",
      "|    time_elapsed    | 14572    |\n",
      "|    total_timesteps | 19202048 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1317         |\n",
      "|    iterations           | 2345         |\n",
      "|    time_elapsed         | 14576        |\n",
      "|    total_timesteps      | 19210240     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.712693e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.381       |\n",
      "|    explained_variance   | 0.0385       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.25e+03     |\n",
      "|    n_updates            | 27000        |\n",
      "|    policy_gradient_loss | -0.000318    |\n",
      "|    value_loss           | 1.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1313         |\n",
      "|    iterations           | 2346         |\n",
      "|    time_elapsed         | 14629        |\n",
      "|    total_timesteps      | 19218432     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.113733e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.377       |\n",
      "|    explained_variance   | 0.0415       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 27010        |\n",
      "|    policy_gradient_loss | -0.000376    |\n",
      "|    value_loss           | 1.96e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1313         |\n",
      "|    iterations           | 2347         |\n",
      "|    time_elapsed         | 14633        |\n",
      "|    total_timesteps      | 19226624     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.787974e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.375       |\n",
      "|    explained_variance   | 0.0152       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 804          |\n",
      "|    n_updates            | 27020        |\n",
      "|    policy_gradient_loss | -0.000408    |\n",
      "|    value_loss           | 2.06e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1314          |\n",
      "|    iterations           | 2348          |\n",
      "|    time_elapsed         | 14637         |\n",
      "|    total_timesteps      | 19234816      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023402862 |\n",
      "|    clip_fraction        | 8.54e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.377        |\n",
      "|    explained_variance   | 0.0355        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.18e+03      |\n",
      "|    n_updates            | 27030         |\n",
      "|    policy_gradient_loss | -0.000734     |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=19240000, episode_reward=662.40 +/- 66.65\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 662         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 19240000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 9.43931e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.378      |\n",
      "|    explained_variance   | 0.0537      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 780         |\n",
      "|    n_updates            | 27040       |\n",
      "|    policy_gradient_loss | -0.000389   |\n",
      "|    value_loss           | 1.97e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1313     |\n",
      "|    iterations      | 2349     |\n",
      "|    time_elapsed    | 14647    |\n",
      "|    total_timesteps | 19243008 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1313          |\n",
      "|    iterations           | 2350          |\n",
      "|    time_elapsed         | 14652         |\n",
      "|    total_timesteps      | 19251200      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015517864 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.384        |\n",
      "|    explained_variance   | 0.0493        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 718           |\n",
      "|    n_updates            | 27050         |\n",
      "|    policy_gradient_loss | -0.000536     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1313          |\n",
      "|    iterations           | 2351          |\n",
      "|    time_elapsed         | 14657         |\n",
      "|    total_timesteps      | 19259392      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.5162395e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.382        |\n",
      "|    explained_variance   | 0.0512        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.09e+03      |\n",
      "|    n_updates            | 27060         |\n",
      "|    policy_gradient_loss | -0.000454     |\n",
      "|    value_loss           | 2.08e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1308          |\n",
      "|    iterations           | 2352          |\n",
      "|    time_elapsed         | 14724         |\n",
      "|    total_timesteps      | 19267584      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017535615 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.385        |\n",
      "|    explained_variance   | 0.0288        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 848           |\n",
      "|    n_updates            | 27070         |\n",
      "|    policy_gradient_loss | -0.000652     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1308          |\n",
      "|    iterations           | 2353          |\n",
      "|    time_elapsed         | 14729         |\n",
      "|    total_timesteps      | 19275776      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015802059 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.387        |\n",
      "|    explained_variance   | 0.0537        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.17e+03      |\n",
      "|    n_updates            | 27080         |\n",
      "|    policy_gradient_loss | -0.00048      |\n",
      "|    value_loss           | 1.97e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=19280000, episode_reward=655.60 +/- 49.08\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 656          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 19280000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002454617 |\n",
      "|    clip_fraction        | 3.66e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.376       |\n",
      "|    explained_variance   | 0.0604       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 964          |\n",
      "|    n_updates            | 27090        |\n",
      "|    policy_gradient_loss | -0.000771    |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1307     |\n",
      "|    iterations      | 2354     |\n",
      "|    time_elapsed    | 14743    |\n",
      "|    total_timesteps | 19283968 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1307          |\n",
      "|    iterations           | 2355          |\n",
      "|    time_elapsed         | 14758         |\n",
      "|    total_timesteps      | 19292160      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010739647 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.372        |\n",
      "|    explained_variance   | 0.0472        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 887           |\n",
      "|    n_updates            | 27100         |\n",
      "|    policy_gradient_loss | -0.000447     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1307         |\n",
      "|    iterations           | 2356         |\n",
      "|    time_elapsed         | 14762        |\n",
      "|    total_timesteps      | 19300352     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002144272 |\n",
      "|    clip_fraction        | 8.54e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.38        |\n",
      "|    explained_variance   | 0.0392       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 27110        |\n",
      "|    policy_gradient_loss | -0.000587    |\n",
      "|    value_loss           | 1.95e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1307          |\n",
      "|    iterations           | 2357          |\n",
      "|    time_elapsed         | 14766         |\n",
      "|    total_timesteps      | 19308544      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019726102 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.371        |\n",
      "|    explained_variance   | 0.0598        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 872           |\n",
      "|    n_updates            | 27120         |\n",
      "|    policy_gradient_loss | -0.00059      |\n",
      "|    value_loss           | 1.93e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1307         |\n",
      "|    iterations           | 2358         |\n",
      "|    time_elapsed         | 14770        |\n",
      "|    total_timesteps      | 19316736     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001821113 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.382       |\n",
      "|    explained_variance   | 0.0075       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 27130        |\n",
      "|    policy_gradient_loss | -0.000632    |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19320000, episode_reward=653.60 +/- 54.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 654           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 19320000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017335209 |\n",
      "|    clip_fraction        | 3.66e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.383        |\n",
      "|    explained_variance   | 0.035         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.07e+03      |\n",
      "|    n_updates            | 27140         |\n",
      "|    policy_gradient_loss | -0.000665     |\n",
      "|    value_loss           | 1.95e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1307     |\n",
      "|    iterations      | 2359     |\n",
      "|    time_elapsed    | 14781    |\n",
      "|    total_timesteps | 19324928 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1307         |\n",
      "|    iterations           | 2360         |\n",
      "|    time_elapsed         | 14785        |\n",
      "|    total_timesteps      | 19333120     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.577355e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.385       |\n",
      "|    explained_variance   | 0.0405       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 27150        |\n",
      "|    policy_gradient_loss | -0.000393    |\n",
      "|    value_loss           | 2.03e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1307          |\n",
      "|    iterations           | 2361          |\n",
      "|    time_elapsed         | 14790         |\n",
      "|    total_timesteps      | 19341312      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013617457 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.388        |\n",
      "|    explained_variance   | 0.0474        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 908           |\n",
      "|    n_updates            | 27160         |\n",
      "|    policy_gradient_loss | -0.00051      |\n",
      "|    value_loss           | 1.93e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1307          |\n",
      "|    iterations           | 2362          |\n",
      "|    time_elapsed         | 14795         |\n",
      "|    total_timesteps      | 19349504      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017490683 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.386        |\n",
      "|    explained_variance   | 0.0588        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 765           |\n",
      "|    n_updates            | 27170         |\n",
      "|    policy_gradient_loss | -0.000559     |\n",
      "|    value_loss           | 1.85e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1307         |\n",
      "|    iterations           | 2363         |\n",
      "|    time_elapsed         | 14808        |\n",
      "|    total_timesteps      | 19357696     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.937834e-05 |\n",
      "|    clip_fraction        | 3.66e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.381       |\n",
      "|    explained_variance   | 0.0477       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 786          |\n",
      "|    n_updates            | 27180        |\n",
      "|    policy_gradient_loss | -0.00047     |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19360000, episode_reward=655.20 +/- 48.51\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 655          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 19360000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.187365e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.38        |\n",
      "|    explained_variance   | 0.0404       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 27190        |\n",
      "|    policy_gradient_loss | -0.000428    |\n",
      "|    value_loss           | 1.97e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1305     |\n",
      "|    iterations      | 2364     |\n",
      "|    time_elapsed    | 14834    |\n",
      "|    total_timesteps | 19365888 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1305          |\n",
      "|    iterations           | 2365          |\n",
      "|    time_elapsed         | 14838         |\n",
      "|    total_timesteps      | 19374080      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018532343 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.386        |\n",
      "|    explained_variance   | 0.0417        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.01e+03      |\n",
      "|    n_updates            | 27200         |\n",
      "|    policy_gradient_loss | -0.000576     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1305          |\n",
      "|    iterations           | 2366          |\n",
      "|    time_elapsed         | 14842         |\n",
      "|    total_timesteps      | 19382272      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015886364 |\n",
      "|    clip_fraction        | 6.1e-05       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.382        |\n",
      "|    explained_variance   | 0.0496        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 719           |\n",
      "|    n_updates            | 27210         |\n",
      "|    policy_gradient_loss | -0.000489     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1304          |\n",
      "|    iterations           | 2367          |\n",
      "|    time_elapsed         | 14867         |\n",
      "|    total_timesteps      | 19390464      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014396652 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.391        |\n",
      "|    explained_variance   | 0.0331        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 730           |\n",
      "|    n_updates            | 27220         |\n",
      "|    policy_gradient_loss | -0.000487     |\n",
      "|    value_loss           | 1.94e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1304          |\n",
      "|    iterations           | 2368          |\n",
      "|    time_elapsed         | 14871         |\n",
      "|    total_timesteps      | 19398656      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023047705 |\n",
      "|    clip_fraction        | 8.54e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.371        |\n",
      "|    explained_variance   | 0.026         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 999           |\n",
      "|    n_updates            | 27230         |\n",
      "|    policy_gradient_loss | -0.000651     |\n",
      "|    value_loss           | 2.05e+03      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=19400000, episode_reward=676.00 +/- 53.07\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 676          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 19400000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001068027 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.38        |\n",
      "|    explained_variance   | 0.0323       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 894          |\n",
      "|    n_updates            | 27240        |\n",
      "|    policy_gradient_loss | -0.000489    |\n",
      "|    value_loss           | 1.96e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1304     |\n",
      "|    iterations      | 2369     |\n",
      "|    time_elapsed    | 14882    |\n",
      "|    total_timesteps | 19406848 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1304          |\n",
      "|    iterations           | 2370          |\n",
      "|    time_elapsed         | 14886         |\n",
      "|    total_timesteps      | 19415040      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013582112 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.385        |\n",
      "|    explained_variance   | 0.0614        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 958           |\n",
      "|    n_updates            | 27250         |\n",
      "|    policy_gradient_loss | -0.000512     |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1304          |\n",
      "|    iterations           | 2371          |\n",
      "|    time_elapsed         | 14890         |\n",
      "|    total_timesteps      | 19423232      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013146049 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.379        |\n",
      "|    explained_variance   | 0.0196        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 755           |\n",
      "|    n_updates            | 27260         |\n",
      "|    policy_gradient_loss | -0.000469     |\n",
      "|    value_loss           | 1.98e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1304         |\n",
      "|    iterations           | 2372         |\n",
      "|    time_elapsed         | 14895        |\n",
      "|    total_timesteps      | 19431424     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.739501e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.378       |\n",
      "|    explained_variance   | 0.0481       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 934          |\n",
      "|    n_updates            | 27270        |\n",
      "|    policy_gradient_loss | -0.000343    |\n",
      "|    value_loss           | 2.08e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1304         |\n",
      "|    iterations           | 2373         |\n",
      "|    time_elapsed         | 14899        |\n",
      "|    total_timesteps      | 19439616     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001906467 |\n",
      "|    clip_fraction        | 3.66e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.379       |\n",
      "|    explained_variance   | 0.0183       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 965          |\n",
      "|    n_updates            | 27280        |\n",
      "|    policy_gradient_loss | -0.000588    |\n",
      "|    value_loss           | 1.93e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19440000, episode_reward=654.20 +/- 65.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 654          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 19440000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.955443e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.384       |\n",
      "|    explained_variance   | 0.0308       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 989          |\n",
      "|    n_updates            | 27290        |\n",
      "|    policy_gradient_loss | -0.000422    |\n",
      "|    value_loss           | 1.91e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1304     |\n",
      "|    iterations      | 2374     |\n",
      "|    time_elapsed    | 14909    |\n",
      "|    total_timesteps | 19447808 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1304         |\n",
      "|    iterations           | 2375         |\n",
      "|    time_elapsed         | 14913        |\n",
      "|    total_timesteps      | 19456000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.780835e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.382       |\n",
      "|    explained_variance   | 0.0431       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 810          |\n",
      "|    n_updates            | 27300        |\n",
      "|    policy_gradient_loss | -0.000384    |\n",
      "|    value_loss           | 1.92e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1304          |\n",
      "|    iterations           | 2376          |\n",
      "|    time_elapsed         | 14917         |\n",
      "|    total_timesteps      | 19464192      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012074453 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.382        |\n",
      "|    explained_variance   | 0.0482        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 841           |\n",
      "|    n_updates            | 27310         |\n",
      "|    policy_gradient_loss | -0.000593     |\n",
      "|    value_loss           | 2.07e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1304         |\n",
      "|    iterations           | 2377         |\n",
      "|    time_elapsed         | 14921        |\n",
      "|    total_timesteps      | 19472384     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.743051e-05 |\n",
      "|    clip_fraction        | 2.44e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.381       |\n",
      "|    explained_variance   | 0.0483       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 27320        |\n",
      "|    policy_gradient_loss | -0.000526    |\n",
      "|    value_loss           | 2e+03        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19480000, episode_reward=650.20 +/- 57.36\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 650           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 19480000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011876364 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.374        |\n",
      "|    explained_variance   | 0.0485        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.49e+03      |\n",
      "|    n_updates            | 27330         |\n",
      "|    policy_gradient_loss | -0.000442     |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1304     |\n",
      "|    iterations      | 2378     |\n",
      "|    time_elapsed    | 14932    |\n",
      "|    total_timesteps | 19480576 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1304          |\n",
      "|    iterations           | 2379          |\n",
      "|    time_elapsed         | 14937         |\n",
      "|    total_timesteps      | 19488768      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013680302 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.375        |\n",
      "|    explained_variance   | 0.0529        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.29e+03      |\n",
      "|    n_updates            | 27340         |\n",
      "|    policy_gradient_loss | -0.000534     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1304          |\n",
      "|    iterations           | 2380          |\n",
      "|    time_elapsed         | 14942         |\n",
      "|    total_timesteps      | 19496960      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012500728 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.38         |\n",
      "|    explained_variance   | 0.0383        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 807           |\n",
      "|    n_updates            | 27350         |\n",
      "|    policy_gradient_loss | -0.000392     |\n",
      "|    value_loss           | 1.88e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1304          |\n",
      "|    iterations           | 2381          |\n",
      "|    time_elapsed         | 14946         |\n",
      "|    total_timesteps      | 19505152      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.9264784e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.39         |\n",
      "|    explained_variance   | 0.0141        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.08e+03      |\n",
      "|    n_updates            | 27360         |\n",
      "|    policy_gradient_loss | -0.000447     |\n",
      "|    value_loss           | 1.99e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1305          |\n",
      "|    iterations           | 2382          |\n",
      "|    time_elapsed         | 14950         |\n",
      "|    total_timesteps      | 19513344      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016699985 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.385        |\n",
      "|    explained_variance   | 0.0721        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.04e+03      |\n",
      "|    n_updates            | 27370         |\n",
      "|    policy_gradient_loss | -0.000597     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=19520000, episode_reward=654.60 +/- 56.36\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 655           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 19520000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026983168 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.375        |\n",
      "|    explained_variance   | 0.052         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 853           |\n",
      "|    n_updates            | 27380         |\n",
      "|    policy_gradient_loss | -0.000776     |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1304     |\n",
      "|    iterations      | 2383     |\n",
      "|    time_elapsed    | 14962    |\n",
      "|    total_timesteps | 19521536 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1304          |\n",
      "|    iterations           | 2384          |\n",
      "|    time_elapsed         | 14966         |\n",
      "|    total_timesteps      | 19529728      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021143042 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.377        |\n",
      "|    explained_variance   | 0.0463        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.32e+03      |\n",
      "|    n_updates            | 27390         |\n",
      "|    policy_gradient_loss | -0.000726     |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1305         |\n",
      "|    iterations           | 2385         |\n",
      "|    time_elapsed         | 14971        |\n",
      "|    total_timesteps      | 19537920     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.690895e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.378       |\n",
      "|    explained_variance   | 0.0391       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 27400        |\n",
      "|    policy_gradient_loss | -0.000415    |\n",
      "|    value_loss           | 2.06e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1305          |\n",
      "|    iterations           | 2386          |\n",
      "|    time_elapsed         | 14975         |\n",
      "|    total_timesteps      | 19546112      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022166467 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.383        |\n",
      "|    explained_variance   | 0.0335        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 852           |\n",
      "|    n_updates            | 27410         |\n",
      "|    policy_gradient_loss | -0.000741     |\n",
      "|    value_loss           | 1.93e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1302         |\n",
      "|    iterations           | 2387         |\n",
      "|    time_elapsed         | 15009        |\n",
      "|    total_timesteps      | 19554304     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001234141 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.383       |\n",
      "|    explained_variance   | 0.0496       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 931          |\n",
      "|    n_updates            | 27420        |\n",
      "|    policy_gradient_loss | -0.000474    |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19560000, episode_reward=648.80 +/- 47.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 649           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 19560000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015455912 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.371        |\n",
      "|    explained_variance   | 0.0173        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.05e+03      |\n",
      "|    n_updates            | 27430         |\n",
      "|    policy_gradient_loss | -0.00058      |\n",
      "|    value_loss           | 1.94e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1302     |\n",
      "|    iterations      | 2388     |\n",
      "|    time_elapsed    | 15019    |\n",
      "|    total_timesteps | 19562496 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1302          |\n",
      "|    iterations           | 2389          |\n",
      "|    time_elapsed         | 15023         |\n",
      "|    total_timesteps      | 19570688      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.0461447e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.376        |\n",
      "|    explained_variance   | 0.0182        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.13e+03      |\n",
      "|    n_updates            | 27440         |\n",
      "|    policy_gradient_loss | -0.000366     |\n",
      "|    value_loss           | 1.95e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1302          |\n",
      "|    iterations           | 2390          |\n",
      "|    time_elapsed         | 15027         |\n",
      "|    total_timesteps      | 19578880      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018992365 |\n",
      "|    clip_fraction        | 2.44e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.389        |\n",
      "|    explained_variance   | 0.0445        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 883           |\n",
      "|    n_updates            | 27450         |\n",
      "|    policy_gradient_loss | -0.000708     |\n",
      "|    value_loss           | 1.96e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1302          |\n",
      "|    iterations           | 2391          |\n",
      "|    time_elapsed         | 15032         |\n",
      "|    total_timesteps      | 19587072      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012202189 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.378        |\n",
      "|    explained_variance   | 0.054         |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 915           |\n",
      "|    n_updates            | 27460         |\n",
      "|    policy_gradient_loss | -0.000502     |\n",
      "|    value_loss           | 2e+03         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1294        |\n",
      "|    iterations           | 2392        |\n",
      "|    time_elapsed         | 15140       |\n",
      "|    total_timesteps      | 19595264    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 6.54424e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.387      |\n",
      "|    explained_variance   | 0.0112      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 928         |\n",
      "|    n_updates            | 27470       |\n",
      "|    policy_gradient_loss | -0.000289   |\n",
      "|    value_loss           | 1.82e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=19600000, episode_reward=658.60 +/- 66.39\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 659          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 19600000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.082742e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.381       |\n",
      "|    explained_variance   | 0.0538       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 847          |\n",
      "|    n_updates            | 27480        |\n",
      "|    policy_gradient_loss | -0.000399    |\n",
      "|    value_loss           | 2.03e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1293     |\n",
      "|    iterations      | 2393     |\n",
      "|    time_elapsed    | 15150    |\n",
      "|    total_timesteps | 19603456 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1292         |\n",
      "|    iterations           | 2394         |\n",
      "|    time_elapsed         | 15170        |\n",
      "|    total_timesteps      | 19611648     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.194421e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.382       |\n",
      "|    explained_variance   | 0.0428       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 949          |\n",
      "|    n_updates            | 27490        |\n",
      "|    policy_gradient_loss | -0.000472    |\n",
      "|    value_loss           | 1.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1292         |\n",
      "|    iterations           | 2395         |\n",
      "|    time_elapsed         | 15174        |\n",
      "|    total_timesteps      | 19619840     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002070488 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.373       |\n",
      "|    explained_variance   | 0.0266       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 27500        |\n",
      "|    policy_gradient_loss | -0.000633    |\n",
      "|    value_loss           | 1.92e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1293          |\n",
      "|    iterations           | 2396          |\n",
      "|    time_elapsed         | 15178         |\n",
      "|    total_timesteps      | 19628032      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017266051 |\n",
      "|    clip_fraction        | 1.22e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.378        |\n",
      "|    explained_variance   | 0.0574        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 908           |\n",
      "|    n_updates            | 27510         |\n",
      "|    policy_gradient_loss | -0.000683     |\n",
      "|    value_loss           | 1.89e+03      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 1285        |\n",
      "|    iterations           | 2397        |\n",
      "|    time_elapsed         | 15279       |\n",
      "|    total_timesteps      | 19636224    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 9.84657e-05 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.385      |\n",
      "|    explained_variance   | 0.0219      |\n",
      "|    learning_rate        | 1e-05       |\n",
      "|    loss                 | 1.21e+03    |\n",
      "|    n_updates            | 27520       |\n",
      "|    policy_gradient_loss | -0.000448   |\n",
      "|    value_loss           | 2.01e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=19640000, episode_reward=650.20 +/- 59.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 650           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 19640000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013473301 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.384        |\n",
      "|    explained_variance   | 0.0467        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1e+03         |\n",
      "|    n_updates            | 27530         |\n",
      "|    policy_gradient_loss | -0.000554     |\n",
      "|    value_loss           | 1.93e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1284     |\n",
      "|    iterations      | 2398     |\n",
      "|    time_elapsed    | 15290    |\n",
      "|    total_timesteps | 19644416 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1284         |\n",
      "|    iterations           | 2399         |\n",
      "|    time_elapsed         | 15298        |\n",
      "|    total_timesteps      | 19652608     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002357359 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.374       |\n",
      "|    explained_variance   | 0.0512       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 810          |\n",
      "|    n_updates            | 27540        |\n",
      "|    policy_gradient_loss | -0.000796    |\n",
      "|    value_loss           | 1.82e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1281          |\n",
      "|    iterations           | 2400          |\n",
      "|    time_elapsed         | 15346         |\n",
      "|    total_timesteps      | 19660800      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.6218625e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.378        |\n",
      "|    explained_variance   | 0.0597        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.24e+03      |\n",
      "|    n_updates            | 27550         |\n",
      "|    policy_gradient_loss | -0.000424     |\n",
      "|    value_loss           | 2.02e+03      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1281         |\n",
      "|    iterations           | 2401         |\n",
      "|    time_elapsed         | 15349        |\n",
      "|    total_timesteps      | 19668992     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.666596e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.383       |\n",
      "|    explained_variance   | 0.0225       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 799          |\n",
      "|    n_updates            | 27560        |\n",
      "|    policy_gradient_loss | -0.000319    |\n",
      "|    value_loss           | 2e+03        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1281         |\n",
      "|    iterations           | 2402         |\n",
      "|    time_elapsed         | 15353        |\n",
      "|    total_timesteps      | 19677184     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.232343e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.376       |\n",
      "|    explained_variance   | 0.0513       |\n",
      "|    learning_rate        | 1e-05        |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 27570        |\n",
      "|    policy_gradient_loss | -0.000372    |\n",
      "|    value_loss           | 1.92e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19680000, episode_reward=651.80 +/- 63.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 200           |\n",
      "|    mean_reward          | 652           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 19680000      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024905615 |\n",
      "|    clip_fraction        | 7.32e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.377        |\n",
      "|    explained_variance   | 0.0323        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 936           |\n",
      "|    n_updates            | 27580         |\n",
      "|    policy_gradient_loss | -0.000652     |\n",
      "|    value_loss           | 1.92e+03      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 1279     |\n",
      "|    iterations      | 2403     |\n",
      "|    time_elapsed    | 15390    |\n",
      "|    total_timesteps | 19685376 |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1279          |\n",
      "|    iterations           | 2404          |\n",
      "|    time_elapsed         | 15395         |\n",
      "|    total_timesteps      | 19693568      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.1610884e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.381        |\n",
      "|    explained_variance   | 0.0409        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 949           |\n",
      "|    n_updates            | 27590         |\n",
      "|    policy_gradient_loss | -0.000443     |\n",
      "|    value_loss           | 1.91e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1274          |\n",
      "|    iterations           | 2405          |\n",
      "|    time_elapsed         | 15458         |\n",
      "|    total_timesteps      | 19701760      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018297938 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.372        |\n",
      "|    explained_variance   | 0.0468        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 945           |\n",
      "|    n_updates            | 27600         |\n",
      "|    policy_gradient_loss | -0.000649     |\n",
      "|    value_loss           | 2e+03         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1274          |\n",
      "|    iterations           | 2406          |\n",
      "|    time_elapsed         | 15462         |\n",
      "|    total_timesteps      | 19709952      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00014995731 |\n",
      "|    clip_fraction        | 3.66e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.383        |\n",
      "|    explained_variance   | 0.0318        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.2e+03       |\n",
      "|    n_updates            | 27610         |\n",
      "|    policy_gradient_loss | -0.00048      |\n",
      "|    value_loss           | 2.05e+03      |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 1274          |\n",
      "|    iterations           | 2407          |\n",
      "|    time_elapsed         | 15466         |\n",
      "|    total_timesteps      | 19718144      |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020158912 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.381        |\n",
      "|    explained_variance   | 0.0456        |\n",
      "|    learning_rate        | 1e-05         |\n",
      "|    loss                 | 1.06e+03      |\n",
      "|    n_updates            | 27620         |\n",
      "|    policy_gradient_loss | -0.000717     |\n",
      "|    value_loss           | 1.9e+03       |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.callbacks import CallbackList, CheckpointCallback, EvalCallback\n",
    "\n",
    "best_model_save_path = \"./models/2_adv/\"\n",
    "\n",
    "# # Save a checkpoint every 1000 steps\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "                             save_freq=500_000,\n",
    "                             save_path=\"./models/2_adv\",\n",
    "                             name_prefix=\"2_adv_after_15M_steps\",\n",
    "                            )\n",
    "eval_callback = EvalCallback(conv_env,\n",
    "                             eval_freq=10_000,\n",
    "                             best_model_save_path=best_model_save_path,\n",
    "                             log_path=log_path,\n",
    "                             n_eval_episodes=100,\n",
    "                             verbose=1)\n",
    "\n",
    "callback_list = CallbackList([eval_callback, checkpoint_callback])\n",
    "\n",
    "# first 10M timesteps\n",
    "model.learn(total_timesteps=30_000_000, callback=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mPPO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBufferedIOBase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0menv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgymnasium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'VecEnv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcustom_objects\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprint_system_info\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mforce_reset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mSelfBaseAlgorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "    \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# noqa: C901\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSelfBaseAlgorithm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBufferedIOBase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0menv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGymEnv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcustom_objects\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mprint_system_info\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mforce_reset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelfBaseAlgorithm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
      "\u001b[0;34m        Load the model from a zip-file.\u001b[0m\n",
      "\u001b[0;34m        Warning: ``load`` re-creates the model from scratch, it does not update it in-place!\u001b[0m\n",
      "\u001b[0;34m        For an in-place load use ``set_parameters`` instead.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        :param path: path to the file (or a file-like) where to\u001b[0m\n",
      "\u001b[0;34m            load the agent from\u001b[0m\n",
      "\u001b[0;34m        :param env: the new environment to run the loaded model on\u001b[0m\n",
      "\u001b[0;34m            (can be None if you only need prediction from a trained model) has priority over any saved environment\u001b[0m\n",
      "\u001b[0;34m        :param device: Device on which the code should run.\u001b[0m\n",
      "\u001b[0;34m        :param custom_objects: Dictionary of objects to replace\u001b[0m\n",
      "\u001b[0;34m            upon loading. If a variable is present in this dictionary as a\u001b[0m\n",
      "\u001b[0;34m            key, it will not be deserialized and the corresponding item\u001b[0m\n",
      "\u001b[0;34m            will be used instead. Similar to custom_objects in\u001b[0m\n",
      "\u001b[0;34m            ``keras.models.load_model``. Useful when you have an object in\u001b[0m\n",
      "\u001b[0;34m            file that can not be deserialized.\u001b[0m\n",
      "\u001b[0;34m        :param print_system_info: Whether to print system info from the saved model\u001b[0m\n",
      "\u001b[0;34m            and the current system info (useful to debug loading issues)\u001b[0m\n",
      "\u001b[0;34m        :param force_reset: Force call to ``reset()`` before training\u001b[0m\n",
      "\u001b[0;34m            to avoid unexpected behavior.\u001b[0m\n",
      "\u001b[0;34m            See https://github.com/DLR-RM/stable-baselines3/issues/597\u001b[0m\n",
      "\u001b[0;34m        :param kwargs: extra arguments to change the model when loading\u001b[0m\n",
      "\u001b[0;34m        :return: new model instance with loaded parameters\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mprint_system_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"== CURRENT SYSTEM INFO ==\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mget_system_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpytorch_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_from_zip_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mprint_system_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_system_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No data found in the saved file\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No params found in the saved file\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Remove stored device information and replace with ours\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"policy_kwargs\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m\"device\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mdel\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# backward compatibility, convert to new format\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m\"net_arch\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"net_arch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0msaved_net_arch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"net_arch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_net_arch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_net_arch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"net_arch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_net_arch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"policy_kwargs\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"The specified policy kwargs do not equal the stored policy kwargs.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"Stored kwargs: {data['policy_kwargs']}, specified kwargs: {kwargs['policy_kwargs']}\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"observation_space\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"action_space\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The observation_space and action_space were not given, can't verify new environments\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Gym -> Gymnasium space conversion\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"observation_space\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"action_space\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0menv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Wrap first if needed\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"verbose\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Check if given env is valid\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcheck_for_correct_spaces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"observation_space\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"action_space\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Discard `_last_obs`, this will force the env to reset before training\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# See issue https://github.com/DLR-RM/stable-baselines3/issues/597\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mforce_reset\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_last_obs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# `n_envs` must be updated. See issue https://github.com/DLR-RM/stable-baselines3/issues/1018\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_envs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Use stored env, if one exists. If not, continue as is (can be used for predict)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m\"env\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"env\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpolicy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy_class\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0m_init_setup_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# load parameters\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# put state_dicts back in place\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact_match\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Patch to load Policy saved using SB3 < 1.7.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# the error is probably due to old policy being loaded\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# See https://github.com/DLR-RM/stable-baselines3/issues/1233\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m\"pi_features_extractor\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"Missing key(s) in state_dict\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact_match\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"You are probably loading a model saved with SB3 < 1.7.0, \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"we deactivated exact_match so you can save the model \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"again to avoid issues in the future \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"(see https://github.com/DLR-RM/stable-baselines3/issues/1233 for more info). \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"Original error: {e} \\n\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"Note: the model should still work fine, this only a warning.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# put other pytorch variables back in place\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mpytorch_variables\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpytorch_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# Skip if PyTorch variable was not defined (to ensure backward compatibility).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# This happens when using SAC/TQC.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# SAC has an entropy coefficient which can be fixed or optimized.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# If it is optimized, an additional PyTorch variable `log_ent_coef` is defined,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# otherwise it is initialized to `None`.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mpytorch_variables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# Set the data attribute directly to avoid issue when using optimizers\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# See https://github.com/DLR-RM/stable-baselines3/issues/391\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mrecursive_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{name}.data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpytorch_variables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Sample gSDE exploration matrix, so it uses the right device\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# see issue #44\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_sde\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[operator]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.10/site-packages/stable_baselines3/common/base_class.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "PPO.load??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariusvaardal/.local/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2.32, 7.497839688870388)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "evaluate_policy(model=model, env=conv_env, n_eval_episodes=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adversary_0', 'adversary_1', 'adversary_2']\n",
      "Episode reward: 710.0\n"
     ]
    }
   ],
   "source": [
    "RENDER_MODE = None\n",
    "MAX_CYCLES = 200\n",
    "env = CustomEnvironment(num_good=NUM_GOOD, num_adversaries=NUM_ADV, num_obstacles=NUM_OBST, max_cycles=MAX_CYCLES, continuous_actions=CONTINOUS_ACTIONS, render_mode=RENDER_MODE)\n",
    "observations, infos = env.reset()\n",
    "\n",
    "terminated = False\n",
    "timestep = 1\n",
    "episode_reward = 0\n",
    "print(env.agents)\n",
    "while not terminated:\n",
    "\n",
    "    # this is where you would insert your policy\n",
    "    actions = {agent: model.predict(observations[agent])[0] for agent in env.agents}\n",
    "\n",
    "    observations, rewards, terminations, truncations, infos = env.step(actions)\n",
    "\n",
    "    episode_reward += sum(rewards.values()) / NUM_ADV\n",
    "\n",
    "    if not observations:\n",
    "        terminated = True\n",
    "    \n",
    "print(f\"Episode reward: {episode_reward}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1:\n",
      "\n",
      "from pettingzoo.mpe import simple_tag_v3\n",
      "from pettingzoo import ParallelEnv\n",
      "import numpy as np\n",
      "import functools\n",
      "import os\n",
      "import sys\n",
      "sys.path.append('/home/mariusvaardal/AAMAS_project/AAMAS_project')\n",
      "\n",
      "import supersuit as ss\n",
      "from stable_baselines3 import PPO\n",
      "from stable_baselines3.ppo import MlpPolicy\n",
      "\n",
      "from stable_baselines3.common.evaluation import evaluate_policy\n",
      "   2:\n",
      "NUM_GOOD = 1\n",
      "NUM_ADV = 3\n",
      "NUM_OBST = 0\n",
      "MAX_CYCLES = 50\n",
      "CONTINOUS_ACTIONS = False\n",
      "   3:\n",
      "def remove_agent_0_from_dicts(dicts):\n",
      "    ret = []\n",
      "    for dict in dicts:\n",
      "        del dict['agent_0']\n",
      "        ret.append(dict)\n",
      "    return ret\n",
      "   4:\n",
      "# from agent_types.AvoidingAgent import AvoidingAgent\n",
      "# from agent_types.AvoidingNearestAdversaryAgent import AvoidingNearestAdversaryAgent\n",
      "from agent_types.ImmobileAgent import ImmobileAgent\n",
      "\n",
      "class CustomEnvironment(ParallelEnv):\n",
      "    metadata = {\n",
      "        \"name\": \"custom_environment_v0\",\n",
      "    }\n",
      "\n",
      "    def __init__(self, num_good, num_adversaries, num_obstacles, max_cycles, continuous_actions, render_mode):\n",
      "        self.env = simple_tag_v3.parallel_env(num_good=num_good, num_adversaries=num_adversaries, num_obstacles=num_obstacles, max_cycles=max_cycles, continuous_actions=continuous_actions, render_mode=render_mode)\n",
      "        self.env.reset() \n",
      "        # Setting all the required attributes\n",
      "        self.agents = [agent for agent in self.env.agents if agent.startswith(\"adversary\")]\n",
      "        self.possible_agents = [adv for adv in self.env.possible_agents if adv.startswith(\"adversary\")]\n",
      "        self.render_mode = render_mode\n",
      "        # Adding agent_0 as part of the environment. Agent_0 is not meant to be included in the training\n",
      "        self.agent_0 = ImmobileAgent('agent_0', num_adversaries=NUM_ADV, num_landmarks=NUM_OBST)\n",
      "        \n",
      "    def reset(self, seed=None, options=None):\n",
      "        observations, infos = self.env.reset(seed=seed, options=options)\n",
      "        self.agent_0.see(observations[self.agent_0.name])\n",
      "        observations, infos = remove_agent_0_from_dicts([observations, infos])\n",
      "        return observations, infos\n",
      "\n",
      "    def step(self, actions):\n",
      "        actions['agent_0'] = self.agent_0.get_action()\n",
      "        observations, rewards, terminations, truncations, infos =  self.env.step(actions)\n",
      "        if observations:\n",
      "            self.agent_0.see(observations[self.agent_0.name])\n",
      "            observations, rewards, terminations, truncations, infos = remove_agent_0_from_dicts([observations, rewards, terminations, truncations, infos])\n",
      "        return observations, rewards, terminations, truncations, infos\n",
      "\n",
      "    def render(self):\n",
      "        self.env.render()\n",
      "\n",
      "    # Observation space should be defined here.\n",
      "    # lru_cache allows observation and action spaces to be memoized, reducing clock cycles required to get each agent's space.\n",
      "    # If your spaces change over time, remove this line (disable caching).\n",
      "    @functools.lru_cache(maxsize=None)\n",
      "    def observation_space(self, agent):\n",
      "        return self.env.observation_space(agent)\n",
      "\n",
      "    # Action space should be defined here.\n",
      "    # If your spaces change over time, remove this line (disable caching).\n",
      "    @functools.lru_cache(maxsize=None)\n",
      "    def action_space(self, agent):\n",
      "        return self.env.action_space(agent)\n",
      "   5:\n",
      "env = CustomEnvironment(num_good=NUM_GOOD, num_adversaries=NUM_ADV, num_obstacles=NUM_OBST, max_cycles=MAX_CYCLES, continuous_actions=CONTINOUS_ACTIONS, render_mode=RENDER_MODE)\n",
      "env.reset(seed=45)\n",
      "conv_env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
      "conv_env = ss.concat_vec_envs_v1(conv_env, 2, num_cpus=1, base_class=\"stable_baselines3\")\n",
      "   6:\n",
      "NUM_GOOD = 1\n",
      "NUM_ADV = 3\n",
      "NUM_OBST = 0\n",
      "MAX_CYCLES = 50\n",
      "CONTINOUS_ACTIONS = False\n",
      "RENDER_MODE = None\n",
      "   7:\n",
      "env = CustomEnvironment(num_good=NUM_GOOD, num_adversaries=NUM_ADV, num_obstacles=NUM_OBST, max_cycles=MAX_CYCLES, continuous_actions=CONTINOUS_ACTIONS, render_mode=RENDER_MODE)\n",
      "env.reset(seed=45)\n",
      "conv_env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
      "conv_env = ss.concat_vec_envs_v1(conv_env, 2, num_cpus=1, base_class=\"stable_baselines3\")\n",
      "   8:\n",
      "model = PPO(\n",
      "        MlpPolicy,\n",
      "        conv_env,\n",
      "        verbose=3,\n",
      "        learning_rate=1e-3,\n",
      "        batch_size=256,\n",
      "    )\n",
      "   9:\n",
      "model_save_path = \"../models\"\n",
      "model.learn(total_timesteps=1000)\n",
      "model.save(model_save_path)\n",
      "  10:\n",
      "model_save_path = \"../../models\"\n",
      "model.learn(total_timesteps=1000)\n",
      "model.save(model_save_path)\n",
      "  11:\n",
      "model_save_path = \"../../models/model\"\n",
      "model.learn(total_timesteps=1000)\n",
      "model.save(model_save_path)\n",
      "  12:\n",
      "\n",
      "from pettingzoo.mpe import simple_tag_v3\n",
      "from pettingzoo import ParallelEnv\n",
      "import numpy as np\n",
      "import functools\n",
      "import os\n",
      "import sys\n",
      "sys.path.append('/home/mariusvaardal/AAMAS_project/AAMAS_project')\n",
      "\n",
      "import supersuit as ss\n",
      "from stable_baselines3 import PPO\n",
      "from stable_baselines3.ppo import MlpPolicy\n",
      "\n",
      "from stable_baselines3.common.evaluation import evaluate_policy\n",
      "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
      "  13:\n",
      "best_model_save_path = \"../../best_model/best_model\"\n",
      "log_path = \"../../logs/log\"\n",
      "threshold_callback = StopTrainingOnRewardThreshold(reward_threshold=300, verbose=1)\n",
      "eval_callback = EvalCallback(env,\n",
      "                             eval_freq=10_000,\n",
      "                             best_model_save_path=best_model_save_path,\n",
      "                             callback_on_new_best=threshold_callback,\n",
      "                             log_path=log_path,\n",
      "                             n_eval_episodes=10,\n",
      "                             verbose=1)\n",
      "model.learn(total_timesteps=5_000_000, callback=eval_callback)\n",
      "  14:\n",
      "\n",
      "from pettingzoo.mpe import simple_tag_v3\n",
      "from pettingzoo import ParallelEnv\n",
      "import numpy as np\n",
      "import functools\n",
      "import os\n",
      "import sys\n",
      "sys.path.append('/home/mariusvaardal/AAMAS_project/AAMAS_project')\n",
      "\n",
      "import supersuit as ss\n",
      "from stable_baselines3 import PPO\n",
      "from stable_baselines3.ppo import MlpPolicy\n",
      "\n",
      "from stable_baselines3.common.evaluation import evaluate_policy\n",
      "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
      "import shimmy\n",
      "  15:\n",
      "best_model_save_path = \"../../best_model/best_model\"\n",
      "log_path = \"../../logs/log\"\n",
      "threshold_callback = StopTrainingOnRewardThreshold(reward_threshold=300, verbose=1)\n",
      "eval_callback = EvalCallback(env,\n",
      "                             eval_freq=10_000,\n",
      "                             best_model_save_path=best_model_save_path,\n",
      "                             callback_on_new_best=threshold_callback,\n",
      "                             log_path=log_path,\n",
      "                             n_eval_episodes=10,\n",
      "                             verbose=1)\n",
      "model.learn(total_timesteps=5_000_000, callback=eval_callback)\n",
      "  16:\n",
      "best_model_save_path = \"../../best_model/best_model\"\n",
      "log_path = \"../../logs/log\"\n",
      "threshold_callback = StopTrainingOnRewardThreshold(reward_threshold=300, verbose=1)\n",
      "eval_callback = EvalCallback(conv_env,\n",
      "                             eval_freq=10_000,\n",
      "                             best_model_save_path=best_model_save_path,\n",
      "                             callback_on_new_best=threshold_callback,\n",
      "                             log_path=log_path,\n",
      "                             n_eval_episodes=10,\n",
      "                             verbose=1)\n",
      "model.learn(total_timesteps=5_000_000, callback=eval_callback)\n",
      "  17: model.learn(total_timesteps=1000)\n",
      "  18:\n",
      "env = CustomEnvironment(num_good=NUM_GOOD, num_adversaries=NUM_ADV, num_obstacles=NUM_OBST, max_cycles=MAX_CYCLES, continuous_actions=CONTINOUS_ACTIONS, render_mode=RENDER_MODE)\n",
      "env.reset(seed=45)\n",
      "conv_env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
      "conv_env = ss.concat_vec_envs_v1(conv_env, 0, num_cpus=1, base_class=\"stable_baselines3\")\n",
      "  19:\n",
      "env = CustomEnvironment(num_good=NUM_GOOD, num_adversaries=NUM_ADV, num_obstacles=NUM_OBST, max_cycles=MAX_CYCLES, continuous_actions=CONTINOUS_ACTIONS, render_mode=RENDER_MODE)\n",
      "env.reset(seed=45)\n",
      "conv_env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
      "conv_env = ss.concat_vec_envs_v1(conv_env, 2, num_cpus=0, base_class=\"stable_baselines3\")\n",
      "  20:\n",
      "model = PPO(\n",
      "        MlpPolicy,\n",
      "        conv_env,\n",
      "        verbose=3,\n",
      "        learning_rate=1e-3,\n",
      "        batch_size=256,\n",
      "    )\n"
     ]
    }
   ],
   "source": [
    "%history -n 1-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from agent_types.AvoidingAgent import AvoidingAgent\n",
    "# from agent_types.AvoidingNearestAdversaryAgent import AvoidingNearestAdversaryAgent\n",
    "from agent_types.ImmobileAgent import ImmobileAgent\n",
    "\n",
    "class CustomEnvironment(ParallelEnv):\n",
    "    metadata = {\n",
    "        \"name\": \"custom_environment_v0\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, num_good, num_adversaries, num_obstacles, max_cycles, continuous_actions, render_mode):\n",
    "        self.env = simple_tag_v3.parallel_env(num_good=num_good, num_adversaries=num_adversaries, num_obstacles=num_obstacles, max_cycles=max_cycles, continuous_actions=continuous_actions, render_mode=render_mode)\n",
    "        self.env.reset() \n",
    "        # Setting all the required attributes\n",
    "        self.agents = [agent for agent in self.env.agents if agent.startswith(\"adversary\")]\n",
    "        self.possible_agents = [adv for adv in self.env.possible_agents if adv.startswith(\"adversary\")]\n",
    "        self.render_mode = render_mode\n",
    "        # Adding agent_0 as part of the environment. Agent_0 is not meant to be included in the training\n",
    "        self.agent_0 = ImmobileAgent('agent_0', num_adversaries=NUM_ADV, num_landmarks=NUM_OBST)\n",
    "        \n",
    "    def reset(self, seed=None, options=None):\n",
    "        observations, infos = self.env.reset(seed=seed, options=options)\n",
    "        self.agent_0.see(observations[self.agent_0.name])\n",
    "        observations, infos = remove_agent_0_from_dicts([observations, infos])\n",
    "        return observations, infos\n",
    "\n",
    "    def step(self, actions):\n",
    "        actions['agent_0'] = self.agent_0.get_action()\n",
    "        observations, rewards, terminations, truncations, infos =  self.env.step(actions)\n",
    "        if observations:\n",
    "            self.agent_0.see(observations[self.agent_0.name])\n",
    "            observations, rewards, terminations, truncations, infos = remove_agent_0_from_dicts([observations, rewards, terminations, truncations, infos])\n",
    "        return observations, rewards, terminations, truncations, infos\n",
    "\n",
    "    def render(self):\n",
    "        self.env.render()\n",
    "\n",
    "    # Observation space should be defined here.\n",
    "    # lru_cache allows observation and action spaces to be memoized, reducing clock cycles required to get each agent's space.\n",
    "    # If your spaces change over time, remove this line (disable caching).\n",
    "    @functools.lru_cache(maxsize=None)\n",
    "    def observation_space(self, agent):\n",
    "        return self.env.observation_space(agent)\n",
    "\n",
    "    # Action space should be defined here.\n",
    "    # If your spaces change over time, remove this line (disable caching).\n",
    "    @functools.lru_cache(maxsize=None)\n",
    "    def action_space(self, agent):\n",
    "        return self.env.action_space(agent)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
