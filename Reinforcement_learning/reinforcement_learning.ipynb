{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pettingzoo.mpe import simple_tag_v3\n",
    "from pettingzoo import ParallelEnv\n",
    "import numpy as np\n",
    "import functools\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/mariusvaardal/AAMAS_project/AAMAS_project')\n",
    "\n",
    "import supersuit as ss\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_GOOD = 1\n",
    "NUM_ADV = 4\n",
    "NUM_OBST = 0\n",
    "MAX_CYCLES = 200\n",
    "CONTINOUS_ACTIONS = False\n",
    "RENDER_MODE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_agent_0_from_dicts(dicts):\n",
    "    ret = []\n",
    "    for dict in dicts:\n",
    "        del dict['agent_0']\n",
    "        ret.append(dict)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_types.AvoidingAgent import AvoidingAgent\n",
    "# from agent_types.AvoidingNearestAdversaryAgent import AvoidingNearestAdversaryAgent\n",
    "# from agent_types.ImmobileAgent import ImmobileAgent\n",
    "\n",
    "class CustomEnvironment(ParallelEnv):\n",
    "    metadata = {\n",
    "        \"name\": \"custom_environment_v0\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, num_good, num_adversaries, num_obstacles, max_cycles, continuous_actions, render_mode):\n",
    "        self.env = simple_tag_v3.parallel_env(num_good=num_good, num_adversaries=num_adversaries, num_obstacles=num_obstacles, max_cycles=max_cycles, continuous_actions=continuous_actions, render_mode=render_mode)\n",
    "        self.env.reset() \n",
    "        # Setting all the required attributes\n",
    "        self.agents = [agent for agent in self.env.agents if agent.startswith(\"adversary\")]\n",
    "        self.possible_agents = [adv for adv in self.env.possible_agents if adv.startswith(\"adversary\")]\n",
    "        self.render_mode = render_mode\n",
    "        # Adding agent_0 as part of the environment. Agent_0 is not meant to be included in the training\n",
    "        # self.agent_0 = AvoidingNearestAdversaryAgent('agent_0', num_adversaries=NUM_ADV, num_landmarks=NUM_OBST)\n",
    "        self.agent_0 = AvoidingAgent('agent_0', num_adversaries=NUM_ADV, num_landmarks=NUM_OBST)\n",
    "        \n",
    "    def reset(self, seed=None, options=None):\n",
    "        observations, infos = self.env.reset(seed=seed, options=options)\n",
    "        self.agent_0.see(observations[self.agent_0.name])\n",
    "        observations, infos = remove_agent_0_from_dicts([observations, infos])\n",
    "        return observations, infos\n",
    "\n",
    "    def step(self, actions):\n",
    "        actions['agent_0'] = self.agent_0.get_action()\n",
    "        observations, rewards, terminations, truncations, infos =  self.env.step(actions)\n",
    "        if observations:\n",
    "            self.agent_0.see(observations[self.agent_0.name])\n",
    "            observations, rewards, terminations, truncations, infos = remove_agent_0_from_dicts([observations, rewards, terminations, truncations, infos])\n",
    "        return observations, rewards, terminations, truncations, infos\n",
    "\n",
    "    def render(self):\n",
    "        self.env.render()\n",
    "\n",
    "    # Observation space should be defined here.\n",
    "    # lru_cache allows observation and action spaces to be memoized, reducing clock cycles required to get each agent's space.\n",
    "    # If your spaces change over time, remove this line (disable caching).\n",
    "    @functools.lru_cache(maxsize=None)\n",
    "    def observation_space(self, agent):\n",
    "        return self.env.observation_space(agent)\n",
    "\n",
    "    # Action space should be defined here.\n",
    "    # If your spaces change over time, remove this line (disable caching).\n",
    "    @functools.lru_cache(maxsize=None)\n",
    "    def action_space(self, agent):\n",
    "        return self.env.action_space(agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CustomEnvironment(num_good=NUM_GOOD, num_adversaries=NUM_ADV, num_obstacles=NUM_OBST, max_cycles=MAX_CYCLES, continuous_actions=CONTINOUS_ACTIONS, render_mode='human')\n",
    "observations, infos = env.reset()\n",
    "\n",
    "terminated = False\n",
    "timestep = 1\n",
    "while not terminated:\n",
    "    # this is where you would insert your policy\n",
    "    actions = {agent: env.action_space(agent).sample() for agent in env.agents}\n",
    "\n",
    "    observations, rewards, terminations, truncations, infos = env.step(actions)\n",
    "    if not observations:\n",
    "        terminated = True\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = CustomEnvironment(num_good=NUM_GOOD, num_adversaries=NUM_ADV, num_obstacles=NUM_OBST, max_cycles=MAX_CYCLES, continuous_actions=CONTINOUS_ACTIONS, render_mode=RENDER_MODE)\n",
    "env.reset(seed=45)\n",
    "conv_env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
    "conv_env = ss.concat_vec_envs_v1(conv_env, 2, num_cpus=0, base_class=\"stable_baselines3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "log_path = \"./logs/4_adv_0_to_50M_steps\"\n",
    "\n",
    "model = PPO(\n",
    "        MlpPolicy,\n",
    "        conv_env,\n",
    "        verbose=3,\n",
    "        learning_rate=1e-3,\n",
    "        batch_size=256,\n",
    "        tensorboard_log=log_path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models/3_adv\"\n",
    "model = PPO.load(os.path.join(model_path, \"106M_ANAA\"), conv_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./models/3_adv\"\n",
    "model = PPO.load(os.path.join(model_path, \"best_model\"), conv_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_object = {'learning_rate': 1e-4}\n",
    "\n",
    "model = PPO.load('./models/4_adv/best_model_30M/best_model', conv_env, custom_objects=custom_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/4_adv_0_to_50M_steps/PPO_6\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 4308  |\n",
      "|    iterations      | 1     |\n",
      "|    time_elapsed    | 3     |\n",
      "|    total_timesteps | 16384 |\n",
      "------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3791         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 8            |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027862673 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.588       |\n",
      "|    explained_variance   | 0.0469       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 828          |\n",
      "|    n_updates            | 14480        |\n",
      "|    policy_gradient_loss | -0.00756     |\n",
      "|    value_loss           | 2.12e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3569         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029899236 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.582       |\n",
      "|    explained_variance   | 0.027        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 955          |\n",
      "|    n_updates            | 14490        |\n",
      "|    policy_gradient_loss | -0.00651     |\n",
      "|    value_loss           | 2.17e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3429         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 19           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032427418 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.588       |\n",
      "|    explained_variance   | 0.0252       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 862          |\n",
      "|    n_updates            | 14500        |\n",
      "|    policy_gradient_loss | -0.00737     |\n",
      "|    value_loss           | 2.05e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mariusvaardal/.local/lib/python3.10/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=80000, episode_reward=648.40 +/- 81.32\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 648          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031067193 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.569       |\n",
      "|    explained_variance   | 0.00666      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 871          |\n",
      "|    n_updates            | 14510        |\n",
      "|    policy_gradient_loss | -0.00747     |\n",
      "|    value_loss           | 2.01e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 2846  |\n",
      "|    iterations      | 5     |\n",
      "|    time_elapsed    | 28    |\n",
      "|    total_timesteps | 81920 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2899        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002775665 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.572      |\n",
      "|    explained_variance   | 0.00584     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 14520       |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    value_loss           | 2.27e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2941         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 38           |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026773377 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.574       |\n",
      "|    explained_variance   | 0.00929      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 827          |\n",
      "|    n_updates            | 14530        |\n",
      "|    policy_gradient_loss | -0.00686     |\n",
      "|    value_loss           | 2.22e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2970         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 44           |\n",
      "|    total_timesteps      | 131072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027122572 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.565       |\n",
      "|    explained_variance   | 0.0479       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 928          |\n",
      "|    n_updates            | 14540        |\n",
      "|    policy_gradient_loss | -0.00659     |\n",
      "|    value_loss           | 2.32e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2972         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032759085 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.573       |\n",
      "|    explained_variance   | 0.0451       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 952          |\n",
      "|    n_updates            | 14550        |\n",
      "|    policy_gradient_loss | -0.00726     |\n",
      "|    value_loss           | 2.14e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=662.40 +/- 108.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 662          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 160000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029675881 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.563       |\n",
      "|    explained_variance   | 0.0369       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.65e+03     |\n",
      "|    n_updates            | 14560        |\n",
      "|    policy_gradient_loss | -0.00704     |\n",
      "|    value_loss           | 2.63e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 2650   |\n",
      "|    iterations      | 10     |\n",
      "|    time_elapsed    | 61     |\n",
      "|    total_timesteps | 163840 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2662        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 180224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002920323 |\n",
      "|    clip_fraction        | 0.0168      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.557      |\n",
      "|    explained_variance   | 0.013       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.45e+03    |\n",
      "|    n_updates            | 14570       |\n",
      "|    policy_gradient_loss | -0.00721    |\n",
      "|    value_loss           | 2.35e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2680         |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033047309 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.561       |\n",
      "|    explained_variance   | 0.00471      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 730          |\n",
      "|    n_updates            | 14580        |\n",
      "|    policy_gradient_loss | -0.00717     |\n",
      "|    value_loss           | 2.21e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2692         |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031235358 |\n",
      "|    clip_fraction        | 0.0216       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.564       |\n",
      "|    explained_variance   | 0.0177       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 907          |\n",
      "|    n_updates            | 14590        |\n",
      "|    policy_gradient_loss | -0.00732     |\n",
      "|    value_loss           | 2.14e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2699         |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 84           |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026495461 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.571       |\n",
      "|    explained_variance   | 0.000812     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.19e+03     |\n",
      "|    n_updates            | 14600        |\n",
      "|    policy_gradient_loss | -0.00689     |\n",
      "|    value_loss           | 2.38e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=720.00 +/- 114.05\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 720          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 240000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031357831 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.569       |\n",
      "|    explained_variance   | 0.0288       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.18e+03     |\n",
      "|    n_updates            | 14610        |\n",
      "|    policy_gradient_loss | -0.00777     |\n",
      "|    value_loss           | 2.27e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 2573   |\n",
      "|    iterations      | 15     |\n",
      "|    time_elapsed    | 95     |\n",
      "|    total_timesteps | 245760 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2584         |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 101          |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029815836 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.564       |\n",
      "|    explained_variance   | 0.0338       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 14620        |\n",
      "|    policy_gradient_loss | -0.0065      |\n",
      "|    value_loss           | 2.36e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2594         |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 278528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031881793 |\n",
      "|    clip_fraction        | 0.021        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.567       |\n",
      "|    explained_variance   | 0.0167       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 14630        |\n",
      "|    policy_gradient_loss | -0.00744     |\n",
      "|    value_loss           | 2.28e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2600         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 113          |\n",
      "|    total_timesteps      | 294912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028655338 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.564       |\n",
      "|    explained_variance   | 0.0273       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.18e+03     |\n",
      "|    n_updates            | 14640        |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    value_loss           | 2.42e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2608         |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 119          |\n",
      "|    total_timesteps      | 311296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029605213 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.564       |\n",
      "|    explained_variance   | 0.0204       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 14650        |\n",
      "|    policy_gradient_loss | -0.00698     |\n",
      "|    value_loss           | 2.12e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=320000, episode_reward=684.80 +/- 71.95\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 685          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 320000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028401231 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.559       |\n",
      "|    explained_variance   | 0.00559      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.33e+03     |\n",
      "|    n_updates            | 14660        |\n",
      "|    policy_gradient_loss | -0.00698     |\n",
      "|    value_loss           | 2.22e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 2511   |\n",
      "|    iterations      | 20     |\n",
      "|    time_elapsed    | 130    |\n",
      "|    total_timesteps | 327680 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2524        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003022784 |\n",
      "|    clip_fraction        | 0.0175      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.569      |\n",
      "|    explained_variance   | 0.00688     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.35e+03    |\n",
      "|    n_updates            | 14670       |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    value_loss           | 2.27e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2514         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 143          |\n",
      "|    total_timesteps      | 360448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029554926 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.562       |\n",
      "|    explained_variance   | 0.0163       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.44e+03     |\n",
      "|    n_updates            | 14680        |\n",
      "|    policy_gradient_loss | -0.00685     |\n",
      "|    value_loss           | 2.44e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2524         |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 149          |\n",
      "|    total_timesteps      | 376832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034125992 |\n",
      "|    clip_fraction        | 0.0252       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.575       |\n",
      "|    explained_variance   | 0.0261       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 14690        |\n",
      "|    policy_gradient_loss | -0.0082      |\n",
      "|    value_loss           | 2.39e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2534        |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 155         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003109298 |\n",
      "|    clip_fraction        | 0.0219      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.567      |\n",
      "|    explained_variance   | 0.0444      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 14700       |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    value_loss           | 2.25e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=706.80 +/- 75.72\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 707          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 400000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029471237 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.567       |\n",
      "|    explained_variance   | 0.0185       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 904          |\n",
      "|    n_updates            | 14710        |\n",
      "|    policy_gradient_loss | -0.00767     |\n",
      "|    value_loss           | 2.27e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 2472   |\n",
      "|    iterations      | 25     |\n",
      "|    time_elapsed    | 165    |\n",
      "|    total_timesteps | 409600 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2487         |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 171          |\n",
      "|    total_timesteps      | 425984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034127948 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.577       |\n",
      "|    explained_variance   | -0.0241      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.19e+03     |\n",
      "|    n_updates            | 14720        |\n",
      "|    policy_gradient_loss | -0.00704     |\n",
      "|    value_loss           | 2.37e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2501         |\n",
      "|    iterations           | 27           |\n",
      "|    time_elapsed         | 176          |\n",
      "|    total_timesteps      | 442368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033680997 |\n",
      "|    clip_fraction        | 0.0237       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.567       |\n",
      "|    explained_variance   | 0.0186       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 14730        |\n",
      "|    policy_gradient_loss | -0.00754     |\n",
      "|    value_loss           | 2.28e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2512         |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 182          |\n",
      "|    total_timesteps      | 458752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025314565 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.573       |\n",
      "|    explained_variance   | 0.0389       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.4e+03      |\n",
      "|    n_updates            | 14740        |\n",
      "|    policy_gradient_loss | -0.00644     |\n",
      "|    value_loss           | 2.42e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2521         |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 188          |\n",
      "|    total_timesteps      | 475136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031850236 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.563       |\n",
      "|    explained_variance   | 0.0324       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 873          |\n",
      "|    n_updates            | 14750        |\n",
      "|    policy_gradient_loss | -0.00774     |\n",
      "|    value_loss           | 2.33e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=702.40 +/- 114.31\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 702         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 480000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002741315 |\n",
      "|    clip_fraction        | 0.0169      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.573      |\n",
      "|    explained_variance   | 0.0213      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.03e+03    |\n",
      "|    n_updates            | 14760       |\n",
      "|    policy_gradient_loss | -0.00725    |\n",
      "|    value_loss           | 2.34e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 2475   |\n",
      "|    iterations      | 30     |\n",
      "|    time_elapsed    | 198    |\n",
      "|    total_timesteps | 491520 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2489         |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 204          |\n",
      "|    total_timesteps      | 507904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030922387 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.574       |\n",
      "|    explained_variance   | 0.0432       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 14770        |\n",
      "|    policy_gradient_loss | -0.00739     |\n",
      "|    value_loss           | 2.34e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2500        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 209         |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003133586 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.579      |\n",
      "|    explained_variance   | 0.0204      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.25e+03    |\n",
      "|    n_updates            | 14780       |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    value_loss           | 2.21e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2514         |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 215          |\n",
      "|    total_timesteps      | 540672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029680426 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.568       |\n",
      "|    explained_variance   | 0.0425       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 942          |\n",
      "|    n_updates            | 14790        |\n",
      "|    policy_gradient_loss | -0.0077      |\n",
      "|    value_loss           | 2.16e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2526        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 220         |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002746324 |\n",
      "|    clip_fraction        | 0.0181      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.57       |\n",
      "|    explained_variance   | 0.0368      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.39e+03    |\n",
      "|    n_updates            | 14800       |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    value_loss           | 2.33e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=628.40 +/- 162.50\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 628          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 560000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028936109 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.562       |\n",
      "|    explained_variance   | 0.0276       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 14810        |\n",
      "|    policy_gradient_loss | -0.00677     |\n",
      "|    value_loss           | 2.56e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 2482   |\n",
      "|    iterations      | 35     |\n",
      "|    time_elapsed    | 231    |\n",
      "|    total_timesteps | 573440 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2493         |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 236          |\n",
      "|    total_timesteps      | 589824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027944637 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.562       |\n",
      "|    explained_variance   | 0.0384       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 919          |\n",
      "|    n_updates            | 14820        |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    value_loss           | 2.24e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2503         |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 242          |\n",
      "|    total_timesteps      | 606208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031229756 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.571       |\n",
      "|    explained_variance   | 0.0269       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 838          |\n",
      "|    n_updates            | 14830        |\n",
      "|    policy_gradient_loss | -0.00756     |\n",
      "|    value_loss           | 2.24e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2514         |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 247          |\n",
      "|    total_timesteps      | 622592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029003401 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.568       |\n",
      "|    explained_variance   | 0.0612       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 14840        |\n",
      "|    policy_gradient_loss | -0.00689     |\n",
      "|    value_loss           | 2.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2525         |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 252          |\n",
      "|    total_timesteps      | 638976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032469172 |\n",
      "|    clip_fraction        | 0.0237       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.572       |\n",
      "|    explained_variance   | 0.013        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 14850        |\n",
      "|    policy_gradient_loss | -0.0077      |\n",
      "|    value_loss           | 2.29e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=687.60 +/- 124.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 688         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 640000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003080464 |\n",
      "|    clip_fraction        | 0.0209      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.576      |\n",
      "|    explained_variance   | 0.065       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 14860       |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    value_loss           | 2.31e+03    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 2491   |\n",
      "|    iterations      | 40     |\n",
      "|    time_elapsed    | 263    |\n",
      "|    total_timesteps | 655360 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2502        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 671744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003016268 |\n",
      "|    clip_fraction        | 0.0178      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.578      |\n",
      "|    explained_variance   | 0.0177      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 14870       |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    value_loss           | 2.25e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2512        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 273         |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003039158 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.58       |\n",
      "|    explained_variance   | 0.0149      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.09e+03    |\n",
      "|    n_updates            | 14880       |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    value_loss           | 2.44e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2521         |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 279          |\n",
      "|    total_timesteps      | 704512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031077035 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.572       |\n",
      "|    explained_variance   | 0.0359       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 14890        |\n",
      "|    policy_gradient_loss | -0.00702     |\n",
      "|    value_loss           | 2.44e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=657.20 +/- 114.74\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 657          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 720000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029130876 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.572       |\n",
      "|    explained_variance   | 0.0382       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 14900        |\n",
      "|    policy_gradient_loss | -0.00763     |\n",
      "|    value_loss           | 2.17e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 2487   |\n",
      "|    iterations      | 44     |\n",
      "|    time_elapsed    | 289    |\n",
      "|    total_timesteps | 720896 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2496         |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 295          |\n",
      "|    total_timesteps      | 737280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031433436 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.568       |\n",
      "|    explained_variance   | 0.0279       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 954          |\n",
      "|    n_updates            | 14910        |\n",
      "|    policy_gradient_loss | -0.00775     |\n",
      "|    value_loss           | 2.4e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2505         |\n",
      "|    iterations           | 46           |\n",
      "|    time_elapsed         | 300          |\n",
      "|    total_timesteps      | 753664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029324484 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.572       |\n",
      "|    explained_variance   | 0.0426       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 14920        |\n",
      "|    policy_gradient_loss | -0.00674     |\n",
      "|    value_loss           | 2.41e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2513        |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 306         |\n",
      "|    total_timesteps      | 770048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003105297 |\n",
      "|    clip_fraction        | 0.0209      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.564      |\n",
      "|    explained_variance   | 0.0508      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.27e+03    |\n",
      "|    n_updates            | 14930       |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    value_loss           | 2.54e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2520         |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 312          |\n",
      "|    total_timesteps      | 786432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028791316 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.572       |\n",
      "|    explained_variance   | 0.0753       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 955          |\n",
      "|    n_updates            | 14940        |\n",
      "|    policy_gradient_loss | -0.00681     |\n",
      "|    value_loss           | 2.33e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=654.00 +/- 104.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 654          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 800000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026873155 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.566       |\n",
      "|    explained_variance   | 0.0418       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 946          |\n",
      "|    n_updates            | 14950        |\n",
      "|    policy_gradient_loss | -0.00688     |\n",
      "|    value_loss           | 2.23e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 2491   |\n",
      "|    iterations      | 49     |\n",
      "|    time_elapsed    | 322    |\n",
      "|    total_timesteps | 802816 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2499        |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 327         |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003017162 |\n",
      "|    clip_fraction        | 0.0192      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.572      |\n",
      "|    explained_variance   | 0.0502      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.4e+03     |\n",
      "|    n_updates            | 14960       |\n",
      "|    policy_gradient_loss | -0.00672    |\n",
      "|    value_loss           | 2.22e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2507         |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 333          |\n",
      "|    total_timesteps      | 835584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027061338 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.575       |\n",
      "|    explained_variance   | 0.0361       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 14970        |\n",
      "|    policy_gradient_loss | -0.00641     |\n",
      "|    value_loss           | 2.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2515         |\n",
      "|    iterations           | 52           |\n",
      "|    time_elapsed         | 338          |\n",
      "|    total_timesteps      | 851968       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032498026 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.576       |\n",
      "|    explained_variance   | 0.0125       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 931          |\n",
      "|    n_updates            | 14980        |\n",
      "|    policy_gradient_loss | -0.00761     |\n",
      "|    value_loss           | 2.16e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2523         |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 344          |\n",
      "|    total_timesteps      | 868352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030669284 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.575       |\n",
      "|    explained_variance   | 0.0531       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.51e+03     |\n",
      "|    n_updates            | 14990        |\n",
      "|    policy_gradient_loss | -0.00754     |\n",
      "|    value_loss           | 2.34e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=880000, episode_reward=673.20 +/- 76.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 673          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 880000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029322817 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.574       |\n",
      "|    explained_variance   | 0.0131       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 15000        |\n",
      "|    policy_gradient_loss | -0.00663     |\n",
      "|    value_loss           | 2.29e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 2496   |\n",
      "|    iterations      | 54     |\n",
      "|    time_elapsed    | 354    |\n",
      "|    total_timesteps | 884736 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2505         |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 359          |\n",
      "|    total_timesteps      | 901120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029432918 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.583       |\n",
      "|    explained_variance   | 0.0527       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 872          |\n",
      "|    n_updates            | 15010        |\n",
      "|    policy_gradient_loss | -0.0066      |\n",
      "|    value_loss           | 2.1e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2513         |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 365          |\n",
      "|    total_timesteps      | 917504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033244444 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.561       |\n",
      "|    explained_variance   | -0.000185    |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.5e+03      |\n",
      "|    n_updates            | 15020        |\n",
      "|    policy_gradient_loss | -0.00682     |\n",
      "|    value_loss           | 2.37e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2519         |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 370          |\n",
      "|    total_timesteps      | 933888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031598173 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.567       |\n",
      "|    explained_variance   | 0.0734       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 15030        |\n",
      "|    policy_gradient_loss | -0.00702     |\n",
      "|    value_loss           | 2.26e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2527         |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 375          |\n",
      "|    total_timesteps      | 950272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033248821 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.567       |\n",
      "|    explained_variance   | 0.0435       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 957          |\n",
      "|    n_updates            | 15040        |\n",
      "|    policy_gradient_loss | -0.00764     |\n",
      "|    value_loss           | 2.3e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=960000, episode_reward=662.40 +/- 86.08\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 662          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 960000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028550755 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.569       |\n",
      "|    explained_variance   | 0.053        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 851          |\n",
      "|    n_updates            | 15050        |\n",
      "|    policy_gradient_loss | -0.00674     |\n",
      "|    value_loss           | 2.19e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 2503   |\n",
      "|    iterations      | 59     |\n",
      "|    time_elapsed    | 386    |\n",
      "|    total_timesteps | 966656 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2510         |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 391          |\n",
      "|    total_timesteps      | 983040       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029320696 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.562       |\n",
      "|    explained_variance   | 0.0395       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1e+03        |\n",
      "|    n_updates            | 15060        |\n",
      "|    policy_gradient_loss | -0.00727     |\n",
      "|    value_loss           | 2.54e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2518         |\n",
      "|    iterations           | 61           |\n",
      "|    time_elapsed         | 396          |\n",
      "|    total_timesteps      | 999424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034467303 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.568       |\n",
      "|    explained_variance   | 0.0393       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 15070        |\n",
      "|    policy_gradient_loss | -0.0081      |\n",
      "|    value_loss           | 2.13e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2524         |\n",
      "|    iterations           | 62           |\n",
      "|    time_elapsed         | 402          |\n",
      "|    total_timesteps      | 1015808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033249455 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.563       |\n",
      "|    explained_variance   | 0.0315       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 15080        |\n",
      "|    policy_gradient_loss | -0.00684     |\n",
      "|    value_loss           | 2.3e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2531         |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 407          |\n",
      "|    total_timesteps      | 1032192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030788984 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.572       |\n",
      "|    explained_variance   | 0.0547       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 15090        |\n",
      "|    policy_gradient_loss | -0.00728     |\n",
      "|    value_loss           | 2.33e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1040000, episode_reward=723.60 +/- 120.10\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 724          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1040000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029529764 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.567       |\n",
      "|    explained_variance   | 0.0234       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.21e+03     |\n",
      "|    n_updates            | 15100        |\n",
      "|    policy_gradient_loss | -0.00708     |\n",
      "|    value_loss           | 2.48e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2507    |\n",
      "|    iterations      | 64      |\n",
      "|    time_elapsed    | 418     |\n",
      "|    total_timesteps | 1048576 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2512        |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 423         |\n",
      "|    total_timesteps      | 1064960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003175268 |\n",
      "|    clip_fraction        | 0.0233      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.562      |\n",
      "|    explained_variance   | 0.0626      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 15110       |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    value_loss           | 2.3e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2518         |\n",
      "|    iterations           | 66           |\n",
      "|    time_elapsed         | 429          |\n",
      "|    total_timesteps      | 1081344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028060894 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.573       |\n",
      "|    explained_variance   | 0.0641       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 15120        |\n",
      "|    policy_gradient_loss | -0.00644     |\n",
      "|    value_loss           | 2.48e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2524         |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 434          |\n",
      "|    total_timesteps      | 1097728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030897313 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.568       |\n",
      "|    explained_variance   | 0.0175       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 15130        |\n",
      "|    policy_gradient_loss | -0.00739     |\n",
      "|    value_loss           | 2.34e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2530        |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 440         |\n",
      "|    total_timesteps      | 1114112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002899279 |\n",
      "|    clip_fraction        | 0.0173      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.575      |\n",
      "|    explained_variance   | 0.0243      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 881         |\n",
      "|    n_updates            | 15140       |\n",
      "|    policy_gradient_loss | -0.00661    |\n",
      "|    value_loss           | 2.43e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1120000, episode_reward=663.60 +/- 100.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 664          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027237986 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.568       |\n",
      "|    explained_variance   | 0.0669       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1e+03        |\n",
      "|    n_updates            | 15150        |\n",
      "|    policy_gradient_loss | -0.00689     |\n",
      "|    value_loss           | 2.33e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2509    |\n",
      "|    iterations      | 69      |\n",
      "|    time_elapsed    | 450     |\n",
      "|    total_timesteps | 1130496 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2513         |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 456          |\n",
      "|    total_timesteps      | 1146880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028726005 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.568       |\n",
      "|    explained_variance   | 0.0322       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.54e+03     |\n",
      "|    n_updates            | 15160        |\n",
      "|    policy_gradient_loss | -0.00705     |\n",
      "|    value_loss           | 2.49e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2517         |\n",
      "|    iterations           | 71           |\n",
      "|    time_elapsed         | 461          |\n",
      "|    total_timesteps      | 1163264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030638948 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.571       |\n",
      "|    explained_variance   | 0.0242       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 773          |\n",
      "|    n_updates            | 15170        |\n",
      "|    policy_gradient_loss | -0.00676     |\n",
      "|    value_loss           | 2.26e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2521         |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 467          |\n",
      "|    total_timesteps      | 1179648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027683256 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.578       |\n",
      "|    explained_variance   | 0.0423       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 15180        |\n",
      "|    policy_gradient_loss | -0.00667     |\n",
      "|    value_loss           | 2.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2525         |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 473          |\n",
      "|    total_timesteps      | 1196032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030273662 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.568       |\n",
      "|    explained_variance   | 0.0429       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.08e+03     |\n",
      "|    n_updates            | 15190        |\n",
      "|    policy_gradient_loss | -0.00762     |\n",
      "|    value_loss           | 2.25e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1200000, episode_reward=695.20 +/- 84.43\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 695          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032029483 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.569       |\n",
      "|    explained_variance   | 0.0604       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 15200        |\n",
      "|    policy_gradient_loss | -0.00696     |\n",
      "|    value_loss           | 2.38e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2504    |\n",
      "|    iterations      | 74      |\n",
      "|    time_elapsed    | 484     |\n",
      "|    total_timesteps | 1212416 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2509        |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 489         |\n",
      "|    total_timesteps      | 1228800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003206918 |\n",
      "|    clip_fraction        | 0.0217      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.578      |\n",
      "|    explained_variance   | 0.0187      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 15210       |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    value_loss           | 2.33e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2514         |\n",
      "|    iterations           | 76           |\n",
      "|    time_elapsed         | 495          |\n",
      "|    total_timesteps      | 1245184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029479042 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.58        |\n",
      "|    explained_variance   | 0.0326       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 15220        |\n",
      "|    policy_gradient_loss | -0.00703     |\n",
      "|    value_loss           | 2.57e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2519         |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 500          |\n",
      "|    total_timesteps      | 1261568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031737941 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.569       |\n",
      "|    explained_variance   | 0.0482       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 15230        |\n",
      "|    policy_gradient_loss | -0.00681     |\n",
      "|    value_loss           | 2.32e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2523         |\n",
      "|    iterations           | 78           |\n",
      "|    time_elapsed         | 506          |\n",
      "|    total_timesteps      | 1277952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028585796 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.57        |\n",
      "|    explained_variance   | 0.0414       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 15240        |\n",
      "|    policy_gradient_loss | -0.00638     |\n",
      "|    value_loss           | 2.32e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1280000, episode_reward=722.40 +/- 78.55\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 722          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030365176 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.562       |\n",
      "|    explained_variance   | 0.0443       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 15250        |\n",
      "|    policy_gradient_loss | -0.00754     |\n",
      "|    value_loss           | 2.3e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2504    |\n",
      "|    iterations      | 79      |\n",
      "|    time_elapsed    | 516     |\n",
      "|    total_timesteps | 1294336 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2509         |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 522          |\n",
      "|    total_timesteps      | 1310720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027796822 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.563       |\n",
      "|    explained_variance   | 0.0316       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 15260        |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    value_loss           | 2.42e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2512         |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 528          |\n",
      "|    total_timesteps      | 1327104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026329998 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.557       |\n",
      "|    explained_variance   | 0.0606       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 15270        |\n",
      "|    policy_gradient_loss | -0.00696     |\n",
      "|    value_loss           | 2.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2516         |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 533          |\n",
      "|    total_timesteps      | 1343488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030019004 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.562       |\n",
      "|    explained_variance   | -0.0017      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 15280        |\n",
      "|    policy_gradient_loss | -0.00668     |\n",
      "|    value_loss           | 2.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2520         |\n",
      "|    iterations           | 83           |\n",
      "|    time_elapsed         | 539          |\n",
      "|    total_timesteps      | 1359872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030173613 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.569       |\n",
      "|    explained_variance   | 0.0112       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 15290        |\n",
      "|    policy_gradient_loss | -0.00695     |\n",
      "|    value_loss           | 2.26e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1360000, episode_reward=690.00 +/- 180.40\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 690         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1360000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002845547 |\n",
      "|    clip_fraction        | 0.0191      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.572      |\n",
      "|    explained_variance   | 0.0397      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.3e+03     |\n",
      "|    n_updates            | 15300       |\n",
      "|    policy_gradient_loss | -0.00742    |\n",
      "|    value_loss           | 2.38e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2500    |\n",
      "|    iterations      | 84      |\n",
      "|    time_elapsed    | 550     |\n",
      "|    total_timesteps | 1376256 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2502         |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 556          |\n",
      "|    total_timesteps      | 1392640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029693441 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.568       |\n",
      "|    explained_variance   | 0.0229       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.44e+03     |\n",
      "|    n_updates            | 15310        |\n",
      "|    policy_gradient_loss | -0.00679     |\n",
      "|    value_loss           | 2.6e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2506         |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 562          |\n",
      "|    total_timesteps      | 1409024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030747515 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.564       |\n",
      "|    explained_variance   | 0.0403       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.24e+03     |\n",
      "|    n_updates            | 15320        |\n",
      "|    policy_gradient_loss | -0.00707     |\n",
      "|    value_loss           | 2.31e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2507         |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 568          |\n",
      "|    total_timesteps      | 1425408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027372388 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.565       |\n",
      "|    explained_variance   | 0.0825       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.43e+03     |\n",
      "|    n_updates            | 15330        |\n",
      "|    policy_gradient_loss | -0.00686     |\n",
      "|    value_loss           | 2.36e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1440000, episode_reward=663.20 +/- 79.94\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 663          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1440000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028643766 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.0459       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 15340        |\n",
      "|    policy_gradient_loss | -0.00725     |\n",
      "|    value_loss           | 2.35e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2487    |\n",
      "|    iterations      | 88      |\n",
      "|    time_elapsed    | 579     |\n",
      "|    total_timesteps | 1441792 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2491         |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 585          |\n",
      "|    total_timesteps      | 1458176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027839711 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.563       |\n",
      "|    explained_variance   | 0.0333       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 15350        |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    value_loss           | 2.43e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2495         |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 590          |\n",
      "|    total_timesteps      | 1474560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028464985 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.55        |\n",
      "|    explained_variance   | 0.0671       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 15360        |\n",
      "|    policy_gradient_loss | -0.00653     |\n",
      "|    value_loss           | 2.39e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2498         |\n",
      "|    iterations           | 91           |\n",
      "|    time_elapsed         | 596          |\n",
      "|    total_timesteps      | 1490944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033720743 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.557       |\n",
      "|    explained_variance   | 0.0317       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 15370        |\n",
      "|    policy_gradient_loss | -0.00749     |\n",
      "|    value_loss           | 2.31e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2501         |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 602          |\n",
      "|    total_timesteps      | 1507328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030317814 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.569       |\n",
      "|    explained_variance   | 0.0535       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 15380        |\n",
      "|    policy_gradient_loss | -0.00717     |\n",
      "|    value_loss           | 2.33e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1520000, episode_reward=674.00 +/- 97.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 674          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1520000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028691231 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.557       |\n",
      "|    explained_variance   | 0.0413       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 956          |\n",
      "|    n_updates            | 15390        |\n",
      "|    policy_gradient_loss | -0.0069      |\n",
      "|    value_loss           | 2.55e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2485    |\n",
      "|    iterations      | 93      |\n",
      "|    time_elapsed    | 613     |\n",
      "|    total_timesteps | 1523712 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2488         |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 618          |\n",
      "|    total_timesteps      | 1540096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028165444 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.56        |\n",
      "|    explained_variance   | 0.0328       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 15400        |\n",
      "|    policy_gradient_loss | -0.00697     |\n",
      "|    value_loss           | 2.35e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2490         |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 624          |\n",
      "|    total_timesteps      | 1556480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030862968 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.561       |\n",
      "|    explained_variance   | 0.0488       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 920          |\n",
      "|    n_updates            | 15410        |\n",
      "|    policy_gradient_loss | -0.00708     |\n",
      "|    value_loss           | 2.33e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2493         |\n",
      "|    iterations           | 96           |\n",
      "|    time_elapsed         | 630          |\n",
      "|    total_timesteps      | 1572864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030571944 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.569       |\n",
      "|    explained_variance   | 0.0287       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 15420        |\n",
      "|    policy_gradient_loss | -0.00709     |\n",
      "|    value_loss           | 2.47e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2496        |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 636         |\n",
      "|    total_timesteps      | 1589248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003450667 |\n",
      "|    clip_fraction        | 0.0239      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.567      |\n",
      "|    explained_variance   | 0.0263      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.28e+03    |\n",
      "|    n_updates            | 15430       |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    value_loss           | 2.62e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1600000, episode_reward=701.20 +/- 116.66\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 701          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1600000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025795437 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.563       |\n",
      "|    explained_variance   | 0.0199       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 974          |\n",
      "|    n_updates            | 15440        |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    value_loss           | 2.54e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2479    |\n",
      "|    iterations      | 98      |\n",
      "|    time_elapsed    | 647     |\n",
      "|    total_timesteps | 1605632 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2481         |\n",
      "|    iterations           | 99           |\n",
      "|    time_elapsed         | 653          |\n",
      "|    total_timesteps      | 1622016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031296434 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.559       |\n",
      "|    explained_variance   | 0.0508       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.45e+03     |\n",
      "|    n_updates            | 15450        |\n",
      "|    policy_gradient_loss | -0.0072      |\n",
      "|    value_loss           | 2.44e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2485         |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 659          |\n",
      "|    total_timesteps      | 1638400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030073754 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.565       |\n",
      "|    explained_variance   | 0.0142       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 15460        |\n",
      "|    policy_gradient_loss | -0.00717     |\n",
      "|    value_loss           | 2.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2488         |\n",
      "|    iterations           | 101          |\n",
      "|    time_elapsed         | 665          |\n",
      "|    total_timesteps      | 1654784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028890623 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.565       |\n",
      "|    explained_variance   | 0.0333       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 15470        |\n",
      "|    policy_gradient_loss | -0.00664     |\n",
      "|    value_loss           | 2.59e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2491         |\n",
      "|    iterations           | 102          |\n",
      "|    time_elapsed         | 670          |\n",
      "|    total_timesteps      | 1671168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033315313 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.572       |\n",
      "|    explained_variance   | 0.0706       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 15480        |\n",
      "|    policy_gradient_loss | -0.0074      |\n",
      "|    value_loss           | 2.34e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1680000, episode_reward=712.40 +/- 83.82\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 712          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1680000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031084106 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.571       |\n",
      "|    explained_variance   | 0.0387       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 961          |\n",
      "|    n_updates            | 15490        |\n",
      "|    policy_gradient_loss | -0.00717     |\n",
      "|    value_loss           | 2.21e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2474    |\n",
      "|    iterations      | 103     |\n",
      "|    time_elapsed    | 681     |\n",
      "|    total_timesteps | 1687552 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2478         |\n",
      "|    iterations           | 104          |\n",
      "|    time_elapsed         | 687          |\n",
      "|    total_timesteps      | 1703936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028707662 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.566       |\n",
      "|    explained_variance   | 0.00976      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 904          |\n",
      "|    n_updates            | 15500        |\n",
      "|    policy_gradient_loss | -0.00669     |\n",
      "|    value_loss           | 2.17e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2481         |\n",
      "|    iterations           | 105          |\n",
      "|    time_elapsed         | 693          |\n",
      "|    total_timesteps      | 1720320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028256117 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.562       |\n",
      "|    explained_variance   | 0.0383       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 15510        |\n",
      "|    policy_gradient_loss | -0.00706     |\n",
      "|    value_loss           | 2.27e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2484         |\n",
      "|    iterations           | 106          |\n",
      "|    time_elapsed         | 699          |\n",
      "|    total_timesteps      | 1736704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027093687 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.561       |\n",
      "|    explained_variance   | 0.00798      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.43e+03     |\n",
      "|    n_updates            | 15520        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    value_loss           | 2.43e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2487        |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 704         |\n",
      "|    total_timesteps      | 1753088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002777392 |\n",
      "|    clip_fraction        | 0.0176      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.558      |\n",
      "|    explained_variance   | 0.0278      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.33e+03    |\n",
      "|    n_updates            | 15530       |\n",
      "|    policy_gradient_loss | -0.00731    |\n",
      "|    value_loss           | 2.34e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1760000, episode_reward=671.20 +/- 99.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 671          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1760000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032231568 |\n",
      "|    clip_fraction        | 0.0237       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.561       |\n",
      "|    explained_variance   | 0.012        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 15540        |\n",
      "|    policy_gradient_loss | -0.00765     |\n",
      "|    value_loss           | 2.38e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2473    |\n",
      "|    iterations      | 108     |\n",
      "|    time_elapsed    | 715     |\n",
      "|    total_timesteps | 1769472 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2476        |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 721         |\n",
      "|    total_timesteps      | 1785856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002663963 |\n",
      "|    clip_fraction        | 0.0174      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.558      |\n",
      "|    explained_variance   | 0.042       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 15550       |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    value_loss           | 2.47e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2478         |\n",
      "|    iterations           | 110          |\n",
      "|    time_elapsed         | 727          |\n",
      "|    total_timesteps      | 1802240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032947995 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.557       |\n",
      "|    explained_variance   | 0.0196       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 15560        |\n",
      "|    policy_gradient_loss | -0.00711     |\n",
      "|    value_loss           | 2.57e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2482        |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 732         |\n",
      "|    total_timesteps      | 1818624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002927657 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.554      |\n",
      "|    explained_variance   | 0.0739      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.03e+03    |\n",
      "|    n_updates            | 15570       |\n",
      "|    policy_gradient_loss | -0.00713    |\n",
      "|    value_loss           | 2.36e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2485        |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 738         |\n",
      "|    total_timesteps      | 1835008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002864601 |\n",
      "|    clip_fraction        | 0.0173      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.548      |\n",
      "|    explained_variance   | -0.00391    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 15580       |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    value_loss           | 2.28e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1840000, episode_reward=702.40 +/- 94.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 702          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1840000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025356496 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.544       |\n",
      "|    explained_variance   | 0.0313       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 15590        |\n",
      "|    policy_gradient_loss | -0.00662     |\n",
      "|    value_loss           | 2.41e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2471    |\n",
      "|    iterations      | 113     |\n",
      "|    time_elapsed    | 749     |\n",
      "|    total_timesteps | 1851392 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2474        |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 754         |\n",
      "|    total_timesteps      | 1867776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003053885 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.556      |\n",
      "|    explained_variance   | 0.0323      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 15600       |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    value_loss           | 2.63e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2477         |\n",
      "|    iterations           | 115          |\n",
      "|    time_elapsed         | 760          |\n",
      "|    total_timesteps      | 1884160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024325966 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.551       |\n",
      "|    explained_variance   | 0.0349       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 735          |\n",
      "|    n_updates            | 15610        |\n",
      "|    policy_gradient_loss | -0.00659     |\n",
      "|    value_loss           | 2.41e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2479         |\n",
      "|    iterations           | 116          |\n",
      "|    time_elapsed         | 766          |\n",
      "|    total_timesteps      | 1900544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030318284 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.0204       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 764          |\n",
      "|    n_updates            | 15620        |\n",
      "|    policy_gradient_loss | -0.00738     |\n",
      "|    value_loss           | 2.48e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2482         |\n",
      "|    iterations           | 117          |\n",
      "|    time_elapsed         | 772          |\n",
      "|    total_timesteps      | 1916928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030835988 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.542       |\n",
      "|    explained_variance   | 0.0406       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 15630        |\n",
      "|    policy_gradient_loss | -0.00706     |\n",
      "|    value_loss           | 2.48e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1920000, episode_reward=718.80 +/- 96.84\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 719         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1920000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002824161 |\n",
      "|    clip_fraction        | 0.0176      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.558      |\n",
      "|    explained_variance   | 0.0364      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.4e+03     |\n",
      "|    n_updates            | 15640       |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    value_loss           | 2.67e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2469    |\n",
      "|    iterations      | 118     |\n",
      "|    time_elapsed    | 782     |\n",
      "|    total_timesteps | 1933312 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2471         |\n",
      "|    iterations           | 119          |\n",
      "|    time_elapsed         | 788          |\n",
      "|    total_timesteps      | 1949696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030454583 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.547       |\n",
      "|    explained_variance   | 0.0251       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 968          |\n",
      "|    n_updates            | 15650        |\n",
      "|    policy_gradient_loss | -0.00714     |\n",
      "|    value_loss           | 2.4e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2474         |\n",
      "|    iterations           | 120          |\n",
      "|    time_elapsed         | 794          |\n",
      "|    total_timesteps      | 1966080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024008297 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.558       |\n",
      "|    explained_variance   | 0.00881      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 15660        |\n",
      "|    policy_gradient_loss | -0.00622     |\n",
      "|    value_loss           | 2.49e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2477         |\n",
      "|    iterations           | 121          |\n",
      "|    time_elapsed         | 800          |\n",
      "|    total_timesteps      | 1982464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030518733 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.557       |\n",
      "|    explained_variance   | 0.0202       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.55e+03     |\n",
      "|    n_updates            | 15670        |\n",
      "|    policy_gradient_loss | -0.00696     |\n",
      "|    value_loss           | 2.4e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2481         |\n",
      "|    iterations           | 122          |\n",
      "|    time_elapsed         | 805          |\n",
      "|    total_timesteps      | 1998848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027174708 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.546       |\n",
      "|    explained_variance   | 0.0273       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 15680        |\n",
      "|    policy_gradient_loss | -0.0068      |\n",
      "|    value_loss           | 2.56e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2000000, episode_reward=659.60 +/- 138.58\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 660          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028179307 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.551       |\n",
      "|    explained_variance   | 0.0441       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 930          |\n",
      "|    n_updates            | 15690        |\n",
      "|    policy_gradient_loss | -0.00679     |\n",
      "|    value_loss           | 2.35e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2470    |\n",
      "|    iterations      | 123     |\n",
      "|    time_elapsed    | 815     |\n",
      "|    total_timesteps | 2015232 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2474         |\n",
      "|    iterations           | 124          |\n",
      "|    time_elapsed         | 821          |\n",
      "|    total_timesteps      | 2031616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025984254 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.55        |\n",
      "|    explained_variance   | 0.0357       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 15700        |\n",
      "|    policy_gradient_loss | -0.0065      |\n",
      "|    value_loss           | 2.5e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2478         |\n",
      "|    iterations           | 125          |\n",
      "|    time_elapsed         | 826          |\n",
      "|    total_timesteps      | 2048000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026519876 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.546       |\n",
      "|    explained_variance   | 0.0462       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 15710        |\n",
      "|    policy_gradient_loss | -0.00702     |\n",
      "|    value_loss           | 2.28e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2481         |\n",
      "|    iterations           | 126          |\n",
      "|    time_elapsed         | 831          |\n",
      "|    total_timesteps      | 2064384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030104257 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.544       |\n",
      "|    explained_variance   | -0.0106      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 15720        |\n",
      "|    policy_gradient_loss | -0.00705     |\n",
      "|    value_loss           | 2.66e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2080000, episode_reward=693.20 +/- 90.94\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 693         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2080000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003205948 |\n",
      "|    clip_fraction        | 0.0243      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.554      |\n",
      "|    explained_variance   | 0.0501      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 15730       |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    value_loss           | 2.47e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2471    |\n",
      "|    iterations      | 127     |\n",
      "|    time_elapsed    | 842     |\n",
      "|    total_timesteps | 2080768 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2474         |\n",
      "|    iterations           | 128          |\n",
      "|    time_elapsed         | 847          |\n",
      "|    total_timesteps      | 2097152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028538737 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.561       |\n",
      "|    explained_variance   | 0.0551       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.64e+03     |\n",
      "|    n_updates            | 15740        |\n",
      "|    policy_gradient_loss | -0.00722     |\n",
      "|    value_loss           | 2.42e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2477         |\n",
      "|    iterations           | 129          |\n",
      "|    time_elapsed         | 852          |\n",
      "|    total_timesteps      | 2113536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029698575 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.0266       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 15750        |\n",
      "|    policy_gradient_loss | -0.00716     |\n",
      "|    value_loss           | 2.32e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2481        |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 858         |\n",
      "|    total_timesteps      | 2129920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002755323 |\n",
      "|    clip_fraction        | 0.0163      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.556      |\n",
      "|    explained_variance   | 0.0492      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.33e+03    |\n",
      "|    n_updates            | 15760       |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    value_loss           | 2.41e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2484         |\n",
      "|    iterations           | 131          |\n",
      "|    time_elapsed         | 863          |\n",
      "|    total_timesteps      | 2146304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029588481 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.557       |\n",
      "|    explained_variance   | 0.0102       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 15770        |\n",
      "|    policy_gradient_loss | -0.00705     |\n",
      "|    value_loss           | 2.58e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2160000, episode_reward=686.40 +/- 109.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 686          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2160000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028107276 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.557       |\n",
      "|    explained_variance   | 0.0406       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 15780        |\n",
      "|    policy_gradient_loss | -0.007       |\n",
      "|    value_loss           | 2.44e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2474    |\n",
      "|    iterations      | 132     |\n",
      "|    time_elapsed    | 874     |\n",
      "|    total_timesteps | 2162688 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2477         |\n",
      "|    iterations           | 133          |\n",
      "|    time_elapsed         | 879          |\n",
      "|    total_timesteps      | 2179072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024946076 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.549       |\n",
      "|    explained_variance   | 0.0374       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 976          |\n",
      "|    n_updates            | 15790        |\n",
      "|    policy_gradient_loss | -0.00652     |\n",
      "|    value_loss           | 2.26e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2481         |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 884          |\n",
      "|    total_timesteps      | 2195456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030117882 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.56        |\n",
      "|    explained_variance   | -0.0154      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 952          |\n",
      "|    n_updates            | 15800        |\n",
      "|    policy_gradient_loss | -0.00663     |\n",
      "|    value_loss           | 2.42e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2484         |\n",
      "|    iterations           | 135          |\n",
      "|    time_elapsed         | 890          |\n",
      "|    total_timesteps      | 2211840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028550394 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.538       |\n",
      "|    explained_variance   | 0.0162       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.8e+03      |\n",
      "|    n_updates            | 15810        |\n",
      "|    policy_gradient_loss | -0.00724     |\n",
      "|    value_loss           | 2.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2488         |\n",
      "|    iterations           | 136          |\n",
      "|    time_elapsed         | 895          |\n",
      "|    total_timesteps      | 2228224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032635308 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.55        |\n",
      "|    explained_variance   | 0.0149       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 15820        |\n",
      "|    policy_gradient_loss | -0.00731     |\n",
      "|    value_loss           | 2.48e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2240000, episode_reward=732.00 +/- 120.70\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 732          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2240000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029041765 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.551       |\n",
      "|    explained_variance   | 0.0156       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 15830        |\n",
      "|    policy_gradient_loss | -0.00686     |\n",
      "|    value_loss           | 2.47e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2477    |\n",
      "|    iterations      | 137     |\n",
      "|    time_elapsed    | 905     |\n",
      "|    total_timesteps | 2244608 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2480         |\n",
      "|    iterations           | 138          |\n",
      "|    time_elapsed         | 911          |\n",
      "|    total_timesteps      | 2260992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030110623 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.55        |\n",
      "|    explained_variance   | 0.06         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 15840        |\n",
      "|    policy_gradient_loss | -0.00667     |\n",
      "|    value_loss           | 2.47e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2483         |\n",
      "|    iterations           | 139          |\n",
      "|    time_elapsed         | 916          |\n",
      "|    total_timesteps      | 2277376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028923887 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.552       |\n",
      "|    explained_variance   | 0.00601      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 15850        |\n",
      "|    policy_gradient_loss | -0.00693     |\n",
      "|    value_loss           | 2.46e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2486         |\n",
      "|    iterations           | 140          |\n",
      "|    time_elapsed         | 922          |\n",
      "|    total_timesteps      | 2293760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030948543 |\n",
      "|    clip_fraction        | 0.021        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.056        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 15860        |\n",
      "|    policy_gradient_loss | -0.00747     |\n",
      "|    value_loss           | 2.4e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2490         |\n",
      "|    iterations           | 141          |\n",
      "|    time_elapsed         | 927          |\n",
      "|    total_timesteps      | 2310144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031696218 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.552       |\n",
      "|    explained_variance   | 0.0336       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 15870        |\n",
      "|    policy_gradient_loss | -0.00721     |\n",
      "|    value_loss           | 2.43e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2320000, episode_reward=719.20 +/- 112.25\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 719         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2320000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003455833 |\n",
      "|    clip_fraction        | 0.0221      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.56       |\n",
      "|    explained_variance   | 0.0329      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.25e+03    |\n",
      "|    n_updates            | 15880       |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    value_loss           | 2.5e+03     |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2480    |\n",
      "|    iterations      | 142     |\n",
      "|    time_elapsed    | 937     |\n",
      "|    total_timesteps | 2326528 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2484        |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 943         |\n",
      "|    total_timesteps      | 2342912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002747675 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.551      |\n",
      "|    explained_variance   | 0.0573      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.56e+03    |\n",
      "|    n_updates            | 15890       |\n",
      "|    policy_gradient_loss | -0.00685    |\n",
      "|    value_loss           | 2.67e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2486         |\n",
      "|    iterations           | 144          |\n",
      "|    time_elapsed         | 948          |\n",
      "|    total_timesteps      | 2359296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028181593 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.55        |\n",
      "|    explained_variance   | 0.0279       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.31e+03     |\n",
      "|    n_updates            | 15900        |\n",
      "|    policy_gradient_loss | -0.00674     |\n",
      "|    value_loss           | 2.47e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2489        |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 954         |\n",
      "|    total_timesteps      | 2375680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002982428 |\n",
      "|    clip_fraction        | 0.0196      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.572      |\n",
      "|    explained_variance   | 0.0609      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.22e+03    |\n",
      "|    n_updates            | 15910       |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    value_loss           | 2.32e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2492        |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 959         |\n",
      "|    total_timesteps      | 2392064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002951338 |\n",
      "|    clip_fraction        | 0.0191      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.556      |\n",
      "|    explained_variance   | 0.0266      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 862         |\n",
      "|    n_updates            | 15920       |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    value_loss           | 2.35e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2400000, episode_reward=671.60 +/- 82.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 672          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2400000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028997276 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.558       |\n",
      "|    explained_variance   | 0.0283       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 15930        |\n",
      "|    policy_gradient_loss | -0.00678     |\n",
      "|    value_loss           | 2.67e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2483    |\n",
      "|    iterations      | 147     |\n",
      "|    time_elapsed    | 969     |\n",
      "|    total_timesteps | 2408448 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2485         |\n",
      "|    iterations           | 148          |\n",
      "|    time_elapsed         | 975          |\n",
      "|    total_timesteps      | 2424832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026032687 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.0756       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 15940        |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    value_loss           | 2.53e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2488         |\n",
      "|    iterations           | 149          |\n",
      "|    time_elapsed         | 981          |\n",
      "|    total_timesteps      | 2441216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027030322 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.555       |\n",
      "|    explained_variance   | 0.0421       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 961          |\n",
      "|    n_updates            | 15950        |\n",
      "|    policy_gradient_loss | -0.00631     |\n",
      "|    value_loss           | 2.52e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2491         |\n",
      "|    iterations           | 150          |\n",
      "|    time_elapsed         | 986          |\n",
      "|    total_timesteps      | 2457600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031762593 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.565       |\n",
      "|    explained_variance   | 0.0388       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 15960        |\n",
      "|    policy_gradient_loss | -0.00712     |\n",
      "|    value_loss           | 2.31e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2494         |\n",
      "|    iterations           | 151          |\n",
      "|    time_elapsed         | 991          |\n",
      "|    total_timesteps      | 2473984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026492202 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.558       |\n",
      "|    explained_variance   | 0.0425       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 15970        |\n",
      "|    policy_gradient_loss | -0.00638     |\n",
      "|    value_loss           | 2.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2480000, episode_reward=703.60 +/- 107.10\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 200        |\n",
      "|    mean_reward          | 704        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2480000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00328787 |\n",
      "|    clip_fraction        | 0.0193     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.557     |\n",
      "|    explained_variance   | 0.0185     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.2e+03    |\n",
      "|    n_updates            | 15980      |\n",
      "|    policy_gradient_loss | -0.00729   |\n",
      "|    value_loss           | 2.25e+03   |\n",
      "----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2485    |\n",
      "|    iterations      | 152     |\n",
      "|    time_elapsed    | 1002    |\n",
      "|    total_timesteps | 2490368 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2488         |\n",
      "|    iterations           | 153          |\n",
      "|    time_elapsed         | 1007         |\n",
      "|    total_timesteps      | 2506752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032126145 |\n",
      "|    clip_fraction        | 0.023        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.558       |\n",
      "|    explained_variance   | 0.0517       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.45e+03     |\n",
      "|    n_updates            | 15990        |\n",
      "|    policy_gradient_loss | -0.00737     |\n",
      "|    value_loss           | 2.32e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2491        |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 1012        |\n",
      "|    total_timesteps      | 2523136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002866921 |\n",
      "|    clip_fraction        | 0.0192      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.553      |\n",
      "|    explained_variance   | 0.039       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 990         |\n",
      "|    n_updates            | 16000       |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    value_loss           | 2.36e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2494        |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 1017        |\n",
      "|    total_timesteps      | 2539520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003045511 |\n",
      "|    clip_fraction        | 0.0195      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.555      |\n",
      "|    explained_variance   | 0.0256      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.59e+03    |\n",
      "|    n_updates            | 16010       |\n",
      "|    policy_gradient_loss | -0.00735    |\n",
      "|    value_loss           | 2.6e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2498         |\n",
      "|    iterations           | 156          |\n",
      "|    time_elapsed         | 1023         |\n",
      "|    total_timesteps      | 2555904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031724772 |\n",
      "|    clip_fraction        | 0.0218       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.553       |\n",
      "|    explained_variance   | 0.0213       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.39e+03     |\n",
      "|    n_updates            | 16020        |\n",
      "|    policy_gradient_loss | -0.00735     |\n",
      "|    value_loss           | 2.64e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2560000, episode_reward=664.80 +/- 170.95\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 665          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027124921 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.553       |\n",
      "|    explained_variance   | 0.0514       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 16030        |\n",
      "|    policy_gradient_loss | -0.00693     |\n",
      "|    value_loss           | 2.53e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2489    |\n",
      "|    iterations      | 157     |\n",
      "|    time_elapsed    | 1033    |\n",
      "|    total_timesteps | 2572288 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2491        |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 1038        |\n",
      "|    total_timesteps      | 2588672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002626001 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.554      |\n",
      "|    explained_variance   | 0.0298      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.81e+03    |\n",
      "|    n_updates            | 16040       |\n",
      "|    policy_gradient_loss | -0.00708    |\n",
      "|    value_loss           | 2.52e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2494         |\n",
      "|    iterations           | 159          |\n",
      "|    time_elapsed         | 1044         |\n",
      "|    total_timesteps      | 2605056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030932808 |\n",
      "|    clip_fraction        | 0.0218       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.56        |\n",
      "|    explained_variance   | 0.0289       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 957          |\n",
      "|    n_updates            | 16050        |\n",
      "|    policy_gradient_loss | -0.00713     |\n",
      "|    value_loss           | 2.43e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2495         |\n",
      "|    iterations           | 160          |\n",
      "|    time_elapsed         | 1050         |\n",
      "|    total_timesteps      | 2621440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028346805 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.553       |\n",
      "|    explained_variance   | 0.0639       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 16060        |\n",
      "|    policy_gradient_loss | -0.00675     |\n",
      "|    value_loss           | 2.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2498         |\n",
      "|    iterations           | 161          |\n",
      "|    time_elapsed         | 1055         |\n",
      "|    total_timesteps      | 2637824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028988293 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.56        |\n",
      "|    explained_variance   | 0.0183       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 16070        |\n",
      "|    policy_gradient_loss | -0.00744     |\n",
      "|    value_loss           | 2.51e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2640000, episode_reward=710.00 +/- 100.24\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 710          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2640000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031567179 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.555       |\n",
      "|    explained_variance   | 0.0304       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 16080        |\n",
      "|    policy_gradient_loss | -0.00704     |\n",
      "|    value_loss           | 2.31e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2489    |\n",
      "|    iterations      | 162     |\n",
      "|    time_elapsed    | 1066    |\n",
      "|    total_timesteps | 2654208 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2491         |\n",
      "|    iterations           | 163          |\n",
      "|    time_elapsed         | 1071         |\n",
      "|    total_timesteps      | 2670592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029009432 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.562       |\n",
      "|    explained_variance   | 0.0638       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 783          |\n",
      "|    n_updates            | 16090        |\n",
      "|    policy_gradient_loss | -0.00681     |\n",
      "|    value_loss           | 2.31e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2493         |\n",
      "|    iterations           | 164          |\n",
      "|    time_elapsed         | 1077         |\n",
      "|    total_timesteps      | 2686976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031805222 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.559       |\n",
      "|    explained_variance   | 0.0305       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.29e+03     |\n",
      "|    n_updates            | 16100        |\n",
      "|    policy_gradient_loss | -0.00733     |\n",
      "|    value_loss           | 2.52e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2495         |\n",
      "|    iterations           | 165          |\n",
      "|    time_elapsed         | 1083         |\n",
      "|    total_timesteps      | 2703360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032029129 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.551       |\n",
      "|    explained_variance   | -0.00134     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 949          |\n",
      "|    n_updates            | 16110        |\n",
      "|    policy_gradient_loss | -0.0073      |\n",
      "|    value_loss           | 2.24e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2498        |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 1088        |\n",
      "|    total_timesteps      | 2719744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002899797 |\n",
      "|    clip_fraction        | 0.0191      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.558      |\n",
      "|    explained_variance   | 0.036       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 891         |\n",
      "|    n_updates            | 16120       |\n",
      "|    policy_gradient_loss | -0.00681    |\n",
      "|    value_loss           | 2.37e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2720000, episode_reward=698.40 +/- 112.17\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 698          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2720000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028249053 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.567       |\n",
      "|    explained_variance   | 0.0476       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.25e+03     |\n",
      "|    n_updates            | 16130        |\n",
      "|    policy_gradient_loss | -0.00691     |\n",
      "|    value_loss           | 2.34e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2489    |\n",
      "|    iterations      | 167     |\n",
      "|    time_elapsed    | 1099    |\n",
      "|    total_timesteps | 2736128 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2491        |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 1104        |\n",
      "|    total_timesteps      | 2752512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003206728 |\n",
      "|    clip_fraction        | 0.023       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.547      |\n",
      "|    explained_variance   | 0.0272      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.13e+03    |\n",
      "|    n_updates            | 16140       |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    value_loss           | 2.55e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2494         |\n",
      "|    iterations           | 169          |\n",
      "|    time_elapsed         | 1110         |\n",
      "|    total_timesteps      | 2768896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028231947 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.555       |\n",
      "|    explained_variance   | 0.0559       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.24e+03     |\n",
      "|    n_updates            | 16150        |\n",
      "|    policy_gradient_loss | -0.00682     |\n",
      "|    value_loss           | 2.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2496         |\n",
      "|    iterations           | 170          |\n",
      "|    time_elapsed         | 1115         |\n",
      "|    total_timesteps      | 2785280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029742084 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.562       |\n",
      "|    explained_variance   | 0.0363       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 933          |\n",
      "|    n_updates            | 16160        |\n",
      "|    policy_gradient_loss | -0.00746     |\n",
      "|    value_loss           | 2.23e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2800000, episode_reward=705.60 +/- 93.68\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 706          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2800000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024395774 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.561       |\n",
      "|    explained_variance   | 0.0612       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 968          |\n",
      "|    n_updates            | 16170        |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    value_loss           | 2.34e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2485    |\n",
      "|    iterations      | 171     |\n",
      "|    time_elapsed    | 1127    |\n",
      "|    total_timesteps | 2801664 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2487         |\n",
      "|    iterations           | 172          |\n",
      "|    time_elapsed         | 1132         |\n",
      "|    total_timesteps      | 2818048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027430754 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.55        |\n",
      "|    explained_variance   | 0.0428       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.45e+03     |\n",
      "|    n_updates            | 16180        |\n",
      "|    policy_gradient_loss | -0.00687     |\n",
      "|    value_loss           | 2.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2489         |\n",
      "|    iterations           | 173          |\n",
      "|    time_elapsed         | 1138         |\n",
      "|    total_timesteps      | 2834432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027583544 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.0188       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 16190        |\n",
      "|    policy_gradient_loss | -0.00697     |\n",
      "|    value_loss           | 2.35e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2490         |\n",
      "|    iterations           | 174          |\n",
      "|    time_elapsed         | 1144         |\n",
      "|    total_timesteps      | 2850816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028556362 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.563       |\n",
      "|    explained_variance   | 0.0517       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 16200        |\n",
      "|    policy_gradient_loss | -0.00705     |\n",
      "|    value_loss           | 2.4e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2492        |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 1150        |\n",
      "|    total_timesteps      | 2867200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003229206 |\n",
      "|    clip_fraction        | 0.021       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.571      |\n",
      "|    explained_variance   | 0.0072      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 943         |\n",
      "|    n_updates            | 16210       |\n",
      "|    policy_gradient_loss | -0.0074     |\n",
      "|    value_loss           | 2.15e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2880000, episode_reward=671.60 +/- 90.41\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 672         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2880000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002982646 |\n",
      "|    clip_fraction        | 0.0193      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.561      |\n",
      "|    explained_variance   | 0.0181      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 16220       |\n",
      "|    policy_gradient_loss | -0.00679    |\n",
      "|    value_loss           | 2.65e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2482    |\n",
      "|    iterations      | 176     |\n",
      "|    time_elapsed    | 1161    |\n",
      "|    total_timesteps | 2883584 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2484         |\n",
      "|    iterations           | 177          |\n",
      "|    time_elapsed         | 1167         |\n",
      "|    total_timesteps      | 2899968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031369233 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.559       |\n",
      "|    explained_variance   | 0.0245       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.32e+03     |\n",
      "|    n_updates            | 16230        |\n",
      "|    policy_gradient_loss | -0.00746     |\n",
      "|    value_loss           | 2.28e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2485        |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 1173        |\n",
      "|    total_timesteps      | 2916352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003046662 |\n",
      "|    clip_fraction        | 0.0187      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.552      |\n",
      "|    explained_variance   | 0.0649      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.56e+03    |\n",
      "|    n_updates            | 16240       |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    value_loss           | 2.41e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2488         |\n",
      "|    iterations           | 179          |\n",
      "|    time_elapsed         | 1178         |\n",
      "|    total_timesteps      | 2932736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029867198 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.571       |\n",
      "|    explained_variance   | 0.0802       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 16250        |\n",
      "|    policy_gradient_loss | -0.00688     |\n",
      "|    value_loss           | 2.3e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2490         |\n",
      "|    iterations           | 180          |\n",
      "|    time_elapsed         | 1184         |\n",
      "|    total_timesteps      | 2949120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034774127 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.564       |\n",
      "|    explained_variance   | 0.0451       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 16260        |\n",
      "|    policy_gradient_loss | -0.00726     |\n",
      "|    value_loss           | 2.52e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2960000, episode_reward=658.80 +/- 111.08\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 659         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2960000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002600181 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.557      |\n",
      "|    explained_variance   | 0.0242      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 787         |\n",
      "|    n_updates            | 16270       |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    value_loss           | 2.82e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2482    |\n",
      "|    iterations      | 181     |\n",
      "|    time_elapsed    | 1194    |\n",
      "|    total_timesteps | 2965504 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2484         |\n",
      "|    iterations           | 182          |\n",
      "|    time_elapsed         | 1200         |\n",
      "|    total_timesteps      | 2981888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030919504 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.563       |\n",
      "|    explained_variance   | 0.0289       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.36e+03     |\n",
      "|    n_updates            | 16280        |\n",
      "|    policy_gradient_loss | -0.00719     |\n",
      "|    value_loss           | 2.4e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2487         |\n",
      "|    iterations           | 183          |\n",
      "|    time_elapsed         | 1205         |\n",
      "|    total_timesteps      | 2998272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027914946 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.568       |\n",
      "|    explained_variance   | 0.0535       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.37e+03     |\n",
      "|    n_updates            | 16290        |\n",
      "|    policy_gradient_loss | -0.0068      |\n",
      "|    value_loss           | 2.5e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2489        |\n",
      "|    iterations           | 184         |\n",
      "|    time_elapsed         | 1210        |\n",
      "|    total_timesteps      | 3014656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002710085 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.557      |\n",
      "|    explained_variance   | 0.0122      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.48e+03    |\n",
      "|    n_updates            | 16300       |\n",
      "|    policy_gradient_loss | -0.00681    |\n",
      "|    value_loss           | 2.4e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2491         |\n",
      "|    iterations           | 185          |\n",
      "|    time_elapsed         | 1216         |\n",
      "|    total_timesteps      | 3031040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030337265 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.56        |\n",
      "|    explained_variance   | 0.0349       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.49e+03     |\n",
      "|    n_updates            | 16310        |\n",
      "|    policy_gradient_loss | -0.00693     |\n",
      "|    value_loss           | 2.6e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3040000, episode_reward=709.20 +/- 109.29\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 709          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3040000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031575023 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.565       |\n",
      "|    explained_variance   | 0.00581      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 16320        |\n",
      "|    policy_gradient_loss | -0.00732     |\n",
      "|    value_loss           | 2.42e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2484    |\n",
      "|    iterations      | 186     |\n",
      "|    time_elapsed    | 1226    |\n",
      "|    total_timesteps | 3047424 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2486        |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 1232        |\n",
      "|    total_timesteps      | 3063808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003295029 |\n",
      "|    clip_fraction        | 0.022       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.567      |\n",
      "|    explained_variance   | 0.0671      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 16330       |\n",
      "|    policy_gradient_loss | -0.00745    |\n",
      "|    value_loss           | 2.46e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2488         |\n",
      "|    iterations           | 188          |\n",
      "|    time_elapsed         | 1237         |\n",
      "|    total_timesteps      | 3080192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029551294 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.567       |\n",
      "|    explained_variance   | 0.0554       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.25e+03     |\n",
      "|    n_updates            | 16340        |\n",
      "|    policy_gradient_loss | -0.00728     |\n",
      "|    value_loss           | 2.45e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2490         |\n",
      "|    iterations           | 189          |\n",
      "|    time_elapsed         | 1243         |\n",
      "|    total_timesteps      | 3096576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027943212 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.567       |\n",
      "|    explained_variance   | 0.0536       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 16350        |\n",
      "|    policy_gradient_loss | -0.00648     |\n",
      "|    value_loss           | 2.53e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2492         |\n",
      "|    iterations           | 190          |\n",
      "|    time_elapsed         | 1248         |\n",
      "|    total_timesteps      | 3112960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030229092 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.581       |\n",
      "|    explained_variance   | 0.0268       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 944          |\n",
      "|    n_updates            | 16360        |\n",
      "|    policy_gradient_loss | -0.00689     |\n",
      "|    value_loss           | 2.52e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3120000, episode_reward=737.60 +/- 95.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 738         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3120000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002878509 |\n",
      "|    clip_fraction        | 0.0194      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.576      |\n",
      "|    explained_variance   | 0.0184      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.22e+03    |\n",
      "|    n_updates            | 16370       |\n",
      "|    policy_gradient_loss | -0.00747    |\n",
      "|    value_loss           | 2.4e+03     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2486    |\n",
      "|    iterations      | 191     |\n",
      "|    time_elapsed    | 1258    |\n",
      "|    total_timesteps | 3129344 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2488         |\n",
      "|    iterations           | 192          |\n",
      "|    time_elapsed         | 1264         |\n",
      "|    total_timesteps      | 3145728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024898665 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.0345       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.31e+03     |\n",
      "|    n_updates            | 16380        |\n",
      "|    policy_gradient_loss | -0.00633     |\n",
      "|    value_loss           | 2.3e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2491        |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 1269        |\n",
      "|    total_timesteps      | 3162112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002920302 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.554      |\n",
      "|    explained_variance   | 0.0684      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.12e+03    |\n",
      "|    n_updates            | 16390       |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    value_loss           | 2.62e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2492         |\n",
      "|    iterations           | 194          |\n",
      "|    time_elapsed         | 1274         |\n",
      "|    total_timesteps      | 3178496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032222485 |\n",
      "|    clip_fraction        | 0.0216       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.563       |\n",
      "|    explained_variance   | 0.0181       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 16400        |\n",
      "|    policy_gradient_loss | -0.00712     |\n",
      "|    value_loss           | 2.29e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2494         |\n",
      "|    iterations           | 195          |\n",
      "|    time_elapsed         | 1280         |\n",
      "|    total_timesteps      | 3194880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029086806 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.562       |\n",
      "|    explained_variance   | 0.0381       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 16410        |\n",
      "|    policy_gradient_loss | -0.00676     |\n",
      "|    value_loss           | 2.22e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3200000, episode_reward=684.00 +/- 88.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 684          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031072267 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.558       |\n",
      "|    explained_variance   | 0.0287       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 919          |\n",
      "|    n_updates            | 16420        |\n",
      "|    policy_gradient_loss | -0.00731     |\n",
      "|    value_loss           | 2.37e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2487    |\n",
      "|    iterations      | 196     |\n",
      "|    time_elapsed    | 1290    |\n",
      "|    total_timesteps | 3211264 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2490         |\n",
      "|    iterations           | 197          |\n",
      "|    time_elapsed         | 1296         |\n",
      "|    total_timesteps      | 3227648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028757397 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.557       |\n",
      "|    explained_variance   | 0.026        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 16430        |\n",
      "|    policy_gradient_loss | -0.00682     |\n",
      "|    value_loss           | 2.56e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2492         |\n",
      "|    iterations           | 198          |\n",
      "|    time_elapsed         | 1301         |\n",
      "|    total_timesteps      | 3244032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029964654 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.558       |\n",
      "|    explained_variance   | 0.0342       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 16440        |\n",
      "|    policy_gradient_loss | -0.00673     |\n",
      "|    value_loss           | 2.41e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2494         |\n",
      "|    iterations           | 199          |\n",
      "|    time_elapsed         | 1307         |\n",
      "|    total_timesteps      | 3260416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031996802 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.549       |\n",
      "|    explained_variance   | 0.0463       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 16450        |\n",
      "|    policy_gradient_loss | -0.00776     |\n",
      "|    value_loss           | 2.49e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2496         |\n",
      "|    iterations           | 200          |\n",
      "|    time_elapsed         | 1312         |\n",
      "|    total_timesteps      | 3276800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030097826 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.555       |\n",
      "|    explained_variance   | 0.0459       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 16460        |\n",
      "|    policy_gradient_loss | -0.0074      |\n",
      "|    value_loss           | 2.34e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3280000, episode_reward=683.20 +/- 114.57\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 683          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031212594 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.556       |\n",
      "|    explained_variance   | 0.00564      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 16470        |\n",
      "|    policy_gradient_loss | -0.00711     |\n",
      "|    value_loss           | 2.56e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2489    |\n",
      "|    iterations      | 201     |\n",
      "|    time_elapsed    | 1322    |\n",
      "|    total_timesteps | 3293184 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2491         |\n",
      "|    iterations           | 202          |\n",
      "|    time_elapsed         | 1328         |\n",
      "|    total_timesteps      | 3309568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031492398 |\n",
      "|    clip_fraction        | 0.0216       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.538       |\n",
      "|    explained_variance   | 0.0407       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 16480        |\n",
      "|    policy_gradient_loss | -0.00702     |\n",
      "|    value_loss           | 2.39e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2493         |\n",
      "|    iterations           | 203          |\n",
      "|    time_elapsed         | 1333         |\n",
      "|    total_timesteps      | 3325952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033718424 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.543       |\n",
      "|    explained_variance   | 0.0532       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.08e+03     |\n",
      "|    n_updates            | 16490        |\n",
      "|    policy_gradient_loss | -0.00726     |\n",
      "|    value_loss           | 2.43e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2495        |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 1339        |\n",
      "|    total_timesteps      | 3342336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003140284 |\n",
      "|    clip_fraction        | 0.0193      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.544      |\n",
      "|    explained_variance   | 0.0424      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.35e+03    |\n",
      "|    n_updates            | 16500       |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    value_loss           | 2.63e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2498        |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 1344        |\n",
      "|    total_timesteps      | 3358720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002968963 |\n",
      "|    clip_fraction        | 0.0208      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.547      |\n",
      "|    explained_variance   | 0.0317      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 912         |\n",
      "|    n_updates            | 16510       |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    value_loss           | 2.7e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3360000, episode_reward=718.00 +/- 134.85\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 200        |\n",
      "|    mean_reward          | 718        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3360000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00309586 |\n",
      "|    clip_fraction        | 0.0202     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.534     |\n",
      "|    explained_variance   | 0.0452     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.43e+03   |\n",
      "|    n_updates            | 16520      |\n",
      "|    policy_gradient_loss | -0.00713   |\n",
      "|    value_loss           | 2.51e+03   |\n",
      "----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2491    |\n",
      "|    iterations      | 206     |\n",
      "|    time_elapsed    | 1354    |\n",
      "|    total_timesteps | 3375104 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2493         |\n",
      "|    iterations           | 207          |\n",
      "|    time_elapsed         | 1359         |\n",
      "|    total_timesteps      | 3391488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028243365 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.532       |\n",
      "|    explained_variance   | 0.0533       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 995          |\n",
      "|    n_updates            | 16530        |\n",
      "|    policy_gradient_loss | -0.00663     |\n",
      "|    value_loss           | 2.34e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2496         |\n",
      "|    iterations           | 208          |\n",
      "|    time_elapsed         | 1365         |\n",
      "|    total_timesteps      | 3407872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027880233 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.536       |\n",
      "|    explained_variance   | 0.0372       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 16540        |\n",
      "|    policy_gradient_loss | -0.00704     |\n",
      "|    value_loss           | 2.45e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2498         |\n",
      "|    iterations           | 209          |\n",
      "|    time_elapsed         | 1370         |\n",
      "|    total_timesteps      | 3424256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024811882 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.535       |\n",
      "|    explained_variance   | 0.0367       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 16550        |\n",
      "|    policy_gradient_loss | -0.00604     |\n",
      "|    value_loss           | 2.51e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3440000, episode_reward=692.00 +/- 139.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 692         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002693187 |\n",
      "|    clip_fraction        | 0.016       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.538      |\n",
      "|    explained_variance   | 0.0474      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.33e+03    |\n",
      "|    n_updates            | 16560       |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    value_loss           | 2.81e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2491    |\n",
      "|    iterations      | 210     |\n",
      "|    time_elapsed    | 1380    |\n",
      "|    total_timesteps | 3440640 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2493         |\n",
      "|    iterations           | 211          |\n",
      "|    time_elapsed         | 1386         |\n",
      "|    total_timesteps      | 3457024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024215363 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.535       |\n",
      "|    explained_variance   | 0.0175       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 16570        |\n",
      "|    policy_gradient_loss | -0.00601     |\n",
      "|    value_loss           | 2.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2495         |\n",
      "|    iterations           | 212          |\n",
      "|    time_elapsed         | 1391         |\n",
      "|    total_timesteps      | 3473408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025898013 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.538       |\n",
      "|    explained_variance   | 0.0336       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.19e+03     |\n",
      "|    n_updates            | 16580        |\n",
      "|    policy_gradient_loss | -0.00627     |\n",
      "|    value_loss           | 2.6e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2498         |\n",
      "|    iterations           | 213          |\n",
      "|    time_elapsed         | 1397         |\n",
      "|    total_timesteps      | 3489792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031061368 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.525       |\n",
      "|    explained_variance   | 0.041        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.54e+03     |\n",
      "|    n_updates            | 16590        |\n",
      "|    policy_gradient_loss | -0.00708     |\n",
      "|    value_loss           | 2.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2500         |\n",
      "|    iterations           | 214          |\n",
      "|    time_elapsed         | 1402         |\n",
      "|    total_timesteps      | 3506176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030616731 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.526       |\n",
      "|    explained_variance   | 0.0651       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.77e+03     |\n",
      "|    n_updates            | 16600        |\n",
      "|    policy_gradient_loss | -0.00671     |\n",
      "|    value_loss           | 2.93e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3520000, episode_reward=694.80 +/- 88.10\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 695          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3520000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025772692 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | 0.0581       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.39e+03     |\n",
      "|    n_updates            | 16610        |\n",
      "|    policy_gradient_loss | -0.00688     |\n",
      "|    value_loss           | 2.6e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2493    |\n",
      "|    iterations      | 215     |\n",
      "|    time_elapsed    | 1412    |\n",
      "|    total_timesteps | 3522560 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2495         |\n",
      "|    iterations           | 216          |\n",
      "|    time_elapsed         | 1418         |\n",
      "|    total_timesteps      | 3538944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027676756 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.52        |\n",
      "|    explained_variance   | 0.062        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 16620        |\n",
      "|    policy_gradient_loss | -0.00658     |\n",
      "|    value_loss           | 2.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2496         |\n",
      "|    iterations           | 217          |\n",
      "|    time_elapsed         | 1423         |\n",
      "|    total_timesteps      | 3555328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030868994 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.0134       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.33e+03     |\n",
      "|    n_updates            | 16630        |\n",
      "|    policy_gradient_loss | -0.00789     |\n",
      "|    value_loss           | 2.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2498         |\n",
      "|    iterations           | 218          |\n",
      "|    time_elapsed         | 1429         |\n",
      "|    total_timesteps      | 3571712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026506116 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.538       |\n",
      "|    explained_variance   | 0.0573       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 16640        |\n",
      "|    policy_gradient_loss | -0.00646     |\n",
      "|    value_loss           | 2.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2500         |\n",
      "|    iterations           | 219          |\n",
      "|    time_elapsed         | 1434         |\n",
      "|    total_timesteps      | 3588096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027108411 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.529       |\n",
      "|    explained_variance   | 0.0354       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 16650        |\n",
      "|    policy_gradient_loss | -0.00662     |\n",
      "|    value_loss           | 2.37e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3600000, episode_reward=709.60 +/- 105.28\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 710          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3600000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025762531 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.524       |\n",
      "|    explained_variance   | 0.00374      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 16660        |\n",
      "|    policy_gradient_loss | -0.00667     |\n",
      "|    value_loss           | 2.44e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2494    |\n",
      "|    iterations      | 220     |\n",
      "|    time_elapsed    | 1444    |\n",
      "|    total_timesteps | 3604480 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2496        |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 1450        |\n",
      "|    total_timesteps      | 3620864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002456794 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.52       |\n",
      "|    explained_variance   | 0.0698      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.34e+03    |\n",
      "|    n_updates            | 16670       |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    value_loss           | 2.67e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2498        |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 1455        |\n",
      "|    total_timesteps      | 3637248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002890481 |\n",
      "|    clip_fraction        | 0.018       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.531      |\n",
      "|    explained_variance   | 0.0107      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 16680       |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    value_loss           | 2.89e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2500         |\n",
      "|    iterations           | 223          |\n",
      "|    time_elapsed         | 1461         |\n",
      "|    total_timesteps      | 3653632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027338457 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | 0.0364       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 887          |\n",
      "|    n_updates            | 16690        |\n",
      "|    policy_gradient_loss | -0.00667     |\n",
      "|    value_loss           | 2.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2502         |\n",
      "|    iterations           | 224          |\n",
      "|    time_elapsed         | 1466         |\n",
      "|    total_timesteps      | 3670016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029585683 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.519       |\n",
      "|    explained_variance   | 0.0717       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.36e+03     |\n",
      "|    n_updates            | 16700        |\n",
      "|    policy_gradient_loss | -0.00693     |\n",
      "|    value_loss           | 2.6e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3680000, episode_reward=718.80 +/- 104.66\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 719          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3680000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029464103 |\n",
      "|    clip_fraction        | 0.0216       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.519       |\n",
      "|    explained_variance   | 0.052        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.51e+03     |\n",
      "|    n_updates            | 16710        |\n",
      "|    policy_gradient_loss | -0.00657     |\n",
      "|    value_loss           | 2.54e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2495    |\n",
      "|    iterations      | 225     |\n",
      "|    time_elapsed    | 1477    |\n",
      "|    total_timesteps | 3686400 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2497        |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 1482        |\n",
      "|    total_timesteps      | 3702784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002988079 |\n",
      "|    clip_fraction        | 0.0197      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.531      |\n",
      "|    explained_variance   | 0.019       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.77e+03    |\n",
      "|    n_updates            | 16720       |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    value_loss           | 2.84e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2499         |\n",
      "|    iterations           | 227          |\n",
      "|    time_elapsed         | 1487         |\n",
      "|    total_timesteps      | 3719168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027203192 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | 0.0503       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 16730        |\n",
      "|    policy_gradient_loss | -0.00641     |\n",
      "|    value_loss           | 2.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2501         |\n",
      "|    iterations           | 228          |\n",
      "|    time_elapsed         | 1493         |\n",
      "|    total_timesteps      | 3735552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029561778 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.528       |\n",
      "|    explained_variance   | 0.0584       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.68e+03     |\n",
      "|    n_updates            | 16740        |\n",
      "|    policy_gradient_loss | -0.00678     |\n",
      "|    value_loss           | 2.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2502         |\n",
      "|    iterations           | 229          |\n",
      "|    time_elapsed         | 1499         |\n",
      "|    total_timesteps      | 3751936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031578236 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.526       |\n",
      "|    explained_variance   | 0.0399       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.43e+03     |\n",
      "|    n_updates            | 16750        |\n",
      "|    policy_gradient_loss | -0.00728     |\n",
      "|    value_loss           | 2.67e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3760000, episode_reward=764.00 +/- 114.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 764          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3760000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031753813 |\n",
      "|    clip_fraction        | 0.0248       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | -0.00179     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.69e+03     |\n",
      "|    n_updates            | 16760        |\n",
      "|    policy_gradient_loss | -0.00751     |\n",
      "|    value_loss           | 2.71e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2496    |\n",
      "|    iterations      | 230     |\n",
      "|    time_elapsed    | 1509    |\n",
      "|    total_timesteps | 3768320 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2498        |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 1515        |\n",
      "|    total_timesteps      | 3784704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003104554 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.532      |\n",
      "|    explained_variance   | 0.0335      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.23e+03    |\n",
      "|    n_updates            | 16770       |\n",
      "|    policy_gradient_loss | -0.00677    |\n",
      "|    value_loss           | 2.77e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2499         |\n",
      "|    iterations           | 232          |\n",
      "|    time_elapsed         | 1520         |\n",
      "|    total_timesteps      | 3801088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031844932 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.0216       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.4e+03      |\n",
      "|    n_updates            | 16780        |\n",
      "|    policy_gradient_loss | -0.00822     |\n",
      "|    value_loss           | 2.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2501         |\n",
      "|    iterations           | 233          |\n",
      "|    time_elapsed         | 1526         |\n",
      "|    total_timesteps      | 3817472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030732949 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.527       |\n",
      "|    explained_variance   | 0.0293       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 970          |\n",
      "|    n_updates            | 16790        |\n",
      "|    policy_gradient_loss | -0.00687     |\n",
      "|    value_loss           | 2.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2502         |\n",
      "|    iterations           | 234          |\n",
      "|    time_elapsed         | 1531         |\n",
      "|    total_timesteps      | 3833856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028072055 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.525       |\n",
      "|    explained_variance   | 0.0102       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 16800        |\n",
      "|    policy_gradient_loss | -0.00664     |\n",
      "|    value_loss           | 2.7e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3840000, episode_reward=714.00 +/- 108.74\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 714         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3840000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003398132 |\n",
      "|    clip_fraction        | 0.0247      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.529      |\n",
      "|    explained_variance   | 0.0376      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.35e+03    |\n",
      "|    n_updates            | 16810       |\n",
      "|    policy_gradient_loss | -0.00758    |\n",
      "|    value_loss           | 2.72e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2496    |\n",
      "|    iterations      | 235     |\n",
      "|    time_elapsed    | 1542    |\n",
      "|    total_timesteps | 3850240 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2498         |\n",
      "|    iterations           | 236          |\n",
      "|    time_elapsed         | 1547         |\n",
      "|    total_timesteps      | 3866624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027058064 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.527       |\n",
      "|    explained_variance   | 0.00999      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 968          |\n",
      "|    n_updates            | 16820        |\n",
      "|    policy_gradient_loss | -0.00691     |\n",
      "|    value_loss           | 2.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2500         |\n",
      "|    iterations           | 237          |\n",
      "|    time_elapsed         | 1552         |\n",
      "|    total_timesteps      | 3883008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030347966 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.533       |\n",
      "|    explained_variance   | 0.0732       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 16830        |\n",
      "|    policy_gradient_loss | -0.0068      |\n",
      "|    value_loss           | 2.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2502         |\n",
      "|    iterations           | 238          |\n",
      "|    time_elapsed         | 1558         |\n",
      "|    total_timesteps      | 3899392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032833167 |\n",
      "|    clip_fraction        | 0.021        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.538       |\n",
      "|    explained_variance   | 0.0269       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 16840        |\n",
      "|    policy_gradient_loss | -0.00731     |\n",
      "|    value_loss           | 2.55e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2504         |\n",
      "|    iterations           | 239          |\n",
      "|    time_elapsed         | 1563         |\n",
      "|    total_timesteps      | 3915776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028021964 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.532       |\n",
      "|    explained_variance   | 0.0454       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 16850        |\n",
      "|    policy_gradient_loss | -0.00647     |\n",
      "|    value_loss           | 2.82e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3920000, episode_reward=748.80 +/- 86.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 749          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3920000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029179926 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.527       |\n",
      "|    explained_variance   | 0.0339       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 16860        |\n",
      "|    policy_gradient_loss | -0.00634     |\n",
      "|    value_loss           | 2.75e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2498    |\n",
      "|    iterations      | 240     |\n",
      "|    time_elapsed    | 1573    |\n",
      "|    total_timesteps | 3932160 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2500         |\n",
      "|    iterations           | 241          |\n",
      "|    time_elapsed         | 1579         |\n",
      "|    total_timesteps      | 3948544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023671626 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.0563       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 16870        |\n",
      "|    policy_gradient_loss | -0.00616     |\n",
      "|    value_loss           | 2.82e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2501         |\n",
      "|    iterations           | 242          |\n",
      "|    time_elapsed         | 1585         |\n",
      "|    total_timesteps      | 3964928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023247213 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.0528       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 745          |\n",
      "|    n_updates            | 16880        |\n",
      "|    policy_gradient_loss | -0.00563     |\n",
      "|    value_loss           | 2.61e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2503        |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 1590        |\n",
      "|    total_timesteps      | 3981312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002694159 |\n",
      "|    clip_fraction        | 0.0192      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.524      |\n",
      "|    explained_variance   | 0.0155      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.23e+03    |\n",
      "|    n_updates            | 16890       |\n",
      "|    policy_gradient_loss | -0.00657    |\n",
      "|    value_loss           | 2.88e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2505        |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 1595        |\n",
      "|    total_timesteps      | 3997696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002835121 |\n",
      "|    clip_fraction        | 0.0158      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.513      |\n",
      "|    explained_variance   | 0.0267      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.28e+03    |\n",
      "|    n_updates            | 16900       |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    value_loss           | 2.62e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4000000, episode_reward=745.20 +/- 129.87\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 745          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031786354 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | 0.0437       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.69e+03     |\n",
      "|    n_updates            | 16910        |\n",
      "|    policy_gradient_loss | -0.0069      |\n",
      "|    value_loss           | 2.73e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2499    |\n",
      "|    iterations      | 245     |\n",
      "|    time_elapsed    | 1605    |\n",
      "|    total_timesteps | 4014080 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2501         |\n",
      "|    iterations           | 246          |\n",
      "|    time_elapsed         | 1611         |\n",
      "|    total_timesteps      | 4030464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031344928 |\n",
      "|    clip_fraction        | 0.0244       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.526       |\n",
      "|    explained_variance   | 0.0642       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.19e+03     |\n",
      "|    n_updates            | 16920        |\n",
      "|    policy_gradient_loss | -0.00779     |\n",
      "|    value_loss           | 2.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2502         |\n",
      "|    iterations           | 247          |\n",
      "|    time_elapsed         | 1616         |\n",
      "|    total_timesteps      | 4046848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026856218 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.531       |\n",
      "|    explained_variance   | 0.0389       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.56e+03     |\n",
      "|    n_updates            | 16930        |\n",
      "|    policy_gradient_loss | -0.00658     |\n",
      "|    value_loss           | 2.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2505         |\n",
      "|    iterations           | 248          |\n",
      "|    time_elapsed         | 1622         |\n",
      "|    total_timesteps      | 4063232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027074679 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.52        |\n",
      "|    explained_variance   | 0.0172       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 980          |\n",
      "|    n_updates            | 16940        |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    value_loss           | 2.43e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2506        |\n",
      "|    iterations           | 249         |\n",
      "|    time_elapsed         | 1627        |\n",
      "|    total_timesteps      | 4079616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002412431 |\n",
      "|    clip_fraction        | 0.0131      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.521      |\n",
      "|    explained_variance   | 0.054       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.34e+03    |\n",
      "|    n_updates            | 16950       |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    value_loss           | 2.69e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4080000, episode_reward=740.00 +/- 127.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 740          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4080000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031003251 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.528       |\n",
      "|    explained_variance   | 0.0386       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.66e+03     |\n",
      "|    n_updates            | 16960        |\n",
      "|    policy_gradient_loss | -0.00722     |\n",
      "|    value_loss           | 2.52e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2500    |\n",
      "|    iterations      | 250     |\n",
      "|    time_elapsed    | 1638    |\n",
      "|    total_timesteps | 4096000 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2501         |\n",
      "|    iterations           | 251          |\n",
      "|    time_elapsed         | 1643         |\n",
      "|    total_timesteps      | 4112384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029256057 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.526       |\n",
      "|    explained_variance   | 0.0404       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.73e+03     |\n",
      "|    n_updates            | 16970        |\n",
      "|    policy_gradient_loss | -0.00735     |\n",
      "|    value_loss           | 2.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2502         |\n",
      "|    iterations           | 252          |\n",
      "|    time_elapsed         | 1649         |\n",
      "|    total_timesteps      | 4128768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027945742 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.528       |\n",
      "|    explained_variance   | 0.0145       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.72e+03     |\n",
      "|    n_updates            | 16980        |\n",
      "|    policy_gradient_loss | -0.00671     |\n",
      "|    value_loss           | 2.63e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2504         |\n",
      "|    iterations           | 253          |\n",
      "|    time_elapsed         | 1655         |\n",
      "|    total_timesteps      | 4145152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027184032 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.0575       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 16990        |\n",
      "|    policy_gradient_loss | -0.0064      |\n",
      "|    value_loss           | 2.61e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4160000, episode_reward=723.60 +/- 61.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 724          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4160000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033373663 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.519       |\n",
      "|    explained_variance   | 0.0466       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 17000        |\n",
      "|    policy_gradient_loss | -0.00713     |\n",
      "|    value_loss           | 2.54e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2499    |\n",
      "|    iterations      | 254     |\n",
      "|    time_elapsed    | 1665    |\n",
      "|    total_timesteps | 4161536 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2500         |\n",
      "|    iterations           | 255          |\n",
      "|    time_elapsed         | 1670         |\n",
      "|    total_timesteps      | 4177920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029357276 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | -0.0102      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 17010        |\n",
      "|    policy_gradient_loss | -0.00674     |\n",
      "|    value_loss           | 2.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2502         |\n",
      "|    iterations           | 256          |\n",
      "|    time_elapsed         | 1675         |\n",
      "|    total_timesteps      | 4194304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027354802 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.529       |\n",
      "|    explained_variance   | 0.0298       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.21e+03     |\n",
      "|    n_updates            | 17020        |\n",
      "|    policy_gradient_loss | -0.00644     |\n",
      "|    value_loss           | 2.59e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2504         |\n",
      "|    iterations           | 257          |\n",
      "|    time_elapsed         | 1681         |\n",
      "|    total_timesteps      | 4210688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028809882 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.533       |\n",
      "|    explained_variance   | 0.0616       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 17030        |\n",
      "|    policy_gradient_loss | -0.0065      |\n",
      "|    value_loss           | 2.84e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2506        |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 1686        |\n",
      "|    total_timesteps      | 4227072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002929638 |\n",
      "|    clip_fraction        | 0.0173      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.529      |\n",
      "|    explained_variance   | 0.0475      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.35e+03    |\n",
      "|    n_updates            | 17040       |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    value_loss           | 2.55e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4240000, episode_reward=746.40 +/- 117.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 746         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4240000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002807535 |\n",
      "|    clip_fraction        | 0.0188      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.522      |\n",
      "|    explained_variance   | 0.0851      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.34e+03    |\n",
      "|    n_updates            | 17050       |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    value_loss           | 2.56e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2500    |\n",
      "|    iterations      | 259     |\n",
      "|    time_elapsed    | 1696    |\n",
      "|    total_timesteps | 4243456 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2502         |\n",
      "|    iterations           | 260          |\n",
      "|    time_elapsed         | 1702         |\n",
      "|    total_timesteps      | 4259840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025218616 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.0294       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.69e+03     |\n",
      "|    n_updates            | 17060        |\n",
      "|    policy_gradient_loss | -0.00666     |\n",
      "|    value_loss           | 2.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2504         |\n",
      "|    iterations           | 261          |\n",
      "|    time_elapsed         | 1707         |\n",
      "|    total_timesteps      | 4276224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022902181 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.529       |\n",
      "|    explained_variance   | 0.0568       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.82e+03     |\n",
      "|    n_updates            | 17070        |\n",
      "|    policy_gradient_loss | -0.00616     |\n",
      "|    value_loss           | 2.7e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2506        |\n",
      "|    iterations           | 262         |\n",
      "|    time_elapsed         | 1712        |\n",
      "|    total_timesteps      | 4292608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002784915 |\n",
      "|    clip_fraction        | 0.0178      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.516      |\n",
      "|    explained_variance   | 0.00345     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.46e+03    |\n",
      "|    n_updates            | 17080       |\n",
      "|    policy_gradient_loss | -0.00649    |\n",
      "|    value_loss           | 2.66e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2507         |\n",
      "|    iterations           | 263          |\n",
      "|    time_elapsed         | 1718         |\n",
      "|    total_timesteps      | 4308992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025877138 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.0436       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 792          |\n",
      "|    n_updates            | 17090        |\n",
      "|    policy_gradient_loss | -0.00668     |\n",
      "|    value_loss           | 2.66e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4320000, episode_reward=741.60 +/- 91.99\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 742          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4320000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022903052 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.523       |\n",
      "|    explained_variance   | 0.0441       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.65e+03     |\n",
      "|    n_updates            | 17100        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    value_loss           | 2.67e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2501    |\n",
      "|    iterations      | 264     |\n",
      "|    time_elapsed    | 1728    |\n",
      "|    total_timesteps | 4325376 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2503         |\n",
      "|    iterations           | 265          |\n",
      "|    time_elapsed         | 1734         |\n",
      "|    total_timesteps      | 4341760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023442921 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.516       |\n",
      "|    explained_variance   | 0.0543       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 17110        |\n",
      "|    policy_gradient_loss | -0.00572     |\n",
      "|    value_loss           | 2.57e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2504         |\n",
      "|    iterations           | 266          |\n",
      "|    time_elapsed         | 1739         |\n",
      "|    total_timesteps      | 4358144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029643048 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.0553       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 933          |\n",
      "|    n_updates            | 17120        |\n",
      "|    policy_gradient_loss | -0.00659     |\n",
      "|    value_loss           | 2.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2505         |\n",
      "|    iterations           | 267          |\n",
      "|    time_elapsed         | 1745         |\n",
      "|    total_timesteps      | 4374528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033232532 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.532       |\n",
      "|    explained_variance   | 0.00841      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.19e+03     |\n",
      "|    n_updates            | 17130        |\n",
      "|    policy_gradient_loss | -0.00785     |\n",
      "|    value_loss           | 2.61e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2507        |\n",
      "|    iterations           | 268         |\n",
      "|    time_elapsed         | 1751        |\n",
      "|    total_timesteps      | 4390912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002831721 |\n",
      "|    clip_fraction        | 0.0185      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.535      |\n",
      "|    explained_variance   | 0.0239      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 988         |\n",
      "|    n_updates            | 17140       |\n",
      "|    policy_gradient_loss | -0.00689    |\n",
      "|    value_loss           | 2.81e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4400000, episode_reward=719.60 +/- 108.35\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 720          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4400000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025149183 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.527       |\n",
      "|    explained_variance   | 0.0557       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.33e+03     |\n",
      "|    n_updates            | 17150        |\n",
      "|    policy_gradient_loss | -0.00659     |\n",
      "|    value_loss           | 2.51e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2502    |\n",
      "|    iterations      | 269     |\n",
      "|    time_elapsed    | 1761    |\n",
      "|    total_timesteps | 4407296 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2504         |\n",
      "|    iterations           | 270          |\n",
      "|    time_elapsed         | 1766         |\n",
      "|    total_timesteps      | 4423680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028224771 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.526       |\n",
      "|    explained_variance   | 0.0591       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 962          |\n",
      "|    n_updates            | 17160        |\n",
      "|    policy_gradient_loss | -0.00671     |\n",
      "|    value_loss           | 2.52e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2505         |\n",
      "|    iterations           | 271          |\n",
      "|    time_elapsed         | 1771         |\n",
      "|    total_timesteps      | 4440064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023366802 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.51        |\n",
      "|    explained_variance   | 0.065        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 17170        |\n",
      "|    policy_gradient_loss | -0.00554     |\n",
      "|    value_loss           | 2.52e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2507         |\n",
      "|    iterations           | 272          |\n",
      "|    time_elapsed         | 1777         |\n",
      "|    total_timesteps      | 4456448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022969171 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.0285       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.69e+03     |\n",
      "|    n_updates            | 17180        |\n",
      "|    policy_gradient_loss | -0.00548     |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2509         |\n",
      "|    iterations           | 273          |\n",
      "|    time_elapsed         | 1782         |\n",
      "|    total_timesteps      | 4472832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025575287 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.0642       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.29e+03     |\n",
      "|    n_updates            | 17190        |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    value_loss           | 2.64e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4480000, episode_reward=768.40 +/- 126.45\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 768         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4480000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002925083 |\n",
      "|    clip_fraction        | 0.0201      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.517      |\n",
      "|    explained_variance   | -0.00966    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 17200       |\n",
      "|    policy_gradient_loss | -0.00672    |\n",
      "|    value_loss           | 2.65e+03    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2503    |\n",
      "|    iterations      | 274     |\n",
      "|    time_elapsed    | 1793    |\n",
      "|    total_timesteps | 4489216 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2505         |\n",
      "|    iterations           | 275          |\n",
      "|    time_elapsed         | 1798         |\n",
      "|    total_timesteps      | 4505600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027549043 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0276       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 17210        |\n",
      "|    policy_gradient_loss | -0.00685     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2506        |\n",
      "|    iterations           | 276         |\n",
      "|    time_elapsed         | 1804        |\n",
      "|    total_timesteps      | 4521984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003021351 |\n",
      "|    clip_fraction        | 0.021       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.523      |\n",
      "|    explained_variance   | 0.0596      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 17220       |\n",
      "|    policy_gradient_loss | -0.0069     |\n",
      "|    value_loss           | 2.86e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2507         |\n",
      "|    iterations           | 277          |\n",
      "|    time_elapsed         | 1809         |\n",
      "|    total_timesteps      | 4538368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025703658 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.0377       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 17230        |\n",
      "|    policy_gradient_loss | -0.00616     |\n",
      "|    value_loss           | 2.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2509         |\n",
      "|    iterations           | 278          |\n",
      "|    time_elapsed         | 1815         |\n",
      "|    total_timesteps      | 4554752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024807672 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | 0.0122       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 17240        |\n",
      "|    policy_gradient_loss | -0.00581     |\n",
      "|    value_loss           | 2.52e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4560000, episode_reward=695.60 +/- 124.26\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 696          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026944524 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.0326       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 17250        |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    value_loss           | 2.57e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2504    |\n",
      "|    iterations      | 279     |\n",
      "|    time_elapsed    | 1825    |\n",
      "|    total_timesteps | 4571136 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2505         |\n",
      "|    iterations           | 280          |\n",
      "|    time_elapsed         | 1830         |\n",
      "|    total_timesteps      | 4587520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026057456 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.523       |\n",
      "|    explained_variance   | 0.0419       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.32e+03     |\n",
      "|    n_updates            | 17260        |\n",
      "|    policy_gradient_loss | -0.00608     |\n",
      "|    value_loss           | 2.68e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2506        |\n",
      "|    iterations           | 281         |\n",
      "|    time_elapsed         | 1836        |\n",
      "|    total_timesteps      | 4603904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002515926 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.52       |\n",
      "|    explained_variance   | 0.0439      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.47e+03    |\n",
      "|    n_updates            | 17270       |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    value_loss           | 2.84e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2508         |\n",
      "|    iterations           | 282          |\n",
      "|    time_elapsed         | 1842         |\n",
      "|    total_timesteps      | 4620288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023857907 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.0589       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 17280        |\n",
      "|    policy_gradient_loss | -0.00607     |\n",
      "|    value_loss           | 2.63e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2509         |\n",
      "|    iterations           | 283          |\n",
      "|    time_elapsed         | 1847         |\n",
      "|    total_timesteps      | 4636672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030188696 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.531       |\n",
      "|    explained_variance   | 0.0323       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 17290        |\n",
      "|    policy_gradient_loss | -0.00739     |\n",
      "|    value_loss           | 2.7e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4640000, episode_reward=748.80 +/- 107.16\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 749         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4640000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002892774 |\n",
      "|    clip_fraction        | 0.0193      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.515      |\n",
      "|    explained_variance   | 0.0264      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.66e+03    |\n",
      "|    n_updates            | 17300       |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    value_loss           | 2.79e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2504    |\n",
      "|    iterations      | 284     |\n",
      "|    time_elapsed    | 1858    |\n",
      "|    total_timesteps | 4653056 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2505        |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 1863        |\n",
      "|    total_timesteps      | 4669440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003004734 |\n",
      "|    clip_fraction        | 0.0196      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.52       |\n",
      "|    explained_variance   | 0.0475      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.47e+03    |\n",
      "|    n_updates            | 17310       |\n",
      "|    policy_gradient_loss | -0.00679    |\n",
      "|    value_loss           | 2.89e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2507        |\n",
      "|    iterations           | 286         |\n",
      "|    time_elapsed         | 1869        |\n",
      "|    total_timesteps      | 4685824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002489613 |\n",
      "|    clip_fraction        | 0.0163      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.0258      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.21e+03    |\n",
      "|    n_updates            | 17320       |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    value_loss           | 2.78e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2508         |\n",
      "|    iterations           | 287          |\n",
      "|    time_elapsed         | 1874         |\n",
      "|    total_timesteps      | 4702208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032559535 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.519       |\n",
      "|    explained_variance   | 0.0511       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.01e+03     |\n",
      "|    n_updates            | 17330        |\n",
      "|    policy_gradient_loss | -0.00702     |\n",
      "|    value_loss           | 2.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2509         |\n",
      "|    iterations           | 288          |\n",
      "|    time_elapsed         | 1880         |\n",
      "|    total_timesteps      | 4718592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027011372 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.0331       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.19e+03     |\n",
      "|    n_updates            | 17340        |\n",
      "|    policy_gradient_loss | -0.00644     |\n",
      "|    value_loss           | 2.65e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4720000, episode_reward=744.00 +/- 136.76\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 744          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4720000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025916295 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.51        |\n",
      "|    explained_variance   | 0.0527       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 17350        |\n",
      "|    policy_gradient_loss | -0.0056      |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2504    |\n",
      "|    iterations      | 289     |\n",
      "|    time_elapsed    | 1890    |\n",
      "|    total_timesteps | 4734976 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2506         |\n",
      "|    iterations           | 290          |\n",
      "|    time_elapsed         | 1895         |\n",
      "|    total_timesteps      | 4751360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026474465 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.0454       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 909          |\n",
      "|    n_updates            | 17360        |\n",
      "|    policy_gradient_loss | -0.00658     |\n",
      "|    value_loss           | 2.58e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2507         |\n",
      "|    iterations           | 291          |\n",
      "|    time_elapsed         | 1901         |\n",
      "|    total_timesteps      | 4767744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030449792 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.0196       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.47e+03     |\n",
      "|    n_updates            | 17370        |\n",
      "|    policy_gradient_loss | -0.00646     |\n",
      "|    value_loss           | 2.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2509         |\n",
      "|    iterations           | 292          |\n",
      "|    time_elapsed         | 1906         |\n",
      "|    total_timesteps      | 4784128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030891688 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.52        |\n",
      "|    explained_variance   | -0.000986    |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 17380        |\n",
      "|    policy_gradient_loss | -0.00709     |\n",
      "|    value_loss           | 2.85e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4800000, episode_reward=793.60 +/- 135.64\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 794          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4800000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026293239 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | 0.0378       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 17390        |\n",
      "|    policy_gradient_loss | -0.00597     |\n",
      "|    value_loss           | 3.11e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2504    |\n",
      "|    iterations      | 293     |\n",
      "|    time_elapsed    | 1916    |\n",
      "|    total_timesteps | 4800512 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2506         |\n",
      "|    iterations           | 294          |\n",
      "|    time_elapsed         | 1921         |\n",
      "|    total_timesteps      | 4816896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028329473 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.0217       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 17400        |\n",
      "|    policy_gradient_loss | -0.00662     |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2507         |\n",
      "|    iterations           | 295          |\n",
      "|    time_elapsed         | 1927         |\n",
      "|    total_timesteps      | 4833280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027774705 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | 0.038        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 17410        |\n",
      "|    policy_gradient_loss | -0.00603     |\n",
      "|    value_loss           | 2.91e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2508         |\n",
      "|    iterations           | 296          |\n",
      "|    time_elapsed         | 1933         |\n",
      "|    total_timesteps      | 4849664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026059556 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0562       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.83e+03     |\n",
      "|    n_updates            | 17420        |\n",
      "|    policy_gradient_loss | -0.00658     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2509         |\n",
      "|    iterations           | 297          |\n",
      "|    time_elapsed         | 1938         |\n",
      "|    total_timesteps      | 4866048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025701488 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0451       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.68e+03     |\n",
      "|    n_updates            | 17430        |\n",
      "|    policy_gradient_loss | -0.0064      |\n",
      "|    value_loss           | 2.99e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4880000, episode_reward=746.40 +/- 95.87\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 746         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4880000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002646369 |\n",
      "|    clip_fraction        | 0.0165      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.525      |\n",
      "|    explained_variance   | 0.0498      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.6e+03     |\n",
      "|    n_updates            | 17440       |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    value_loss           | 2.8e+03     |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2505    |\n",
      "|    iterations      | 298     |\n",
      "|    time_elapsed    | 1948    |\n",
      "|    total_timesteps | 4882432 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2506         |\n",
      "|    iterations           | 299          |\n",
      "|    time_elapsed         | 1954         |\n",
      "|    total_timesteps      | 4898816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025754939 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.0297       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 17450        |\n",
      "|    policy_gradient_loss | -0.00685     |\n",
      "|    value_loss           | 2.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2508         |\n",
      "|    iterations           | 300          |\n",
      "|    time_elapsed         | 1959         |\n",
      "|    total_timesteps      | 4915200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024702565 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.52        |\n",
      "|    explained_variance   | 0.0316       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 17460        |\n",
      "|    policy_gradient_loss | -0.00538     |\n",
      "|    value_loss           | 2.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2509         |\n",
      "|    iterations           | 301          |\n",
      "|    time_elapsed         | 1964         |\n",
      "|    total_timesteps      | 4931584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027282133 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.516       |\n",
      "|    explained_variance   | 0.0317       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 17470        |\n",
      "|    policy_gradient_loss | -0.00621     |\n",
      "|    value_loss           | 3.01e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2511         |\n",
      "|    iterations           | 302          |\n",
      "|    time_elapsed         | 1970         |\n",
      "|    total_timesteps      | 4947968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025471586 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.064        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.47e+03     |\n",
      "|    n_updates            | 17480        |\n",
      "|    policy_gradient_loss | -0.00624     |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4960000, episode_reward=785.20 +/- 76.48\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 785         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4960000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002663275 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.507      |\n",
      "|    explained_variance   | 0.0346      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 932         |\n",
      "|    n_updates            | 17490       |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    value_loss           | 2.67e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2506    |\n",
      "|    iterations      | 303     |\n",
      "|    time_elapsed    | 1980    |\n",
      "|    total_timesteps | 4964352 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2507         |\n",
      "|    iterations           | 304          |\n",
      "|    time_elapsed         | 1985         |\n",
      "|    total_timesteps      | 4980736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028942632 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0591       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 17500        |\n",
      "|    policy_gradient_loss | -0.00658     |\n",
      "|    value_loss           | 2.79e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2509        |\n",
      "|    iterations           | 305         |\n",
      "|    time_elapsed         | 1991        |\n",
      "|    total_timesteps      | 4997120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002949711 |\n",
      "|    clip_fraction        | 0.0196      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.516      |\n",
      "|    explained_variance   | 0.0742      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.25e+03    |\n",
      "|    n_updates            | 17510       |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    value_loss           | 2.75e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2510         |\n",
      "|    iterations           | 306          |\n",
      "|    time_elapsed         | 1997         |\n",
      "|    total_timesteps      | 5013504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027233646 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.018        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 17520        |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2511        |\n",
      "|    iterations           | 307         |\n",
      "|    time_elapsed         | 2002        |\n",
      "|    total_timesteps      | 5029888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002346619 |\n",
      "|    clip_fraction        | 0.0123      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.505      |\n",
      "|    explained_variance   | 0.093       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.63e+03    |\n",
      "|    n_updates            | 17530       |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    value_loss           | 2.78e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5040000, episode_reward=752.00 +/- 112.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 752          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5040000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024811425 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.0884       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 17540        |\n",
      "|    policy_gradient_loss | -0.00631     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2506    |\n",
      "|    iterations      | 308     |\n",
      "|    time_elapsed    | 2013    |\n",
      "|    total_timesteps | 5046272 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2508         |\n",
      "|    iterations           | 309          |\n",
      "|    time_elapsed         | 2018         |\n",
      "|    total_timesteps      | 5062656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027916469 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0999       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 17550        |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    value_loss           | 2.52e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2509         |\n",
      "|    iterations           | 310          |\n",
      "|    time_elapsed         | 2024         |\n",
      "|    total_timesteps      | 5079040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030365193 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | 0.0145       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.62e+03     |\n",
      "|    n_updates            | 17560        |\n",
      "|    policy_gradient_loss | -0.00691     |\n",
      "|    value_loss           | 2.98e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2510         |\n",
      "|    iterations           | 311          |\n",
      "|    time_elapsed         | 2029         |\n",
      "|    total_timesteps      | 5095424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026917423 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.51        |\n",
      "|    explained_variance   | 0.0585       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 17570        |\n",
      "|    policy_gradient_loss | -0.00641     |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2511         |\n",
      "|    iterations           | 312          |\n",
      "|    time_elapsed         | 2035         |\n",
      "|    total_timesteps      | 5111808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028709748 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0678       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 17580        |\n",
      "|    policy_gradient_loss | -0.00658     |\n",
      "|    value_loss           | 2.83e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5120000, episode_reward=753.60 +/- 100.71\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 754          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024987299 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.51        |\n",
      "|    explained_variance   | 0.0178       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.19e+03     |\n",
      "|    n_updates            | 17590        |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    value_loss           | 2.74e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2507    |\n",
      "|    iterations      | 313     |\n",
      "|    time_elapsed    | 2045    |\n",
      "|    total_timesteps | 5128192 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2508         |\n",
      "|    iterations           | 314          |\n",
      "|    time_elapsed         | 2050         |\n",
      "|    total_timesteps      | 5144576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024222261 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.0161       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 950          |\n",
      "|    n_updates            | 17600        |\n",
      "|    policy_gradient_loss | -0.00677     |\n",
      "|    value_loss           | 2.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2509         |\n",
      "|    iterations           | 315          |\n",
      "|    time_elapsed         | 2056         |\n",
      "|    total_timesteps      | 5160960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027456456 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.51        |\n",
      "|    explained_variance   | 0.0399       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 17610        |\n",
      "|    policy_gradient_loss | -0.00677     |\n",
      "|    value_loss           | 2.77e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2511       |\n",
      "|    iterations           | 316        |\n",
      "|    time_elapsed         | 2061       |\n",
      "|    total_timesteps      | 5177344    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00267237 |\n",
      "|    clip_fraction        | 0.0173     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.512     |\n",
      "|    explained_variance   | 0.0365     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.07e+03   |\n",
      "|    n_updates            | 17620      |\n",
      "|    policy_gradient_loss | -0.00619   |\n",
      "|    value_loss           | 2.78e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2512         |\n",
      "|    iterations           | 317          |\n",
      "|    time_elapsed         | 2067         |\n",
      "|    total_timesteps      | 5193728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026795669 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0797       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 17630        |\n",
      "|    policy_gradient_loss | -0.00656     |\n",
      "|    value_loss           | 2.92e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5200000, episode_reward=741.20 +/- 97.83\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 741          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023213993 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.0462       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.4e+03      |\n",
      "|    n_updates            | 17640        |\n",
      "|    policy_gradient_loss | -0.00585     |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2508    |\n",
      "|    iterations      | 318     |\n",
      "|    time_elapsed    | 2077    |\n",
      "|    total_timesteps | 5210112 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2509        |\n",
      "|    iterations           | 319         |\n",
      "|    time_elapsed         | 2082        |\n",
      "|    total_timesteps      | 5226496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002400463 |\n",
      "|    clip_fraction        | 0.0137      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.491      |\n",
      "|    explained_variance   | 0.0448      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.28e+03    |\n",
      "|    n_updates            | 17650       |\n",
      "|    policy_gradient_loss | -0.00583    |\n",
      "|    value_loss           | 2.93e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2510         |\n",
      "|    iterations           | 320          |\n",
      "|    time_elapsed         | 2088         |\n",
      "|    total_timesteps      | 5242880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026994771 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0531       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 17660        |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2512         |\n",
      "|    iterations           | 321          |\n",
      "|    time_elapsed         | 2093         |\n",
      "|    total_timesteps      | 5259264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025629767 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0565       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 772          |\n",
      "|    n_updates            | 17670        |\n",
      "|    policy_gradient_loss | -0.00597     |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2513         |\n",
      "|    iterations           | 322          |\n",
      "|    time_elapsed         | 2099         |\n",
      "|    total_timesteps      | 5275648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026312042 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.0338       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.32e+03     |\n",
      "|    n_updates            | 17680        |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    value_loss           | 3.03e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5280000, episode_reward=750.80 +/- 106.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 751          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027485392 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.0453       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.43e+03     |\n",
      "|    n_updates            | 17690        |\n",
      "|    policy_gradient_loss | -0.00607     |\n",
      "|    value_loss           | 2.79e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2508    |\n",
      "|    iterations      | 323     |\n",
      "|    time_elapsed    | 2109    |\n",
      "|    total_timesteps | 5292032 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2509         |\n",
      "|    iterations           | 324          |\n",
      "|    time_elapsed         | 2115         |\n",
      "|    total_timesteps      | 5308416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027141813 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0256       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 17700        |\n",
      "|    policy_gradient_loss | -0.00638     |\n",
      "|    value_loss           | 2.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2510         |\n",
      "|    iterations           | 325          |\n",
      "|    time_elapsed         | 2120         |\n",
      "|    total_timesteps      | 5324800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027726996 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0168       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.72e+03     |\n",
      "|    n_updates            | 17710        |\n",
      "|    policy_gradient_loss | -0.00662     |\n",
      "|    value_loss           | 2.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2512         |\n",
      "|    iterations           | 326          |\n",
      "|    time_elapsed         | 2126         |\n",
      "|    total_timesteps      | 5341184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027229618 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.0171       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.18e+03     |\n",
      "|    n_updates            | 17720        |\n",
      "|    policy_gradient_loss | -0.00668     |\n",
      "|    value_loss           | 2.82e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2513         |\n",
      "|    iterations           | 327          |\n",
      "|    time_elapsed         | 2131         |\n",
      "|    total_timesteps      | 5357568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023711254 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.0164       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 17730        |\n",
      "|    policy_gradient_loss | -0.00651     |\n",
      "|    value_loss           | 2.77e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5360000, episode_reward=739.60 +/- 99.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 740          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5360000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024599712 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.0101       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 17740        |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2508    |\n",
      "|    iterations      | 328     |\n",
      "|    time_elapsed    | 2141    |\n",
      "|    total_timesteps | 5373952 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2510        |\n",
      "|    iterations           | 329         |\n",
      "|    time_elapsed         | 2147        |\n",
      "|    total_timesteps      | 5390336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002991787 |\n",
      "|    clip_fraction        | 0.0203      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.496      |\n",
      "|    explained_variance   | 0.0369      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.41e+03    |\n",
      "|    n_updates            | 17750       |\n",
      "|    policy_gradient_loss | -0.00713    |\n",
      "|    value_loss           | 2.82e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2511         |\n",
      "|    iterations           | 330          |\n",
      "|    time_elapsed         | 2152         |\n",
      "|    total_timesteps      | 5406720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026973938 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.0562       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 17760        |\n",
      "|    policy_gradient_loss | -0.00687     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2512         |\n",
      "|    iterations           | 331          |\n",
      "|    time_elapsed         | 2158         |\n",
      "|    total_timesteps      | 5423104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019048925 |\n",
      "|    clip_fraction        | 0.01         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.0421       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.45e+03     |\n",
      "|    n_updates            | 17770        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2514         |\n",
      "|    iterations           | 332          |\n",
      "|    time_elapsed         | 2163         |\n",
      "|    total_timesteps      | 5439488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026544118 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.0284       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.45e+03     |\n",
      "|    n_updates            | 17780        |\n",
      "|    policy_gradient_loss | -0.00599     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5440000, episode_reward=736.00 +/- 133.99\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 736          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5440000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020983513 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.0705       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 17790        |\n",
      "|    policy_gradient_loss | -0.00586     |\n",
      "|    value_loss           | 2.73e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2510    |\n",
      "|    iterations      | 333     |\n",
      "|    time_elapsed    | 2173    |\n",
      "|    total_timesteps | 5455872 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2511         |\n",
      "|    iterations           | 334          |\n",
      "|    time_elapsed         | 2179         |\n",
      "|    total_timesteps      | 5472256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023401333 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.0376       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 17800        |\n",
      "|    policy_gradient_loss | -0.00631     |\n",
      "|    value_loss           | 2.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2512         |\n",
      "|    iterations           | 335          |\n",
      "|    time_elapsed         | 2184         |\n",
      "|    total_timesteps      | 5488640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023726346 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.0371       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.81e+03     |\n",
      "|    n_updates            | 17810        |\n",
      "|    policy_gradient_loss | -0.00558     |\n",
      "|    value_loss           | 2.92e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2513        |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 2190        |\n",
      "|    total_timesteps      | 5505024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002658897 |\n",
      "|    clip_fraction        | 0.0184      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.5        |\n",
      "|    explained_variance   | 0.056       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.47e+03    |\n",
      "|    n_updates            | 17820       |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    value_loss           | 2.73e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5520000, episode_reward=744.00 +/- 108.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 744          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5520000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027827006 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.071        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.69e+03     |\n",
      "|    n_updates            | 17830        |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    value_loss           | 2.92e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2509    |\n",
      "|    iterations      | 337     |\n",
      "|    time_elapsed    | 2200    |\n",
      "|    total_timesteps | 5521408 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2510         |\n",
      "|    iterations           | 338          |\n",
      "|    time_elapsed         | 2205         |\n",
      "|    total_timesteps      | 5537792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028145777 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.0438       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 17840        |\n",
      "|    policy_gradient_loss | -0.00667     |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2512         |\n",
      "|    iterations           | 339          |\n",
      "|    time_elapsed         | 2210         |\n",
      "|    total_timesteps      | 5554176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021734205 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.0685       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 17850        |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    value_loss           | 3.01e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2513         |\n",
      "|    iterations           | 340          |\n",
      "|    time_elapsed         | 2216         |\n",
      "|    total_timesteps      | 5570560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028107422 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0513       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.67e+03     |\n",
      "|    n_updates            | 17860        |\n",
      "|    policy_gradient_loss | -0.00678     |\n",
      "|    value_loss           | 2.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2514         |\n",
      "|    iterations           | 341          |\n",
      "|    time_elapsed         | 2222         |\n",
      "|    total_timesteps      | 5586944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029015117 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.0807       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 17870        |\n",
      "|    policy_gradient_loss | -0.0071      |\n",
      "|    value_loss           | 2.75e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5600000, episode_reward=751.20 +/- 89.99\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 751          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5600000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024064193 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.0585       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.88e+03     |\n",
      "|    n_updates            | 17880        |\n",
      "|    policy_gradient_loss | -0.00617     |\n",
      "|    value_loss           | 2.71e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2509    |\n",
      "|    iterations      | 342     |\n",
      "|    time_elapsed    | 2232    |\n",
      "|    total_timesteps | 5603328 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2510         |\n",
      "|    iterations           | 343          |\n",
      "|    time_elapsed         | 2238         |\n",
      "|    total_timesteps      | 5619712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022382173 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0368       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 17890        |\n",
      "|    policy_gradient_loss | -0.00626     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2512        |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 2243        |\n",
      "|    total_timesteps      | 5636096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002920637 |\n",
      "|    clip_fraction        | 0.0187      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.507      |\n",
      "|    explained_variance   | 0.0369      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 17900       |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    value_loss           | 3.02e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2513         |\n",
      "|    iterations           | 345          |\n",
      "|    time_elapsed         | 2248         |\n",
      "|    total_timesteps      | 5652480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028415746 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0284       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.56e+03     |\n",
      "|    n_updates            | 17910        |\n",
      "|    policy_gradient_loss | -0.00639     |\n",
      "|    value_loss           | 2.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2514         |\n",
      "|    iterations           | 346          |\n",
      "|    time_elapsed         | 2254         |\n",
      "|    total_timesteps      | 5668864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024287351 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.0384       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 17920        |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    value_loss           | 2.89e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5680000, episode_reward=714.80 +/- 88.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 715         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5680000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002715166 |\n",
      "|    clip_fraction        | 0.018       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.512      |\n",
      "|    explained_variance   | 0.0122      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.25e+03    |\n",
      "|    n_updates            | 17930       |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    value_loss           | 2.96e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2510    |\n",
      "|    iterations      | 347     |\n",
      "|    time_elapsed    | 2264    |\n",
      "|    total_timesteps | 5685248 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2511         |\n",
      "|    iterations           | 348          |\n",
      "|    time_elapsed         | 2270         |\n",
      "|    total_timesteps      | 5701632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027919575 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.0545       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.37e+03     |\n",
      "|    n_updates            | 17940        |\n",
      "|    policy_gradient_loss | -0.0069      |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2512         |\n",
      "|    iterations           | 349          |\n",
      "|    time_elapsed         | 2275         |\n",
      "|    total_timesteps      | 5718016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028394465 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.0156       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.73e+03     |\n",
      "|    n_updates            | 17950        |\n",
      "|    policy_gradient_loss | -0.00663     |\n",
      "|    value_loss           | 2.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2514         |\n",
      "|    iterations           | 350          |\n",
      "|    time_elapsed         | 2280         |\n",
      "|    total_timesteps      | 5734400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026547988 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0216       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 17960        |\n",
      "|    policy_gradient_loss | -0.00674     |\n",
      "|    value_loss           | 2.89e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2515        |\n",
      "|    iterations           | 351         |\n",
      "|    time_elapsed         | 2286        |\n",
      "|    total_timesteps      | 5750784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002559599 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.514      |\n",
      "|    explained_variance   | 0.0365      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.09e+03    |\n",
      "|    n_updates            | 17970       |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    value_loss           | 3.02e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5760000, episode_reward=774.80 +/- 81.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 775          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5760000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031893244 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0398       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 17980        |\n",
      "|    policy_gradient_loss | -0.00677     |\n",
      "|    value_loss           | 2.76e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2510    |\n",
      "|    iterations      | 352     |\n",
      "|    time_elapsed    | 2296    |\n",
      "|    total_timesteps | 5767168 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2511        |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 2302        |\n",
      "|    total_timesteps      | 5783552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002869392 |\n",
      "|    clip_fraction        | 0.0181      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.503      |\n",
      "|    explained_variance   | 0.0462      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.75e+03    |\n",
      "|    n_updates            | 17990       |\n",
      "|    policy_gradient_loss | -0.00664    |\n",
      "|    value_loss           | 2.94e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2513        |\n",
      "|    iterations           | 354         |\n",
      "|    time_elapsed         | 2307        |\n",
      "|    total_timesteps      | 5799936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002899137 |\n",
      "|    clip_fraction        | 0.019       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.504      |\n",
      "|    explained_variance   | 0.0103      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 18000       |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    value_loss           | 2.79e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2514         |\n",
      "|    iterations           | 355          |\n",
      "|    time_elapsed         | 2313         |\n",
      "|    total_timesteps      | 5816320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026912305 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0293       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 18010        |\n",
      "|    policy_gradient_loss | -0.0065      |\n",
      "|    value_loss           | 2.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2515         |\n",
      "|    iterations           | 356          |\n",
      "|    time_elapsed         | 2318         |\n",
      "|    total_timesteps      | 5832704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026519112 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0289       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 18020        |\n",
      "|    policy_gradient_loss | -0.00619     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5840000, episode_reward=751.60 +/- 82.74\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 752          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5840000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024468591 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0477       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 18030        |\n",
      "|    policy_gradient_loss | -0.00563     |\n",
      "|    value_loss           | 2.85e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2511    |\n",
      "|    iterations      | 357     |\n",
      "|    time_elapsed    | 2328    |\n",
      "|    total_timesteps | 5849088 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2512         |\n",
      "|    iterations           | 358          |\n",
      "|    time_elapsed         | 2334         |\n",
      "|    total_timesteps      | 5865472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023390776 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.523       |\n",
      "|    explained_variance   | 0.0324       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.46e+03     |\n",
      "|    n_updates            | 18040        |\n",
      "|    policy_gradient_loss | -0.00607     |\n",
      "|    value_loss           | 2.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2513         |\n",
      "|    iterations           | 359          |\n",
      "|    time_elapsed         | 2339         |\n",
      "|    total_timesteps      | 5881856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024208422 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.072        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 18050        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    value_loss           | 2.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2514         |\n",
      "|    iterations           | 360          |\n",
      "|    time_elapsed         | 2345         |\n",
      "|    total_timesteps      | 5898240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027793783 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.00978      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.68e+03     |\n",
      "|    n_updates            | 18060        |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2516         |\n",
      "|    iterations           | 361          |\n",
      "|    time_elapsed         | 2350         |\n",
      "|    total_timesteps      | 5914624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027684022 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.0206       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 18070        |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    value_loss           | 2.7e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=5920000, episode_reward=776.80 +/- 95.24\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 777         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5920000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002239882 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.51       |\n",
      "|    explained_variance   | 0.0381      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.6e+03     |\n",
      "|    n_updates            | 18080       |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    value_loss           | 2.8e+03     |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2512    |\n",
      "|    iterations      | 362     |\n",
      "|    time_elapsed    | 2360    |\n",
      "|    total_timesteps | 5931008 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2513         |\n",
      "|    iterations           | 363          |\n",
      "|    time_elapsed         | 2366         |\n",
      "|    total_timesteps      | 5947392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034006191 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.0197       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 18090        |\n",
      "|    policy_gradient_loss | -0.00714     |\n",
      "|    value_loss           | 2.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2514         |\n",
      "|    iterations           | 364          |\n",
      "|    time_elapsed         | 2371         |\n",
      "|    total_timesteps      | 5963776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026612435 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.525       |\n",
      "|    explained_variance   | 0.0448       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 18100        |\n",
      "|    policy_gradient_loss | -0.00624     |\n",
      "|    value_loss           | 2.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2515         |\n",
      "|    iterations           | 365          |\n",
      "|    time_elapsed         | 2377         |\n",
      "|    total_timesteps      | 5980160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029216523 |\n",
      "|    clip_fraction        | 0.0211       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.0337       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.55e+03     |\n",
      "|    n_updates            | 18110        |\n",
      "|    policy_gradient_loss | -0.00638     |\n",
      "|    value_loss           | 2.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2516         |\n",
      "|    iterations           | 366          |\n",
      "|    time_elapsed         | 2382         |\n",
      "|    total_timesteps      | 5996544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025031392 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.0535       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.24e+03     |\n",
      "|    n_updates            | 18120        |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    value_loss           | 2.79e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6000000, episode_reward=720.40 +/- 81.71\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 720          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023094409 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.0881       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.51e+03     |\n",
      "|    n_updates            | 18130        |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2512    |\n",
      "|    iterations      | 367     |\n",
      "|    time_elapsed    | 2393    |\n",
      "|    total_timesteps | 6012928 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2513         |\n",
      "|    iterations           | 368          |\n",
      "|    time_elapsed         | 2398         |\n",
      "|    total_timesteps      | 6029312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025916193 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0543       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 18140        |\n",
      "|    policy_gradient_loss | -0.00617     |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2514        |\n",
      "|    iterations           | 369         |\n",
      "|    time_elapsed         | 2404        |\n",
      "|    total_timesteps      | 6045696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002303623 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.517      |\n",
      "|    explained_variance   | 0.0402      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.02e+03    |\n",
      "|    n_updates            | 18150       |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    value_loss           | 3e+03       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2515         |\n",
      "|    iterations           | 370          |\n",
      "|    time_elapsed         | 2409         |\n",
      "|    total_timesteps      | 6062080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029298896 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.0022       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 18160        |\n",
      "|    policy_gradient_loss | -0.00695     |\n",
      "|    value_loss           | 2.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2516         |\n",
      "|    iterations           | 371          |\n",
      "|    time_elapsed         | 2414         |\n",
      "|    total_timesteps      | 6078464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024409108 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.00482      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 18170        |\n",
      "|    policy_gradient_loss | -0.0056      |\n",
      "|    value_loss           | 2.82e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6080000, episode_reward=726.00 +/- 96.91\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 726          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6080000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028528934 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.0484       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.66e+03     |\n",
      "|    n_updates            | 18180        |\n",
      "|    policy_gradient_loss | -0.00647     |\n",
      "|    value_loss           | 3.07e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2512    |\n",
      "|    iterations      | 372     |\n",
      "|    time_elapsed    | 2425    |\n",
      "|    total_timesteps | 6094848 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2513         |\n",
      "|    iterations           | 373          |\n",
      "|    time_elapsed         | 2431         |\n",
      "|    total_timesteps      | 6111232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024477514 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.52        |\n",
      "|    explained_variance   | 0.0302       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 18190        |\n",
      "|    policy_gradient_loss | -0.00671     |\n",
      "|    value_loss           | 2.67e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2514         |\n",
      "|    iterations           | 374          |\n",
      "|    time_elapsed         | 2436         |\n",
      "|    total_timesteps      | 6127616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024657804 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0473       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.31e+03     |\n",
      "|    n_updates            | 18200        |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2515         |\n",
      "|    iterations           | 375          |\n",
      "|    time_elapsed         | 2442         |\n",
      "|    total_timesteps      | 6144000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028388523 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.0317       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.23e+03     |\n",
      "|    n_updates            | 18210        |\n",
      "|    policy_gradient_loss | -0.00666     |\n",
      "|    value_loss           | 2.74e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6160000, episode_reward=724.00 +/- 78.38\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 724          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6160000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032460527 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.0334       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 18220        |\n",
      "|    policy_gradient_loss | -0.00734     |\n",
      "|    value_loss           | 2.89e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2511    |\n",
      "|    iterations      | 376     |\n",
      "|    time_elapsed    | 2452    |\n",
      "|    total_timesteps | 6160384 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2513         |\n",
      "|    iterations           | 377          |\n",
      "|    time_elapsed         | 2457         |\n",
      "|    total_timesteps      | 6176768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027425895 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.0465       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.78e+03     |\n",
      "|    n_updates            | 18230        |\n",
      "|    policy_gradient_loss | -0.00647     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2514        |\n",
      "|    iterations           | 378         |\n",
      "|    time_elapsed         | 2463        |\n",
      "|    total_timesteps      | 6193152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002529949 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.509      |\n",
      "|    explained_variance   | -0.0149     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.35e+03    |\n",
      "|    n_updates            | 18240       |\n",
      "|    policy_gradient_loss | -0.00582    |\n",
      "|    value_loss           | 2.66e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2515         |\n",
      "|    iterations           | 379          |\n",
      "|    time_elapsed         | 2468         |\n",
      "|    total_timesteps      | 6209536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027672872 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.0403       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.69e+03     |\n",
      "|    n_updates            | 18250        |\n",
      "|    policy_gradient_loss | -0.00628     |\n",
      "|    value_loss           | 2.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2516         |\n",
      "|    iterations           | 380          |\n",
      "|    time_elapsed         | 2473         |\n",
      "|    total_timesteps      | 6225920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029130736 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0435       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 986          |\n",
      "|    n_updates            | 18260        |\n",
      "|    policy_gradient_loss | -0.00664     |\n",
      "|    value_loss           | 2.85e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6240000, episode_reward=752.40 +/- 105.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 752          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6240000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029021313 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.51        |\n",
      "|    explained_variance   | 0.0332       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.37e+03     |\n",
      "|    n_updates            | 18270        |\n",
      "|    policy_gradient_loss | -0.00675     |\n",
      "|    value_loss           | 2.89e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2512    |\n",
      "|    iterations      | 381     |\n",
      "|    time_elapsed    | 2484    |\n",
      "|    total_timesteps | 6242304 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2513         |\n",
      "|    iterations           | 382          |\n",
      "|    time_elapsed         | 2489         |\n",
      "|    total_timesteps      | 6258688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024662009 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.0474       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 18280        |\n",
      "|    policy_gradient_loss | -0.00644     |\n",
      "|    value_loss           | 2.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2514         |\n",
      "|    iterations           | 383          |\n",
      "|    time_elapsed         | 2495         |\n",
      "|    total_timesteps      | 6275072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027842189 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0445       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.94e+03     |\n",
      "|    n_updates            | 18290        |\n",
      "|    policy_gradient_loss | -0.0068      |\n",
      "|    value_loss           | 2.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2515         |\n",
      "|    iterations           | 384          |\n",
      "|    time_elapsed         | 2500         |\n",
      "|    total_timesteps      | 6291456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024095154 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.051        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 18300        |\n",
      "|    policy_gradient_loss | -0.00617     |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2517         |\n",
      "|    iterations           | 385          |\n",
      "|    time_elapsed         | 2505         |\n",
      "|    total_timesteps      | 6307840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025321345 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.0627       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 18310        |\n",
      "|    policy_gradient_loss | -0.00624     |\n",
      "|    value_loss           | 2.92e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6320000, episode_reward=741.20 +/- 89.05\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 741          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6320000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024771318 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0628       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 944          |\n",
      "|    n_updates            | 18320        |\n",
      "|    policy_gradient_loss | -0.00626     |\n",
      "|    value_loss           | 2.72e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2513    |\n",
      "|    iterations      | 386     |\n",
      "|    time_elapsed    | 2516    |\n",
      "|    total_timesteps | 6324224 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2514         |\n",
      "|    iterations           | 387          |\n",
      "|    time_elapsed         | 2521         |\n",
      "|    total_timesteps      | 6340608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025377597 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0485       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 833          |\n",
      "|    n_updates            | 18330        |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    value_loss           | 2.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2515         |\n",
      "|    iterations           | 388          |\n",
      "|    time_elapsed         | 2526         |\n",
      "|    total_timesteps      | 6356992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024432144 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0247       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.51e+03     |\n",
      "|    n_updates            | 18340        |\n",
      "|    policy_gradient_loss | -0.00596     |\n",
      "|    value_loss           | 2.93e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2516         |\n",
      "|    iterations           | 389          |\n",
      "|    time_elapsed         | 2532         |\n",
      "|    total_timesteps      | 6373376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029729041 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.0535       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 18350        |\n",
      "|    policy_gradient_loss | -0.00731     |\n",
      "|    value_loss           | 3.06e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2517         |\n",
      "|    iterations           | 390          |\n",
      "|    time_elapsed         | 2538         |\n",
      "|    total_timesteps      | 6389760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030301586 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0173       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 18360        |\n",
      "|    policy_gradient_loss | -0.00668     |\n",
      "|    value_loss           | 2.85e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6400000, episode_reward=748.00 +/- 79.75\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 748          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6400000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026728348 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.0275       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 18370        |\n",
      "|    policy_gradient_loss | -0.0055      |\n",
      "|    value_loss           | 2.73e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2513    |\n",
      "|    iterations      | 391     |\n",
      "|    time_elapsed    | 2548    |\n",
      "|    total_timesteps | 6406144 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2514         |\n",
      "|    iterations           | 392          |\n",
      "|    time_elapsed         | 2554         |\n",
      "|    total_timesteps      | 6422528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026557166 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0685       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 18380        |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2514         |\n",
      "|    iterations           | 393          |\n",
      "|    time_elapsed         | 2560         |\n",
      "|    total_timesteps      | 6438912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025580013 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.0148       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 18390        |\n",
      "|    policy_gradient_loss | -0.00623     |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2515         |\n",
      "|    iterations           | 394          |\n",
      "|    time_elapsed         | 2566         |\n",
      "|    total_timesteps      | 6455296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024962497 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | -0.00846     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 18400        |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2516         |\n",
      "|    iterations           | 395          |\n",
      "|    time_elapsed         | 2571         |\n",
      "|    total_timesteps      | 6471680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023961216 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0678       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 18410        |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    value_loss           | 2.79e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6480000, episode_reward=793.60 +/- 126.01\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 794          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6480000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031121662 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.516       |\n",
      "|    explained_variance   | 0.0226       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.54e+03     |\n",
      "|    n_updates            | 18420        |\n",
      "|    policy_gradient_loss | -0.00708     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2512    |\n",
      "|    iterations      | 396     |\n",
      "|    time_elapsed    | 2582    |\n",
      "|    total_timesteps | 6488064 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2512         |\n",
      "|    iterations           | 397          |\n",
      "|    time_elapsed         | 2588         |\n",
      "|    total_timesteps      | 6504448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027247786 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.52        |\n",
      "|    explained_variance   | 0.0669       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 18430        |\n",
      "|    policy_gradient_loss | -0.00565     |\n",
      "|    value_loss           | 3e+03        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2512         |\n",
      "|    iterations           | 398          |\n",
      "|    time_elapsed         | 2594         |\n",
      "|    total_timesteps      | 6520832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026273662 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.0564       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 18440        |\n",
      "|    policy_gradient_loss | -0.00646     |\n",
      "|    value_loss           | 2.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2513         |\n",
      "|    iterations           | 399          |\n",
      "|    time_elapsed         | 2601         |\n",
      "|    total_timesteps      | 6537216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029073418 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.0462       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.44e+03     |\n",
      "|    n_updates            | 18450        |\n",
      "|    policy_gradient_loss | -0.00666     |\n",
      "|    value_loss           | 2.91e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2513         |\n",
      "|    iterations           | 400          |\n",
      "|    time_elapsed         | 2607         |\n",
      "|    total_timesteps      | 6553600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026765675 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0443       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 18460        |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6560000, episode_reward=754.00 +/- 117.54\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 754          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022440094 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.51        |\n",
      "|    explained_variance   | 0.0645       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 18470        |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    value_loss           | 3.19e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2509    |\n",
      "|    iterations      | 401     |\n",
      "|    time_elapsed    | 2618    |\n",
      "|    total_timesteps | 6569984 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2510        |\n",
      "|    iterations           | 402         |\n",
      "|    time_elapsed         | 2623        |\n",
      "|    total_timesteps      | 6586368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002724865 |\n",
      "|    clip_fraction        | 0.0177      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.511      |\n",
      "|    explained_variance   | 0.061       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.56e+03    |\n",
      "|    n_updates            | 18480       |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    value_loss           | 3e+03       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2510         |\n",
      "|    iterations           | 403          |\n",
      "|    time_elapsed         | 2629         |\n",
      "|    total_timesteps      | 6602752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030212074 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.065        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 18490        |\n",
      "|    policy_gradient_loss | -0.00714     |\n",
      "|    value_loss           | 2.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2511         |\n",
      "|    iterations           | 404          |\n",
      "|    time_elapsed         | 2635         |\n",
      "|    total_timesteps      | 6619136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025798876 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.00494      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.57e+03     |\n",
      "|    n_updates            | 18500        |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    value_loss           | 2.71e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2512        |\n",
      "|    iterations           | 405         |\n",
      "|    time_elapsed         | 2640        |\n",
      "|    total_timesteps      | 6635520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002783632 |\n",
      "|    clip_fraction        | 0.0183      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.505      |\n",
      "|    explained_variance   | 0.0545      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.57e+03    |\n",
      "|    n_updates            | 18510       |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    value_loss           | 2.99e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6640000, episode_reward=748.40 +/- 70.81\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 748          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6640000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027819402 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.0114       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.82e+03     |\n",
      "|    n_updates            | 18520        |\n",
      "|    policy_gradient_loss | -0.00666     |\n",
      "|    value_loss           | 2.98e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2508    |\n",
      "|    iterations      | 406     |\n",
      "|    time_elapsed    | 2651    |\n",
      "|    total_timesteps | 6651904 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2509         |\n",
      "|    iterations           | 407          |\n",
      "|    time_elapsed         | 2657         |\n",
      "|    total_timesteps      | 6668288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027642585 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.0646       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 18530        |\n",
      "|    policy_gradient_loss | -0.00693     |\n",
      "|    value_loss           | 2.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2510         |\n",
      "|    iterations           | 408          |\n",
      "|    time_elapsed         | 2662         |\n",
      "|    total_timesteps      | 6684672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022708047 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0605       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 18540        |\n",
      "|    policy_gradient_loss | -0.00612     |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2510         |\n",
      "|    iterations           | 409          |\n",
      "|    time_elapsed         | 2668         |\n",
      "|    total_timesteps      | 6701056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031631724 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.0153       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.19e+03     |\n",
      "|    n_updates            | 18550        |\n",
      "|    policy_gradient_loss | -0.00711     |\n",
      "|    value_loss           | 2.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2511         |\n",
      "|    iterations           | 410          |\n",
      "|    time_elapsed         | 2674         |\n",
      "|    total_timesteps      | 6717440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026546689 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0462       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 18560        |\n",
      "|    policy_gradient_loss | -0.00628     |\n",
      "|    value_loss           | 3.03e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6720000, episode_reward=768.00 +/- 90.51\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 768          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6720000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025503538 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.00525      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 18570        |\n",
      "|    policy_gradient_loss | -0.00586     |\n",
      "|    value_loss           | 2.76e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2508    |\n",
      "|    iterations      | 411     |\n",
      "|    time_elapsed    | 2684    |\n",
      "|    total_timesteps | 6733824 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2508         |\n",
      "|    iterations           | 412          |\n",
      "|    time_elapsed         | 2690         |\n",
      "|    total_timesteps      | 6750208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026021856 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.516       |\n",
      "|    explained_variance   | 0.0468       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.66e+03     |\n",
      "|    n_updates            | 18580        |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    value_loss           | 3.03e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2510         |\n",
      "|    iterations           | 413          |\n",
      "|    time_elapsed         | 2695         |\n",
      "|    total_timesteps      | 6766592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026660797 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.516       |\n",
      "|    explained_variance   | 0.0359       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.57e+03     |\n",
      "|    n_updates            | 18590        |\n",
      "|    policy_gradient_loss | -0.0064      |\n",
      "|    value_loss           | 3e+03        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2510        |\n",
      "|    iterations           | 414         |\n",
      "|    time_elapsed         | 2701        |\n",
      "|    total_timesteps      | 6782976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002515338 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.507      |\n",
      "|    explained_variance   | 0.0635      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.44e+03    |\n",
      "|    n_updates            | 18600       |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    value_loss           | 3.05e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2511         |\n",
      "|    iterations           | 415          |\n",
      "|    time_elapsed         | 2707         |\n",
      "|    total_timesteps      | 6799360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031445816 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.05         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 18610        |\n",
      "|    policy_gradient_loss | -0.00706     |\n",
      "|    value_loss           | 2.77e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6800000, episode_reward=772.80 +/- 90.97\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 773          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6800000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025181468 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | 0.0473       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.68e+03     |\n",
      "|    n_updates            | 18620        |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    value_loss           | 2.77e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2507    |\n",
      "|    iterations      | 416     |\n",
      "|    time_elapsed    | 2718    |\n",
      "|    total_timesteps | 6815744 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2508         |\n",
      "|    iterations           | 417          |\n",
      "|    time_elapsed         | 2723         |\n",
      "|    total_timesteps      | 6832128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026853727 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.00739      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 18630        |\n",
      "|    policy_gradient_loss | -0.00583     |\n",
      "|    value_loss           | 2.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2508         |\n",
      "|    iterations           | 418          |\n",
      "|    time_elapsed         | 2729         |\n",
      "|    total_timesteps      | 6848512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028069038 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0313       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.39e+03     |\n",
      "|    n_updates            | 18640        |\n",
      "|    policy_gradient_loss | -0.00661     |\n",
      "|    value_loss           | 3.05e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2509        |\n",
      "|    iterations           | 419         |\n",
      "|    time_elapsed         | 2735        |\n",
      "|    total_timesteps      | 6864896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002170117 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.505      |\n",
      "|    explained_variance   | 0.0616      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 917         |\n",
      "|    n_updates            | 18650       |\n",
      "|    policy_gradient_loss | -0.0053     |\n",
      "|    value_loss           | 2.92e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6880000, episode_reward=770.80 +/- 100.36\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 771          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6880000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023477958 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0509       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 935          |\n",
      "|    n_updates            | 18660        |\n",
      "|    policy_gradient_loss | -0.00563     |\n",
      "|    value_loss           | 2.97e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2505    |\n",
      "|    iterations      | 420     |\n",
      "|    time_elapsed    | 2746    |\n",
      "|    total_timesteps | 6881280 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2506         |\n",
      "|    iterations           | 421          |\n",
      "|    time_elapsed         | 2751         |\n",
      "|    total_timesteps      | 6897664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025365835 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.0488       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.55e+03     |\n",
      "|    n_updates            | 18670        |\n",
      "|    policy_gradient_loss | -0.00631     |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2507         |\n",
      "|    iterations           | 422          |\n",
      "|    time_elapsed         | 2756         |\n",
      "|    total_timesteps      | 6914048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023448872 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0198       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 18680        |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    value_loss           | 2.97e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2508         |\n",
      "|    iterations           | 423          |\n",
      "|    time_elapsed         | 2762         |\n",
      "|    total_timesteps      | 6930432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026131729 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.000907     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.57e+03     |\n",
      "|    n_updates            | 18690        |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    value_loss           | 2.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2509         |\n",
      "|    iterations           | 424          |\n",
      "|    time_elapsed         | 2768         |\n",
      "|    total_timesteps      | 6946816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025273194 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.0198       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.36e+03     |\n",
      "|    n_updates            | 18700        |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    value_loss           | 2.66e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=6960000, episode_reward=758.00 +/- 89.08\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 758          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 6960000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026362212 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.523       |\n",
      "|    explained_variance   | 0.0715       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.43e+03     |\n",
      "|    n_updates            | 18710        |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    value_loss           | 2.69e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2505    |\n",
      "|    iterations      | 425     |\n",
      "|    time_elapsed    | 2779    |\n",
      "|    total_timesteps | 6963200 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2505         |\n",
      "|    iterations           | 426          |\n",
      "|    time_elapsed         | 2785         |\n",
      "|    total_timesteps      | 6979584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027889977 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.526       |\n",
      "|    explained_variance   | 0.0111       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.73e+03     |\n",
      "|    n_updates            | 18720        |\n",
      "|    policy_gradient_loss | -0.00661     |\n",
      "|    value_loss           | 3.11e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2506         |\n",
      "|    iterations           | 427          |\n",
      "|    time_elapsed         | 2791         |\n",
      "|    total_timesteps      | 6995968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021908535 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.52        |\n",
      "|    explained_variance   | 0.0536       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 18730        |\n",
      "|    policy_gradient_loss | -0.00575     |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2507         |\n",
      "|    iterations           | 428          |\n",
      "|    time_elapsed         | 2796         |\n",
      "|    total_timesteps      | 7012352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025759863 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.0465       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.47e+03     |\n",
      "|    n_updates            | 18740        |\n",
      "|    policy_gradient_loss | -0.00617     |\n",
      "|    value_loss           | 2.79e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2507        |\n",
      "|    iterations           | 429         |\n",
      "|    time_elapsed         | 2802        |\n",
      "|    total_timesteps      | 7028736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002553105 |\n",
      "|    clip_fraction        | 0.0155      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.508      |\n",
      "|    explained_variance   | 0.0598      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 18750       |\n",
      "|    policy_gradient_loss | -0.00596    |\n",
      "|    value_loss           | 2.91e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=7040000, episode_reward=766.40 +/- 78.68\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 766          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7040000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025759928 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.51        |\n",
      "|    explained_variance   | 0.0494       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1e+03        |\n",
      "|    n_updates            | 18760        |\n",
      "|    policy_gradient_loss | -0.00603     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2503    |\n",
      "|    iterations      | 430     |\n",
      "|    time_elapsed    | 2813    |\n",
      "|    total_timesteps | 7045120 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2504         |\n",
      "|    iterations           | 431          |\n",
      "|    time_elapsed         | 2819         |\n",
      "|    total_timesteps      | 7061504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026948585 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.0156       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 18770        |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    value_loss           | 3.06e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2505         |\n",
      "|    iterations           | 432          |\n",
      "|    time_elapsed         | 2824         |\n",
      "|    total_timesteps      | 7077888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024695955 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.0267       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.59e+03     |\n",
      "|    n_updates            | 18780        |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2506         |\n",
      "|    iterations           | 433          |\n",
      "|    time_elapsed         | 2830         |\n",
      "|    total_timesteps      | 7094272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027893842 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | 0.0506       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 953          |\n",
      "|    n_updates            | 18790        |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2507         |\n",
      "|    iterations           | 434          |\n",
      "|    time_elapsed         | 2836         |\n",
      "|    total_timesteps      | 7110656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027090132 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.0583       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 18800        |\n",
      "|    policy_gradient_loss | -0.00612     |\n",
      "|    value_loss           | 2.77e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7120000, episode_reward=770.00 +/- 95.54\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 770         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 7120000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002381017 |\n",
      "|    clip_fraction        | 0.0131      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.512      |\n",
      "|    explained_variance   | 0.0404      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.39e+03    |\n",
      "|    n_updates            | 18810       |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    value_loss           | 3.07e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2503    |\n",
      "|    iterations      | 435     |\n",
      "|    time_elapsed    | 2846    |\n",
      "|    total_timesteps | 7127040 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2504        |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 2852        |\n",
      "|    total_timesteps      | 7143424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003438719 |\n",
      "|    clip_fraction        | 0.0247      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.511      |\n",
      "|    explained_variance   | 0.0497      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.53e+03    |\n",
      "|    n_updates            | 18820       |\n",
      "|    policy_gradient_loss | -0.00707    |\n",
      "|    value_loss           | 2.75e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2504         |\n",
      "|    iterations           | 437          |\n",
      "|    time_elapsed         | 2858         |\n",
      "|    total_timesteps      | 7159808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027442267 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0571       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.49e+03     |\n",
      "|    n_updates            | 18830        |\n",
      "|    policy_gradient_loss | -0.0065      |\n",
      "|    value_loss           | 2.74e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2504        |\n",
      "|    iterations           | 438         |\n",
      "|    time_elapsed         | 2864        |\n",
      "|    total_timesteps      | 7176192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002639203 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.0552      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.76e+03    |\n",
      "|    n_updates            | 18840       |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    value_loss           | 2.82e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2505         |\n",
      "|    iterations           | 439          |\n",
      "|    time_elapsed         | 2870         |\n",
      "|    total_timesteps      | 7192576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025427344 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.0464       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 824          |\n",
      "|    n_updates            | 18850        |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    value_loss           | 2.94e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7200000, episode_reward=758.00 +/- 114.54\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 758          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023384413 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0761       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 18860        |\n",
      "|    policy_gradient_loss | -0.00658     |\n",
      "|    value_loss           | 3.01e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2501    |\n",
      "|    iterations      | 440     |\n",
      "|    time_elapsed    | 2881    |\n",
      "|    total_timesteps | 7208960 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2501         |\n",
      "|    iterations           | 441          |\n",
      "|    time_elapsed         | 2888         |\n",
      "|    total_timesteps      | 7225344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024362975 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0512       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 18870        |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    value_loss           | 3.02e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2502         |\n",
      "|    iterations           | 442          |\n",
      "|    time_elapsed         | 2894         |\n",
      "|    total_timesteps      | 7241728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024503078 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.0961       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 18880        |\n",
      "|    policy_gradient_loss | -0.0058      |\n",
      "|    value_loss           | 2.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2502         |\n",
      "|    iterations           | 443          |\n",
      "|    time_elapsed         | 2900         |\n",
      "|    total_timesteps      | 7258112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025705076 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0401       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.02e+03     |\n",
      "|    n_updates            | 18890        |\n",
      "|    policy_gradient_loss | -0.00604     |\n",
      "|    value_loss           | 2.94e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2501         |\n",
      "|    iterations           | 444          |\n",
      "|    time_elapsed         | 2907         |\n",
      "|    total_timesteps      | 7274496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022330037 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.079        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.33e+03     |\n",
      "|    n_updates            | 18900        |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    value_loss           | 2.7e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7280000, episode_reward=756.40 +/- 101.43\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 756          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024576734 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.102        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.45e+03     |\n",
      "|    n_updates            | 18910        |\n",
      "|    policy_gradient_loss | -0.00653     |\n",
      "|    value_loss           | 2.74e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2496    |\n",
      "|    iterations      | 445     |\n",
      "|    time_elapsed    | 2920    |\n",
      "|    total_timesteps | 7290880 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2497         |\n",
      "|    iterations           | 446          |\n",
      "|    time_elapsed         | 2926         |\n",
      "|    total_timesteps      | 7307264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029636952 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0557       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 18920        |\n",
      "|    policy_gradient_loss | -0.0066      |\n",
      "|    value_loss           | 3.12e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2497         |\n",
      "|    iterations           | 447          |\n",
      "|    time_elapsed         | 2932         |\n",
      "|    total_timesteps      | 7323648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030442523 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.0369       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 18930        |\n",
      "|    policy_gradient_loss | -0.00653     |\n",
      "|    value_loss           | 3.18e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2498         |\n",
      "|    iterations           | 448          |\n",
      "|    time_elapsed         | 2938         |\n",
      "|    total_timesteps      | 7340032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022743293 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.0446       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 891          |\n",
      "|    n_updates            | 18940        |\n",
      "|    policy_gradient_loss | -0.00603     |\n",
      "|    value_loss           | 2.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2497         |\n",
      "|    iterations           | 449          |\n",
      "|    time_elapsed         | 2945         |\n",
      "|    total_timesteps      | 7356416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026504204 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.0645       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.8e+03      |\n",
      "|    n_updates            | 18950        |\n",
      "|    policy_gradient_loss | -0.00657     |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7360000, episode_reward=737.20 +/- 126.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 737         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 7360000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002425709 |\n",
      "|    clip_fraction        | 0.015       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.495      |\n",
      "|    explained_variance   | 0.0465      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.41e+03    |\n",
      "|    n_updates            | 18960       |\n",
      "|    policy_gradient_loss | -0.00641    |\n",
      "|    value_loss           | 2.84e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2492    |\n",
      "|    iterations      | 450     |\n",
      "|    time_elapsed    | 2957    |\n",
      "|    total_timesteps | 7372800 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2493         |\n",
      "|    iterations           | 451          |\n",
      "|    time_elapsed         | 2963         |\n",
      "|    total_timesteps      | 7389184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024232112 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0678       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.74e+03     |\n",
      "|    n_updates            | 18970        |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    value_loss           | 3.13e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2493         |\n",
      "|    iterations           | 452          |\n",
      "|    time_elapsed         | 2969         |\n",
      "|    total_timesteps      | 7405568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029115737 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.0852       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 18980        |\n",
      "|    policy_gradient_loss | -0.00648     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2494         |\n",
      "|    iterations           | 453          |\n",
      "|    time_elapsed         | 2975         |\n",
      "|    total_timesteps      | 7421952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024254993 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.0515       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 18990        |\n",
      "|    policy_gradient_loss | -0.00605     |\n",
      "|    value_loss           | 2.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2494         |\n",
      "|    iterations           | 454          |\n",
      "|    time_elapsed         | 2981         |\n",
      "|    total_timesteps      | 7438336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023073922 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0361       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.07e+03     |\n",
      "|    n_updates            | 19000        |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7440000, episode_reward=783.20 +/- 114.67\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 783          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7440000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022460376 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.0529       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.71e+03     |\n",
      "|    n_updates            | 19010        |\n",
      "|    policy_gradient_loss | -0.00546     |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2490    |\n",
      "|    iterations      | 455     |\n",
      "|    time_elapsed    | 2993    |\n",
      "|    total_timesteps | 7454720 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2490         |\n",
      "|    iterations           | 456          |\n",
      "|    time_elapsed         | 2999         |\n",
      "|    total_timesteps      | 7471104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026144825 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0841       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.49e+03     |\n",
      "|    n_updates            | 19020        |\n",
      "|    policy_gradient_loss | -0.00601     |\n",
      "|    value_loss           | 3.1e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2491         |\n",
      "|    iterations           | 457          |\n",
      "|    time_elapsed         | 3004         |\n",
      "|    total_timesteps      | 7487488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024722677 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.0453       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 19030        |\n",
      "|    policy_gradient_loss | -0.00604     |\n",
      "|    value_loss           | 2.98e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2492         |\n",
      "|    iterations           | 458          |\n",
      "|    time_elapsed         | 3010         |\n",
      "|    total_timesteps      | 7503872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025154776 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.102        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.18e+03     |\n",
      "|    n_updates            | 19040        |\n",
      "|    policy_gradient_loss | -0.00559     |\n",
      "|    value_loss           | 2.83e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7520000, episode_reward=768.40 +/- 136.72\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 768          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7520000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029617264 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0491       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.49e+03     |\n",
      "|    n_updates            | 19050        |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    value_loss           | 3.04e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2488    |\n",
      "|    iterations      | 459     |\n",
      "|    time_elapsed    | 3021    |\n",
      "|    total_timesteps | 7520256 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2489         |\n",
      "|    iterations           | 460          |\n",
      "|    time_elapsed         | 3027         |\n",
      "|    total_timesteps      | 7536640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024839574 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.043        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.33e+03     |\n",
      "|    n_updates            | 19060        |\n",
      "|    policy_gradient_loss | -0.00583     |\n",
      "|    value_loss           | 3.21e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2489         |\n",
      "|    iterations           | 461          |\n",
      "|    time_elapsed         | 3033         |\n",
      "|    total_timesteps      | 7553024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019782884 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.477       |\n",
      "|    explained_variance   | 0.0386       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.8e+03      |\n",
      "|    n_updates            | 19070        |\n",
      "|    policy_gradient_loss | -0.00534     |\n",
      "|    value_loss           | 3.15e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2489        |\n",
      "|    iterations           | 462         |\n",
      "|    time_elapsed         | 3040        |\n",
      "|    total_timesteps      | 7569408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002476369 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.482      |\n",
      "|    explained_variance   | 0.0617      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.68e+03    |\n",
      "|    n_updates            | 19080       |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    value_loss           | 3.04e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2490         |\n",
      "|    iterations           | 463          |\n",
      "|    time_elapsed         | 3046         |\n",
      "|    total_timesteps      | 7585792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027884026 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.0462       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.62e+03     |\n",
      "|    n_updates            | 19090        |\n",
      "|    policy_gradient_loss | -0.00671     |\n",
      "|    value_loss           | 3.1e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7600000, episode_reward=754.40 +/- 102.34\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 754          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7600000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022874922 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.00916      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.81e+03     |\n",
      "|    n_updates            | 19100        |\n",
      "|    policy_gradient_loss | -0.0055      |\n",
      "|    value_loss           | 3.23e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2485    |\n",
      "|    iterations      | 464     |\n",
      "|    time_elapsed    | 3058    |\n",
      "|    total_timesteps | 7602176 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2486        |\n",
      "|    iterations           | 465         |\n",
      "|    time_elapsed         | 3064        |\n",
      "|    total_timesteps      | 7618560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002402575 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.502      |\n",
      "|    explained_variance   | 0.0372      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 19110       |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    value_loss           | 2.84e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2486        |\n",
      "|    iterations           | 466         |\n",
      "|    time_elapsed         | 3070        |\n",
      "|    total_timesteps      | 7634944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002240709 |\n",
      "|    clip_fraction        | 0.0121      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.498      |\n",
      "|    explained_variance   | 0.0526      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.55e+03    |\n",
      "|    n_updates            | 19120       |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    value_loss           | 3.08e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2487         |\n",
      "|    iterations           | 467          |\n",
      "|    time_elapsed         | 3076         |\n",
      "|    total_timesteps      | 7651328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026016121 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.0262       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.68e+03     |\n",
      "|    n_updates            | 19130        |\n",
      "|    policy_gradient_loss | -0.00616     |\n",
      "|    value_loss           | 2.99e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2487        |\n",
      "|    iterations           | 468         |\n",
      "|    time_elapsed         | 3082        |\n",
      "|    total_timesteps      | 7667712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002707648 |\n",
      "|    clip_fraction        | 0.0159      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.499      |\n",
      "|    explained_variance   | 0.014       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 19140       |\n",
      "|    policy_gradient_loss | -0.0064     |\n",
      "|    value_loss           | 3.21e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=7680000, episode_reward=762.40 +/- 128.23\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 762          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7680000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027162589 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0343       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 19150        |\n",
      "|    policy_gradient_loss | -0.00646     |\n",
      "|    value_loss           | 2.82e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2483    |\n",
      "|    iterations      | 469     |\n",
      "|    time_elapsed    | 3093    |\n",
      "|    total_timesteps | 7684096 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2484         |\n",
      "|    iterations           | 470          |\n",
      "|    time_elapsed         | 3099         |\n",
      "|    total_timesteps      | 7700480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024343827 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0493       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 882          |\n",
      "|    n_updates            | 19160        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2484         |\n",
      "|    iterations           | 471          |\n",
      "|    time_elapsed         | 3106         |\n",
      "|    total_timesteps      | 7716864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025410156 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | 0.0297       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 19170        |\n",
      "|    policy_gradient_loss | -0.00621     |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2485         |\n",
      "|    iterations           | 472          |\n",
      "|    time_elapsed         | 3111         |\n",
      "|    total_timesteps      | 7733248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028846697 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.0376       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.81e+03     |\n",
      "|    n_updates            | 19180        |\n",
      "|    policy_gradient_loss | -0.00728     |\n",
      "|    value_loss           | 3.41e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2484         |\n",
      "|    iterations           | 473          |\n",
      "|    time_elapsed         | 3118         |\n",
      "|    total_timesteps      | 7749632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023348208 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.0556       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.43e+03     |\n",
      "|    n_updates            | 19190        |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    value_loss           | 2.96e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7760000, episode_reward=759.20 +/- 110.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 759          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7760000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029854183 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.00901      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 19200        |\n",
      "|    policy_gradient_loss | -0.00627     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2481    |\n",
      "|    iterations      | 474     |\n",
      "|    time_elapsed    | 3129    |\n",
      "|    total_timesteps | 7766016 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2482         |\n",
      "|    iterations           | 475          |\n",
      "|    time_elapsed         | 3135         |\n",
      "|    total_timesteps      | 7782400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027333905 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.0491       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 19210        |\n",
      "|    policy_gradient_loss | -0.00647     |\n",
      "|    value_loss           | 3e+03        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2482         |\n",
      "|    iterations           | 476          |\n",
      "|    time_elapsed         | 3141         |\n",
      "|    total_timesteps      | 7798784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027167392 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.0421       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.67e+03     |\n",
      "|    n_updates            | 19220        |\n",
      "|    policy_gradient_loss | -0.00616     |\n",
      "|    value_loss           | 3.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2483         |\n",
      "|    iterations           | 477          |\n",
      "|    time_elapsed         | 3146         |\n",
      "|    total_timesteps      | 7815168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030512293 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.055        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.73e+03     |\n",
      "|    n_updates            | 19230        |\n",
      "|    policy_gradient_loss | -0.00704     |\n",
      "|    value_loss           | 3.03e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2483         |\n",
      "|    iterations           | 478          |\n",
      "|    time_elapsed         | 3153         |\n",
      "|    total_timesteps      | 7831552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028038523 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.03         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.4e+03      |\n",
      "|    n_updates            | 19240        |\n",
      "|    policy_gradient_loss | -0.00644     |\n",
      "|    value_loss           | 2.98e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7840000, episode_reward=756.80 +/- 91.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 757          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7840000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028630802 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0473       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 19250        |\n",
      "|    policy_gradient_loss | -0.00647     |\n",
      "|    value_loss           | 2.78e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2480    |\n",
      "|    iterations      | 479     |\n",
      "|    time_elapsed    | 3163    |\n",
      "|    total_timesteps | 7847936 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2481         |\n",
      "|    iterations           | 480          |\n",
      "|    time_elapsed         | 3169         |\n",
      "|    total_timesteps      | 7864320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024186603 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.0894       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.29e+03     |\n",
      "|    n_updates            | 19260        |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    value_loss           | 2.94e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2482         |\n",
      "|    iterations           | 481          |\n",
      "|    time_elapsed         | 3174         |\n",
      "|    total_timesteps      | 7880704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025903534 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.0446       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 19270        |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    value_loss           | 3.14e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2482        |\n",
      "|    iterations           | 482         |\n",
      "|    time_elapsed         | 3180        |\n",
      "|    total_timesteps      | 7897088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002743759 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.495      |\n",
      "|    explained_variance   | 0.0622      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.5e+03     |\n",
      "|    n_updates            | 19280       |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    value_loss           | 3.12e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2483         |\n",
      "|    iterations           | 483          |\n",
      "|    time_elapsed         | 3185         |\n",
      "|    total_timesteps      | 7913472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025721504 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0763       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.62e+03     |\n",
      "|    n_updates            | 19290        |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    value_loss           | 2.98e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=7920000, episode_reward=781.20 +/- 94.63\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 781          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 7920000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029463177 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.00984      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.07e+03     |\n",
      "|    n_updates            | 19300        |\n",
      "|    policy_gradient_loss | -0.00662     |\n",
      "|    value_loss           | 2.96e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2480    |\n",
      "|    iterations      | 484     |\n",
      "|    time_elapsed    | 3196    |\n",
      "|    total_timesteps | 7929856 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2481        |\n",
      "|    iterations           | 485         |\n",
      "|    time_elapsed         | 3202        |\n",
      "|    total_timesteps      | 7946240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002353305 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.487      |\n",
      "|    explained_variance   | 0.0809      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.62e+03    |\n",
      "|    n_updates            | 19310       |\n",
      "|    policy_gradient_loss | -0.00568    |\n",
      "|    value_loss           | 3.2e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2481         |\n",
      "|    iterations           | 486          |\n",
      "|    time_elapsed         | 3208         |\n",
      "|    total_timesteps      | 7962624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024547032 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.0755       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.36e+03     |\n",
      "|    n_updates            | 19320        |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    value_loss           | 2.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2482         |\n",
      "|    iterations           | 487          |\n",
      "|    time_elapsed         | 3214         |\n",
      "|    total_timesteps      | 7979008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019888885 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.0989       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.82e+03     |\n",
      "|    n_updates            | 19330        |\n",
      "|    policy_gradient_loss | -0.00535     |\n",
      "|    value_loss           | 3.07e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2482         |\n",
      "|    iterations           | 488          |\n",
      "|    time_elapsed         | 3220         |\n",
      "|    total_timesteps      | 7995392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025386512 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.0876       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.73e+03     |\n",
      "|    n_updates            | 19340        |\n",
      "|    policy_gradient_loss | -0.00586     |\n",
      "|    value_loss           | 3.1e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8000000, episode_reward=791.20 +/- 113.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 791          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020816624 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.0581       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 19350        |\n",
      "|    policy_gradient_loss | -0.00552     |\n",
      "|    value_loss           | 3.29e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2479    |\n",
      "|    iterations      | 489     |\n",
      "|    time_elapsed    | 3231    |\n",
      "|    total_timesteps | 8011776 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2479         |\n",
      "|    iterations           | 490          |\n",
      "|    time_elapsed         | 3237         |\n",
      "|    total_timesteps      | 8028160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027857772 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.0319       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 19360        |\n",
      "|    policy_gradient_loss | -0.00685     |\n",
      "|    value_loss           | 3.07e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2480         |\n",
      "|    iterations           | 491          |\n",
      "|    time_elapsed         | 3243         |\n",
      "|    total_timesteps      | 8044544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022364578 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.0645       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.21e+03     |\n",
      "|    n_updates            | 19370        |\n",
      "|    policy_gradient_loss | -0.00557     |\n",
      "|    value_loss           | 3e+03        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2480        |\n",
      "|    iterations           | 492         |\n",
      "|    time_elapsed         | 3249        |\n",
      "|    total_timesteps      | 8060928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002617446 |\n",
      "|    clip_fraction        | 0.0161      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.49       |\n",
      "|    explained_variance   | 0.0326      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.45e+03    |\n",
      "|    n_updates            | 19380       |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    value_loss           | 3.05e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2481         |\n",
      "|    iterations           | 493          |\n",
      "|    time_elapsed         | 3255         |\n",
      "|    total_timesteps      | 8077312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024665617 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0503       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.77e+03     |\n",
      "|    n_updates            | 19390        |\n",
      "|    policy_gradient_loss | -0.00607     |\n",
      "|    value_loss           | 3.33e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8080000, episode_reward=787.20 +/- 117.93\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 787         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 8080000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002660707 |\n",
      "|    clip_fraction        | 0.0158      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.495      |\n",
      "|    explained_variance   | 0.029       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.4e+03     |\n",
      "|    n_updates            | 19400       |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    value_loss           | 3.05e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2477    |\n",
      "|    iterations      | 494     |\n",
      "|    time_elapsed    | 3267    |\n",
      "|    total_timesteps | 8093696 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2477         |\n",
      "|    iterations           | 495          |\n",
      "|    time_elapsed         | 3273         |\n",
      "|    total_timesteps      | 8110080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026975337 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | 0.0574       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.72e+03     |\n",
      "|    n_updates            | 19410        |\n",
      "|    policy_gradient_loss | -0.00651     |\n",
      "|    value_loss           | 3.19e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2478        |\n",
      "|    iterations           | 496         |\n",
      "|    time_elapsed         | 3278        |\n",
      "|    total_timesteps      | 8126464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002295385 |\n",
      "|    clip_fraction        | 0.0126      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.487      |\n",
      "|    explained_variance   | 0.0471      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.84e+03    |\n",
      "|    n_updates            | 19420       |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    value_loss           | 3.18e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2478         |\n",
      "|    iterations           | 497          |\n",
      "|    time_elapsed         | 3284         |\n",
      "|    total_timesteps      | 8142848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025933231 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.483       |\n",
      "|    explained_variance   | 0.0493       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.55e+03     |\n",
      "|    n_updates            | 19430        |\n",
      "|    policy_gradient_loss | -0.00647     |\n",
      "|    value_loss           | 3.03e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2479         |\n",
      "|    iterations           | 498          |\n",
      "|    time_elapsed         | 3290         |\n",
      "|    total_timesteps      | 8159232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024431185 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.479       |\n",
      "|    explained_variance   | 0.0557       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 19440        |\n",
      "|    policy_gradient_loss | -0.00581     |\n",
      "|    value_loss           | 3.05e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8160000, episode_reward=813.20 +/- 130.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 813          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8160000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023927686 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.00467      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 19450        |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    value_loss           | 3.27e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2476    |\n",
      "|    iterations      | 499     |\n",
      "|    time_elapsed    | 3301    |\n",
      "|    total_timesteps | 8175616 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2476         |\n",
      "|    iterations           | 500          |\n",
      "|    time_elapsed         | 3307         |\n",
      "|    total_timesteps      | 8192000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025861766 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.0274       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.18e+03     |\n",
      "|    n_updates            | 19460        |\n",
      "|    policy_gradient_loss | -0.0062      |\n",
      "|    value_loss           | 3.02e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2477         |\n",
      "|    iterations           | 501          |\n",
      "|    time_elapsed         | 3313         |\n",
      "|    total_timesteps      | 8208384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025330223 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.0227       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.92e+03     |\n",
      "|    n_updates            | 19470        |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    value_loss           | 3.16e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2477         |\n",
      "|    iterations           | 502          |\n",
      "|    time_elapsed         | 3319         |\n",
      "|    total_timesteps      | 8224768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023586897 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.483       |\n",
      "|    explained_variance   | 0.0811       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 994          |\n",
      "|    n_updates            | 19480        |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    value_loss           | 2.74e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8240000, episode_reward=818.00 +/- 99.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 818          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8240000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024197754 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0656       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.51e+03     |\n",
      "|    n_updates            | 19490        |\n",
      "|    policy_gradient_loss | -0.00581     |\n",
      "|    value_loss           | 2.97e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2474    |\n",
      "|    iterations      | 503     |\n",
      "|    time_elapsed    | 3330    |\n",
      "|    total_timesteps | 8241152 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2474         |\n",
      "|    iterations           | 504          |\n",
      "|    time_elapsed         | 3336         |\n",
      "|    total_timesteps      | 8257536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025211284 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.483       |\n",
      "|    explained_variance   | 0.0917       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.7e+03      |\n",
      "|    n_updates            | 19500        |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    value_loss           | 3.11e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2475         |\n",
      "|    iterations           | 505          |\n",
      "|    time_elapsed         | 3342         |\n",
      "|    total_timesteps      | 8273920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023584682 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0452       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.95e+03     |\n",
      "|    n_updates            | 19510        |\n",
      "|    policy_gradient_loss | -0.00616     |\n",
      "|    value_loss           | 3.08e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2475         |\n",
      "|    iterations           | 506          |\n",
      "|    time_elapsed         | 3348         |\n",
      "|    total_timesteps      | 8290304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027519315 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.068        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 19520        |\n",
      "|    policy_gradient_loss | -0.00668     |\n",
      "|    value_loss           | 3.11e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2475         |\n",
      "|    iterations           | 507          |\n",
      "|    time_elapsed         | 3355         |\n",
      "|    total_timesteps      | 8306688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023683133 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.0751       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.68e+03     |\n",
      "|    n_updates            | 19530        |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    value_loss           | 3.18e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8320000, episode_reward=758.80 +/- 66.11\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 759         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 8320000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002610552 |\n",
      "|    clip_fraction        | 0.0152      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.493      |\n",
      "|    explained_variance   | 0.1         |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.53e+03    |\n",
      "|    n_updates            | 19540       |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    value_loss           | 2.99e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2472    |\n",
      "|    iterations      | 508     |\n",
      "|    time_elapsed    | 3366    |\n",
      "|    total_timesteps | 8323072 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2472         |\n",
      "|    iterations           | 509          |\n",
      "|    time_elapsed         | 3372         |\n",
      "|    total_timesteps      | 8339456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021405655 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.0655       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 19550        |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    value_loss           | 3.01e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2473        |\n",
      "|    iterations           | 510         |\n",
      "|    time_elapsed         | 3378        |\n",
      "|    total_timesteps      | 8355840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002306885 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.493      |\n",
      "|    explained_variance   | 0.00668     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.91e+03    |\n",
      "|    n_updates            | 19560       |\n",
      "|    policy_gradient_loss | -0.0058     |\n",
      "|    value_loss           | 3.43e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2473         |\n",
      "|    iterations           | 511          |\n",
      "|    time_elapsed         | 3384         |\n",
      "|    total_timesteps      | 8372224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026763338 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.0614       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.66e+03     |\n",
      "|    n_updates            | 19570        |\n",
      "|    policy_gradient_loss | -0.00651     |\n",
      "|    value_loss           | 3.03e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2474         |\n",
      "|    iterations           | 512          |\n",
      "|    time_elapsed         | 3390         |\n",
      "|    total_timesteps      | 8388608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025445218 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0747       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 19580        |\n",
      "|    policy_gradient_loss | -0.00609     |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8400000, episode_reward=772.40 +/- 113.18\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 772          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8400000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027671086 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0458       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 19590        |\n",
      "|    policy_gradient_loss | -0.00588     |\n",
      "|    value_loss           | 3.1e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2470    |\n",
      "|    iterations      | 513     |\n",
      "|    time_elapsed    | 3402    |\n",
      "|    total_timesteps | 8404992 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2470         |\n",
      "|    iterations           | 514          |\n",
      "|    time_elapsed         | 3408         |\n",
      "|    total_timesteps      | 8421376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029149833 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | -0.0135      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.77e+03     |\n",
      "|    n_updates            | 19600        |\n",
      "|    policy_gradient_loss | -0.00664     |\n",
      "|    value_loss           | 3.34e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2470         |\n",
      "|    iterations           | 515          |\n",
      "|    time_elapsed         | 3415         |\n",
      "|    total_timesteps      | 8437760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024461471 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0922       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.43e+03     |\n",
      "|    n_updates            | 19610        |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    value_loss           | 2.98e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2470         |\n",
      "|    iterations           | 516          |\n",
      "|    time_elapsed         | 3422         |\n",
      "|    total_timesteps      | 8454144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025420282 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.489       |\n",
      "|    explained_variance   | 0.0556       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 869          |\n",
      "|    n_updates            | 19620        |\n",
      "|    policy_gradient_loss | -0.00589     |\n",
      "|    value_loss           | 2.93e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2470         |\n",
      "|    iterations           | 517          |\n",
      "|    time_elapsed         | 3428         |\n",
      "|    total_timesteps      | 8470528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026119654 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0264       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 19630        |\n",
      "|    policy_gradient_loss | -0.0062      |\n",
      "|    value_loss           | 3.06e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8480000, episode_reward=783.60 +/- 121.02\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 784          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8480000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023564897 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.0427       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.82e+03     |\n",
      "|    n_updates            | 19640        |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    value_loss           | 3.17e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2466    |\n",
      "|    iterations      | 518     |\n",
      "|    time_elapsed    | 3440    |\n",
      "|    total_timesteps | 8486912 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2467         |\n",
      "|    iterations           | 519          |\n",
      "|    time_elapsed         | 3446         |\n",
      "|    total_timesteps      | 8503296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024633845 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0292       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.14e+03     |\n",
      "|    n_updates            | 19650        |\n",
      "|    policy_gradient_loss | -0.00599     |\n",
      "|    value_loss           | 3.04e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2467         |\n",
      "|    iterations           | 520          |\n",
      "|    time_elapsed         | 3453         |\n",
      "|    total_timesteps      | 8519680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025809985 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.0469       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 19660        |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    value_loss           | 2.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2467         |\n",
      "|    iterations           | 521          |\n",
      "|    time_elapsed         | 3459         |\n",
      "|    total_timesteps      | 8536064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019259567 |\n",
      "|    clip_fraction        | 0.00974      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.0242       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.49e+03     |\n",
      "|    n_updates            | 19670        |\n",
      "|    policy_gradient_loss | -0.00559     |\n",
      "|    value_loss           | 3.13e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2468         |\n",
      "|    iterations           | 522          |\n",
      "|    time_elapsed         | 3464         |\n",
      "|    total_timesteps      | 8552448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024736044 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0181       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.58e+03     |\n",
      "|    n_updates            | 19680        |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    value_loss           | 3.07e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8560000, episode_reward=775.60 +/- 111.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 776          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025330617 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.51        |\n",
      "|    explained_variance   | 0.0611       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 19690        |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    value_loss           | 2.76e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2464    |\n",
      "|    iterations      | 523     |\n",
      "|    time_elapsed    | 3476    |\n",
      "|    total_timesteps | 8568832 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2464         |\n",
      "|    iterations           | 524          |\n",
      "|    time_elapsed         | 3483         |\n",
      "|    total_timesteps      | 8585216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022563643 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.00576      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.57e+03     |\n",
      "|    n_updates            | 19700        |\n",
      "|    policy_gradient_loss | -0.00534     |\n",
      "|    value_loss           | 2.98e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2464         |\n",
      "|    iterations           | 525          |\n",
      "|    time_elapsed         | 3489         |\n",
      "|    total_timesteps      | 8601600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024461886 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.0382       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.56e+03     |\n",
      "|    n_updates            | 19710        |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    value_loss           | 2.89e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2465         |\n",
      "|    iterations           | 526          |\n",
      "|    time_elapsed         | 3495         |\n",
      "|    total_timesteps      | 8617984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024047093 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.0273       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.58e+03     |\n",
      "|    n_updates            | 19720        |\n",
      "|    policy_gradient_loss | -0.00628     |\n",
      "|    value_loss           | 3.09e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2465         |\n",
      "|    iterations           | 527          |\n",
      "|    time_elapsed         | 3501         |\n",
      "|    total_timesteps      | 8634368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026902077 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.0427       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 830          |\n",
      "|    n_updates            | 19730        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    value_loss           | 3.03e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8640000, episode_reward=776.00 +/- 85.56\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 776          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8640000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029577762 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0277       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.01e+03     |\n",
      "|    n_updates            | 19740        |\n",
      "|    policy_gradient_loss | -0.00693     |\n",
      "|    value_loss           | 3e+03        |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2463    |\n",
      "|    iterations      | 528     |\n",
      "|    time_elapsed    | 3512    |\n",
      "|    total_timesteps | 8650752 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2463         |\n",
      "|    iterations           | 529          |\n",
      "|    time_elapsed         | 3518         |\n",
      "|    total_timesteps      | 8667136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025099271 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.0478       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.4e+03      |\n",
      "|    n_updates            | 19750        |\n",
      "|    policy_gradient_loss | -0.00624     |\n",
      "|    value_loss           | 3e+03        |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 2464     |\n",
      "|    iterations           | 530      |\n",
      "|    time_elapsed         | 3523     |\n",
      "|    total_timesteps      | 8683520  |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.00256  |\n",
      "|    clip_fraction        | 0.0171   |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -0.503   |\n",
      "|    explained_variance   | 0.0452   |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 1.64e+03 |\n",
      "|    n_updates            | 19760    |\n",
      "|    policy_gradient_loss | -0.00657 |\n",
      "|    value_loss           | 2.96e+03 |\n",
      "--------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2464         |\n",
      "|    iterations           | 531          |\n",
      "|    time_elapsed         | 3529         |\n",
      "|    total_timesteps      | 8699904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023509138 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.0557       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.56e+03     |\n",
      "|    n_updates            | 19770        |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    value_loss           | 3.25e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2465         |\n",
      "|    iterations           | 532          |\n",
      "|    time_elapsed         | 3535         |\n",
      "|    total_timesteps      | 8716288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025067804 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.0812       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.69e+03     |\n",
      "|    n_updates            | 19780        |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    value_loss           | 3.07e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8720000, episode_reward=785.20 +/- 123.81\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 785          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 8720000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026413184 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0657       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.55e+03     |\n",
      "|    n_updates            | 19790        |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    value_loss           | 3.17e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2461    |\n",
      "|    iterations      | 533     |\n",
      "|    time_elapsed    | 3547    |\n",
      "|    total_timesteps | 8732672 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2462         |\n",
      "|    iterations           | 534          |\n",
      "|    time_elapsed         | 3553         |\n",
      "|    total_timesteps      | 8749056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026603835 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.0477       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 19800        |\n",
      "|    policy_gradient_loss | -0.0062      |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2462         |\n",
      "|    iterations           | 535          |\n",
      "|    time_elapsed         | 3559         |\n",
      "|    total_timesteps      | 8765440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024257973 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.027        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.91e+03     |\n",
      "|    n_updates            | 19810        |\n",
      "|    policy_gradient_loss | -0.00608     |\n",
      "|    value_loss           | 3.29e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2461         |\n",
      "|    iterations           | 536          |\n",
      "|    time_elapsed         | 3567         |\n",
      "|    total_timesteps      | 8781824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024978658 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.0665       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 19820        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2462         |\n",
      "|    iterations           | 537          |\n",
      "|    time_elapsed         | 3573         |\n",
      "|    total_timesteps      | 8798208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025360477 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.0334       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.23e+03     |\n",
      "|    n_updates            | 19830        |\n",
      "|    policy_gradient_loss | -0.00628     |\n",
      "|    value_loss           | 3.01e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8800000, episode_reward=809.20 +/- 92.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 200        |\n",
      "|    mean_reward          | 809        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 8800000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00248026 |\n",
      "|    clip_fraction        | 0.02       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.493     |\n",
      "|    explained_variance   | 0.00886    |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.32e+03   |\n",
      "|    n_updates            | 19840      |\n",
      "|    policy_gradient_loss | -0.00664   |\n",
      "|    value_loss           | 2.76e+03   |\n",
      "----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2459    |\n",
      "|    iterations      | 538     |\n",
      "|    time_elapsed    | 3584    |\n",
      "|    total_timesteps | 8814592 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2459         |\n",
      "|    iterations           | 539          |\n",
      "|    time_elapsed         | 3590         |\n",
      "|    total_timesteps      | 8830976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027658232 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.047        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 19850        |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    value_loss           | 3.17e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2459        |\n",
      "|    iterations           | 540         |\n",
      "|    time_elapsed         | 3597        |\n",
      "|    total_timesteps      | 8847360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002511853 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.489      |\n",
      "|    explained_variance   | 0.0567      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.55e+03    |\n",
      "|    n_updates            | 19860       |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    value_loss           | 2.9e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2459         |\n",
      "|    iterations           | 541          |\n",
      "|    time_elapsed         | 3603         |\n",
      "|    total_timesteps      | 8863744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026639942 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0131       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.57e+03     |\n",
      "|    n_updates            | 19870        |\n",
      "|    policy_gradient_loss | -0.00695     |\n",
      "|    value_loss           | 3.06e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8880000, episode_reward=800.40 +/- 118.64\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 200        |\n",
      "|    mean_reward          | 800        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 8880000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00240546 |\n",
      "|    clip_fraction        | 0.014      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.502     |\n",
      "|    explained_variance   | 0.0476     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.56e+03   |\n",
      "|    n_updates            | 19880      |\n",
      "|    policy_gradient_loss | -0.00587   |\n",
      "|    value_loss           | 2.96e+03   |\n",
      "----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2456    |\n",
      "|    iterations      | 542     |\n",
      "|    time_elapsed    | 3615    |\n",
      "|    total_timesteps | 8880128 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2456        |\n",
      "|    iterations           | 543         |\n",
      "|    time_elapsed         | 3621        |\n",
      "|    total_timesteps      | 8896512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002403472 |\n",
      "|    clip_fraction        | 0.0153      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.494      |\n",
      "|    explained_variance   | 0.00817     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.58e+03    |\n",
      "|    n_updates            | 19890       |\n",
      "|    policy_gradient_loss | -0.00606    |\n",
      "|    value_loss           | 3.1e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2456        |\n",
      "|    iterations           | 544         |\n",
      "|    time_elapsed         | 3628        |\n",
      "|    total_timesteps      | 8912896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002911284 |\n",
      "|    clip_fraction        | 0.019       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.496      |\n",
      "|    explained_variance   | 0.0621      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.67e+03    |\n",
      "|    n_updates            | 19900       |\n",
      "|    policy_gradient_loss | -0.00712    |\n",
      "|    value_loss           | 3.03e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2457         |\n",
      "|    iterations           | 545          |\n",
      "|    time_elapsed         | 3634         |\n",
      "|    total_timesteps      | 8929280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025872923 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.0519       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 974          |\n",
      "|    n_updates            | 19910        |\n",
      "|    policy_gradient_loss | -0.00631     |\n",
      "|    value_loss           | 2.7e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2457         |\n",
      "|    iterations           | 546          |\n",
      "|    time_elapsed         | 3640         |\n",
      "|    total_timesteps      | 8945664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025708757 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.032        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.32e+03     |\n",
      "|    n_updates            | 19920        |\n",
      "|    policy_gradient_loss | -0.0064      |\n",
      "|    value_loss           | 2.98e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=8960000, episode_reward=758.00 +/- 113.84\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 758         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 8960000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002991545 |\n",
      "|    clip_fraction        | 0.0207      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.495      |\n",
      "|    explained_variance   | 0.0385      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.18e+03    |\n",
      "|    n_updates            | 19930       |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    value_loss           | 2.97e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2453    |\n",
      "|    iterations      | 547     |\n",
      "|    time_elapsed    | 3652    |\n",
      "|    total_timesteps | 8962048 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2454         |\n",
      "|    iterations           | 548          |\n",
      "|    time_elapsed         | 3658         |\n",
      "|    total_timesteps      | 8978432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027849157 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.0321       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.44e+03     |\n",
      "|    n_updates            | 19940        |\n",
      "|    policy_gradient_loss | -0.00696     |\n",
      "|    value_loss           | 2.92e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2454         |\n",
      "|    iterations           | 549          |\n",
      "|    time_elapsed         | 3664         |\n",
      "|    total_timesteps      | 8994816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026811485 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0539       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 19950        |\n",
      "|    policy_gradient_loss | -0.0069      |\n",
      "|    value_loss           | 3.1e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2454        |\n",
      "|    iterations           | 550         |\n",
      "|    time_elapsed         | 3670        |\n",
      "|    total_timesteps      | 9011200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002509404 |\n",
      "|    clip_fraction        | 0.015       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.496      |\n",
      "|    explained_variance   | 0.0485      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 983         |\n",
      "|    n_updates            | 19960       |\n",
      "|    policy_gradient_loss | -0.00674    |\n",
      "|    value_loss           | 2.97e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2455         |\n",
      "|    iterations           | 551          |\n",
      "|    time_elapsed         | 3676         |\n",
      "|    total_timesteps      | 9027584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021486622 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.065        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.44e+03     |\n",
      "|    n_updates            | 19970        |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    value_loss           | 3.14e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9040000, episode_reward=809.60 +/- 91.10\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 810          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9040000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028455607 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.0848       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 19980        |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2452    |\n",
      "|    iterations      | 552     |\n",
      "|    time_elapsed    | 3688    |\n",
      "|    total_timesteps | 9043968 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2452         |\n",
      "|    iterations           | 553          |\n",
      "|    time_elapsed         | 3693         |\n",
      "|    total_timesteps      | 9060352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028057038 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0648       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.4e+03      |\n",
      "|    n_updates            | 19990        |\n",
      "|    policy_gradient_loss | -0.006       |\n",
      "|    value_loss           | 2.97e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2453         |\n",
      "|    iterations           | 554          |\n",
      "|    time_elapsed         | 3699         |\n",
      "|    total_timesteps      | 9076736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025403302 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.0352       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.59e+03     |\n",
      "|    n_updates            | 20000        |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    value_loss           | 2.93e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2453        |\n",
      "|    iterations           | 555         |\n",
      "|    time_elapsed         | 3705        |\n",
      "|    total_timesteps      | 9093120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002776064 |\n",
      "|    clip_fraction        | 0.0159      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.491      |\n",
      "|    explained_variance   | 0.0506      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.7e+03     |\n",
      "|    n_updates            | 20010       |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    value_loss           | 2.99e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2454         |\n",
      "|    iterations           | 556          |\n",
      "|    time_elapsed         | 3711         |\n",
      "|    total_timesteps      | 9109504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020510228 |\n",
      "|    clip_fraction        | 0.00997      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0453       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 988          |\n",
      "|    n_updates            | 20020        |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    value_loss           | 3.16e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9120000, episode_reward=795.20 +/- 128.75\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 795          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024110037 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.0289       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 20030        |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    value_loss           | 3.03e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2451    |\n",
      "|    iterations      | 557     |\n",
      "|    time_elapsed    | 3723    |\n",
      "|    total_timesteps | 9125888 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2451         |\n",
      "|    iterations           | 558          |\n",
      "|    time_elapsed         | 3729         |\n",
      "|    total_timesteps      | 9142272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026376673 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.067        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.43e+03     |\n",
      "|    n_updates            | 20040        |\n",
      "|    policy_gradient_loss | -0.00622     |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2451        |\n",
      "|    iterations           | 559         |\n",
      "|    time_elapsed         | 3735        |\n",
      "|    total_timesteps      | 9158656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002518266 |\n",
      "|    clip_fraction        | 0.0155      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.495      |\n",
      "|    explained_variance   | 0.0729      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.11e+03    |\n",
      "|    n_updates            | 20050       |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    value_loss           | 2.92e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2452        |\n",
      "|    iterations           | 560         |\n",
      "|    time_elapsed         | 3741        |\n",
      "|    total_timesteps      | 9175040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002749182 |\n",
      "|    clip_fraction        | 0.0169      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.497      |\n",
      "|    explained_variance   | 0.0354      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.62e+03    |\n",
      "|    n_updates            | 20060       |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    value_loss           | 3.27e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2452         |\n",
      "|    iterations           | 561          |\n",
      "|    time_elapsed         | 3747         |\n",
      "|    total_timesteps      | 9191424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026808437 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0383       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.79e+03     |\n",
      "|    n_updates            | 20070        |\n",
      "|    policy_gradient_loss | -0.00621     |\n",
      "|    value_loss           | 3.14e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9200000, episode_reward=736.00 +/- 92.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 736         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 9200000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002619287 |\n",
      "|    clip_fraction        | 0.0154      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.515      |\n",
      "|    explained_variance   | 0.0694      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.68e+03    |\n",
      "|    n_updates            | 20080       |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    value_loss           | 2.96e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2449    |\n",
      "|    iterations      | 562     |\n",
      "|    time_elapsed    | 3758    |\n",
      "|    total_timesteps | 9207808 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2450        |\n",
      "|    iterations           | 563         |\n",
      "|    time_elapsed         | 3764        |\n",
      "|    total_timesteps      | 9224192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002879849 |\n",
      "|    clip_fraction        | 0.02        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.516      |\n",
      "|    explained_variance   | 0.0247      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.64e+03    |\n",
      "|    n_updates            | 20090       |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    value_loss           | 2.99e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2450         |\n",
      "|    iterations           | 564          |\n",
      "|    time_elapsed         | 3770         |\n",
      "|    total_timesteps      | 9240576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019522314 |\n",
      "|    clip_fraction        | 0.00991      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.063        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 20100        |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    value_loss           | 3.03e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2451         |\n",
      "|    iterations           | 565          |\n",
      "|    time_elapsed         | 3776         |\n",
      "|    total_timesteps      | 9256960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028873985 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | -0.00527     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.78e+03     |\n",
      "|    n_updates            | 20110        |\n",
      "|    policy_gradient_loss | -0.00638     |\n",
      "|    value_loss           | 2.91e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2451        |\n",
      "|    iterations           | 566         |\n",
      "|    time_elapsed         | 3781        |\n",
      "|    total_timesteps      | 9273344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002682066 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.51       |\n",
      "|    explained_variance   | 0.0449      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.76e+03    |\n",
      "|    n_updates            | 20120       |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    value_loss           | 2.87e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=9280000, episode_reward=763.20 +/- 82.64\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 763          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022359933 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.0495       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 20130        |\n",
      "|    policy_gradient_loss | -0.00533     |\n",
      "|    value_loss           | 3.04e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2449    |\n",
      "|    iterations      | 567     |\n",
      "|    time_elapsed    | 3793    |\n",
      "|    total_timesteps | 9289728 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2449         |\n",
      "|    iterations           | 568          |\n",
      "|    time_elapsed         | 3798         |\n",
      "|    total_timesteps      | 9306112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024035922 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.047        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.87e+03     |\n",
      "|    n_updates            | 20140        |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    value_loss           | 3.18e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2450         |\n",
      "|    iterations           | 569          |\n",
      "|    time_elapsed         | 3804         |\n",
      "|    total_timesteps      | 9322496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026773224 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0424       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.39e+03     |\n",
      "|    n_updates            | 20150        |\n",
      "|    policy_gradient_loss | -0.00647     |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2450         |\n",
      "|    iterations           | 570          |\n",
      "|    time_elapsed         | 3810         |\n",
      "|    total_timesteps      | 9338880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027086763 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.00234      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.18e+03     |\n",
      "|    n_updates            | 20160        |\n",
      "|    policy_gradient_loss | -0.00663     |\n",
      "|    value_loss           | 2.89e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2451         |\n",
      "|    iterations           | 571          |\n",
      "|    time_elapsed         | 3816         |\n",
      "|    total_timesteps      | 9355264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025894167 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.065        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.46e+03     |\n",
      "|    n_updates            | 20170        |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9360000, episode_reward=793.60 +/- 111.85\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 794          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9360000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030400897 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.0275       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.65e+03     |\n",
      "|    n_updates            | 20180        |\n",
      "|    policy_gradient_loss | -0.00616     |\n",
      "|    value_loss           | 3.16e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2448    |\n",
      "|    iterations      | 572     |\n",
      "|    time_elapsed    | 3827    |\n",
      "|    total_timesteps | 9371648 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2449         |\n",
      "|    iterations           | 573          |\n",
      "|    time_elapsed         | 3833         |\n",
      "|    total_timesteps      | 9388032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026566205 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0624       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.56e+03     |\n",
      "|    n_updates            | 20190        |\n",
      "|    policy_gradient_loss | -0.00687     |\n",
      "|    value_loss           | 3.06e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2449         |\n",
      "|    iterations           | 574          |\n",
      "|    time_elapsed         | 3838         |\n",
      "|    total_timesteps      | 9404416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028553186 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.0463       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.47e+03     |\n",
      "|    n_updates            | 20200        |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    value_loss           | 2.94e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2450         |\n",
      "|    iterations           | 575          |\n",
      "|    time_elapsed         | 3844         |\n",
      "|    total_timesteps      | 9420800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024279617 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.51        |\n",
      "|    explained_variance   | 0.0435       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.21e+03     |\n",
      "|    n_updates            | 20210        |\n",
      "|    policy_gradient_loss | -0.00583     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2450         |\n",
      "|    iterations           | 576          |\n",
      "|    time_elapsed         | 3850         |\n",
      "|    total_timesteps      | 9437184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026572407 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | -0.00308     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.56e+03     |\n",
      "|    n_updates            | 20220        |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    value_loss           | 3.19e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9440000, episode_reward=742.40 +/- 93.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 742          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9440000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026502274 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | 0.0244       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 20230        |\n",
      "|    policy_gradient_loss | -0.00662     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2448    |\n",
      "|    iterations      | 577     |\n",
      "|    time_elapsed    | 3861    |\n",
      "|    total_timesteps | 9453568 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2448         |\n",
      "|    iterations           | 578          |\n",
      "|    time_elapsed         | 3867         |\n",
      "|    total_timesteps      | 9469952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028323776 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.0532       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.29e+03     |\n",
      "|    n_updates            | 20240        |\n",
      "|    policy_gradient_loss | -0.00644     |\n",
      "|    value_loss           | 2.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2449         |\n",
      "|    iterations           | 579          |\n",
      "|    time_elapsed         | 3873         |\n",
      "|    total_timesteps      | 9486336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028169625 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.0186       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.36e+03     |\n",
      "|    n_updates            | 20250        |\n",
      "|    policy_gradient_loss | -0.00655     |\n",
      "|    value_loss           | 2.93e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2449         |\n",
      "|    iterations           | 580          |\n",
      "|    time_elapsed         | 3879         |\n",
      "|    total_timesteps      | 9502720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025229082 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0429       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.56e+03     |\n",
      "|    n_updates            | 20260        |\n",
      "|    policy_gradient_loss | -0.0065      |\n",
      "|    value_loss           | 2.71e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2450        |\n",
      "|    iterations           | 581         |\n",
      "|    time_elapsed         | 3885        |\n",
      "|    total_timesteps      | 9519104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002797175 |\n",
      "|    clip_fraction        | 0.0193      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.505      |\n",
      "|    explained_variance   | 0.0416      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.59e+03    |\n",
      "|    n_updates            | 20270       |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    value_loss           | 3e+03       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=9520000, episode_reward=820.00 +/- 99.48\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 820          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9520000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024916586 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.51        |\n",
      "|    explained_variance   | 0.0409       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.33e+03     |\n",
      "|    n_updates            | 20280        |\n",
      "|    policy_gradient_loss | -0.00633     |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2447    |\n",
      "|    iterations      | 582     |\n",
      "|    time_elapsed    | 3896    |\n",
      "|    total_timesteps | 9535488 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2447         |\n",
      "|    iterations           | 583          |\n",
      "|    time_elapsed         | 3902         |\n",
      "|    total_timesteps      | 9551872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027993256 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0364       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 20290        |\n",
      "|    policy_gradient_loss | -0.00654     |\n",
      "|    value_loss           | 2.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2448         |\n",
      "|    iterations           | 584          |\n",
      "|    time_elapsed         | 3907         |\n",
      "|    total_timesteps      | 9568256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027224189 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.0704       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.19e+03     |\n",
      "|    n_updates            | 20300        |\n",
      "|    policy_gradient_loss | -0.00653     |\n",
      "|    value_loss           | 2.72e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2448        |\n",
      "|    iterations           | 585         |\n",
      "|    time_elapsed         | 3913        |\n",
      "|    total_timesteps      | 9584640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002593805 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.522      |\n",
      "|    explained_variance   | 0.00727     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.25e+03    |\n",
      "|    n_updates            | 20310       |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    value_loss           | 2.88e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=9600000, episode_reward=769.60 +/- 77.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 770         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 9600000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002149629 |\n",
      "|    clip_fraction        | 0.0112      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.503      |\n",
      "|    explained_variance   | 0.0746      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.26e+03    |\n",
      "|    n_updates            | 20320       |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    value_loss           | 2.9e+03     |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2446    |\n",
      "|    iterations      | 586     |\n",
      "|    time_elapsed    | 3924    |\n",
      "|    total_timesteps | 9601024 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2446         |\n",
      "|    iterations           | 587          |\n",
      "|    time_elapsed         | 3930         |\n",
      "|    total_timesteps      | 9617408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025784662 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.078        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 20330        |\n",
      "|    policy_gradient_loss | -0.00612     |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2447       |\n",
      "|    iterations           | 588        |\n",
      "|    time_elapsed         | 3936       |\n",
      "|    total_timesteps      | 9633792    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00258096 |\n",
      "|    clip_fraction        | 0.0151     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.503     |\n",
      "|    explained_variance   | 0.0647     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.14e+03   |\n",
      "|    n_updates            | 20340      |\n",
      "|    policy_gradient_loss | -0.00616   |\n",
      "|    value_loss           | 2.63e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2447        |\n",
      "|    iterations           | 589         |\n",
      "|    time_elapsed         | 3942        |\n",
      "|    total_timesteps      | 9650176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002616605 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.507      |\n",
      "|    explained_variance   | 0.0509      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.78e+03    |\n",
      "|    n_updates            | 20350       |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    value_loss           | 3.08e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2448         |\n",
      "|    iterations           | 590          |\n",
      "|    time_elapsed         | 3948         |\n",
      "|    total_timesteps      | 9666560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024939897 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.0691       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 997          |\n",
      "|    n_updates            | 20360        |\n",
      "|    policy_gradient_loss | -0.00619     |\n",
      "|    value_loss           | 2.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9680000, episode_reward=782.40 +/- 131.22\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 782         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 9680000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002410828 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.0904      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 20370       |\n",
      "|    policy_gradient_loss | -0.00588    |\n",
      "|    value_loss           | 2.64e+03    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2445    |\n",
      "|    iterations      | 591     |\n",
      "|    time_elapsed    | 3959    |\n",
      "|    total_timesteps | 9682944 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2446         |\n",
      "|    iterations           | 592          |\n",
      "|    time_elapsed         | 3965         |\n",
      "|    total_timesteps      | 9699328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025268188 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.526       |\n",
      "|    explained_variance   | 0.0669       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 20380        |\n",
      "|    policy_gradient_loss | -0.00702     |\n",
      "|    value_loss           | 2.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2446         |\n",
      "|    iterations           | 593          |\n",
      "|    time_elapsed         | 3971         |\n",
      "|    total_timesteps      | 9715712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024216878 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0312       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.5e+03      |\n",
      "|    n_updates            | 20390        |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    value_loss           | 2.93e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2447        |\n",
      "|    iterations           | 594         |\n",
      "|    time_elapsed         | 3977        |\n",
      "|    total_timesteps      | 9732096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002462655 |\n",
      "|    clip_fraction        | 0.0151      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.52       |\n",
      "|    explained_variance   | 0.036       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.23e+03    |\n",
      "|    n_updates            | 20400       |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    value_loss           | 2.39e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2447        |\n",
      "|    iterations           | 595         |\n",
      "|    time_elapsed         | 3983        |\n",
      "|    total_timesteps      | 9748480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002524681 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.514      |\n",
      "|    explained_variance   | 0.00865     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 20410       |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    value_loss           | 2.71e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=9760000, episode_reward=710.00 +/- 113.56\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 710          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9760000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021180012 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.0331       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.64e+03     |\n",
      "|    n_updates            | 20420        |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    value_loss           | 2.7e+03      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2444    |\n",
      "|    iterations      | 596     |\n",
      "|    time_elapsed    | 3994    |\n",
      "|    total_timesteps | 9764864 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2445         |\n",
      "|    iterations           | 597          |\n",
      "|    time_elapsed         | 4000         |\n",
      "|    total_timesteps      | 9781248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028059555 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.0443       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.4e+03      |\n",
      "|    n_updates            | 20430        |\n",
      "|    policy_gradient_loss | -0.00628     |\n",
      "|    value_loss           | 2.92e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2445         |\n",
      "|    iterations           | 598          |\n",
      "|    time_elapsed         | 4005         |\n",
      "|    total_timesteps      | 9797632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025504925 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0395       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 20440        |\n",
      "|    policy_gradient_loss | -0.00594     |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2446         |\n",
      "|    iterations           | 599          |\n",
      "|    time_elapsed         | 4011         |\n",
      "|    total_timesteps      | 9814016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031212159 |\n",
      "|    clip_fraction        | 0.023        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0631       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 20450        |\n",
      "|    policy_gradient_loss | -0.00706     |\n",
      "|    value_loss           | 2.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2446         |\n",
      "|    iterations           | 600          |\n",
      "|    time_elapsed         | 4017         |\n",
      "|    total_timesteps      | 9830400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024944572 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0327       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.85e+03     |\n",
      "|    n_updates            | 20460        |\n",
      "|    policy_gradient_loss | -0.00638     |\n",
      "|    value_loss           | 2.76e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9840000, episode_reward=728.00 +/- 99.80\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 728          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 9840000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025394529 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | 0.0575       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.43e+03     |\n",
      "|    n_updates            | 20470        |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    value_loss           | 2.83e+03     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2444    |\n",
      "|    iterations      | 601     |\n",
      "|    time_elapsed    | 4028    |\n",
      "|    total_timesteps | 9846784 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2444         |\n",
      "|    iterations           | 602          |\n",
      "|    time_elapsed         | 4034         |\n",
      "|    total_timesteps      | 9863168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029468136 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0393       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 20480        |\n",
      "|    policy_gradient_loss | -0.00659     |\n",
      "|    value_loss           | 2.62e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2445        |\n",
      "|    iterations           | 603         |\n",
      "|    time_elapsed         | 4040        |\n",
      "|    total_timesteps      | 9879552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002586672 |\n",
      "|    clip_fraction        | 0.0178      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.0421      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.09e+03    |\n",
      "|    n_updates            | 20490       |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    value_loss           | 2.7e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2445        |\n",
      "|    iterations           | 604         |\n",
      "|    time_elapsed         | 4045        |\n",
      "|    total_timesteps      | 9895936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002459946 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.512      |\n",
      "|    explained_variance   | 0.0279      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.3e+03     |\n",
      "|    n_updates            | 20500       |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    value_loss           | 2.64e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2446         |\n",
      "|    iterations           | 605          |\n",
      "|    time_elapsed         | 4051         |\n",
      "|    total_timesteps      | 9912320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021612886 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.0331       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 893          |\n",
      "|    n_updates            | 20510        |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    value_loss           | 2.73e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=9920000, episode_reward=793.60 +/- 112.57\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 200        |\n",
      "|    mean_reward          | 794        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 9920000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00235291 |\n",
      "|    clip_fraction        | 0.0128     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.506     |\n",
      "|    explained_variance   | 0.0596     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.6e+03    |\n",
      "|    n_updates            | 20520      |\n",
      "|    policy_gradient_loss | -0.00651   |\n",
      "|    value_loss           | 2.96e+03   |\n",
      "----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 2443    |\n",
      "|    iterations      | 606     |\n",
      "|    time_elapsed    | 4062    |\n",
      "|    total_timesteps | 9928704 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2444         |\n",
      "|    iterations           | 607          |\n",
      "|    time_elapsed         | 4068         |\n",
      "|    total_timesteps      | 9945088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022541988 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.12         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.54e+03     |\n",
      "|    n_updates            | 20530        |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    value_loss           | 2.74e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2445        |\n",
      "|    iterations           | 608         |\n",
      "|    time_elapsed         | 4073        |\n",
      "|    total_timesteps      | 9961472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002734167 |\n",
      "|    clip_fraction        | 0.0176      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.499      |\n",
      "|    explained_variance   | 0.0236      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.25e+03    |\n",
      "|    n_updates            | 20540       |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    value_loss           | 2.71e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2445         |\n",
      "|    iterations           | 609          |\n",
      "|    time_elapsed         | 4079         |\n",
      "|    total_timesteps      | 9977856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027879141 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0677       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.39e+03     |\n",
      "|    n_updates            | 20550        |\n",
      "|    policy_gradient_loss | -0.00634     |\n",
      "|    value_loss           | 2.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2446         |\n",
      "|    iterations           | 610          |\n",
      "|    time_elapsed         | 4085         |\n",
      "|    total_timesteps      | 9994240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026233508 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0509       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 20560        |\n",
      "|    policy_gradient_loss | -0.00609     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10000000, episode_reward=759.20 +/- 105.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 759          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10000000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028942977 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0454       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 20570        |\n",
      "|    policy_gradient_loss | -0.00654     |\n",
      "|    value_loss           | 2.96e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2443     |\n",
      "|    iterations      | 611      |\n",
      "|    time_elapsed    | 4096     |\n",
      "|    total_timesteps | 10010624 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2444        |\n",
      "|    iterations           | 612         |\n",
      "|    time_elapsed         | 4102        |\n",
      "|    total_timesteps      | 10027008    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002496725 |\n",
      "|    clip_fraction        | 0.0149      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.505      |\n",
      "|    explained_variance   | 0.0103      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.26e+03    |\n",
      "|    n_updates            | 20580       |\n",
      "|    policy_gradient_loss | -0.00641    |\n",
      "|    value_loss           | 2.93e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2444         |\n",
      "|    iterations           | 613          |\n",
      "|    time_elapsed         | 4108         |\n",
      "|    total_timesteps      | 10043392     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026582242 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.0696       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.36e+03     |\n",
      "|    n_updates            | 20590        |\n",
      "|    policy_gradient_loss | -0.00636     |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2444         |\n",
      "|    iterations           | 614          |\n",
      "|    time_elapsed         | 4115         |\n",
      "|    total_timesteps      | 10059776     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028383469 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0401       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 20600        |\n",
      "|    policy_gradient_loss | -0.00637     |\n",
      "|    value_loss           | 3.05e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2444         |\n",
      "|    iterations           | 615          |\n",
      "|    time_elapsed         | 4121         |\n",
      "|    total_timesteps      | 10076160     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024262744 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.00466      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 20610        |\n",
      "|    policy_gradient_loss | -0.00589     |\n",
      "|    value_loss           | 3.03e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10080000, episode_reward=723.60 +/- 106.43\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 724          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10080000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028253256 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.0701       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 20620        |\n",
      "|    policy_gradient_loss | -0.00637     |\n",
      "|    value_loss           | 2.84e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2442     |\n",
      "|    iterations      | 616      |\n",
      "|    time_elapsed    | 4132     |\n",
      "|    total_timesteps | 10092544 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2442         |\n",
      "|    iterations           | 617          |\n",
      "|    time_elapsed         | 4138         |\n",
      "|    total_timesteps      | 10108928     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022360915 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.0311       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 20630        |\n",
      "|    policy_gradient_loss | -0.00572     |\n",
      "|    value_loss           | 2.96e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2442         |\n",
      "|    iterations           | 618          |\n",
      "|    time_elapsed         | 4144         |\n",
      "|    total_timesteps      | 10125312     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023309526 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0513       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 20640        |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    value_loss           | 3.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2443         |\n",
      "|    iterations           | 619          |\n",
      "|    time_elapsed         | 4150         |\n",
      "|    total_timesteps      | 10141696     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025300104 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.00594      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 20650        |\n",
      "|    policy_gradient_loss | -0.00671     |\n",
      "|    value_loss           | 2.93e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2443        |\n",
      "|    iterations           | 620         |\n",
      "|    time_elapsed         | 4156        |\n",
      "|    total_timesteps      | 10158080    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002750143 |\n",
      "|    clip_fraction        | 0.0173      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.503      |\n",
      "|    explained_variance   | 0.0393      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.29e+03    |\n",
      "|    n_updates            | 20660       |\n",
      "|    policy_gradient_loss | -0.00639    |\n",
      "|    value_loss           | 2.83e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10160000, episode_reward=800.40 +/- 83.02\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 800          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10160000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023067354 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0254       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 20670        |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    value_loss           | 2.94e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2440     |\n",
      "|    iterations      | 621      |\n",
      "|    time_elapsed    | 4168     |\n",
      "|    total_timesteps | 10174464 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2441         |\n",
      "|    iterations           | 622          |\n",
      "|    time_elapsed         | 4174         |\n",
      "|    total_timesteps      | 10190848     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021979506 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0262       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.43e+03     |\n",
      "|    n_updates            | 20680        |\n",
      "|    policy_gradient_loss | -0.00575     |\n",
      "|    value_loss           | 3.04e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2441        |\n",
      "|    iterations           | 623         |\n",
      "|    time_elapsed         | 4181        |\n",
      "|    total_timesteps      | 10207232    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003015168 |\n",
      "|    clip_fraction        | 0.0207      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.509      |\n",
      "|    explained_variance   | 0.0451      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 20690       |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    value_loss           | 2.67e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2441         |\n",
      "|    iterations           | 624          |\n",
      "|    time_elapsed         | 4188         |\n",
      "|    total_timesteps      | 10223616     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029427668 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0484       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.34e+03     |\n",
      "|    n_updates            | 20700        |\n",
      "|    policy_gradient_loss | -0.00626     |\n",
      "|    value_loss           | 2.91e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10240000, episode_reward=812.00 +/- 115.13\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 812          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10240000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025128447 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0463       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.43e+03     |\n",
      "|    n_updates            | 20710        |\n",
      "|    policy_gradient_loss | -0.00616     |\n",
      "|    value_loss           | 2.96e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2438     |\n",
      "|    iterations      | 625      |\n",
      "|    time_elapsed    | 4199     |\n",
      "|    total_timesteps | 10240000 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2438        |\n",
      "|    iterations           | 626         |\n",
      "|    time_elapsed         | 4205        |\n",
      "|    total_timesteps      | 10256384    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002131505 |\n",
      "|    clip_fraction        | 0.0117      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.502      |\n",
      "|    explained_variance   | 0.0471      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 20720       |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    value_loss           | 3.17e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2439         |\n",
      "|    iterations           | 627          |\n",
      "|    time_elapsed         | 4211         |\n",
      "|    total_timesteps      | 10272768     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028693164 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0667       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.55e+03     |\n",
      "|    n_updates            | 20730        |\n",
      "|    policy_gradient_loss | -0.00713     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2439         |\n",
      "|    iterations           | 628          |\n",
      "|    time_elapsed         | 4217         |\n",
      "|    total_timesteps      | 10289152     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026781876 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.0282       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.54e+03     |\n",
      "|    n_updates            | 20740        |\n",
      "|    policy_gradient_loss | -0.00655     |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2439         |\n",
      "|    iterations           | 629          |\n",
      "|    time_elapsed         | 4223         |\n",
      "|    total_timesteps      | 10305536     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026413633 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.0779       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 20750        |\n",
      "|    policy_gradient_loss | -0.00608     |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10320000, episode_reward=766.80 +/- 114.15\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 767          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10320000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022213953 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.0307       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.76e+03     |\n",
      "|    n_updates            | 20760        |\n",
      "|    policy_gradient_loss | -0.00537     |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2437     |\n",
      "|    iterations      | 630      |\n",
      "|    time_elapsed    | 4234     |\n",
      "|    total_timesteps | 10321920 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2437         |\n",
      "|    iterations           | 631          |\n",
      "|    time_elapsed         | 4240         |\n",
      "|    total_timesteps      | 10338304     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024293433 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.0468       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 20770        |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    value_loss           | 3.06e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2438         |\n",
      "|    iterations           | 632          |\n",
      "|    time_elapsed         | 4246         |\n",
      "|    total_timesteps      | 10354688     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025796469 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.525       |\n",
      "|    explained_variance   | 0.0414       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 20780        |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    value_loss           | 2.92e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2438         |\n",
      "|    iterations           | 633          |\n",
      "|    time_elapsed         | 4252         |\n",
      "|    total_timesteps      | 10371072     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025315066 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.0405       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 20790        |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    value_loss           | 2.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2439         |\n",
      "|    iterations           | 634          |\n",
      "|    time_elapsed         | 4258         |\n",
      "|    total_timesteps      | 10387456     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028251037 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.044        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 20800        |\n",
      "|    policy_gradient_loss | -0.00678     |\n",
      "|    value_loss           | 2.74e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10400000, episode_reward=801.60 +/- 94.39\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 802         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10400000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002579874 |\n",
      "|    clip_fraction        | 0.0167      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.501      |\n",
      "|    explained_variance   | 0.0488      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.32e+03    |\n",
      "|    n_updates            | 20810       |\n",
      "|    policy_gradient_loss | -0.00664    |\n",
      "|    value_loss           | 3.14e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2436     |\n",
      "|    iterations      | 635      |\n",
      "|    time_elapsed    | 4269     |\n",
      "|    total_timesteps | 10403840 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2437         |\n",
      "|    iterations           | 636          |\n",
      "|    time_elapsed         | 4275         |\n",
      "|    total_timesteps      | 10420224     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024988172 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.0696       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 20820        |\n",
      "|    policy_gradient_loss | -0.0062      |\n",
      "|    value_loss           | 2.68e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2437         |\n",
      "|    iterations           | 637          |\n",
      "|    time_elapsed         | 4281         |\n",
      "|    total_timesteps      | 10436608     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028904951 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.519       |\n",
      "|    explained_variance   | 0.0783       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 20830        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    value_loss           | 2.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2438         |\n",
      "|    iterations           | 638          |\n",
      "|    time_elapsed         | 4287         |\n",
      "|    total_timesteps      | 10452992     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026937083 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0843       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 20840        |\n",
      "|    policy_gradient_loss | -0.00621     |\n",
      "|    value_loss           | 2.73e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2438        |\n",
      "|    iterations           | 639         |\n",
      "|    time_elapsed         | 4293        |\n",
      "|    total_timesteps      | 10469376    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002166189 |\n",
      "|    clip_fraction        | 0.0109      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.057       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.21e+03    |\n",
      "|    n_updates            | 20850       |\n",
      "|    policy_gradient_loss | -0.00556    |\n",
      "|    value_loss           | 3.11e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10480000, episode_reward=762.00 +/- 88.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 762          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10480000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026516928 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0484       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 20860        |\n",
      "|    policy_gradient_loss | -0.00626     |\n",
      "|    value_loss           | 2.89e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2436     |\n",
      "|    iterations      | 640      |\n",
      "|    time_elapsed    | 4304     |\n",
      "|    total_timesteps | 10485760 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2436        |\n",
      "|    iterations           | 641         |\n",
      "|    time_elapsed         | 4310        |\n",
      "|    total_timesteps      | 10502144    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002580739 |\n",
      "|    clip_fraction        | 0.0143      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.511      |\n",
      "|    explained_variance   | 0.0545      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.05e+03    |\n",
      "|    n_updates            | 20870       |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    value_loss           | 2.86e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2436         |\n",
      "|    iterations           | 642          |\n",
      "|    time_elapsed         | 4317         |\n",
      "|    total_timesteps      | 10518528     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022713465 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.0833       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 20880        |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    value_loss           | 2.82e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2436        |\n",
      "|    iterations           | 643         |\n",
      "|    time_elapsed         | 4324        |\n",
      "|    total_timesteps      | 10534912    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002912842 |\n",
      "|    clip_fraction        | 0.0206      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.508      |\n",
      "|    explained_variance   | 0.0484      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 20890       |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    value_loss           | 3.11e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2436       |\n",
      "|    iterations           | 644        |\n",
      "|    time_elapsed         | 4331       |\n",
      "|    total_timesteps      | 10551296   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00231406 |\n",
      "|    clip_fraction        | 0.0133     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.503     |\n",
      "|    explained_variance   | 0.0896     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.35e+03   |\n",
      "|    n_updates            | 20900      |\n",
      "|    policy_gradient_loss | -0.00557   |\n",
      "|    value_loss           | 2.77e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=10560000, episode_reward=758.00 +/- 95.29\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 758          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10560000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027238799 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0227       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.4e+03      |\n",
      "|    n_updates            | 20910        |\n",
      "|    policy_gradient_loss | -0.00633     |\n",
      "|    value_loss           | 3.02e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2432     |\n",
      "|    iterations      | 645      |\n",
      "|    time_elapsed    | 4343     |\n",
      "|    total_timesteps | 10567680 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2433        |\n",
      "|    iterations           | 646         |\n",
      "|    time_elapsed         | 4349        |\n",
      "|    total_timesteps      | 10584064    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002261181 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.513      |\n",
      "|    explained_variance   | 0.0979      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 20920       |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    value_loss           | 2.88e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2433         |\n",
      "|    iterations           | 647          |\n",
      "|    time_elapsed         | 4355         |\n",
      "|    total_timesteps      | 10600448     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029019173 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.0469       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.25e+03     |\n",
      "|    n_updates            | 20930        |\n",
      "|    policy_gradient_loss | -0.00668     |\n",
      "|    value_loss           | 3.05e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2433         |\n",
      "|    iterations           | 648          |\n",
      "|    time_elapsed         | 4361         |\n",
      "|    total_timesteps      | 10616832     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024105883 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0257       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 20940        |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    value_loss           | 2.96e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2434        |\n",
      "|    iterations           | 649         |\n",
      "|    time_elapsed         | 4368        |\n",
      "|    total_timesteps      | 10633216    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002544629 |\n",
      "|    clip_fraction        | 0.0161      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.0519      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.53e+03    |\n",
      "|    n_updates            | 20950       |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    value_loss           | 2.98e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10640000, episode_reward=757.60 +/- 97.91\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 758          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10640000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030179028 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.0198       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.37e+03     |\n",
      "|    n_updates            | 20960        |\n",
      "|    policy_gradient_loss | -0.00673     |\n",
      "|    value_loss           | 2.92e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2431     |\n",
      "|    iterations      | 650      |\n",
      "|    time_elapsed    | 4379     |\n",
      "|    total_timesteps | 10649600 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2432         |\n",
      "|    iterations           | 651          |\n",
      "|    time_elapsed         | 4385         |\n",
      "|    total_timesteps      | 10665984     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026192488 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | -0.000338    |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 20970        |\n",
      "|    policy_gradient_loss | -0.00641     |\n",
      "|    value_loss           | 3.1e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2432         |\n",
      "|    iterations           | 652          |\n",
      "|    time_elapsed         | 4391         |\n",
      "|    total_timesteps      | 10682368     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021142103 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0462       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.64e+03     |\n",
      "|    n_updates            | 20980        |\n",
      "|    policy_gradient_loss | -0.0055      |\n",
      "|    value_loss           | 3.02e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2433         |\n",
      "|    iterations           | 653          |\n",
      "|    time_elapsed         | 4397         |\n",
      "|    total_timesteps      | 10698752     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026766588 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.51        |\n",
      "|    explained_variance   | 0.0318       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.62e+03     |\n",
      "|    n_updates            | 20990        |\n",
      "|    policy_gradient_loss | -0.00662     |\n",
      "|    value_loss           | 2.92e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2433         |\n",
      "|    iterations           | 654          |\n",
      "|    time_elapsed         | 4402         |\n",
      "|    total_timesteps      | 10715136     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023661463 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.00164      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 21000        |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    value_loss           | 2.82e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10720000, episode_reward=800.80 +/- 108.44\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 801          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10720000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024723297 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0428       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.95e+03     |\n",
      "|    n_updates            | 21010        |\n",
      "|    policy_gradient_loss | -0.00601     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2431     |\n",
      "|    iterations      | 655      |\n",
      "|    time_elapsed    | 4413     |\n",
      "|    total_timesteps | 10731520 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2431         |\n",
      "|    iterations           | 656          |\n",
      "|    time_elapsed         | 4419         |\n",
      "|    total_timesteps      | 10747904     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023878706 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.0327       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 21020        |\n",
      "|    policy_gradient_loss | -0.00647     |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2432         |\n",
      "|    iterations           | 657          |\n",
      "|    time_elapsed         | 4425         |\n",
      "|    total_timesteps      | 10764288     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025112657 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0473       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.85e+03     |\n",
      "|    n_updates            | 21030        |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    value_loss           | 2.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2432         |\n",
      "|    iterations           | 658          |\n",
      "|    time_elapsed         | 4431         |\n",
      "|    total_timesteps      | 10780672     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024343615 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0597       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 21040        |\n",
      "|    policy_gradient_loss | -0.00599     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2432        |\n",
      "|    iterations           | 659         |\n",
      "|    time_elapsed         | 4438        |\n",
      "|    total_timesteps      | 10797056    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002312605 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.491      |\n",
      "|    explained_variance   | 0.027       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.44e+03    |\n",
      "|    n_updates            | 21050       |\n",
      "|    policy_gradient_loss | -0.00582    |\n",
      "|    value_loss           | 2.68e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=10800000, episode_reward=798.80 +/- 86.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 799          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10800000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025540162 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.489       |\n",
      "|    explained_variance   | 0.0301       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 21060        |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    value_loss           | 3.02e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2429     |\n",
      "|    iterations      | 660      |\n",
      "|    time_elapsed    | 4450     |\n",
      "|    total_timesteps | 10813440 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2430         |\n",
      "|    iterations           | 661          |\n",
      "|    time_elapsed         | 4455         |\n",
      "|    total_timesteps      | 10829824     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023122514 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.484       |\n",
      "|    explained_variance   | 0.00133      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.51e+03     |\n",
      "|    n_updates            | 21070        |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2430         |\n",
      "|    iterations           | 662          |\n",
      "|    time_elapsed         | 4461         |\n",
      "|    total_timesteps      | 10846208     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026672198 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.0677       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.25e+03     |\n",
      "|    n_updates            | 21080        |\n",
      "|    policy_gradient_loss | -0.00644     |\n",
      "|    value_loss           | 2.89e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2431         |\n",
      "|    iterations           | 663          |\n",
      "|    time_elapsed         | 4467         |\n",
      "|    total_timesteps      | 10862592     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022036862 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.485       |\n",
      "|    explained_variance   | 0.00863      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 21090        |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    value_loss           | 3.01e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2432         |\n",
      "|    iterations           | 664          |\n",
      "|    time_elapsed         | 4473         |\n",
      "|    total_timesteps      | 10878976     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025083688 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.481       |\n",
      "|    explained_variance   | 0.0287       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.5e+03      |\n",
      "|    n_updates            | 21100        |\n",
      "|    policy_gradient_loss | -0.00651     |\n",
      "|    value_loss           | 3.09e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10880000, episode_reward=784.40 +/- 82.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 784          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10880000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025222804 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.481       |\n",
      "|    explained_variance   | 0.0506       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.96e+03     |\n",
      "|    n_updates            | 21110        |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2429     |\n",
      "|    iterations      | 665      |\n",
      "|    time_elapsed    | 4484     |\n",
      "|    total_timesteps | 10895360 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2430         |\n",
      "|    iterations           | 666          |\n",
      "|    time_elapsed         | 4490         |\n",
      "|    total_timesteps      | 10911744     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025534448 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.484       |\n",
      "|    explained_variance   | 0.0323       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.44e+03     |\n",
      "|    n_updates            | 21120        |\n",
      "|    policy_gradient_loss | -0.00568     |\n",
      "|    value_loss           | 2.89e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2430        |\n",
      "|    iterations           | 667         |\n",
      "|    time_elapsed         | 4496        |\n",
      "|    total_timesteps      | 10928128    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002599583 |\n",
      "|    clip_fraction        | 0.0165      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.493      |\n",
      "|    explained_variance   | 0.0456      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 21130       |\n",
      "|    policy_gradient_loss | -0.00607    |\n",
      "|    value_loss           | 2.81e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2431         |\n",
      "|    iterations           | 668          |\n",
      "|    time_elapsed         | 4501         |\n",
      "|    total_timesteps      | 10944512     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022200355 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.472       |\n",
      "|    explained_variance   | 0.0519       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.23e+03     |\n",
      "|    n_updates            | 21140        |\n",
      "|    policy_gradient_loss | -0.00576     |\n",
      "|    value_loss           | 3.29e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=10960000, episode_reward=774.80 +/- 94.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 775          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10960000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022631697 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.0727       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 21150        |\n",
      "|    policy_gradient_loss | -0.00601     |\n",
      "|    value_loss           | 2.99e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2427     |\n",
      "|    iterations      | 669      |\n",
      "|    time_elapsed    | 4514     |\n",
      "|    total_timesteps | 10960896 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2428        |\n",
      "|    iterations           | 670         |\n",
      "|    time_elapsed         | 4520        |\n",
      "|    total_timesteps      | 10977280    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002374467 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.482      |\n",
      "|    explained_variance   | 0.0461      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 21160       |\n",
      "|    policy_gradient_loss | -0.00606    |\n",
      "|    value_loss           | 2.8e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2428         |\n",
      "|    iterations           | 671          |\n",
      "|    time_elapsed         | 4526         |\n",
      "|    total_timesteps      | 10993664     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027796724 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | 0.0367       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.71e+03     |\n",
      "|    n_updates            | 21170        |\n",
      "|    policy_gradient_loss | -0.00716     |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2428        |\n",
      "|    iterations           | 672         |\n",
      "|    time_elapsed         | 4533        |\n",
      "|    total_timesteps      | 11010048    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002252221 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.479      |\n",
      "|    explained_variance   | 0.0433      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.29e+03    |\n",
      "|    n_updates            | 21180       |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    value_loss           | 3.18e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2428         |\n",
      "|    iterations           | 673          |\n",
      "|    time_elapsed         | 4539         |\n",
      "|    total_timesteps      | 11026432     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023633903 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.483       |\n",
      "|    explained_variance   | 0.0408       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 21190        |\n",
      "|    policy_gradient_loss | -0.00612     |\n",
      "|    value_loss           | 3e+03        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11040000, episode_reward=800.40 +/- 107.87\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 800          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11040000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025314372 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.0721       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.74e+03     |\n",
      "|    n_updates            | 21200        |\n",
      "|    policy_gradient_loss | -0.00616     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2425     |\n",
      "|    iterations      | 674      |\n",
      "|    time_elapsed    | 4552     |\n",
      "|    total_timesteps | 11042816 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2426         |\n",
      "|    iterations           | 675          |\n",
      "|    time_elapsed         | 4558         |\n",
      "|    total_timesteps      | 11059200     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021706435 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.471       |\n",
      "|    explained_variance   | 0.0537       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.32e+03     |\n",
      "|    n_updates            | 21210        |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    value_loss           | 2.99e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2426         |\n",
      "|    iterations           | 676          |\n",
      "|    time_elapsed         | 4564         |\n",
      "|    total_timesteps      | 11075584     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024058442 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.0503       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 21220        |\n",
      "|    policy_gradient_loss | -0.00588     |\n",
      "|    value_loss           | 2.97e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2426         |\n",
      "|    iterations           | 677          |\n",
      "|    time_elapsed         | 4571         |\n",
      "|    total_timesteps      | 11091968     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024425155 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.481       |\n",
      "|    explained_variance   | 0.0277       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 21230        |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    value_loss           | 2.89e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2426        |\n",
      "|    iterations           | 678         |\n",
      "|    time_elapsed         | 4577        |\n",
      "|    total_timesteps      | 11108352    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002519694 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.48       |\n",
      "|    explained_variance   | 0.0498      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.74e+03    |\n",
      "|    n_updates            | 21240       |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    value_loss           | 3.05e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=11120000, episode_reward=774.00 +/- 83.14\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 774          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11120000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024434905 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.481       |\n",
      "|    explained_variance   | 0.0485       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.71e+03     |\n",
      "|    n_updates            | 21250        |\n",
      "|    policy_gradient_loss | -0.00606     |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2424     |\n",
      "|    iterations      | 679      |\n",
      "|    time_elapsed    | 4588     |\n",
      "|    total_timesteps | 11124736 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2424         |\n",
      "|    iterations           | 680          |\n",
      "|    time_elapsed         | 4594         |\n",
      "|    total_timesteps      | 11141120     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020781676 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.484       |\n",
      "|    explained_variance   | 0.0939       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 755          |\n",
      "|    n_updates            | 21260        |\n",
      "|    policy_gradient_loss | -0.00532     |\n",
      "|    value_loss           | 3.11e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2425         |\n",
      "|    iterations           | 681          |\n",
      "|    time_elapsed         | 4600         |\n",
      "|    total_timesteps      | 11157504     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028200245 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.477       |\n",
      "|    explained_variance   | 0.0329       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.89e+03     |\n",
      "|    n_updates            | 21270        |\n",
      "|    policy_gradient_loss | -0.00613     |\n",
      "|    value_loss           | 3.26e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2425         |\n",
      "|    iterations           | 682          |\n",
      "|    time_elapsed         | 4606         |\n",
      "|    total_timesteps      | 11173888     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023532787 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.0673       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.39e+03     |\n",
      "|    n_updates            | 21280        |\n",
      "|    policy_gradient_loss | -0.00554     |\n",
      "|    value_loss           | 3.09e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2426         |\n",
      "|    iterations           | 683          |\n",
      "|    time_elapsed         | 4612         |\n",
      "|    total_timesteps      | 11190272     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026968266 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.0342       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.36e+03     |\n",
      "|    n_updates            | 21290        |\n",
      "|    policy_gradient_loss | -0.00675     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11200000, episode_reward=758.00 +/- 102.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 758          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11200000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024394905 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.468       |\n",
      "|    explained_variance   | 0.0718       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.77e+03     |\n",
      "|    n_updates            | 21300        |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    value_loss           | 3.16e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2423     |\n",
      "|    iterations      | 684      |\n",
      "|    time_elapsed    | 4623     |\n",
      "|    total_timesteps | 11206656 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2424         |\n",
      "|    iterations           | 685          |\n",
      "|    time_elapsed         | 4629         |\n",
      "|    total_timesteps      | 11223040     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024413716 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.477       |\n",
      "|    explained_variance   | 0.0191       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 21310        |\n",
      "|    policy_gradient_loss | -0.00589     |\n",
      "|    value_loss           | 3.28e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2424         |\n",
      "|    iterations           | 686          |\n",
      "|    time_elapsed         | 4635         |\n",
      "|    total_timesteps      | 11239424     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023851935 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.0637       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.62e+03     |\n",
      "|    n_updates            | 21320        |\n",
      "|    policy_gradient_loss | -0.00664     |\n",
      "|    value_loss           | 3.04e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2425         |\n",
      "|    iterations           | 687          |\n",
      "|    time_elapsed         | 4641         |\n",
      "|    total_timesteps      | 11255808     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023998977 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.0496       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.49e+03     |\n",
      "|    n_updates            | 21330        |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    value_loss           | 3.16e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2425         |\n",
      "|    iterations           | 688          |\n",
      "|    time_elapsed         | 4646         |\n",
      "|    total_timesteps      | 11272192     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024540583 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | 0.0429       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.45e+03     |\n",
      "|    n_updates            | 21340        |\n",
      "|    policy_gradient_loss | -0.00585     |\n",
      "|    value_loss           | 3.14e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11280000, episode_reward=786.00 +/- 92.17\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 786          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11280000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026945411 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.47        |\n",
      "|    explained_variance   | 0.0221       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.25e+03     |\n",
      "|    n_updates            | 21350        |\n",
      "|    policy_gradient_loss | -0.00596     |\n",
      "|    value_loss           | 3.35e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2423     |\n",
      "|    iterations      | 689      |\n",
      "|    time_elapsed    | 4657     |\n",
      "|    total_timesteps | 11288576 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2424         |\n",
      "|    iterations           | 690          |\n",
      "|    time_elapsed         | 4663         |\n",
      "|    total_timesteps      | 11304960     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022236356 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.467       |\n",
      "|    explained_variance   | 0.0423       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.31e+03     |\n",
      "|    n_updates            | 21360        |\n",
      "|    policy_gradient_loss | -0.00529     |\n",
      "|    value_loss           | 3.08e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2424         |\n",
      "|    iterations           | 691          |\n",
      "|    time_elapsed         | 4669         |\n",
      "|    total_timesteps      | 11321344     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025365765 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.477       |\n",
      "|    explained_variance   | -0.00739     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 21370        |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    value_loss           | 3.12e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2425        |\n",
      "|    iterations           | 692         |\n",
      "|    time_elapsed         | 4674        |\n",
      "|    total_timesteps      | 11337728    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002337886 |\n",
      "|    clip_fraction        | 0.015       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.476      |\n",
      "|    explained_variance   | 0.0399      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 21380       |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    value_loss           | 3.01e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2425        |\n",
      "|    iterations           | 693         |\n",
      "|    time_elapsed         | 4680        |\n",
      "|    total_timesteps      | 11354112    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002407813 |\n",
      "|    clip_fraction        | 0.0152      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.471      |\n",
      "|    explained_variance   | 0.0457      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.53e+03    |\n",
      "|    n_updates            | 21390       |\n",
      "|    policy_gradient_loss | -0.00617    |\n",
      "|    value_loss           | 3.29e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=11360000, episode_reward=780.80 +/- 93.76\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 781          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11360000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024125066 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.477       |\n",
      "|    explained_variance   | 0.027        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.49e+03     |\n",
      "|    n_updates            | 21400        |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    value_loss           | 3.08e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2423     |\n",
      "|    iterations      | 694      |\n",
      "|    time_elapsed    | 4691     |\n",
      "|    total_timesteps | 11370496 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2424         |\n",
      "|    iterations           | 695          |\n",
      "|    time_elapsed         | 4696         |\n",
      "|    total_timesteps      | 11386880     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023911858 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.479       |\n",
      "|    explained_variance   | 0.0144       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.86e+03     |\n",
      "|    n_updates            | 21410        |\n",
      "|    policy_gradient_loss | -0.00568     |\n",
      "|    value_loss           | 2.97e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2424         |\n",
      "|    iterations           | 696          |\n",
      "|    time_elapsed         | 4702         |\n",
      "|    total_timesteps      | 11403264     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024778766 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.484       |\n",
      "|    explained_variance   | 0.0601       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.49e+03     |\n",
      "|    n_updates            | 21420        |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2425         |\n",
      "|    iterations           | 697          |\n",
      "|    time_elapsed         | 4708         |\n",
      "|    total_timesteps      | 11419648     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023982334 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.475       |\n",
      "|    explained_variance   | 0.0379       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.69e+03     |\n",
      "|    n_updates            | 21430        |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    value_loss           | 3.23e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2426         |\n",
      "|    iterations           | 698          |\n",
      "|    time_elapsed         | 4713         |\n",
      "|    total_timesteps      | 11436032     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021359618 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.483       |\n",
      "|    explained_variance   | 0.0416       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.32e+03     |\n",
      "|    n_updates            | 21440        |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    value_loss           | 2.97e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11440000, episode_reward=789.20 +/- 106.84\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 789          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11440000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022160271 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | 0.105        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 21450        |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    value_loss           | 3.02e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2424     |\n",
      "|    iterations      | 699      |\n",
      "|    time_elapsed    | 4724     |\n",
      "|    total_timesteps | 11452416 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2424        |\n",
      "|    iterations           | 700         |\n",
      "|    time_elapsed         | 4730        |\n",
      "|    total_timesteps      | 11468800    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002610128 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.486      |\n",
      "|    explained_variance   | 0.048       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.51e+03    |\n",
      "|    n_updates            | 21460       |\n",
      "|    policy_gradient_loss | -0.00597    |\n",
      "|    value_loss           | 2.89e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2425         |\n",
      "|    iterations           | 701          |\n",
      "|    time_elapsed         | 4736         |\n",
      "|    total_timesteps      | 11485184     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026517692 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0207       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 21470        |\n",
      "|    policy_gradient_loss | -0.00622     |\n",
      "|    value_loss           | 3.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2425         |\n",
      "|    iterations           | 702          |\n",
      "|    time_elapsed         | 4742         |\n",
      "|    total_timesteps      | 11501568     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021010502 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.484       |\n",
      "|    explained_variance   | 0.0389       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 21480        |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    value_loss           | 2.91e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2425         |\n",
      "|    iterations           | 703          |\n",
      "|    time_elapsed         | 4747         |\n",
      "|    total_timesteps      | 11517952     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024050886 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.0799       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.62e+03     |\n",
      "|    n_updates            | 21490        |\n",
      "|    policy_gradient_loss | -0.00619     |\n",
      "|    value_loss           | 2.93e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11520000, episode_reward=748.80 +/- 96.47\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 749          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11520000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023198954 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.0381       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 21500        |\n",
      "|    policy_gradient_loss | -0.00575     |\n",
      "|    value_loss           | 3.01e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2423     |\n",
      "|    iterations      | 704      |\n",
      "|    time_elapsed    | 4758     |\n",
      "|    total_timesteps | 11534336 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2424         |\n",
      "|    iterations           | 705          |\n",
      "|    time_elapsed         | 4764         |\n",
      "|    total_timesteps      | 11550720     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028539044 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.0394       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 21510        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2424         |\n",
      "|    iterations           | 706          |\n",
      "|    time_elapsed         | 4770         |\n",
      "|    total_timesteps      | 11567104     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027034353 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.0251       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.77e+03     |\n",
      "|    n_updates            | 21520        |\n",
      "|    policy_gradient_loss | -0.00619     |\n",
      "|    value_loss           | 3.3e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2425        |\n",
      "|    iterations           | 707         |\n",
      "|    time_elapsed         | 4775        |\n",
      "|    total_timesteps      | 11583488    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002279618 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.488      |\n",
      "|    explained_variance   | 0.0659      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.51e+03    |\n",
      "|    n_updates            | 21530       |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    value_loss           | 3.06e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2425         |\n",
      "|    iterations           | 708          |\n",
      "|    time_elapsed         | 4781         |\n",
      "|    total_timesteps      | 11599872     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027442512 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.485       |\n",
      "|    explained_variance   | -0.00688     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.51e+03     |\n",
      "|    n_updates            | 21540        |\n",
      "|    policy_gradient_loss | -0.00633     |\n",
      "|    value_loss           | 3.12e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11600000, episode_reward=795.60 +/- 121.79\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 796          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11600000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022945143 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.47        |\n",
      "|    explained_variance   | 0.0407       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.56e+03     |\n",
      "|    n_updates            | 21550        |\n",
      "|    policy_gradient_loss | -0.00608     |\n",
      "|    value_loss           | 3.01e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2423     |\n",
      "|    iterations      | 709      |\n",
      "|    time_elapsed    | 4792     |\n",
      "|    total_timesteps | 11616256 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2424         |\n",
      "|    iterations           | 710          |\n",
      "|    time_elapsed         | 4798         |\n",
      "|    total_timesteps      | 11632640     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024142335 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.0261       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.08e+03     |\n",
      "|    n_updates            | 21560        |\n",
      "|    policy_gradient_loss | -0.00627     |\n",
      "|    value_loss           | 3.23e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2424        |\n",
      "|    iterations           | 711         |\n",
      "|    time_elapsed         | 4804        |\n",
      "|    total_timesteps      | 11649024    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002594071 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.473      |\n",
      "|    explained_variance   | 0.0376      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.48e+03    |\n",
      "|    n_updates            | 21570       |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    value_loss           | 3.02e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2424         |\n",
      "|    iterations           | 712          |\n",
      "|    time_elapsed         | 4811         |\n",
      "|    total_timesteps      | 11665408     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028662132 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.475       |\n",
      "|    explained_variance   | 0.0214       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.32e+03     |\n",
      "|    n_updates            | 21580        |\n",
      "|    policy_gradient_loss | -0.00668     |\n",
      "|    value_loss           | 3.29e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11680000, episode_reward=816.00 +/- 113.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 816          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11680000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024843519 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.477       |\n",
      "|    explained_variance   | 0.0343       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.58e+03     |\n",
      "|    n_updates            | 21590        |\n",
      "|    policy_gradient_loss | -0.00612     |\n",
      "|    value_loss           | 3.09e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2422     |\n",
      "|    iterations      | 713      |\n",
      "|    time_elapsed    | 4822     |\n",
      "|    total_timesteps | 11681792 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2422         |\n",
      "|    iterations           | 714          |\n",
      "|    time_elapsed         | 4829         |\n",
      "|    total_timesteps      | 11698176     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025252118 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.481       |\n",
      "|    explained_variance   | 0.0373       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.54e+03     |\n",
      "|    n_updates            | 21600        |\n",
      "|    policy_gradient_loss | -0.0062      |\n",
      "|    value_loss           | 3.36e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2422         |\n",
      "|    iterations           | 715          |\n",
      "|    time_elapsed         | 4835         |\n",
      "|    total_timesteps      | 11714560     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022614214 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.0332       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.4e+03      |\n",
      "|    n_updates            | 21610        |\n",
      "|    policy_gradient_loss | -0.00609     |\n",
      "|    value_loss           | 3.16e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2422         |\n",
      "|    iterations           | 716          |\n",
      "|    time_elapsed         | 4842         |\n",
      "|    total_timesteps      | 11730944     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025385676 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.0136       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.67e+03     |\n",
      "|    n_updates            | 21620        |\n",
      "|    policy_gradient_loss | -0.00664     |\n",
      "|    value_loss           | 3.01e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2423         |\n",
      "|    iterations           | 717          |\n",
      "|    time_elapsed         | 4848         |\n",
      "|    total_timesteps      | 11747328     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026720432 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.485       |\n",
      "|    explained_variance   | 0.0665       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 21630        |\n",
      "|    policy_gradient_loss | -0.00631     |\n",
      "|    value_loss           | 2.96e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11760000, episode_reward=836.00 +/- 107.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 836          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11760000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019888245 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.0846       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.68e+03     |\n",
      "|    n_updates            | 21640        |\n",
      "|    policy_gradient_loss | -0.00512     |\n",
      "|    value_loss           | 3.32e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2420     |\n",
      "|    iterations      | 718      |\n",
      "|    time_elapsed    | 4859     |\n",
      "|    total_timesteps | 11763712 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2420         |\n",
      "|    iterations           | 719          |\n",
      "|    time_elapsed         | 4865         |\n",
      "|    total_timesteps      | 11780096     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024655205 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.469       |\n",
      "|    explained_variance   | 0.0651       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.32e+03     |\n",
      "|    n_updates            | 21650        |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    value_loss           | 3.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2420         |\n",
      "|    iterations           | 720          |\n",
      "|    time_elapsed         | 4872         |\n",
      "|    total_timesteps      | 11796480     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023204812 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | -0.00334     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 21660        |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    value_loss           | 2.94e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2421         |\n",
      "|    iterations           | 721          |\n",
      "|    time_elapsed         | 4878         |\n",
      "|    total_timesteps      | 11812864     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027151513 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.0446       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.9e+03      |\n",
      "|    n_updates            | 21670        |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    value_loss           | 3.13e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2421         |\n",
      "|    iterations           | 722          |\n",
      "|    time_elapsed         | 4884         |\n",
      "|    total_timesteps      | 11829248     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023897036 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.469       |\n",
      "|    explained_variance   | 0.0624       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 21680        |\n",
      "|    policy_gradient_loss | -0.00554     |\n",
      "|    value_loss           | 3.31e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=11840000, episode_reward=802.40 +/- 104.62\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 802          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11840000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024061678 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.473       |\n",
      "|    explained_variance   | 0.0126       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.46e+03     |\n",
      "|    n_updates            | 21690        |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    value_loss           | 2.91e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2419     |\n",
      "|    iterations      | 723      |\n",
      "|    time_elapsed    | 4895     |\n",
      "|    total_timesteps | 11845632 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2419         |\n",
      "|    iterations           | 724          |\n",
      "|    time_elapsed         | 4902         |\n",
      "|    total_timesteps      | 11862016     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023504584 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.47        |\n",
      "|    explained_variance   | 0.0312       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.4e+03      |\n",
      "|    n_updates            | 21700        |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    value_loss           | 2.99e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2420        |\n",
      "|    iterations           | 725         |\n",
      "|    time_elapsed         | 4908        |\n",
      "|    total_timesteps      | 11878400    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002527617 |\n",
      "|    clip_fraction        | 0.0173      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.477      |\n",
      "|    explained_variance   | 0.0683      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.51e+03    |\n",
      "|    n_updates            | 21710       |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    value_loss           | 3.11e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2420         |\n",
      "|    iterations           | 726          |\n",
      "|    time_elapsed         | 4914         |\n",
      "|    total_timesteps      | 11894784     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026642694 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.479       |\n",
      "|    explained_variance   | 0.0419       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.88e+03     |\n",
      "|    n_updates            | 21720        |\n",
      "|    policy_gradient_loss | -0.00628     |\n",
      "|    value_loss           | 3.24e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2421        |\n",
      "|    iterations           | 727         |\n",
      "|    time_elapsed         | 4919        |\n",
      "|    total_timesteps      | 11911168    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002278205 |\n",
      "|    clip_fraction        | 0.0138      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.478      |\n",
      "|    explained_variance   | 0.0762      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.49e+03    |\n",
      "|    n_updates            | 21730       |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    value_loss           | 3.04e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=11920000, episode_reward=797.60 +/- 105.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 798          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 11920000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023035146 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.0622       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 21740        |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    value_loss           | 3.1e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2418     |\n",
      "|    iterations      | 728      |\n",
      "|    time_elapsed    | 4931     |\n",
      "|    total_timesteps | 11927552 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2418         |\n",
      "|    iterations           | 729          |\n",
      "|    time_elapsed         | 4937         |\n",
      "|    total_timesteps      | 11943936     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027424356 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | 0.0552       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 21750        |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    value_loss           | 2.97e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2419         |\n",
      "|    iterations           | 730          |\n",
      "|    time_elapsed         | 4943         |\n",
      "|    total_timesteps      | 11960320     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023578631 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.0604       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.55e+03     |\n",
      "|    n_updates            | 21760        |\n",
      "|    policy_gradient_loss | -0.00633     |\n",
      "|    value_loss           | 2.98e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2419         |\n",
      "|    iterations           | 731          |\n",
      "|    time_elapsed         | 4949         |\n",
      "|    total_timesteps      | 11976704     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027710614 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.485       |\n",
      "|    explained_variance   | 0.0653       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.72e+03     |\n",
      "|    n_updates            | 21770        |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    value_loss           | 3.17e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2419         |\n",
      "|    iterations           | 732          |\n",
      "|    time_elapsed         | 4955         |\n",
      "|    total_timesteps      | 11993088     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023296145 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.489       |\n",
      "|    explained_variance   | 0.0304       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 21780        |\n",
      "|    policy_gradient_loss | -0.00558     |\n",
      "|    value_loss           | 3.13e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12000000, episode_reward=798.80 +/- 119.17\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 799          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12000000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023140428 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.485       |\n",
      "|    explained_variance   | 0.0564       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.62e+03     |\n",
      "|    n_updates            | 21790        |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    value_loss           | 2.93e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2417     |\n",
      "|    iterations      | 733      |\n",
      "|    time_elapsed    | 4967     |\n",
      "|    total_timesteps | 12009472 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2418         |\n",
      "|    iterations           | 734          |\n",
      "|    time_elapsed         | 4973         |\n",
      "|    total_timesteps      | 12025856     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023037842 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.0409       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.23e+03     |\n",
      "|    n_updates            | 21800        |\n",
      "|    policy_gradient_loss | -0.00601     |\n",
      "|    value_loss           | 2.99e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2418        |\n",
      "|    iterations           | 735         |\n",
      "|    time_elapsed         | 4979        |\n",
      "|    total_timesteps      | 12042240    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002086684 |\n",
      "|    clip_fraction        | 0.0119      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.502      |\n",
      "|    explained_variance   | -0.00889    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.13e+03    |\n",
      "|    n_updates            | 21810       |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    value_loss           | 3.33e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2418         |\n",
      "|    iterations           | 736          |\n",
      "|    time_elapsed         | 4985         |\n",
      "|    total_timesteps      | 12058624     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025001834 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.0259       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.13e+03     |\n",
      "|    n_updates            | 21820        |\n",
      "|    policy_gradient_loss | -0.00575     |\n",
      "|    value_loss           | 3.01e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2418         |\n",
      "|    iterations           | 737          |\n",
      "|    time_elapsed         | 4992         |\n",
      "|    total_timesteps      | 12075008     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027393769 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0446       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 21830        |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12080000, episode_reward=775.60 +/- 100.76\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 776          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12080000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022904794 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.0534       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.43e+03     |\n",
      "|    n_updates            | 21840        |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2416     |\n",
      "|    iterations      | 738      |\n",
      "|    time_elapsed    | 5003     |\n",
      "|    total_timesteps | 12091392 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2416        |\n",
      "|    iterations           | 739         |\n",
      "|    time_elapsed         | 5010        |\n",
      "|    total_timesteps      | 12107776    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002663058 |\n",
      "|    clip_fraction        | 0.0158      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.505      |\n",
      "|    explained_variance   | 0.0448      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.82e+03    |\n",
      "|    n_updates            | 21850       |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    value_loss           | 3.12e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2416         |\n",
      "|    iterations           | 740          |\n",
      "|    time_elapsed         | 5016         |\n",
      "|    total_timesteps      | 12124160     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026320228 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.00459      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.18e+03     |\n",
      "|    n_updates            | 21860        |\n",
      "|    policy_gradient_loss | -0.00645     |\n",
      "|    value_loss           | 2.99e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2417         |\n",
      "|    iterations           | 741          |\n",
      "|    time_elapsed         | 5022         |\n",
      "|    total_timesteps      | 12140544     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025565329 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.0462       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 21870        |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    value_loss           | 2.85e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2417         |\n",
      "|    iterations           | 742          |\n",
      "|    time_elapsed         | 5028         |\n",
      "|    total_timesteps      | 12156928     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027579037 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.0472       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.54e+03     |\n",
      "|    n_updates            | 21880        |\n",
      "|    policy_gradient_loss | -0.00648     |\n",
      "|    value_loss           | 3.06e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12160000, episode_reward=753.20 +/- 82.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 753          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12160000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021409057 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.0707       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 21890        |\n",
      "|    policy_gradient_loss | -0.00529     |\n",
      "|    value_loss           | 3.16e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2415     |\n",
      "|    iterations      | 743      |\n",
      "|    time_elapsed    | 5039     |\n",
      "|    total_timesteps | 12173312 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2415         |\n",
      "|    iterations           | 744          |\n",
      "|    time_elapsed         | 5045         |\n",
      "|    total_timesteps      | 12189696     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023792041 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.0511       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 21900        |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    value_loss           | 3.01e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2416         |\n",
      "|    iterations           | 745          |\n",
      "|    time_elapsed         | 5051         |\n",
      "|    total_timesteps      | 12206080     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025244732 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0288       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.47e+03     |\n",
      "|    n_updates            | 21910        |\n",
      "|    policy_gradient_loss | -0.00554     |\n",
      "|    value_loss           | 2.82e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2416         |\n",
      "|    iterations           | 746          |\n",
      "|    time_elapsed         | 5057         |\n",
      "|    total_timesteps      | 12222464     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024539935 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0693       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.57e+03     |\n",
      "|    n_updates            | 21920        |\n",
      "|    policy_gradient_loss | -0.00572     |\n",
      "|    value_loss           | 3.08e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2416        |\n",
      "|    iterations           | 747         |\n",
      "|    time_elapsed         | 5064        |\n",
      "|    total_timesteps      | 12238848    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002240002 |\n",
      "|    clip_fraction        | 0.0112      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.498      |\n",
      "|    explained_variance   | 0.0347      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.67e+03    |\n",
      "|    n_updates            | 21930       |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    value_loss           | 3.28e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=12240000, episode_reward=756.00 +/- 106.43\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 756          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12240000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026504572 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0461       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 21940        |\n",
      "|    policy_gradient_loss | -0.00621     |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2414     |\n",
      "|    iterations      | 748      |\n",
      "|    time_elapsed    | 5075     |\n",
      "|    total_timesteps | 12255232 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2415         |\n",
      "|    iterations           | 749          |\n",
      "|    time_elapsed         | 5081         |\n",
      "|    total_timesteps      | 12271616     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025518148 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0539       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.29e+03     |\n",
      "|    n_updates            | 21950        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2414         |\n",
      "|    iterations           | 750          |\n",
      "|    time_elapsed         | 5088         |\n",
      "|    total_timesteps      | 12288000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026212423 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.111        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.63e+03     |\n",
      "|    n_updates            | 21960        |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    value_loss           | 3.06e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2415         |\n",
      "|    iterations           | 751          |\n",
      "|    time_elapsed         | 5094         |\n",
      "|    total_timesteps      | 12304384     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024324632 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0493       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.37e+03     |\n",
      "|    n_updates            | 21970        |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    value_loss           | 3.04e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12320000, episode_reward=765.60 +/- 77.10\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 766          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12320000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019731421 |\n",
      "|    clip_fraction        | 0.01         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0395       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 21980        |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2413     |\n",
      "|    iterations      | 752      |\n",
      "|    time_elapsed    | 5105     |\n",
      "|    total_timesteps | 12320768 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2413         |\n",
      "|    iterations           | 753          |\n",
      "|    time_elapsed         | 5111         |\n",
      "|    total_timesteps      | 12337152     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022844053 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0437       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.76e+03     |\n",
      "|    n_updates            | 21990        |\n",
      "|    policy_gradient_loss | -0.00508     |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2413         |\n",
      "|    iterations           | 754          |\n",
      "|    time_elapsed         | 5117         |\n",
      "|    total_timesteps      | 12353536     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021209402 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.479       |\n",
      "|    explained_variance   | 0.059        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.62e+03     |\n",
      "|    n_updates            | 22000        |\n",
      "|    policy_gradient_loss | -0.00535     |\n",
      "|    value_loss           | 2.89e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2414       |\n",
      "|    iterations           | 755        |\n",
      "|    time_elapsed         | 5123       |\n",
      "|    total_timesteps      | 12369920   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00229761 |\n",
      "|    clip_fraction        | 0.0124     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.495     |\n",
      "|    explained_variance   | 0.0505     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.36e+03   |\n",
      "|    n_updates            | 22010      |\n",
      "|    policy_gradient_loss | -0.00586   |\n",
      "|    value_loss           | 3.11e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2414         |\n",
      "|    iterations           | 756          |\n",
      "|    time_elapsed         | 5129         |\n",
      "|    total_timesteps      | 12386304     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026624205 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0682       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.66e+03     |\n",
      "|    n_updates            | 22020        |\n",
      "|    policy_gradient_loss | -0.00626     |\n",
      "|    value_loss           | 3.07e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12400000, episode_reward=745.60 +/- 103.73\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 746          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12400000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030167876 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0671       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 942          |\n",
      "|    n_updates            | 22030        |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    value_loss           | 2.64e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2412     |\n",
      "|    iterations      | 757      |\n",
      "|    time_elapsed    | 5140     |\n",
      "|    total_timesteps | 12402688 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2412         |\n",
      "|    iterations           | 758          |\n",
      "|    time_elapsed         | 5147         |\n",
      "|    total_timesteps      | 12419072     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023709643 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.0448       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.62e+03     |\n",
      "|    n_updates            | 22040        |\n",
      "|    policy_gradient_loss | -0.00572     |\n",
      "|    value_loss           | 2.92e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2412         |\n",
      "|    iterations           | 759          |\n",
      "|    time_elapsed         | 5153         |\n",
      "|    total_timesteps      | 12435456     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027355466 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0534       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.77e+03     |\n",
      "|    n_updates            | 22050        |\n",
      "|    policy_gradient_loss | -0.00688     |\n",
      "|    value_loss           | 2.97e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2413        |\n",
      "|    iterations           | 760         |\n",
      "|    time_elapsed         | 5160        |\n",
      "|    total_timesteps      | 12451840    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002261364 |\n",
      "|    clip_fraction        | 0.0137      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.502      |\n",
      "|    explained_variance   | 0.0497      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.01e+03    |\n",
      "|    n_updates            | 22060       |\n",
      "|    policy_gradient_loss | -0.00561    |\n",
      "|    value_loss           | 3.08e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2413         |\n",
      "|    iterations           | 761          |\n",
      "|    time_elapsed         | 5166         |\n",
      "|    total_timesteps      | 12468224     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028153304 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.0607       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 22070        |\n",
      "|    policy_gradient_loss | -0.0068      |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12480000, episode_reward=779.60 +/- 113.72\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 780          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12480000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021979506 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | 0.0745       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 22080        |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2411     |\n",
      "|    iterations      | 762      |\n",
      "|    time_elapsed    | 5178     |\n",
      "|    total_timesteps | 12484608 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2411        |\n",
      "|    iterations           | 763         |\n",
      "|    time_elapsed         | 5184        |\n",
      "|    total_timesteps      | 12500992    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002295313 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.491      |\n",
      "|    explained_variance   | 0.0686      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 22090       |\n",
      "|    policy_gradient_loss | -0.0059     |\n",
      "|    value_loss           | 2.88e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2411         |\n",
      "|    iterations           | 764          |\n",
      "|    time_elapsed         | 5190         |\n",
      "|    total_timesteps      | 12517376     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024776768 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.0233       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.88e+03     |\n",
      "|    n_updates            | 22100        |\n",
      "|    policy_gradient_loss | -0.00579     |\n",
      "|    value_loss           | 2.91e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2411         |\n",
      "|    iterations           | 765          |\n",
      "|    time_elapsed         | 5196         |\n",
      "|    total_timesteps      | 12533760     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024702263 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0191       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.21e+03     |\n",
      "|    n_updates            | 22110        |\n",
      "|    policy_gradient_loss | -0.00613     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2412         |\n",
      "|    iterations           | 766          |\n",
      "|    time_elapsed         | 5202         |\n",
      "|    total_timesteps      | 12550144     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027772891 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0656       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 22120        |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    value_loss           | 2.83e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12560000, episode_reward=751.60 +/- 73.19\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 752          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12560000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024109588 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.0387       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 884          |\n",
      "|    n_updates            | 22130        |\n",
      "|    policy_gradient_loss | -0.00565     |\n",
      "|    value_loss           | 2.75e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2410     |\n",
      "|    iterations      | 767      |\n",
      "|    time_elapsed    | 5213     |\n",
      "|    total_timesteps | 12566528 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2410        |\n",
      "|    iterations           | 768         |\n",
      "|    time_elapsed         | 5219        |\n",
      "|    total_timesteps      | 12582912    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002460001 |\n",
      "|    clip_fraction        | 0.0152      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.487      |\n",
      "|    explained_variance   | 0.0117      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 22140       |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    value_loss           | 2.96e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2411         |\n",
      "|    iterations           | 769          |\n",
      "|    time_elapsed         | 5225         |\n",
      "|    total_timesteps      | 12599296     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026290587 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.042        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.39e+03     |\n",
      "|    n_updates            | 22150        |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    value_loss           | 2.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2411         |\n",
      "|    iterations           | 770          |\n",
      "|    time_elapsed         | 5231         |\n",
      "|    total_timesteps      | 12615680     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025921622 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.489       |\n",
      "|    explained_variance   | 0.0506       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.69e+03     |\n",
      "|    n_updates            | 22160        |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    value_loss           | 2.89e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2412         |\n",
      "|    iterations           | 771          |\n",
      "|    time_elapsed         | 5236         |\n",
      "|    total_timesteps      | 12632064     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023242114 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | -0.00851     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.56e+03     |\n",
      "|    n_updates            | 22170        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    value_loss           | 2.74e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12640000, episode_reward=738.40 +/- 98.66\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 738          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12640000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025858283 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.0468       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.97e+03     |\n",
      "|    n_updates            | 22180        |\n",
      "|    policy_gradient_loss | -0.00659     |\n",
      "|    value_loss           | 2.98e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2410     |\n",
      "|    iterations      | 772      |\n",
      "|    time_elapsed    | 5247     |\n",
      "|    total_timesteps | 12648448 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2410         |\n",
      "|    iterations           | 773          |\n",
      "|    time_elapsed         | 5253         |\n",
      "|    total_timesteps      | 12664832     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028712084 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0342       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.69e+03     |\n",
      "|    n_updates            | 22190        |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2410         |\n",
      "|    iterations           | 774          |\n",
      "|    time_elapsed         | 5260         |\n",
      "|    total_timesteps      | 12681216     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023706108 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.489       |\n",
      "|    explained_variance   | 0.0685       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.49e+03     |\n",
      "|    n_updates            | 22200        |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    value_loss           | 2.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2411         |\n",
      "|    iterations           | 775          |\n",
      "|    time_elapsed         | 5266         |\n",
      "|    total_timesteps      | 12697600     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025069425 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.0685       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 22210        |\n",
      "|    policy_gradient_loss | -0.00637     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2411         |\n",
      "|    iterations           | 776          |\n",
      "|    time_elapsed         | 5272         |\n",
      "|    total_timesteps      | 12713984     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025540672 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.0293       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.76e+03     |\n",
      "|    n_updates            | 22220        |\n",
      "|    policy_gradient_loss | -0.00628     |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12720000, episode_reward=770.40 +/- 114.59\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 770          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12720000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023761212 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.0482       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 22230        |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    value_loss           | 2.96e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2409     |\n",
      "|    iterations      | 777      |\n",
      "|    time_elapsed    | 5283     |\n",
      "|    total_timesteps | 12730368 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2409         |\n",
      "|    iterations           | 778          |\n",
      "|    time_elapsed         | 5289         |\n",
      "|    total_timesteps      | 12746752     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026328366 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.0562       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.43e+03     |\n",
      "|    n_updates            | 22240        |\n",
      "|    policy_gradient_loss | -0.00646     |\n",
      "|    value_loss           | 2.83e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2409         |\n",
      "|    iterations           | 779          |\n",
      "|    time_elapsed         | 5296         |\n",
      "|    total_timesteps      | 12763136     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024036402 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.0634       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.23e+03     |\n",
      "|    n_updates            | 22250        |\n",
      "|    policy_gradient_loss | -0.0056      |\n",
      "|    value_loss           | 2.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2409         |\n",
      "|    iterations           | 780          |\n",
      "|    time_elapsed         | 5302         |\n",
      "|    total_timesteps      | 12779520     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023896643 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | -0.0249      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.57e+03     |\n",
      "|    n_updates            | 22260        |\n",
      "|    policy_gradient_loss | -0.00627     |\n",
      "|    value_loss           | 2.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2410         |\n",
      "|    iterations           | 781          |\n",
      "|    time_elapsed         | 5309         |\n",
      "|    total_timesteps      | 12795904     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024827123 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.0844       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.76e+03     |\n",
      "|    n_updates            | 22270        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12800000, episode_reward=782.40 +/- 101.60\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 782         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 12800000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002646432 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.495      |\n",
      "|    explained_variance   | 0.0729      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.3e+03     |\n",
      "|    n_updates            | 22280       |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    value_loss           | 2.76e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2407     |\n",
      "|    iterations      | 782      |\n",
      "|    time_elapsed    | 5320     |\n",
      "|    total_timesteps | 12812288 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2408         |\n",
      "|    iterations           | 783          |\n",
      "|    time_elapsed         | 5327         |\n",
      "|    total_timesteps      | 12828672     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025904072 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0538       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.96e+03     |\n",
      "|    n_updates            | 22290        |\n",
      "|    policy_gradient_loss | -0.00594     |\n",
      "|    value_loss           | 3.03e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2408        |\n",
      "|    iterations           | 784         |\n",
      "|    time_elapsed         | 5332        |\n",
      "|    total_timesteps      | 12845056    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002538446 |\n",
      "|    clip_fraction        | 0.0149      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.495      |\n",
      "|    explained_variance   | 0.0223      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 22300       |\n",
      "|    policy_gradient_loss | -0.00607    |\n",
      "|    value_loss           | 3e+03       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2408         |\n",
      "|    iterations           | 785          |\n",
      "|    time_elapsed         | 5339         |\n",
      "|    total_timesteps      | 12861440     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026756944 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0295       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.23e+03     |\n",
      "|    n_updates            | 22310        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    value_loss           | 3e+03        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2409         |\n",
      "|    iterations           | 786          |\n",
      "|    time_elapsed         | 5345         |\n",
      "|    total_timesteps      | 12877824     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023404793 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0561       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 22320        |\n",
      "|    policy_gradient_loss | -0.00605     |\n",
      "|    value_loss           | 2.62e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12880000, episode_reward=782.40 +/- 130.94\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 782          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12880000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024738135 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0558       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.29e+03     |\n",
      "|    n_updates            | 22330        |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2407     |\n",
      "|    iterations      | 787      |\n",
      "|    time_elapsed    | 5356     |\n",
      "|    total_timesteps | 12894208 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2406         |\n",
      "|    iterations           | 788          |\n",
      "|    time_elapsed         | 5363         |\n",
      "|    total_timesteps      | 12910592     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026293024 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.00988      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.1e+03      |\n",
      "|    n_updates            | 22340        |\n",
      "|    policy_gradient_loss | -0.00684     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2407         |\n",
      "|    iterations           | 789          |\n",
      "|    time_elapsed         | 5370         |\n",
      "|    total_timesteps      | 12926976     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024308919 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0398       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.46e+03     |\n",
      "|    n_updates            | 22350        |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2407         |\n",
      "|    iterations           | 790          |\n",
      "|    time_elapsed         | 5376         |\n",
      "|    total_timesteps      | 12943360     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027195718 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.0581       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.23e+03     |\n",
      "|    n_updates            | 22360        |\n",
      "|    policy_gradient_loss | -0.00652     |\n",
      "|    value_loss           | 2.61e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2407         |\n",
      "|    iterations           | 791          |\n",
      "|    time_elapsed         | 5382         |\n",
      "|    total_timesteps      | 12959744     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023629102 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0361       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.51e+03     |\n",
      "|    n_updates            | 22370        |\n",
      "|    policy_gradient_loss | -0.00568     |\n",
      "|    value_loss           | 2.77e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=12960000, episode_reward=766.80 +/- 91.11\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 767          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 12960000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026982776 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.0275       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.4e+03      |\n",
      "|    n_updates            | 22380        |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    value_loss           | 2.85e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2405     |\n",
      "|    iterations      | 792      |\n",
      "|    time_elapsed    | 5394     |\n",
      "|    total_timesteps | 12976128 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2405         |\n",
      "|    iterations           | 793          |\n",
      "|    time_elapsed         | 5400         |\n",
      "|    total_timesteps      | 12992512     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022368163 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.0758       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 22390        |\n",
      "|    policy_gradient_loss | -0.00588     |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2406         |\n",
      "|    iterations           | 794          |\n",
      "|    time_elapsed         | 5406         |\n",
      "|    total_timesteps      | 13008896     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022595688 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0517       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.39e+03     |\n",
      "|    n_updates            | 22400        |\n",
      "|    policy_gradient_loss | -0.00631     |\n",
      "|    value_loss           | 2.94e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2406         |\n",
      "|    iterations           | 795          |\n",
      "|    time_elapsed         | 5412         |\n",
      "|    total_timesteps      | 13025280     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028139339 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0414       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 22410        |\n",
      "|    policy_gradient_loss | -0.00697     |\n",
      "|    value_loss           | 2.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13040000, episode_reward=797.20 +/- 82.20\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 797          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13040000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032992924 |\n",
      "|    clip_fraction        | 0.023        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0724       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 22420        |\n",
      "|    policy_gradient_loss | -0.00735     |\n",
      "|    value_loss           | 2.82e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2404     |\n",
      "|    iterations      | 796      |\n",
      "|    time_elapsed    | 5423     |\n",
      "|    total_timesteps | 13041664 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2404         |\n",
      "|    iterations           | 797          |\n",
      "|    time_elapsed         | 5429         |\n",
      "|    total_timesteps      | 13058048     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023795108 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.00889      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 22430        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    value_loss           | 3.06e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2405         |\n",
      "|    iterations           | 798          |\n",
      "|    time_elapsed         | 5435         |\n",
      "|    total_timesteps      | 13074432     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019882172 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.0904       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.88e+03     |\n",
      "|    n_updates            | 22440        |\n",
      "|    policy_gradient_loss | -0.00572     |\n",
      "|    value_loss           | 2.79e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2405        |\n",
      "|    iterations           | 799         |\n",
      "|    time_elapsed         | 5441        |\n",
      "|    total_timesteps      | 13090816    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002197546 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.507      |\n",
      "|    explained_variance   | 0.0107      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.27e+03    |\n",
      "|    n_updates            | 22450       |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    value_loss           | 2.88e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2406         |\n",
      "|    iterations           | 800          |\n",
      "|    time_elapsed         | 5447         |\n",
      "|    total_timesteps      | 13107200     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024516075 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.1          |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.51e+03     |\n",
      "|    n_updates            | 22460        |\n",
      "|    policy_gradient_loss | -0.00662     |\n",
      "|    value_loss           | 2.72e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13120000, episode_reward=758.80 +/- 115.15\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 759          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13120000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026582596 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.00664      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 22470        |\n",
      "|    policy_gradient_loss | -0.00585     |\n",
      "|    value_loss           | 3.09e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2404     |\n",
      "|    iterations      | 801      |\n",
      "|    time_elapsed    | 5458     |\n",
      "|    total_timesteps | 13123584 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2404         |\n",
      "|    iterations           | 802          |\n",
      "|    time_elapsed         | 5463         |\n",
      "|    total_timesteps      | 13139968     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025560341 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0153       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.62e+03     |\n",
      "|    n_updates            | 22480        |\n",
      "|    policy_gradient_loss | -0.00608     |\n",
      "|    value_loss           | 2.93e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2405        |\n",
      "|    iterations           | 803         |\n",
      "|    time_elapsed         | 5469        |\n",
      "|    total_timesteps      | 13156352    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002550623 |\n",
      "|    clip_fraction        | 0.0143      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.502      |\n",
      "|    explained_variance   | 0.0643      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 22490       |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    value_loss           | 2.77e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2405         |\n",
      "|    iterations           | 804          |\n",
      "|    time_elapsed         | 5475         |\n",
      "|    total_timesteps      | 13172736     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028124773 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.018        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.83e+03     |\n",
      "|    n_updates            | 22500        |\n",
      "|    policy_gradient_loss | -0.00627     |\n",
      "|    value_loss           | 2.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2405         |\n",
      "|    iterations           | 805          |\n",
      "|    time_elapsed         | 5481         |\n",
      "|    total_timesteps      | 13189120     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026653134 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0387       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 22510        |\n",
      "|    policy_gradient_loss | -0.00688     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13200000, episode_reward=758.80 +/- 110.25\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 759          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13200000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031999773 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0192       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.94e+03     |\n",
      "|    n_updates            | 22520        |\n",
      "|    policy_gradient_loss | -0.00663     |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2404     |\n",
      "|    iterations      | 806      |\n",
      "|    time_elapsed    | 5492     |\n",
      "|    total_timesteps | 13205504 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2404         |\n",
      "|    iterations           | 807          |\n",
      "|    time_elapsed         | 5498         |\n",
      "|    total_timesteps      | 13221888     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034658099 |\n",
      "|    clip_fraction        | 0.0264       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0434       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 22530        |\n",
      "|    policy_gradient_loss | -0.00772     |\n",
      "|    value_loss           | 2.82e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2404         |\n",
      "|    iterations           | 808          |\n",
      "|    time_elapsed         | 5504         |\n",
      "|    total_timesteps      | 13238272     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028495258 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.0538       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 22540        |\n",
      "|    policy_gradient_loss | -0.00641     |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2405         |\n",
      "|    iterations           | 809          |\n",
      "|    time_elapsed         | 5510         |\n",
      "|    total_timesteps      | 13254656     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023818603 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0331       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.39e+03     |\n",
      "|    n_updates            | 22550        |\n",
      "|    policy_gradient_loss | -0.00617     |\n",
      "|    value_loss           | 3.03e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2405         |\n",
      "|    iterations           | 810          |\n",
      "|    time_elapsed         | 5517         |\n",
      "|    total_timesteps      | 13271040     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022776253 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.00993      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2e+03        |\n",
      "|    n_updates            | 22560        |\n",
      "|    policy_gradient_loss | -0.00596     |\n",
      "|    value_loss           | 3.25e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13280000, episode_reward=808.00 +/- 66.03\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 808         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 13280000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002581264 |\n",
      "|    clip_fraction        | 0.0153      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.512      |\n",
      "|    explained_variance   | 0.039       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 22570       |\n",
      "|    policy_gradient_loss | -0.00606    |\n",
      "|    value_loss           | 2.9e+03     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2403     |\n",
      "|    iterations      | 811      |\n",
      "|    time_elapsed    | 5529     |\n",
      "|    total_timesteps | 13287424 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2403        |\n",
      "|    iterations           | 812         |\n",
      "|    time_elapsed         | 5535        |\n",
      "|    total_timesteps      | 13303808    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002724409 |\n",
      "|    clip_fraction        | 0.015       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.512      |\n",
      "|    explained_variance   | 0.0371      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 22580       |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    value_loss           | 2.8e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2403         |\n",
      "|    iterations           | 813          |\n",
      "|    time_elapsed         | 5541         |\n",
      "|    total_timesteps      | 13320192     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026613404 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0449       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.39e+03     |\n",
      "|    n_updates            | 22590        |\n",
      "|    policy_gradient_loss | -0.00617     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2403         |\n",
      "|    iterations           | 814          |\n",
      "|    time_elapsed         | 5548         |\n",
      "|    total_timesteps      | 13336576     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024143471 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | 0.0689       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.46e+03     |\n",
      "|    n_updates            | 22600        |\n",
      "|    policy_gradient_loss | -0.00579     |\n",
      "|    value_loss           | 2.94e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2404         |\n",
      "|    iterations           | 815          |\n",
      "|    time_elapsed         | 5554         |\n",
      "|    total_timesteps      | 13352960     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022871438 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.0614       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 22610        |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13360000, episode_reward=796.00 +/- 100.24\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 796          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13360000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027450537 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.516       |\n",
      "|    explained_variance   | 0.0304       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.44e+03     |\n",
      "|    n_updates            | 22620        |\n",
      "|    policy_gradient_loss | -0.0064      |\n",
      "|    value_loss           | 2.77e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2401     |\n",
      "|    iterations      | 816      |\n",
      "|    time_elapsed    | 5566     |\n",
      "|    total_timesteps | 13369344 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2401         |\n",
      "|    iterations           | 817          |\n",
      "|    time_elapsed         | 5573         |\n",
      "|    total_timesteps      | 13385728     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025634402 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.532       |\n",
      "|    explained_variance   | 0.0736       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.47e+03     |\n",
      "|    n_updates            | 22630        |\n",
      "|    policy_gradient_loss | -0.00655     |\n",
      "|    value_loss           | 2.74e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2402        |\n",
      "|    iterations           | 818         |\n",
      "|    time_elapsed         | 5579        |\n",
      "|    total_timesteps      | 13402112    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002519675 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.512      |\n",
      "|    explained_variance   | 0.0455      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 22640       |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    value_loss           | 3.02e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2402         |\n",
      "|    iterations           | 819          |\n",
      "|    time_elapsed         | 5585         |\n",
      "|    total_timesteps      | 13418496     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025759074 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.525       |\n",
      "|    explained_variance   | 0.0637       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.1e+03      |\n",
      "|    n_updates            | 22650        |\n",
      "|    policy_gradient_loss | -0.00585     |\n",
      "|    value_loss           | 2.84e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2402        |\n",
      "|    iterations           | 820         |\n",
      "|    time_elapsed         | 5591        |\n",
      "|    total_timesteps      | 13434880    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002657507 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.519      |\n",
      "|    explained_variance   | 0.0667      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.65e+03    |\n",
      "|    n_updates            | 22660       |\n",
      "|    policy_gradient_loss | -0.00652    |\n",
      "|    value_loss           | 2.77e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=13440000, episode_reward=751.60 +/- 120.82\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 752          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13440000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025379127 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.527       |\n",
      "|    explained_variance   | 0.118        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.47e+03     |\n",
      "|    n_updates            | 22670        |\n",
      "|    policy_gradient_loss | -0.00664     |\n",
      "|    value_loss           | 2.89e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2400     |\n",
      "|    iterations      | 821      |\n",
      "|    time_elapsed    | 5603     |\n",
      "|    total_timesteps | 13451264 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2400         |\n",
      "|    iterations           | 822          |\n",
      "|    time_elapsed         | 5609         |\n",
      "|    total_timesteps      | 13467648     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026956024 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.525       |\n",
      "|    explained_variance   | 0.0417       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.25e+03     |\n",
      "|    n_updates            | 22680        |\n",
      "|    policy_gradient_loss | -0.00652     |\n",
      "|    value_loss           | 2.97e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2400         |\n",
      "|    iterations           | 823          |\n",
      "|    time_elapsed         | 5616         |\n",
      "|    total_timesteps      | 13484032     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025291154 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.519       |\n",
      "|    explained_variance   | 0.0678       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.67e+03     |\n",
      "|    n_updates            | 22690        |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2401         |\n",
      "|    iterations           | 824          |\n",
      "|    time_elapsed         | 5622         |\n",
      "|    total_timesteps      | 13500416     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024021964 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.523       |\n",
      "|    explained_variance   | 0.0436       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 22700        |\n",
      "|    policy_gradient_loss | -0.00626     |\n",
      "|    value_loss           | 2.93e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2401         |\n",
      "|    iterations           | 825          |\n",
      "|    time_elapsed         | 5629         |\n",
      "|    total_timesteps      | 13516800     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024836026 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | 0.112        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 22710        |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    value_loss           | 2.94e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13520000, episode_reward=763.60 +/- 109.76\n",
      "Episode length: 200.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 200        |\n",
      "|    mean_reward          | 764        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 13520000   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00255308 |\n",
      "|    clip_fraction        | 0.0179     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.532     |\n",
      "|    explained_variance   | 0.0632     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.34e+03   |\n",
      "|    n_updates            | 22720      |\n",
      "|    policy_gradient_loss | -0.00624   |\n",
      "|    value_loss           | 2.98e+03   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2398     |\n",
      "|    iterations      | 826      |\n",
      "|    time_elapsed    | 5643     |\n",
      "|    total_timesteps | 13533184 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2398         |\n",
      "|    iterations           | 827          |\n",
      "|    time_elapsed         | 5650         |\n",
      "|    total_timesteps      | 13549568     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027070548 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.534       |\n",
      "|    explained_variance   | 0.0809       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 22730        |\n",
      "|    policy_gradient_loss | -0.00603     |\n",
      "|    value_loss           | 2.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2398         |\n",
      "|    iterations           | 828          |\n",
      "|    time_elapsed         | 5657         |\n",
      "|    total_timesteps      | 13565952     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023501152 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.529       |\n",
      "|    explained_variance   | 0.037        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 22740        |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    value_loss           | 2.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2397         |\n",
      "|    iterations           | 829          |\n",
      "|    time_elapsed         | 5665         |\n",
      "|    total_timesteps      | 13582336     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028926954 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.539       |\n",
      "|    explained_variance   | 0.0467       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.96e+03     |\n",
      "|    n_updates            | 22750        |\n",
      "|    policy_gradient_loss | -0.00669     |\n",
      "|    value_loss           | 2.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2397         |\n",
      "|    iterations           | 830          |\n",
      "|    time_elapsed         | 5672         |\n",
      "|    total_timesteps      | 13598720     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026655518 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | 0.0714       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.69e+03     |\n",
      "|    n_updates            | 22760        |\n",
      "|    policy_gradient_loss | -0.00637     |\n",
      "|    value_loss           | 2.83e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13600000, episode_reward=763.60 +/- 122.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 764          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13600000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025147505 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.531       |\n",
      "|    explained_variance   | 0.0399       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 22770        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    value_loss           | 2.85e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2394     |\n",
      "|    iterations      | 831      |\n",
      "|    time_elapsed    | 5685     |\n",
      "|    total_timesteps | 13615104 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2394         |\n",
      "|    iterations           | 832          |\n",
      "|    time_elapsed         | 5692         |\n",
      "|    total_timesteps      | 13631488     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024610523 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.526       |\n",
      "|    explained_variance   | 0.0678       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.36e+03     |\n",
      "|    n_updates            | 22780        |\n",
      "|    policy_gradient_loss | -0.00655     |\n",
      "|    value_loss           | 2.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2394         |\n",
      "|    iterations           | 833          |\n",
      "|    time_elapsed         | 5699         |\n",
      "|    total_timesteps      | 13647872     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028963985 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | 0.0396       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.66e+03     |\n",
      "|    n_updates            | 22790        |\n",
      "|    policy_gradient_loss | -0.00646     |\n",
      "|    value_loss           | 2.66e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2394         |\n",
      "|    iterations           | 834          |\n",
      "|    time_elapsed         | 5705         |\n",
      "|    total_timesteps      | 13664256     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028255587 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.532       |\n",
      "|    explained_variance   | 0.0939       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 22800        |\n",
      "|    policy_gradient_loss | -0.00672     |\n",
      "|    value_loss           | 2.92e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13680000, episode_reward=756.40 +/- 86.53\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 756          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13680000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027115736 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.543       |\n",
      "|    explained_variance   | 0.0486       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.83e+03     |\n",
      "|    n_updates            | 22810        |\n",
      "|    policy_gradient_loss | -0.00681     |\n",
      "|    value_loss           | 2.94e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2392     |\n",
      "|    iterations      | 835      |\n",
      "|    time_elapsed    | 5718     |\n",
      "|    total_timesteps | 13680640 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2392        |\n",
      "|    iterations           | 836         |\n",
      "|    time_elapsed         | 5724        |\n",
      "|    total_timesteps      | 13697024    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003065042 |\n",
      "|    clip_fraction        | 0.0195      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.535      |\n",
      "|    explained_variance   | 0.0484      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 985         |\n",
      "|    n_updates            | 22820       |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    value_loss           | 2.7e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2392        |\n",
      "|    iterations           | 837         |\n",
      "|    time_elapsed         | 5731        |\n",
      "|    total_timesteps      | 13713408    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002717368 |\n",
      "|    clip_fraction        | 0.0169      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.528      |\n",
      "|    explained_variance   | 0.023       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.4e+03     |\n",
      "|    n_updates            | 22830       |\n",
      "|    policy_gradient_loss | -0.00653    |\n",
      "|    value_loss           | 2.91e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2392        |\n",
      "|    iterations           | 838         |\n",
      "|    time_elapsed         | 5737        |\n",
      "|    total_timesteps      | 13729792    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002356438 |\n",
      "|    clip_fraction        | 0.0121      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.519      |\n",
      "|    explained_variance   | 0.0758      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.64e+03    |\n",
      "|    n_updates            | 22840       |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    value_loss           | 2.77e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2393        |\n",
      "|    iterations           | 839         |\n",
      "|    time_elapsed         | 5744        |\n",
      "|    total_timesteps      | 13746176    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002884591 |\n",
      "|    clip_fraction        | 0.0169      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.52       |\n",
      "|    explained_variance   | 0.072       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.68e+03    |\n",
      "|    n_updates            | 22850       |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    value_loss           | 2.94e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=13760000, episode_reward=746.00 +/- 80.55\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 746          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13760000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026667495 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.0773       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.73e+03     |\n",
      "|    n_updates            | 22860        |\n",
      "|    policy_gradient_loss | -0.00655     |\n",
      "|    value_loss           | 2.67e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2391     |\n",
      "|    iterations      | 840      |\n",
      "|    time_elapsed    | 5755     |\n",
      "|    total_timesteps | 13762560 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2391         |\n",
      "|    iterations           | 841          |\n",
      "|    time_elapsed         | 5762         |\n",
      "|    total_timesteps      | 13778944     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028584283 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.528       |\n",
      "|    explained_variance   | 0.0286       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.45e+03     |\n",
      "|    n_updates            | 22870        |\n",
      "|    policy_gradient_loss | -0.00658     |\n",
      "|    value_loss           | 2.92e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2391         |\n",
      "|    iterations           | 842          |\n",
      "|    time_elapsed         | 5768         |\n",
      "|    total_timesteps      | 13795328     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029252435 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | 0.0421       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 22880        |\n",
      "|    policy_gradient_loss | -0.00682     |\n",
      "|    value_loss           | 2.63e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2391         |\n",
      "|    iterations           | 843          |\n",
      "|    time_elapsed         | 5774         |\n",
      "|    total_timesteps      | 13811712     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027304185 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.527       |\n",
      "|    explained_variance   | 0.0628       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 22890        |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    value_loss           | 2.74e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2391         |\n",
      "|    iterations           | 844          |\n",
      "|    time_elapsed         | 5781         |\n",
      "|    total_timesteps      | 13828096     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026377698 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.524       |\n",
      "|    explained_variance   | 0.0717       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 951          |\n",
      "|    n_updates            | 22900        |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    value_loss           | 2.67e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13840000, episode_reward=765.60 +/- 88.59\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 766          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 13840000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025686757 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | 0.033        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.24e+03     |\n",
      "|    n_updates            | 22910        |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    value_loss           | 2.78e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2389     |\n",
      "|    iterations      | 845      |\n",
      "|    time_elapsed    | 5794     |\n",
      "|    total_timesteps | 13844480 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2389         |\n",
      "|    iterations           | 846          |\n",
      "|    time_elapsed         | 5800         |\n",
      "|    total_timesteps      | 13860864     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026077654 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.533       |\n",
      "|    explained_variance   | 0.0476       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 22920        |\n",
      "|    policy_gradient_loss | -0.00608     |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2389         |\n",
      "|    iterations           | 847          |\n",
      "|    time_elapsed         | 5807         |\n",
      "|    total_timesteps      | 13877248     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026726348 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.536       |\n",
      "|    explained_variance   | 0.041        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 22930        |\n",
      "|    policy_gradient_loss | -0.00636     |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2389        |\n",
      "|    iterations           | 848         |\n",
      "|    time_elapsed         | 5814        |\n",
      "|    total_timesteps      | 13893632    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002521949 |\n",
      "|    clip_fraction        | 0.0167      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.523      |\n",
      "|    explained_variance   | 0.0764      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.3e+03     |\n",
      "|    n_updates            | 22940       |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    value_loss           | 2.71e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2389         |\n",
      "|    iterations           | 849          |\n",
      "|    time_elapsed         | 5820         |\n",
      "|    total_timesteps      | 13910016     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026361286 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.53        |\n",
      "|    explained_variance   | 0.0837       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 22950        |\n",
      "|    policy_gradient_loss | -0.00647     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=13920000, episode_reward=763.60 +/- 100.95\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 764         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 13920000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002436506 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.521      |\n",
      "|    explained_variance   | 0.0433      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.11e+03    |\n",
      "|    n_updates            | 22960       |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    value_loss           | 2.74e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2387     |\n",
      "|    iterations      | 850      |\n",
      "|    time_elapsed    | 5833     |\n",
      "|    total_timesteps | 13926400 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2387         |\n",
      "|    iterations           | 851          |\n",
      "|    time_elapsed         | 5839         |\n",
      "|    total_timesteps      | 13942784     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023227609 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.526       |\n",
      "|    explained_variance   | 0.0469       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.49e+03     |\n",
      "|    n_updates            | 22970        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    value_loss           | 3.1e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2387         |\n",
      "|    iterations           | 852          |\n",
      "|    time_elapsed         | 5845         |\n",
      "|    total_timesteps      | 13959168     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026895464 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.535       |\n",
      "|    explained_variance   | 0.0372       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 22980        |\n",
      "|    policy_gradient_loss | -0.00656     |\n",
      "|    value_loss           | 2.69e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2387         |\n",
      "|    iterations           | 853          |\n",
      "|    time_elapsed         | 5852         |\n",
      "|    total_timesteps      | 13975552     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027628057 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.536       |\n",
      "|    explained_variance   | 0.0146       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 22990        |\n",
      "|    policy_gradient_loss | -0.00681     |\n",
      "|    value_loss           | 2.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2388         |\n",
      "|    iterations           | 854          |\n",
      "|    time_elapsed         | 5859         |\n",
      "|    total_timesteps      | 13991936     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030909926 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.541       |\n",
      "|    explained_variance   | 0.131        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.24e+03     |\n",
      "|    n_updates            | 23000        |\n",
      "|    policy_gradient_loss | -0.00699     |\n",
      "|    value_loss           | 2.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14000000, episode_reward=786.80 +/- 90.98\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 787          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14000000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028801314 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.532       |\n",
      "|    explained_variance   | 0.0235       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.36e+03     |\n",
      "|    n_updates            | 23010        |\n",
      "|    policy_gradient_loss | -0.00669     |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2385     |\n",
      "|    iterations      | 855      |\n",
      "|    time_elapsed    | 5871     |\n",
      "|    total_timesteps | 14008320 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2385         |\n",
      "|    iterations           | 856          |\n",
      "|    time_elapsed         | 5878         |\n",
      "|    total_timesteps      | 14024704     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027489327 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.526       |\n",
      "|    explained_variance   | 0.0181       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 23020        |\n",
      "|    policy_gradient_loss | -0.00641     |\n",
      "|    value_loss           | 2.82e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2385        |\n",
      "|    iterations           | 857         |\n",
      "|    time_elapsed         | 5884        |\n",
      "|    total_timesteps      | 14041088    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003176175 |\n",
      "|    clip_fraction        | 0.0222      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.535      |\n",
      "|    explained_variance   | 0.073       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 926         |\n",
      "|    n_updates            | 23030       |\n",
      "|    policy_gradient_loss | -0.00776    |\n",
      "|    value_loss           | 2.7e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2386         |\n",
      "|    iterations           | 858          |\n",
      "|    time_elapsed         | 5891         |\n",
      "|    total_timesteps      | 14057472     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026186132 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.543       |\n",
      "|    explained_variance   | 0.086        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1e+03        |\n",
      "|    n_updates            | 23040        |\n",
      "|    policy_gradient_loss | -0.00657     |\n",
      "|    value_loss           | 2.42e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2386        |\n",
      "|    iterations           | 859         |\n",
      "|    time_elapsed         | 5897        |\n",
      "|    total_timesteps      | 14073856    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002548901 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.531      |\n",
      "|    explained_variance   | 0.0787      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.87e+03    |\n",
      "|    n_updates            | 23050       |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    value_loss           | 2.76e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=14080000, episode_reward=738.40 +/- 110.26\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 738          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14080000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026011257 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.0547       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.25e+03     |\n",
      "|    n_updates            | 23060        |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    value_loss           | 2.93e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2384     |\n",
      "|    iterations      | 860      |\n",
      "|    time_elapsed    | 5910     |\n",
      "|    total_timesteps | 14090240 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2384        |\n",
      "|    iterations           | 861         |\n",
      "|    time_elapsed         | 5916        |\n",
      "|    total_timesteps      | 14106624    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002769962 |\n",
      "|    clip_fraction        | 0.018       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.526      |\n",
      "|    explained_variance   | 0.0481      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.41e+03    |\n",
      "|    n_updates            | 23070       |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    value_loss           | 2.74e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2384        |\n",
      "|    iterations           | 862         |\n",
      "|    time_elapsed         | 5923        |\n",
      "|    total_timesteps      | 14123008    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002918214 |\n",
      "|    clip_fraction        | 0.0216      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.521      |\n",
      "|    explained_variance   | 0.0604      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.64e+03    |\n",
      "|    n_updates            | 23080       |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    value_loss           | 2.64e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2384        |\n",
      "|    iterations           | 863         |\n",
      "|    time_elapsed         | 5929        |\n",
      "|    total_timesteps      | 14139392    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002662569 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.525      |\n",
      "|    explained_variance   | 0.0348      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.47e+03    |\n",
      "|    n_updates            | 23090       |\n",
      "|    policy_gradient_loss | -0.00679    |\n",
      "|    value_loss           | 2.81e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2384         |\n",
      "|    iterations           | 864          |\n",
      "|    time_elapsed         | 5936         |\n",
      "|    total_timesteps      | 14155776     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029889364 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.528       |\n",
      "|    explained_variance   | 0.0166       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 23100        |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14160000, episode_reward=755.60 +/- 107.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 756          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14160000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024719767 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.0187       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.36e+03     |\n",
      "|    n_updates            | 23110        |\n",
      "|    policy_gradient_loss | -0.00622     |\n",
      "|    value_loss           | 2.63e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2382     |\n",
      "|    iterations      | 865      |\n",
      "|    time_elapsed    | 5948     |\n",
      "|    total_timesteps | 14172160 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2382         |\n",
      "|    iterations           | 866          |\n",
      "|    time_elapsed         | 5956         |\n",
      "|    total_timesteps      | 14188544     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024383718 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.0281       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.4e+03      |\n",
      "|    n_updates            | 23120        |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    value_loss           | 2.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2381         |\n",
      "|    iterations           | 867          |\n",
      "|    time_elapsed         | 5964         |\n",
      "|    total_timesteps      | 14204928     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028177407 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.516       |\n",
      "|    explained_variance   | 0.0662       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.62e+03     |\n",
      "|    n_updates            | 23130        |\n",
      "|    policy_gradient_loss | -0.00631     |\n",
      "|    value_loss           | 2.77e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2381         |\n",
      "|    iterations           | 868          |\n",
      "|    time_elapsed         | 5971         |\n",
      "|    total_timesteps      | 14221312     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028126398 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.0441       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.33e+03     |\n",
      "|    n_updates            | 23140        |\n",
      "|    policy_gradient_loss | -0.00657     |\n",
      "|    value_loss           | 3e+03        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2381         |\n",
      "|    iterations           | 869          |\n",
      "|    time_elapsed         | 5978         |\n",
      "|    total_timesteps      | 14237696     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026167715 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.526       |\n",
      "|    explained_variance   | 0.0618       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.36e+03     |\n",
      "|    n_updates            | 23150        |\n",
      "|    policy_gradient_loss | -0.00656     |\n",
      "|    value_loss           | 2.59e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14240000, episode_reward=741.20 +/- 104.89\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 741          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14240000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026172593 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.523       |\n",
      "|    explained_variance   | 0.0579       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 23160        |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    value_loss           | 2.72e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2379     |\n",
      "|    iterations      | 870      |\n",
      "|    time_elapsed    | 5990     |\n",
      "|    total_timesteps | 14254080 |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2379       |\n",
      "|    iterations           | 871        |\n",
      "|    time_elapsed         | 5997       |\n",
      "|    total_timesteps      | 14270464   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00269497 |\n",
      "|    clip_fraction        | 0.0174     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.521     |\n",
      "|    explained_variance   | 0.0607     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.14e+03   |\n",
      "|    n_updates            | 23170      |\n",
      "|    policy_gradient_loss | -0.00668   |\n",
      "|    value_loss           | 2.51e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2379        |\n",
      "|    iterations           | 872         |\n",
      "|    time_elapsed         | 6004        |\n",
      "|    total_timesteps      | 14286848    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002347948 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.518      |\n",
      "|    explained_variance   | 0.068       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.46e+03    |\n",
      "|    n_updates            | 23180       |\n",
      "|    policy_gradient_loss | -0.00629    |\n",
      "|    value_loss           | 2.89e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2379        |\n",
      "|    iterations           | 873         |\n",
      "|    time_elapsed         | 6010        |\n",
      "|    total_timesteps      | 14303232    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003013446 |\n",
      "|    clip_fraction        | 0.0199      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.516      |\n",
      "|    explained_variance   | -0.0205     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.44e+03    |\n",
      "|    n_updates            | 23190       |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    value_loss           | 2.65e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2379         |\n",
      "|    iterations           | 874          |\n",
      "|    time_elapsed         | 6017         |\n",
      "|    total_timesteps      | 14319616     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025314898 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.0329       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.54e+03     |\n",
      "|    n_updates            | 23200        |\n",
      "|    policy_gradient_loss | -0.00603     |\n",
      "|    value_loss           | 2.6e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14320000, episode_reward=741.20 +/- 131.10\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 741          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14320000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027240212 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | -0.0102      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.56e+03     |\n",
      "|    n_updates            | 23210        |\n",
      "|    policy_gradient_loss | -0.00613     |\n",
      "|    value_loss           | 2.74e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2376     |\n",
      "|    iterations      | 875      |\n",
      "|    time_elapsed    | 6031     |\n",
      "|    total_timesteps | 14336000 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2376        |\n",
      "|    iterations           | 876         |\n",
      "|    time_elapsed         | 6038        |\n",
      "|    total_timesteps      | 14352384    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002788653 |\n",
      "|    clip_fraction        | 0.0207      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.0344      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 23220       |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    value_loss           | 3.04e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2376         |\n",
      "|    iterations           | 877          |\n",
      "|    time_elapsed         | 6045         |\n",
      "|    total_timesteps      | 14368768     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025186515 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.0421       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.63e+03     |\n",
      "|    n_updates            | 23230        |\n",
      "|    policy_gradient_loss | -0.00673     |\n",
      "|    value_loss           | 2.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2376         |\n",
      "|    iterations           | 878          |\n",
      "|    time_elapsed         | 6052         |\n",
      "|    total_timesteps      | 14385152     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024428354 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.516       |\n",
      "|    explained_variance   | 0.0643       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 23240        |\n",
      "|    policy_gradient_loss | -0.00633     |\n",
      "|    value_loss           | 2.7e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14400000, episode_reward=742.80 +/- 80.08\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 743          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14400000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024178731 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | 0.0787       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.32e+03     |\n",
      "|    n_updates            | 23250        |\n",
      "|    policy_gradient_loss | -0.00601     |\n",
      "|    value_loss           | 2.78e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2374     |\n",
      "|    iterations      | 879      |\n",
      "|    time_elapsed    | 6064     |\n",
      "|    total_timesteps | 14401536 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2374        |\n",
      "|    iterations           | 880         |\n",
      "|    time_elapsed         | 6070        |\n",
      "|    total_timesteps      | 14417920    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002368982 |\n",
      "|    clip_fraction        | 0.013       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.513      |\n",
      "|    explained_variance   | 0.0717      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.02e+03    |\n",
      "|    n_updates            | 23260       |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    value_loss           | 2.64e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2375         |\n",
      "|    iterations           | 881          |\n",
      "|    time_elapsed         | 6077         |\n",
      "|    total_timesteps      | 14434304     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026471606 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.0413       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.51e+03     |\n",
      "|    n_updates            | 23270        |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    value_loss           | 2.82e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2375         |\n",
      "|    iterations           | 882          |\n",
      "|    time_elapsed         | 6083         |\n",
      "|    total_timesteps      | 14450688     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024640975 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0482       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.43e+03     |\n",
      "|    n_updates            | 23280        |\n",
      "|    policy_gradient_loss | -0.00596     |\n",
      "|    value_loss           | 2.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2375         |\n",
      "|    iterations           | 883          |\n",
      "|    time_elapsed         | 6090         |\n",
      "|    total_timesteps      | 14467072     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027837243 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | 0.0487       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 23290        |\n",
      "|    policy_gradient_loss | -0.00673     |\n",
      "|    value_loss           | 2.61e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14480000, episode_reward=749.20 +/- 112.25\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 749          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14480000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022040238 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.0542       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 23300        |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    value_loss           | 2.79e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2373     |\n",
      "|    iterations      | 884      |\n",
      "|    time_elapsed    | 6102     |\n",
      "|    total_timesteps | 14483456 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2373         |\n",
      "|    iterations           | 885          |\n",
      "|    time_elapsed         | 6109         |\n",
      "|    total_timesteps      | 14499840     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024235798 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.516       |\n",
      "|    explained_variance   | 0.037        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.7e+03      |\n",
      "|    n_updates            | 23310        |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    value_loss           | 2.84e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2373        |\n",
      "|    iterations           | 886         |\n",
      "|    time_elapsed         | 6116        |\n",
      "|    total_timesteps      | 14516224    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002358005 |\n",
      "|    clip_fraction        | 0.0128      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.51       |\n",
      "|    explained_variance   | 0.0759      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 23320       |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    value_loss           | 3.01e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2373         |\n",
      "|    iterations           | 887          |\n",
      "|    time_elapsed         | 6123         |\n",
      "|    total_timesteps      | 14532608     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030850656 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0755       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.21e+03     |\n",
      "|    n_updates            | 23330        |\n",
      "|    policy_gradient_loss | -0.00687     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2373        |\n",
      "|    iterations           | 888         |\n",
      "|    time_elapsed         | 6130        |\n",
      "|    total_timesteps      | 14548992    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002556821 |\n",
      "|    clip_fraction        | 0.0152      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.501      |\n",
      "|    explained_variance   | 0.0545      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.96e+03    |\n",
      "|    n_updates            | 23340       |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    value_loss           | 3.05e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=14560000, episode_reward=780.80 +/- 98.83\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 781          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14560000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024415804 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0919       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.56e+03     |\n",
      "|    n_updates            | 23350        |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    value_loss           | 3.32e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2371     |\n",
      "|    iterations      | 889      |\n",
      "|    time_elapsed    | 6142     |\n",
      "|    total_timesteps | 14565376 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2371         |\n",
      "|    iterations           | 890          |\n",
      "|    time_elapsed         | 6149         |\n",
      "|    total_timesteps      | 14581760     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024859756 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0287       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 23360        |\n",
      "|    policy_gradient_loss | -0.00596     |\n",
      "|    value_loss           | 2.84e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2371        |\n",
      "|    iterations           | 891         |\n",
      "|    time_elapsed         | 6155        |\n",
      "|    total_timesteps      | 14598144    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002825794 |\n",
      "|    clip_fraction        | 0.0186      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.515      |\n",
      "|    explained_variance   | 0.0353      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.62e+03    |\n",
      "|    n_updates            | 23370       |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    value_loss           | 2.84e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2371        |\n",
      "|    iterations           | 892         |\n",
      "|    time_elapsed         | 6162        |\n",
      "|    total_timesteps      | 14614528    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002296761 |\n",
      "|    clip_fraction        | 0.0138      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.501      |\n",
      "|    explained_variance   | 0.0757      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.7e+03     |\n",
      "|    n_updates            | 23380       |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    value_loss           | 3.06e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2371         |\n",
      "|    iterations           | 893          |\n",
      "|    time_elapsed         | 6168         |\n",
      "|    total_timesteps      | 14630912     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026821364 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.0389       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.4e+03      |\n",
      "|    n_updates            | 23390        |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    value_loss           | 3.31e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14640000, episode_reward=776.00 +/- 100.60\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 776          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14640000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030279052 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | 0.0614       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 23400        |\n",
      "|    policy_gradient_loss | -0.00641     |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2369     |\n",
      "|    iterations      | 894      |\n",
      "|    time_elapsed    | 6181     |\n",
      "|    total_timesteps | 14647296 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2369         |\n",
      "|    iterations           | 895          |\n",
      "|    time_elapsed         | 6188         |\n",
      "|    total_timesteps      | 14663680     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028483197 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.0463       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 23410        |\n",
      "|    policy_gradient_loss | -0.0065      |\n",
      "|    value_loss           | 3.08e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2369         |\n",
      "|    iterations           | 896          |\n",
      "|    time_elapsed         | 6195         |\n",
      "|    total_timesteps      | 14680064     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026422394 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.0861       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.4e+03      |\n",
      "|    n_updates            | 23420        |\n",
      "|    policy_gradient_loss | -0.00626     |\n",
      "|    value_loss           | 2.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2369         |\n",
      "|    iterations           | 897          |\n",
      "|    time_elapsed         | 6201         |\n",
      "|    total_timesteps      | 14696448     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023711536 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.0361       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.25e+03     |\n",
      "|    n_updates            | 23430        |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    value_loss           | 3.24e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2369        |\n",
      "|    iterations           | 898         |\n",
      "|    time_elapsed         | 6208        |\n",
      "|    total_timesteps      | 14712832    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002837176 |\n",
      "|    clip_fraction        | 0.0178      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.517      |\n",
      "|    explained_variance   | 0.0459      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.45e+03    |\n",
      "|    n_updates            | 23440       |\n",
      "|    policy_gradient_loss | -0.0069     |\n",
      "|    value_loss           | 2.94e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=14720000, episode_reward=824.80 +/- 117.27\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 825          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14720000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025984193 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0547       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 23450        |\n",
      "|    policy_gradient_loss | -0.0062      |\n",
      "|    value_loss           | 2.96e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2367     |\n",
      "|    iterations      | 899      |\n",
      "|    time_elapsed    | 6220     |\n",
      "|    total_timesteps | 14729216 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2368        |\n",
      "|    iterations           | 900         |\n",
      "|    time_elapsed         | 6226        |\n",
      "|    total_timesteps      | 14745600    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002804819 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.522      |\n",
      "|    explained_variance   | 0.01        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.48e+03    |\n",
      "|    n_updates            | 23460       |\n",
      "|    policy_gradient_loss | -0.00596    |\n",
      "|    value_loss           | 2.95e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2368         |\n",
      "|    iterations           | 901          |\n",
      "|    time_elapsed         | 6233         |\n",
      "|    total_timesteps      | 14761984     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026240465 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.014        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.43e+03     |\n",
      "|    n_updates            | 23470        |\n",
      "|    policy_gradient_loss | -0.00604     |\n",
      "|    value_loss           | 3.43e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2368         |\n",
      "|    iterations           | 902          |\n",
      "|    time_elapsed         | 6240         |\n",
      "|    total_timesteps      | 14778368     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029710005 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.0249       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.23e+03     |\n",
      "|    n_updates            | 23480        |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    value_loss           | 3.13e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2368         |\n",
      "|    iterations           | 903          |\n",
      "|    time_elapsed         | 6246         |\n",
      "|    total_timesteps      | 14794752     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028633755 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.0359       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.82e+03     |\n",
      "|    n_updates            | 23490        |\n",
      "|    policy_gradient_loss | -0.00654     |\n",
      "|    value_loss           | 3.19e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14800000, episode_reward=775.60 +/- 82.37\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 776          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14800000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024384055 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.0593       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.55e+03     |\n",
      "|    n_updates            | 23500        |\n",
      "|    policy_gradient_loss | -0.00589     |\n",
      "|    value_loss           | 3.16e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2366     |\n",
      "|    iterations      | 904      |\n",
      "|    time_elapsed    | 6259     |\n",
      "|    total_timesteps | 14811136 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2366         |\n",
      "|    iterations           | 905          |\n",
      "|    time_elapsed         | 6265         |\n",
      "|    total_timesteps      | 14827520     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023878869 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.0203       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.62e+03     |\n",
      "|    n_updates            | 23510        |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    value_loss           | 3.11e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2366         |\n",
      "|    iterations           | 906          |\n",
      "|    time_elapsed         | 6272         |\n",
      "|    total_timesteps      | 14843904     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023800451 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | 0.0417       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.45e+03     |\n",
      "|    n_updates            | 23520        |\n",
      "|    policy_gradient_loss | -0.00621     |\n",
      "|    value_loss           | 3.16e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2366         |\n",
      "|    iterations           | 907          |\n",
      "|    time_elapsed         | 6278         |\n",
      "|    total_timesteps      | 14860288     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025688494 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0287       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.33e+03     |\n",
      "|    n_updates            | 23530        |\n",
      "|    policy_gradient_loss | -0.00549     |\n",
      "|    value_loss           | 3.1e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2366         |\n",
      "|    iterations           | 908          |\n",
      "|    time_elapsed         | 6285         |\n",
      "|    total_timesteps      | 14876672     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028371625 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.05         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 973          |\n",
      "|    n_updates            | 23540        |\n",
      "|    policy_gradient_loss | -0.00599     |\n",
      "|    value_loss           | 2.89e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14880000, episode_reward=739.60 +/- 98.69\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 740          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14880000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025696163 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | 0.0419       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 23550        |\n",
      "|    policy_gradient_loss | -0.00627     |\n",
      "|    value_loss           | 3.05e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2364     |\n",
      "|    iterations      | 909      |\n",
      "|    time_elapsed    | 6297     |\n",
      "|    total_timesteps | 14893056 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2364         |\n",
      "|    iterations           | 910          |\n",
      "|    time_elapsed         | 6304         |\n",
      "|    total_timesteps      | 14909440     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029002386 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0549       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.59e+03     |\n",
      "|    n_updates            | 23560        |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    value_loss           | 3.01e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2364         |\n",
      "|    iterations           | 911          |\n",
      "|    time_elapsed         | 6311         |\n",
      "|    total_timesteps      | 14925824     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028977012 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.05         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.29e+03     |\n",
      "|    n_updates            | 23570        |\n",
      "|    policy_gradient_loss | -0.00638     |\n",
      "|    value_loss           | 3.11e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2364         |\n",
      "|    iterations           | 912          |\n",
      "|    time_elapsed         | 6318         |\n",
      "|    total_timesteps      | 14942208     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026810723 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.0535       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.7e+03      |\n",
      "|    n_updates            | 23580        |\n",
      "|    policy_gradient_loss | -0.00575     |\n",
      "|    value_loss           | 3.01e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2365         |\n",
      "|    iterations           | 913          |\n",
      "|    time_elapsed         | 6324         |\n",
      "|    total_timesteps      | 14958592     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024272483 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0446       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.31e+03     |\n",
      "|    n_updates            | 23590        |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    value_loss           | 3.04e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=14960000, episode_reward=775.60 +/- 76.95\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 776          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 14960000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023921272 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0458       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 23600        |\n",
      "|    policy_gradient_loss | -0.00596     |\n",
      "|    value_loss           | 3.04e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2362     |\n",
      "|    iterations      | 914      |\n",
      "|    time_elapsed    | 6338     |\n",
      "|    total_timesteps | 14974976 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2362         |\n",
      "|    iterations           | 915          |\n",
      "|    time_elapsed         | 6344         |\n",
      "|    total_timesteps      | 14991360     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026057134 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0499       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.46e+03     |\n",
      "|    n_updates            | 23610        |\n",
      "|    policy_gradient_loss | -0.00622     |\n",
      "|    value_loss           | 3.01e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2362         |\n",
      "|    iterations           | 916          |\n",
      "|    time_elapsed         | 6351         |\n",
      "|    total_timesteps      | 15007744     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026764753 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0611       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.36e+03     |\n",
      "|    n_updates            | 23620        |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    value_loss           | 2.96e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2362         |\n",
      "|    iterations           | 917          |\n",
      "|    time_elapsed         | 6358         |\n",
      "|    total_timesteps      | 15024128     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021559764 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0744       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 23630        |\n",
      "|    policy_gradient_loss | -0.00546     |\n",
      "|    value_loss           | 3.08e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15040000, episode_reward=779.20 +/- 94.61\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 779         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 15040000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002550527 |\n",
      "|    clip_fraction        | 0.0163      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.505      |\n",
      "|    explained_variance   | 0.0168      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.25e+03    |\n",
      "|    n_updates            | 23640       |\n",
      "|    policy_gradient_loss | -0.0064     |\n",
      "|    value_loss           | 3.04e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2360     |\n",
      "|    iterations      | 918      |\n",
      "|    time_elapsed    | 6370     |\n",
      "|    total_timesteps | 15040512 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2361         |\n",
      "|    iterations           | 919          |\n",
      "|    time_elapsed         | 6377         |\n",
      "|    total_timesteps      | 15056896     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024727015 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0386       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.86e+03     |\n",
      "|    n_updates            | 23650        |\n",
      "|    policy_gradient_loss | -0.00568     |\n",
      "|    value_loss           | 3e+03        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2361         |\n",
      "|    iterations           | 920          |\n",
      "|    time_elapsed         | 6383         |\n",
      "|    total_timesteps      | 15073280     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022695065 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | -0.0107      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.57e+03     |\n",
      "|    n_updates            | 23660        |\n",
      "|    policy_gradient_loss | -0.006       |\n",
      "|    value_loss           | 3.09e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2361         |\n",
      "|    iterations           | 921          |\n",
      "|    time_elapsed         | 6390         |\n",
      "|    total_timesteps      | 15089664     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023639589 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0508       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.92e+03     |\n",
      "|    n_updates            | 23670        |\n",
      "|    policy_gradient_loss | -0.00558     |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2361         |\n",
      "|    iterations           | 922          |\n",
      "|    time_elapsed         | 6396         |\n",
      "|    total_timesteps      | 15106048     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027060362 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0652       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 23680        |\n",
      "|    policy_gradient_loss | -0.00662     |\n",
      "|    value_loss           | 3.2e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15120000, episode_reward=787.60 +/- 106.71\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 788         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 15120000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002630942 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.501      |\n",
      "|    explained_variance   | 0.0145      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.81e+03    |\n",
      "|    n_updates            | 23690       |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    value_loss           | 3.09e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2359     |\n",
      "|    iterations      | 923      |\n",
      "|    time_elapsed    | 6409     |\n",
      "|    total_timesteps | 15122432 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2359         |\n",
      "|    iterations           | 924          |\n",
      "|    time_elapsed         | 6416         |\n",
      "|    total_timesteps      | 15138816     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024477334 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.027        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.25e+03     |\n",
      "|    n_updates            | 23700        |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    value_loss           | 3.01e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2359         |\n",
      "|    iterations           | 925          |\n",
      "|    time_elapsed         | 6423         |\n",
      "|    total_timesteps      | 15155200     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022766725 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.0657       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 23710        |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    value_loss           | 3.02e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2359         |\n",
      "|    iterations           | 926          |\n",
      "|    time_elapsed         | 6430         |\n",
      "|    total_timesteps      | 15171584     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023158006 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0364       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 23720        |\n",
      "|    policy_gradient_loss | -0.0056      |\n",
      "|    value_loss           | 3.3e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2359         |\n",
      "|    iterations           | 927          |\n",
      "|    time_elapsed         | 6437         |\n",
      "|    total_timesteps      | 15187968     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029870104 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.053        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 23730        |\n",
      "|    policy_gradient_loss | -0.00658     |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15200000, episode_reward=766.40 +/- 92.64\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 766          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 15200000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026398515 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0379       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 23740        |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    value_loss           | 2.98e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2357     |\n",
      "|    iterations      | 928      |\n",
      "|    time_elapsed    | 6449     |\n",
      "|    total_timesteps | 15204352 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2357        |\n",
      "|    iterations           | 929         |\n",
      "|    time_elapsed         | 6456        |\n",
      "|    total_timesteps      | 15220736    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002589628 |\n",
      "|    clip_fraction        | 0.016       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.0361      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.84e+03    |\n",
      "|    n_updates            | 23750       |\n",
      "|    policy_gradient_loss | -0.00614    |\n",
      "|    value_loss           | 3.09e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2357       |\n",
      "|    iterations           | 930        |\n",
      "|    time_elapsed         | 6463       |\n",
      "|    total_timesteps      | 15237120   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00227765 |\n",
      "|    clip_fraction        | 0.0144     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.507     |\n",
      "|    explained_variance   | 0.0265     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.86e+03   |\n",
      "|    n_updates            | 23760      |\n",
      "|    policy_gradient_loss | -0.00599   |\n",
      "|    value_loss           | 3.04e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2357         |\n",
      "|    iterations           | 931          |\n",
      "|    time_elapsed         | 6469         |\n",
      "|    total_timesteps      | 15253504     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024536862 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.0309       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.58e+03     |\n",
      "|    n_updates            | 23770        |\n",
      "|    policy_gradient_loss | -0.00605     |\n",
      "|    value_loss           | 3.25e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2357         |\n",
      "|    iterations           | 932          |\n",
      "|    time_elapsed         | 6476         |\n",
      "|    total_timesteps      | 15269888     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027168791 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0889       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.88e+03     |\n",
      "|    n_updates            | 23780        |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15280000, episode_reward=764.40 +/- 93.00\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 764         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 15280000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002289235 |\n",
      "|    clip_fraction        | 0.0119      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.5        |\n",
      "|    explained_variance   | 0.0911      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.39e+03    |\n",
      "|    n_updates            | 23790       |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    value_loss           | 3.16e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2355     |\n",
      "|    iterations      | 933      |\n",
      "|    time_elapsed    | 6488     |\n",
      "|    total_timesteps | 15286272 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2355         |\n",
      "|    iterations           | 934          |\n",
      "|    time_elapsed         | 6496         |\n",
      "|    total_timesteps      | 15302656     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023833425 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.0314       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 23800        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    value_loss           | 3.12e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2355         |\n",
      "|    iterations           | 935          |\n",
      "|    time_elapsed         | 6503         |\n",
      "|    total_timesteps      | 15319040     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022007753 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.0668       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.47e+03     |\n",
      "|    n_updates            | 23810        |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    value_loss           | 3.44e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2355         |\n",
      "|    iterations           | 936          |\n",
      "|    time_elapsed         | 6510         |\n",
      "|    total_timesteps      | 15335424     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022939106 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.0522       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.24e+03     |\n",
      "|    n_updates            | 23820        |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    value_loss           | 2.96e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2355         |\n",
      "|    iterations           | 937          |\n",
      "|    time_elapsed         | 6517         |\n",
      "|    total_timesteps      | 15351808     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022191936 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0457       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 23830        |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    value_loss           | 3e+03        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15360000, episode_reward=778.80 +/- 117.38\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 779         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 15360000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002583575 |\n",
      "|    clip_fraction        | 0.017       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.515      |\n",
      "|    explained_variance   | 0.0764      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.55e+03    |\n",
      "|    n_updates            | 23840       |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    value_loss           | 2.98e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2353     |\n",
      "|    iterations      | 938      |\n",
      "|    time_elapsed    | 6529     |\n",
      "|    total_timesteps | 15368192 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2353         |\n",
      "|    iterations           | 939          |\n",
      "|    time_elapsed         | 6535         |\n",
      "|    total_timesteps      | 15384576     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020728246 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | 0.0582       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 23850        |\n",
      "|    policy_gradient_loss | -0.00547     |\n",
      "|    value_loss           | 3.1e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2354        |\n",
      "|    iterations           | 940         |\n",
      "|    time_elapsed         | 6542        |\n",
      "|    total_timesteps      | 15400960    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002353914 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.51       |\n",
      "|    explained_variance   | 0.0553      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.43e+03    |\n",
      "|    n_updates            | 23860       |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    value_loss           | 2.78e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2354        |\n",
      "|    iterations           | 941         |\n",
      "|    time_elapsed         | 6548        |\n",
      "|    total_timesteps      | 15417344    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002817378 |\n",
      "|    clip_fraction        | 0.0187      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.516      |\n",
      "|    explained_variance   | 0.0224      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.38e+03    |\n",
      "|    n_updates            | 23870       |\n",
      "|    policy_gradient_loss | -0.00632    |\n",
      "|    value_loss           | 2.77e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2354         |\n",
      "|    iterations           | 942          |\n",
      "|    time_elapsed         | 6555         |\n",
      "|    total_timesteps      | 15433728     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023852254 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.525       |\n",
      "|    explained_variance   | 0.0366       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 23880        |\n",
      "|    policy_gradient_loss | -0.00608     |\n",
      "|    value_loss           | 2.99e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15440000, episode_reward=791.60 +/- 121.05\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 792          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 15440000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025227517 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.51        |\n",
      "|    explained_variance   | -0.0116      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.84e+03     |\n",
      "|    n_updates            | 23890        |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    value_loss           | 3.18e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2352     |\n",
      "|    iterations      | 943      |\n",
      "|    time_elapsed    | 6567     |\n",
      "|    total_timesteps | 15450112 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2352         |\n",
      "|    iterations           | 944          |\n",
      "|    time_elapsed         | 6573         |\n",
      "|    total_timesteps      | 15466496     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024155348 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | 0.0304       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.7e+03      |\n",
      "|    n_updates            | 23900        |\n",
      "|    policy_gradient_loss | -0.00579     |\n",
      "|    value_loss           | 3.06e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2352         |\n",
      "|    iterations           | 945          |\n",
      "|    time_elapsed         | 6580         |\n",
      "|    total_timesteps      | 15482880     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025446606 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | -0.0132      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.44e+03     |\n",
      "|    n_updates            | 23910        |\n",
      "|    policy_gradient_loss | -0.00648     |\n",
      "|    value_loss           | 3e+03        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2352         |\n",
      "|    iterations           | 946          |\n",
      "|    time_elapsed         | 6587         |\n",
      "|    total_timesteps      | 15499264     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025009776 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0488       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 23920        |\n",
      "|    policy_gradient_loss | -0.00675     |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2353         |\n",
      "|    iterations           | 947          |\n",
      "|    time_elapsed         | 6593         |\n",
      "|    total_timesteps      | 15515648     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024599747 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0246       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 23930        |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    value_loss           | 3.09e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15520000, episode_reward=779.20 +/- 102.29\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 779          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 15520000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027265188 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.0227       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 23940        |\n",
      "|    policy_gradient_loss | -0.00669     |\n",
      "|    value_loss           | 2.97e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2351     |\n",
      "|    iterations      | 948      |\n",
      "|    time_elapsed    | 6605     |\n",
      "|    total_timesteps | 15532032 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2351         |\n",
      "|    iterations           | 949          |\n",
      "|    time_elapsed         | 6611         |\n",
      "|    total_timesteps      | 15548416     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023478977 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | 0.0404       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 23950        |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2351         |\n",
      "|    iterations           | 950          |\n",
      "|    time_elapsed         | 6618         |\n",
      "|    total_timesteps      | 15564800     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026172195 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.035        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 23960        |\n",
      "|    policy_gradient_loss | -0.00617     |\n",
      "|    value_loss           | 2.82e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2351         |\n",
      "|    iterations           | 951          |\n",
      "|    time_elapsed         | 6624         |\n",
      "|    total_timesteps      | 15581184     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023430604 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.000664     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 23970        |\n",
      "|    policy_gradient_loss | -0.00601     |\n",
      "|    value_loss           | 3.21e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2352         |\n",
      "|    iterations           | 952          |\n",
      "|    time_elapsed         | 6631         |\n",
      "|    total_timesteps      | 15597568     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023633847 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.0378       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.23e+03     |\n",
      "|    n_updates            | 23980        |\n",
      "|    policy_gradient_loss | -0.00558     |\n",
      "|    value_loss           | 3.02e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15600000, episode_reward=781.60 +/- 141.50\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 782          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 15600000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025157637 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0289       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 23990        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    value_loss           | 3.08e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2350     |\n",
      "|    iterations      | 953      |\n",
      "|    time_elapsed    | 6643     |\n",
      "|    total_timesteps | 15613952 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2350         |\n",
      "|    iterations           | 954          |\n",
      "|    time_elapsed         | 6650         |\n",
      "|    total_timesteps      | 15630336     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028892397 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.519       |\n",
      "|    explained_variance   | 0.0169       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.54e+03     |\n",
      "|    n_updates            | 24000        |\n",
      "|    policy_gradient_loss | -0.00679     |\n",
      "|    value_loss           | 3.03e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2350         |\n",
      "|    iterations           | 955          |\n",
      "|    time_elapsed         | 6656         |\n",
      "|    total_timesteps      | 15646720     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027851667 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.0217       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.59e+03     |\n",
      "|    n_updates            | 24010        |\n",
      "|    policy_gradient_loss | -0.00697     |\n",
      "|    value_loss           | 3.01e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2350         |\n",
      "|    iterations           | 956          |\n",
      "|    time_elapsed         | 6663         |\n",
      "|    total_timesteps      | 15663104     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025854234 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.516       |\n",
      "|    explained_variance   | 0.0126       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.59e+03     |\n",
      "|    n_updates            | 24020        |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    value_loss           | 2.97e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2350        |\n",
      "|    iterations           | 957         |\n",
      "|    time_elapsed         | 6670        |\n",
      "|    total_timesteps      | 15679488    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002321309 |\n",
      "|    clip_fraction        | 0.0143      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.513      |\n",
      "|    explained_variance   | 0.0545      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.58e+03    |\n",
      "|    n_updates            | 24030       |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    value_loss           | 3.13e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=15680000, episode_reward=750.40 +/- 96.19\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 750          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 15680000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025882595 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.00312      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.64e+03     |\n",
      "|    n_updates            | 24040        |\n",
      "|    policy_gradient_loss | -0.00678     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2348     |\n",
      "|    iterations      | 958      |\n",
      "|    time_elapsed    | 6682     |\n",
      "|    total_timesteps | 15695872 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2348         |\n",
      "|    iterations           | 959          |\n",
      "|    time_elapsed         | 6689         |\n",
      "|    total_timesteps      | 15712256     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025353848 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.039        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.32e+03     |\n",
      "|    n_updates            | 24050        |\n",
      "|    policy_gradient_loss | -0.00618     |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2349         |\n",
      "|    iterations           | 960          |\n",
      "|    time_elapsed         | 6695         |\n",
      "|    total_timesteps      | 15728640     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020757741 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.52        |\n",
      "|    explained_variance   | 0.0639       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.32e+03     |\n",
      "|    n_updates            | 24060        |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    value_loss           | 3.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2349         |\n",
      "|    iterations           | 961          |\n",
      "|    time_elapsed         | 6702         |\n",
      "|    total_timesteps      | 15745024     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024920844 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.521       |\n",
      "|    explained_variance   | 0.0298       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 24070        |\n",
      "|    policy_gradient_loss | -0.00634     |\n",
      "|    value_loss           | 2.92e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15760000, episode_reward=728.00 +/- 124.84\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 728          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 15760000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022920656 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0715       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 24080        |\n",
      "|    policy_gradient_loss | -0.00548     |\n",
      "|    value_loss           | 3.03e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2347     |\n",
      "|    iterations      | 962      |\n",
      "|    time_elapsed    | 6715     |\n",
      "|    total_timesteps | 15761408 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2347        |\n",
      "|    iterations           | 963         |\n",
      "|    time_elapsed         | 6721        |\n",
      "|    total_timesteps      | 15777792    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002758083 |\n",
      "|    clip_fraction        | 0.0173      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.514      |\n",
      "|    explained_variance   | 0.0533      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.67e+03    |\n",
      "|    n_updates            | 24090       |\n",
      "|    policy_gradient_loss | -0.00699    |\n",
      "|    value_loss           | 2.77e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2347         |\n",
      "|    iterations           | 964          |\n",
      "|    time_elapsed         | 6728         |\n",
      "|    total_timesteps      | 15794176     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022862763 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.0367       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 24100        |\n",
      "|    policy_gradient_loss | -0.00572     |\n",
      "|    value_loss           | 2.89e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2347        |\n",
      "|    iterations           | 965         |\n",
      "|    time_elapsed         | 6734        |\n",
      "|    total_timesteps      | 15810560    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002135929 |\n",
      "|    clip_fraction        | 0.01        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.525      |\n",
      "|    explained_variance   | 0.0315      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.23e+03    |\n",
      "|    n_updates            | 24110       |\n",
      "|    policy_gradient_loss | -0.00516    |\n",
      "|    value_loss           | 2.87e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2347         |\n",
      "|    iterations           | 966          |\n",
      "|    time_elapsed         | 6741         |\n",
      "|    total_timesteps      | 15826944     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027173455 |\n",
      "|    clip_fraction        | 0.0178       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.523       |\n",
      "|    explained_variance   | 0.0468       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.46e+03     |\n",
      "|    n_updates            | 24120        |\n",
      "|    policy_gradient_loss | -0.0067      |\n",
      "|    value_loss           | 2.62e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15840000, episode_reward=765.20 +/- 99.60\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 765          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 15840000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025915448 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.0199       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.67e+03     |\n",
      "|    n_updates            | 24130        |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    value_loss           | 2.73e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2345     |\n",
      "|    iterations      | 967      |\n",
      "|    time_elapsed    | 6754     |\n",
      "|    total_timesteps | 15843328 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2345         |\n",
      "|    iterations           | 968          |\n",
      "|    time_elapsed         | 6760         |\n",
      "|    total_timesteps      | 15859712     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022967919 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.525       |\n",
      "|    explained_variance   | 0.0201       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 24140        |\n",
      "|    policy_gradient_loss | -0.00576     |\n",
      "|    value_loss           | 2.96e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2345         |\n",
      "|    iterations           | 969          |\n",
      "|    time_elapsed         | 6767         |\n",
      "|    total_timesteps      | 15876096     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027395939 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.157        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.56e+03     |\n",
      "|    n_updates            | 24150        |\n",
      "|    policy_gradient_loss | -0.00629     |\n",
      "|    value_loss           | 2.65e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2345         |\n",
      "|    iterations           | 970          |\n",
      "|    time_elapsed         | 6774         |\n",
      "|    total_timesteps      | 15892480     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025463623 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.532       |\n",
      "|    explained_variance   | 0.0141       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 24160        |\n",
      "|    policy_gradient_loss | -0.00613     |\n",
      "|    value_loss           | 2.64e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2345        |\n",
      "|    iterations           | 971         |\n",
      "|    time_elapsed         | 6781        |\n",
      "|    total_timesteps      | 15908864    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002674084 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.518      |\n",
      "|    explained_variance   | 0.0279      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.63e+03    |\n",
      "|    n_updates            | 24170       |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    value_loss           | 2.63e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=15920000, episode_reward=791.20 +/- 114.66\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 791          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 15920000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027394323 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.525       |\n",
      "|    explained_variance   | 0.0261       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.56e+03     |\n",
      "|    n_updates            | 24180        |\n",
      "|    policy_gradient_loss | -0.0069      |\n",
      "|    value_loss           | 3.06e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2344     |\n",
      "|    iterations      | 972      |\n",
      "|    time_elapsed    | 6794     |\n",
      "|    total_timesteps | 15925248 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2344         |\n",
      "|    iterations           | 973          |\n",
      "|    time_elapsed         | 6800         |\n",
      "|    total_timesteps      | 15941632     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023679137 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.00561      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 24190        |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    value_loss           | 2.72e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2344         |\n",
      "|    iterations           | 974          |\n",
      "|    time_elapsed         | 6806         |\n",
      "|    total_timesteps      | 15958016     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023862657 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.0501       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.32e+03     |\n",
      "|    n_updates            | 24200        |\n",
      "|    policy_gradient_loss | -0.0058      |\n",
      "|    value_loss           | 2.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2344         |\n",
      "|    iterations           | 975          |\n",
      "|    time_elapsed         | 6812         |\n",
      "|    total_timesteps      | 15974400     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026199657 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | 0.0464       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.64e+03     |\n",
      "|    n_updates            | 24210        |\n",
      "|    policy_gradient_loss | -0.00647     |\n",
      "|    value_loss           | 2.91e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2345         |\n",
      "|    iterations           | 976          |\n",
      "|    time_elapsed         | 6818         |\n",
      "|    total_timesteps      | 15990784     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027015267 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.513       |\n",
      "|    explained_variance   | 0.0585       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 24220        |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    value_loss           | 3.1e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=16000000, episode_reward=747.60 +/- 82.09\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 748          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16000000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025653746 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | 0.0515       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.31e+03     |\n",
      "|    n_updates            | 24230        |\n",
      "|    policy_gradient_loss | -0.00663     |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2343     |\n",
      "|    iterations      | 977      |\n",
      "|    time_elapsed    | 6830     |\n",
      "|    total_timesteps | 16007168 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2343         |\n",
      "|    iterations           | 978          |\n",
      "|    time_elapsed         | 6837         |\n",
      "|    total_timesteps      | 16023552     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025007324 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | -0.00189     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.55e+03     |\n",
      "|    n_updates            | 24240        |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2343         |\n",
      "|    iterations           | 979          |\n",
      "|    time_elapsed         | 6843         |\n",
      "|    total_timesteps      | 16039936     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031168929 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.514       |\n",
      "|    explained_variance   | 0.0226       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.33e+03     |\n",
      "|    n_updates            | 24250        |\n",
      "|    policy_gradient_loss | -0.00712     |\n",
      "|    value_loss           | 2.73e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2344       |\n",
      "|    iterations           | 980        |\n",
      "|    time_elapsed         | 6849       |\n",
      "|    total_timesteps      | 16056320   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00246787 |\n",
      "|    clip_fraction        | 0.016      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.512     |\n",
      "|    explained_variance   | 0.0295     |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.54e+03   |\n",
      "|    n_updates            | 24260      |\n",
      "|    policy_gradient_loss | -0.00609   |\n",
      "|    value_loss           | 2.88e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2344        |\n",
      "|    iterations           | 981         |\n",
      "|    time_elapsed         | 6855        |\n",
      "|    total_timesteps      | 16072704    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002762898 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.51       |\n",
      "|    explained_variance   | 0.0482      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.3e+03     |\n",
      "|    n_updates            | 24270       |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    value_loss           | 2.98e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=16080000, episode_reward=786.00 +/- 119.57\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 786          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16080000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026035977 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.0575       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 24280        |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    value_loss           | 2.99e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2342     |\n",
      "|    iterations      | 982      |\n",
      "|    time_elapsed    | 6867     |\n",
      "|    total_timesteps | 16089088 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2343         |\n",
      "|    iterations           | 983          |\n",
      "|    time_elapsed         | 6873         |\n",
      "|    total_timesteps      | 16105472     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022060026 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | 0.0466       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 24290        |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2343         |\n",
      "|    iterations           | 984          |\n",
      "|    time_elapsed         | 6880         |\n",
      "|    total_timesteps      | 16121856     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028898777 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.515       |\n",
      "|    explained_variance   | 0.0305       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 24300        |\n",
      "|    policy_gradient_loss | -0.00616     |\n",
      "|    value_loss           | 2.82e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2343        |\n",
      "|    iterations           | 985         |\n",
      "|    time_elapsed         | 6886        |\n",
      "|    total_timesteps      | 16138240    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002445031 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.503      |\n",
      "|    explained_variance   | 0.0647      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.68e+03    |\n",
      "|    n_updates            | 24310       |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    value_loss           | 3.15e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2343         |\n",
      "|    iterations           | 986          |\n",
      "|    time_elapsed         | 6892         |\n",
      "|    total_timesteps      | 16154624     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026149247 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0709       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 24320        |\n",
      "|    policy_gradient_loss | -0.00616     |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=16160000, episode_reward=776.80 +/- 74.82\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 777         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 16160000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002094953 |\n",
      "|    clip_fraction        | 0.0126      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.5        |\n",
      "|    explained_variance   | 0.0688      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.7e+03     |\n",
      "|    n_updates            | 24330       |\n",
      "|    policy_gradient_loss | -0.00564    |\n",
      "|    value_loss           | 2.97e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2342     |\n",
      "|    iterations      | 987      |\n",
      "|    time_elapsed    | 6904     |\n",
      "|    total_timesteps | 16171008 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2342         |\n",
      "|    iterations           | 988          |\n",
      "|    time_elapsed         | 6910         |\n",
      "|    total_timesteps      | 16187392     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027063019 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0393       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.56e+03     |\n",
      "|    n_updates            | 24340        |\n",
      "|    policy_gradient_loss | -0.00664     |\n",
      "|    value_loss           | 2.98e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2342         |\n",
      "|    iterations           | 989          |\n",
      "|    time_elapsed         | 6915         |\n",
      "|    total_timesteps      | 16203776     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024441108 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.00127      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.96e+03     |\n",
      "|    n_updates            | 24350        |\n",
      "|    policy_gradient_loss | -0.006       |\n",
      "|    value_loss           | 3.44e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2343         |\n",
      "|    iterations           | 990          |\n",
      "|    time_elapsed         | 6921         |\n",
      "|    total_timesteps      | 16220160     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026547094 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.0228       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 24360        |\n",
      "|    policy_gradient_loss | -0.00609     |\n",
      "|    value_loss           | 2.97e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2343        |\n",
      "|    iterations           | 991         |\n",
      "|    time_elapsed         | 6927        |\n",
      "|    total_timesteps      | 16236544    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002404069 |\n",
      "|    clip_fraction        | 0.0143      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.501      |\n",
      "|    explained_variance   | 0.0542      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.32e+03    |\n",
      "|    n_updates            | 24370       |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    value_loss           | 2.73e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=16240000, episode_reward=707.20 +/- 165.15\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 707          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16240000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024076193 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.0209       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.23e+03     |\n",
      "|    n_updates            | 24380        |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    value_loss           | 2.98e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2342     |\n",
      "|    iterations      | 992      |\n",
      "|    time_elapsed    | 6938     |\n",
      "|    total_timesteps | 16252928 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2342         |\n",
      "|    iterations           | 993          |\n",
      "|    time_elapsed         | 6945         |\n",
      "|    total_timesteps      | 16269312     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023714136 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.0586       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.63e+03     |\n",
      "|    n_updates            | 24390        |\n",
      "|    policy_gradient_loss | -0.00594     |\n",
      "|    value_loss           | 3.15e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2342        |\n",
      "|    iterations           | 994         |\n",
      "|    time_elapsed         | 6951        |\n",
      "|    total_timesteps      | 16285696    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002345453 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.0302      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.14e+03    |\n",
      "|    n_updates            | 24400       |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    value_loss           | 2.9e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2343        |\n",
      "|    iterations           | 995         |\n",
      "|    time_elapsed         | 6957        |\n",
      "|    total_timesteps      | 16302080    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002532526 |\n",
      "|    clip_fraction        | 0.0167      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.503      |\n",
      "|    explained_variance   | 0.0349      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.14e+03    |\n",
      "|    n_updates            | 24410       |\n",
      "|    policy_gradient_loss | -0.00639    |\n",
      "|    value_loss           | 2.79e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2343        |\n",
      "|    iterations           | 996         |\n",
      "|    time_elapsed         | 6964        |\n",
      "|    total_timesteps      | 16318464    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002396565 |\n",
      "|    clip_fraction        | 0.0146      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.485      |\n",
      "|    explained_variance   | 0.0226      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.28e+03    |\n",
      "|    n_updates            | 24420       |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    value_loss           | 2.75e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=16320000, episode_reward=752.80 +/- 133.16\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 753         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 16320000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002508223 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.504      |\n",
      "|    explained_variance   | 0.0147      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.38e+03    |\n",
      "|    n_updates            | 24430       |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    value_loss           | 3.06e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2341     |\n",
      "|    iterations      | 997      |\n",
      "|    time_elapsed    | 6975     |\n",
      "|    total_timesteps | 16334848 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2341         |\n",
      "|    iterations           | 998          |\n",
      "|    time_elapsed         | 6982         |\n",
      "|    total_timesteps      | 16351232     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027393464 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0408       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.7e+03      |\n",
      "|    n_updates            | 24440        |\n",
      "|    policy_gradient_loss | -0.00653     |\n",
      "|    value_loss           | 2.96e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2342         |\n",
      "|    iterations           | 999          |\n",
      "|    time_elapsed         | 6988         |\n",
      "|    total_timesteps      | 16367616     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025019513 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.046        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.33e+03     |\n",
      "|    n_updates            | 24450        |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    value_loss           | 2.89e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2342        |\n",
      "|    iterations           | 1000        |\n",
      "|    time_elapsed         | 6994        |\n",
      "|    total_timesteps      | 16384000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002592177 |\n",
      "|    clip_fraction        | 0.0167      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.503      |\n",
      "|    explained_variance   | 0.0399      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.2e+03     |\n",
      "|    n_updates            | 24460       |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    value_loss           | 2.94e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=16400000, episode_reward=744.80 +/- 113.64\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 745         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 16400000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002504318 |\n",
      "|    clip_fraction        | 0.0167      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.499      |\n",
      "|    explained_variance   | 0.0085      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.55e+03    |\n",
      "|    n_updates            | 24470       |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    value_loss           | 2.96e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2340     |\n",
      "|    iterations      | 1001     |\n",
      "|    time_elapsed    | 7007     |\n",
      "|    total_timesteps | 16400384 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2340         |\n",
      "|    iterations           | 1002         |\n",
      "|    time_elapsed         | 7014         |\n",
      "|    total_timesteps      | 16416768     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025068112 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0323       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.36e+03     |\n",
      "|    n_updates            | 24480        |\n",
      "|    policy_gradient_loss | -0.00634     |\n",
      "|    value_loss           | 2.71e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2340         |\n",
      "|    iterations           | 1003         |\n",
      "|    time_elapsed         | 7020         |\n",
      "|    total_timesteps      | 16433152     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024443062 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.0474       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.66e+03     |\n",
      "|    n_updates            | 24490        |\n",
      "|    policy_gradient_loss | -0.00606     |\n",
      "|    value_loss           | 2.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2340         |\n",
      "|    iterations           | 1004         |\n",
      "|    time_elapsed         | 7027         |\n",
      "|    total_timesteps      | 16449536     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026610268 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.044        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 24500        |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2341         |\n",
      "|    iterations           | 1005         |\n",
      "|    time_elapsed         | 7033         |\n",
      "|    total_timesteps      | 16465920     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025764173 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.511       |\n",
      "|    explained_variance   | 0.0372       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 24510        |\n",
      "|    policy_gradient_loss | -0.00672     |\n",
      "|    value_loss           | 3.06e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=16480000, episode_reward=790.40 +/- 104.90\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 790         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 16480000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003089944 |\n",
      "|    clip_fraction        | 0.022       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.0275      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.82e+03    |\n",
      "|    n_updates            | 24520       |\n",
      "|    policy_gradient_loss | -0.00719    |\n",
      "|    value_loss           | 3.25e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2339     |\n",
      "|    iterations      | 1006     |\n",
      "|    time_elapsed    | 7046     |\n",
      "|    total_timesteps | 16482304 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2339         |\n",
      "|    iterations           | 1007         |\n",
      "|    time_elapsed         | 7052         |\n",
      "|    total_timesteps      | 16498688     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024935468 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.0233       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.92e+03     |\n",
      "|    n_updates            | 24530        |\n",
      "|    policy_gradient_loss | -0.00628     |\n",
      "|    value_loss           | 2.91e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2339        |\n",
      "|    iterations           | 1008        |\n",
      "|    time_elapsed         | 7059        |\n",
      "|    total_timesteps      | 16515072    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002715892 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.506      |\n",
      "|    explained_variance   | 0.0342      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.91e+03    |\n",
      "|    n_updates            | 24540       |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    value_loss           | 2.86e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2339         |\n",
      "|    iterations           | 1009         |\n",
      "|    time_elapsed         | 7065         |\n",
      "|    total_timesteps      | 16531456     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025769803 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.0372       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.76e+03     |\n",
      "|    n_updates            | 24550        |\n",
      "|    policy_gradient_loss | -0.00667     |\n",
      "|    value_loss           | 2.84e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2339         |\n",
      "|    iterations           | 1010         |\n",
      "|    time_elapsed         | 7072         |\n",
      "|    total_timesteps      | 16547840     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026048704 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0425       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.58e+03     |\n",
      "|    n_updates            | 24560        |\n",
      "|    policy_gradient_loss | -0.00617     |\n",
      "|    value_loss           | 2.92e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=16560000, episode_reward=797.60 +/- 111.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 798          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16560000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022587262 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.00652      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.37e+03     |\n",
      "|    n_updates            | 24570        |\n",
      "|    policy_gradient_loss | -0.00596     |\n",
      "|    value_loss           | 2.76e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2338     |\n",
      "|    iterations      | 1011     |\n",
      "|    time_elapsed    | 7084     |\n",
      "|    total_timesteps | 16564224 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2338         |\n",
      "|    iterations           | 1012         |\n",
      "|    time_elapsed         | 7090         |\n",
      "|    total_timesteps      | 16580608     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028148806 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.12         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.47e+03     |\n",
      "|    n_updates            | 24580        |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    value_loss           | 3.03e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2338         |\n",
      "|    iterations           | 1013         |\n",
      "|    time_elapsed         | 7096         |\n",
      "|    total_timesteps      | 16596992     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023601968 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.0481       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.23e+03     |\n",
      "|    n_updates            | 24590        |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    value_loss           | 3.04e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2338        |\n",
      "|    iterations           | 1014        |\n",
      "|    time_elapsed         | 7102        |\n",
      "|    total_timesteps      | 16613376    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002316874 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.503      |\n",
      "|    explained_variance   | 0.0657      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.81e+03    |\n",
      "|    n_updates            | 24600       |\n",
      "|    policy_gradient_loss | -0.00556    |\n",
      "|    value_loss           | 3.1e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2339         |\n",
      "|    iterations           | 1015         |\n",
      "|    time_elapsed         | 7109         |\n",
      "|    total_timesteps      | 16629760     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028471863 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.508       |\n",
      "|    explained_variance   | 0.0418       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 24610        |\n",
      "|    policy_gradient_loss | -0.00713     |\n",
      "|    value_loss           | 2.73e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=16640000, episode_reward=784.00 +/- 97.90\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 784          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16640000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026078539 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.024        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.45e+03     |\n",
      "|    n_updates            | 24620        |\n",
      "|    policy_gradient_loss | -0.00639     |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2337     |\n",
      "|    iterations      | 1016     |\n",
      "|    time_elapsed    | 7122     |\n",
      "|    total_timesteps | 16646144 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2337         |\n",
      "|    iterations           | 1017         |\n",
      "|    time_elapsed         | 7128         |\n",
      "|    total_timesteps      | 16662528     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025620726 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0849       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.64e+03     |\n",
      "|    n_updates            | 24630        |\n",
      "|    policy_gradient_loss | -0.0065      |\n",
      "|    value_loss           | 2.78e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2337         |\n",
      "|    iterations           | 1018         |\n",
      "|    time_elapsed         | 7134         |\n",
      "|    total_timesteps      | 16678912     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022468232 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.0665       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.96e+03     |\n",
      "|    n_updates            | 24640        |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    value_loss           | 3.18e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2337        |\n",
      "|    iterations           | 1019        |\n",
      "|    time_elapsed         | 7141        |\n",
      "|    total_timesteps      | 16695296    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002313895 |\n",
      "|    clip_fraction        | 0.0132      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.493      |\n",
      "|    explained_variance   | 0.0438      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.14e+03    |\n",
      "|    n_updates            | 24650       |\n",
      "|    policy_gradient_loss | -0.00582    |\n",
      "|    value_loss           | 3e+03       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2338         |\n",
      "|    iterations           | 1020         |\n",
      "|    time_elapsed         | 7147         |\n",
      "|    total_timesteps      | 16711680     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024492205 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0828       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.56e+03     |\n",
      "|    n_updates            | 24660        |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    value_loss           | 2.81e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=16720000, episode_reward=748.40 +/- 99.43\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 748          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16720000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024130598 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.0356       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 24670        |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2336     |\n",
      "|    iterations      | 1021     |\n",
      "|    time_elapsed    | 7158     |\n",
      "|    total_timesteps | 16728064 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2336         |\n",
      "|    iterations           | 1022         |\n",
      "|    time_elapsed         | 7165         |\n",
      "|    total_timesteps      | 16744448     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026196796 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.0196       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.8e+03      |\n",
      "|    n_updates            | 24680        |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    value_loss           | 3.21e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2337        |\n",
      "|    iterations           | 1023        |\n",
      "|    time_elapsed         | 7171        |\n",
      "|    total_timesteps      | 16760832    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002327681 |\n",
      "|    clip_fraction        | 0.0132      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.499      |\n",
      "|    explained_variance   | 0.0389      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.55e+03    |\n",
      "|    n_updates            | 24690       |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    value_loss           | 3.06e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2337         |\n",
      "|    iterations           | 1024         |\n",
      "|    time_elapsed         | 7177         |\n",
      "|    total_timesteps      | 16777216     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027411801 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.041        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.65e+03     |\n",
      "|    n_updates            | 24700        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2338         |\n",
      "|    iterations           | 1025         |\n",
      "|    time_elapsed         | 7182         |\n",
      "|    total_timesteps      | 16793600     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029520793 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0623       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 24710        |\n",
      "|    policy_gradient_loss | -0.00695     |\n",
      "|    value_loss           | 2.82e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=16800000, episode_reward=747.60 +/- 101.56\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 748          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16800000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024134708 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0462       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 24720        |\n",
      "|    policy_gradient_loss | -0.00623     |\n",
      "|    value_loss           | 3.14e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2336     |\n",
      "|    iterations      | 1026     |\n",
      "|    time_elapsed    | 7193     |\n",
      "|    total_timesteps | 16809984 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2336         |\n",
      "|    iterations           | 1027         |\n",
      "|    time_elapsed         | 7200         |\n",
      "|    total_timesteps      | 16826368     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026061728 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.509       |\n",
      "|    explained_variance   | 0.0878       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.09e+03     |\n",
      "|    n_updates            | 24730        |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    value_loss           | 2.94e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2337         |\n",
      "|    iterations           | 1028         |\n",
      "|    time_elapsed         | 7206         |\n",
      "|    total_timesteps      | 16842752     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027154335 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0257       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 24740        |\n",
      "|    policy_gradient_loss | -0.00661     |\n",
      "|    value_loss           | 2.99e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2337         |\n",
      "|    iterations           | 1029         |\n",
      "|    time_elapsed         | 7213         |\n",
      "|    total_timesteps      | 16859136     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024054863 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0671       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 24750        |\n",
      "|    policy_gradient_loss | -0.00647     |\n",
      "|    value_loss           | 2.73e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2337         |\n",
      "|    iterations           | 1030         |\n",
      "|    time_elapsed         | 7220         |\n",
      "|    total_timesteps      | 16875520     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024059196 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.0365       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 24760        |\n",
      "|    policy_gradient_loss | -0.00624     |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=16880000, episode_reward=769.20 +/- 127.25\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 769          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16880000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023421159 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0191       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.95e+03     |\n",
      "|    n_updates            | 24770        |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    value_loss           | 3.15e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2335     |\n",
      "|    iterations      | 1031     |\n",
      "|    time_elapsed    | 7233     |\n",
      "|    total_timesteps | 16891904 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2335         |\n",
      "|    iterations           | 1032         |\n",
      "|    time_elapsed         | 7239         |\n",
      "|    total_timesteps      | 16908288     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025532772 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0465       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 24780        |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    value_loss           | 2.94e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2335         |\n",
      "|    iterations           | 1033         |\n",
      "|    time_elapsed         | 7245         |\n",
      "|    total_timesteps      | 16924672     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027277176 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.518       |\n",
      "|    explained_variance   | 0.00297      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.44e+03     |\n",
      "|    n_updates            | 24790        |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    value_loss           | 2.99e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2335         |\n",
      "|    iterations           | 1034         |\n",
      "|    time_elapsed         | 7252         |\n",
      "|    total_timesteps      | 16941056     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028105187 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | 0.0484       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.4e+03      |\n",
      "|    n_updates            | 24800        |\n",
      "|    policy_gradient_loss | -0.00613     |\n",
      "|    value_loss           | 2.76e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2336         |\n",
      "|    iterations           | 1035         |\n",
      "|    time_elapsed         | 7258         |\n",
      "|    total_timesteps      | 16957440     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022596614 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.522       |\n",
      "|    explained_variance   | -0.00485     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 24810        |\n",
      "|    policy_gradient_loss | -0.00549     |\n",
      "|    value_loss           | 3.02e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=16960000, episode_reward=764.80 +/- 76.74\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 765          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 16960000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023304156 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.505       |\n",
      "|    explained_variance   | 0.0756       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 24820        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    value_loss           | 2.68e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2334     |\n",
      "|    iterations      | 1036     |\n",
      "|    time_elapsed    | 7270     |\n",
      "|    total_timesteps | 16973824 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2334        |\n",
      "|    iterations           | 1037        |\n",
      "|    time_elapsed         | 7276        |\n",
      "|    total_timesteps      | 16990208    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002299265 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.496      |\n",
      "|    explained_variance   | 0.0601      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.33e+03    |\n",
      "|    n_updates            | 24830       |\n",
      "|    policy_gradient_loss | -0.00584    |\n",
      "|    value_loss           | 2.84e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2335        |\n",
      "|    iterations           | 1038        |\n",
      "|    time_elapsed         | 7283        |\n",
      "|    total_timesteps      | 17006592    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002571211 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.503      |\n",
      "|    explained_variance   | 0.0765      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.34e+03    |\n",
      "|    n_updates            | 24840       |\n",
      "|    policy_gradient_loss | -0.00629    |\n",
      "|    value_loss           | 2.95e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2335         |\n",
      "|    iterations           | 1039         |\n",
      "|    time_elapsed         | 7289         |\n",
      "|    total_timesteps      | 17022976     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026769459 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0793       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 24850        |\n",
      "|    policy_gradient_loss | -0.00659     |\n",
      "|    value_loss           | 3.24e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2335         |\n",
      "|    iterations           | 1040         |\n",
      "|    time_elapsed         | 7295         |\n",
      "|    total_timesteps      | 17039360     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025749798 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0455       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 24860        |\n",
      "|    policy_gradient_loss | -0.0058      |\n",
      "|    value_loss           | 3.01e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=17040000, episode_reward=736.80 +/- 174.88\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 737          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 17040000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025672098 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.503       |\n",
      "|    explained_variance   | 0.0239       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1e+03        |\n",
      "|    n_updates            | 24870        |\n",
      "|    policy_gradient_loss | -0.00609     |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2334     |\n",
      "|    iterations      | 1041     |\n",
      "|    time_elapsed    | 7306     |\n",
      "|    total_timesteps | 17055744 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2334         |\n",
      "|    iterations           | 1042         |\n",
      "|    time_elapsed         | 7312         |\n",
      "|    total_timesteps      | 17072128     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024173695 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.0369       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 24880        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    value_loss           | 2.79e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2334         |\n",
      "|    iterations           | 1043         |\n",
      "|    time_elapsed         | 7319         |\n",
      "|    total_timesteps      | 17088512     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023047654 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0615       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.83e+03     |\n",
      "|    n_updates            | 24890        |\n",
      "|    policy_gradient_loss | -0.00565     |\n",
      "|    value_loss           | 3.02e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2335        |\n",
      "|    iterations           | 1044        |\n",
      "|    time_elapsed         | 7325        |\n",
      "|    total_timesteps      | 17104896    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002180806 |\n",
      "|    clip_fraction        | 0.0105      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.51       |\n",
      "|    explained_variance   | 0.0582      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.13e+03    |\n",
      "|    n_updates            | 24900       |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    value_loss           | 3.01e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=17120000, episode_reward=770.00 +/- 106.02\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 770          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 17120000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024585743 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.507       |\n",
      "|    explained_variance   | 0.0961       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.21e+03     |\n",
      "|    n_updates            | 24910        |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    value_loss           | 2.97e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2333     |\n",
      "|    iterations      | 1045     |\n",
      "|    time_elapsed    | 7337     |\n",
      "|    total_timesteps | 17121280 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2333         |\n",
      "|    iterations           | 1046         |\n",
      "|    time_elapsed         | 7343         |\n",
      "|    total_timesteps      | 17137664     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024833325 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0876       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.33e+03     |\n",
      "|    n_updates            | 24920        |\n",
      "|    policy_gradient_loss | -0.00588     |\n",
      "|    value_loss           | 2.92e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2333         |\n",
      "|    iterations           | 1047         |\n",
      "|    time_elapsed         | 7350         |\n",
      "|    total_timesteps      | 17154048     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022309106 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.00971      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 24930        |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    value_loss           | 3.25e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2334        |\n",
      "|    iterations           | 1048        |\n",
      "|    time_elapsed         | 7355        |\n",
      "|    total_timesteps      | 17170432    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002636856 |\n",
      "|    clip_fraction        | 0.017       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.489      |\n",
      "|    explained_variance   | 0.0619      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.39e+03    |\n",
      "|    n_updates            | 24940       |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    value_loss           | 2.93e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2334         |\n",
      "|    iterations           | 1049         |\n",
      "|    time_elapsed         | 7362         |\n",
      "|    total_timesteps      | 17186816     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028589852 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.097        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 24950        |\n",
      "|    policy_gradient_loss | -0.00635     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=17200000, episode_reward=780.40 +/- 81.41\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 780         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 17200000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002674613 |\n",
      "|    clip_fraction        | 0.0176      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.495      |\n",
      "|    explained_variance   | 0.0223      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.79e+03    |\n",
      "|    n_updates            | 24960       |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    value_loss           | 2.9e+03     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2332     |\n",
      "|    iterations      | 1050     |\n",
      "|    time_elapsed    | 7374     |\n",
      "|    total_timesteps | 17203200 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2333         |\n",
      "|    iterations           | 1051         |\n",
      "|    time_elapsed         | 7380         |\n",
      "|    total_timesteps      | 17219584     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021702275 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.479       |\n",
      "|    explained_variance   | 0.0501       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.98e+03     |\n",
      "|    n_updates            | 24970        |\n",
      "|    policy_gradient_loss | -0.00519     |\n",
      "|    value_loss           | 3.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2333         |\n",
      "|    iterations           | 1052         |\n",
      "|    time_elapsed         | 7386         |\n",
      "|    total_timesteps      | 17235968     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023006792 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.025        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 24980        |\n",
      "|    policy_gradient_loss | -0.00556     |\n",
      "|    value_loss           | 2.98e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2333        |\n",
      "|    iterations           | 1053        |\n",
      "|    time_elapsed         | 7393        |\n",
      "|    total_timesteps      | 17252352    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002680813 |\n",
      "|    clip_fraction        | 0.0186      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.485      |\n",
      "|    explained_variance   | 0.0429      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.36e+03    |\n",
      "|    n_updates            | 24990       |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    value_loss           | 2.97e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2333         |\n",
      "|    iterations           | 1054         |\n",
      "|    time_elapsed         | 7399         |\n",
      "|    total_timesteps      | 17268736     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019828063 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.0737       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 25000        |\n",
      "|    policy_gradient_loss | -0.00514     |\n",
      "|    value_loss           | 2.93e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=17280000, episode_reward=817.60 +/- 118.84\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 818          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 17280000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021680724 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | -0.02        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 25010        |\n",
      "|    policy_gradient_loss | -0.00555     |\n",
      "|    value_loss           | 3.09e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2332     |\n",
      "|    iterations      | 1055     |\n",
      "|    time_elapsed    | 7410     |\n",
      "|    total_timesteps | 17285120 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2332         |\n",
      "|    iterations           | 1056         |\n",
      "|    time_elapsed         | 7416         |\n",
      "|    total_timesteps      | 17301504     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024713739 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.0222       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 25020        |\n",
      "|    policy_gradient_loss | -0.00664     |\n",
      "|    value_loss           | 3.24e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2333         |\n",
      "|    iterations           | 1057         |\n",
      "|    time_elapsed         | 7422         |\n",
      "|    total_timesteps      | 17317888     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025760133 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0233       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.68e+03     |\n",
      "|    n_updates            | 25030        |\n",
      "|    policy_gradient_loss | -0.00599     |\n",
      "|    value_loss           | 2.99e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2333        |\n",
      "|    iterations           | 1058        |\n",
      "|    time_elapsed         | 7428        |\n",
      "|    total_timesteps      | 17334272    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002571534 |\n",
      "|    clip_fraction        | 0.0157      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.497      |\n",
      "|    explained_variance   | 0.033       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.05e+03    |\n",
      "|    n_updates            | 25040       |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    value_loss           | 2.94e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2333        |\n",
      "|    iterations           | 1059        |\n",
      "|    time_elapsed         | 7434        |\n",
      "|    total_timesteps      | 17350656    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002803991 |\n",
      "|    clip_fraction        | 0.0209      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.504      |\n",
      "|    explained_variance   | 0.053       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 25050       |\n",
      "|    policy_gradient_loss | -0.00641    |\n",
      "|    value_loss           | 3.02e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=17360000, episode_reward=782.80 +/- 105.21\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 783          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 17360000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019877953 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.485       |\n",
      "|    explained_variance   | 0.0546       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.79e+03     |\n",
      "|    n_updates            | 25060        |\n",
      "|    policy_gradient_loss | -0.00532     |\n",
      "|    value_loss           | 3.28e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2332     |\n",
      "|    iterations      | 1060     |\n",
      "|    time_elapsed    | 7445     |\n",
      "|    total_timesteps | 17367040 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2332        |\n",
      "|    iterations           | 1061        |\n",
      "|    time_elapsed         | 7451        |\n",
      "|    total_timesteps      | 17383424    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002446705 |\n",
      "|    clip_fraction        | 0.0137      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.498      |\n",
      "|    explained_variance   | 0.00657     |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.85e+03    |\n",
      "|    n_updates            | 25070       |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    value_loss           | 3.16e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2333         |\n",
      "|    iterations           | 1062         |\n",
      "|    time_elapsed         | 7457         |\n",
      "|    total_timesteps      | 17399808     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024312516 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0242       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 25080        |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    value_loss           | 3.15e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2333        |\n",
      "|    iterations           | 1063        |\n",
      "|    time_elapsed         | 7463        |\n",
      "|    total_timesteps      | 17416192    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002439503 |\n",
      "|    clip_fraction        | 0.0165      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.492      |\n",
      "|    explained_variance   | 0.0772      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.64e+03    |\n",
      "|    n_updates            | 25090       |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    value_loss           | 2.98e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2333         |\n",
      "|    iterations           | 1064         |\n",
      "|    time_elapsed         | 7469         |\n",
      "|    total_timesteps      | 17432576     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021359809 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.489       |\n",
      "|    explained_variance   | 0.0365       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.51e+03     |\n",
      "|    n_updates            | 25100        |\n",
      "|    policy_gradient_loss | -0.00546     |\n",
      "|    value_loss           | 3.04e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=17440000, episode_reward=752.00 +/- 75.15\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 752          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 17440000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020049012 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | -0.00376     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 25110        |\n",
      "|    policy_gradient_loss | -0.0058      |\n",
      "|    value_loss           | 2.78e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2332     |\n",
      "|    iterations      | 1065     |\n",
      "|    time_elapsed    | 7480     |\n",
      "|    total_timesteps | 17448960 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2332         |\n",
      "|    iterations           | 1066         |\n",
      "|    time_elapsed         | 7486         |\n",
      "|    total_timesteps      | 17465344     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023300448 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.484       |\n",
      "|    explained_variance   | 5.64e-05     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.47e+03     |\n",
      "|    n_updates            | 25120        |\n",
      "|    policy_gradient_loss | -0.00579     |\n",
      "|    value_loss           | 3.07e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2333         |\n",
      "|    iterations           | 1067         |\n",
      "|    time_elapsed         | 7492         |\n",
      "|    total_timesteps      | 17481728     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029739528 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0491       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 25130        |\n",
      "|    policy_gradient_loss | -0.00733     |\n",
      "|    value_loss           | 2.64e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2333         |\n",
      "|    iterations           | 1068         |\n",
      "|    time_elapsed         | 7499         |\n",
      "|    total_timesteps      | 17498112     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023987505 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.0376       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 25140        |\n",
      "|    policy_gradient_loss | -0.00617     |\n",
      "|    value_loss           | 3.06e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2333         |\n",
      "|    iterations           | 1069         |\n",
      "|    time_elapsed         | 7506         |\n",
      "|    total_timesteps      | 17514496     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029515412 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.0166       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 25150        |\n",
      "|    policy_gradient_loss | -0.00664     |\n",
      "|    value_loss           | 3.08e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=17520000, episode_reward=804.40 +/- 100.96\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 804          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 17520000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024650162 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | 0.0412       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.52e+03     |\n",
      "|    n_updates            | 25160        |\n",
      "|    policy_gradient_loss | -0.00594     |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2331     |\n",
      "|    iterations      | 1070     |\n",
      "|    time_elapsed    | 7517     |\n",
      "|    total_timesteps | 17530880 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2332         |\n",
      "|    iterations           | 1071         |\n",
      "|    time_elapsed         | 7524         |\n",
      "|    total_timesteps      | 17547264     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029759458 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.512       |\n",
      "|    explained_variance   | 0.173        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.28e+03     |\n",
      "|    n_updates            | 25170        |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2332         |\n",
      "|    iterations           | 1072         |\n",
      "|    time_elapsed         | 7530         |\n",
      "|    total_timesteps      | 17563648     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027447292 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.0211       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.5e+03      |\n",
      "|    n_updates            | 25180        |\n",
      "|    policy_gradient_loss | -0.00644     |\n",
      "|    value_loss           | 3.21e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2332         |\n",
      "|    iterations           | 1073         |\n",
      "|    time_elapsed         | 7536         |\n",
      "|    total_timesteps      | 17580032     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028577973 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.044        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.49e+03     |\n",
      "|    n_updates            | 25190        |\n",
      "|    policy_gradient_loss | -0.00596     |\n",
      "|    value_loss           | 2.86e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2332         |\n",
      "|    iterations           | 1074         |\n",
      "|    time_elapsed         | 7542         |\n",
      "|    total_timesteps      | 17596416     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026810514 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.025        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.63e+03     |\n",
      "|    n_updates            | 25200        |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    value_loss           | 3e+03        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=17600000, episode_reward=790.40 +/- 113.33\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 790         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 17600000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002134555 |\n",
      "|    clip_fraction        | 0.0121      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.484      |\n",
      "|    explained_variance   | 0.0172      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.94e+03    |\n",
      "|    n_updates            | 25210       |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    value_loss           | 3.06e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2331     |\n",
      "|    iterations      | 1075     |\n",
      "|    time_elapsed    | 7554     |\n",
      "|    total_timesteps | 17612800 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1076         |\n",
      "|    time_elapsed         | 7560         |\n",
      "|    total_timesteps      | 17629184     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028354404 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.00828      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2e+03        |\n",
      "|    n_updates            | 25220        |\n",
      "|    policy_gradient_loss | -0.00624     |\n",
      "|    value_loss           | 3.14e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2332         |\n",
      "|    iterations           | 1077         |\n",
      "|    time_elapsed         | 7566         |\n",
      "|    total_timesteps      | 17645568     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024917638 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.495       |\n",
      "|    explained_variance   | 0.0376       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 25230        |\n",
      "|    policy_gradient_loss | -0.00638     |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2332        |\n",
      "|    iterations           | 1078        |\n",
      "|    time_elapsed         | 7572        |\n",
      "|    total_timesteps      | 17661952    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002532763 |\n",
      "|    clip_fraction        | 0.0158      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.503      |\n",
      "|    explained_variance   | 0.0204      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.43e+03    |\n",
      "|    n_updates            | 25240       |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    value_loss           | 2.92e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2332        |\n",
      "|    iterations           | 1079        |\n",
      "|    time_elapsed         | 7578        |\n",
      "|    total_timesteps      | 17678336    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002516171 |\n",
      "|    clip_fraction        | 0.0159      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.497      |\n",
      "|    explained_variance   | 0.0272      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 25250       |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    value_loss           | 2.96e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=17680000, episode_reward=809.60 +/- 97.18\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 810          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 17680000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025758739 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.498       |\n",
      "|    explained_variance   | 0.0364       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 995          |\n",
      "|    n_updates            | 25260        |\n",
      "|    policy_gradient_loss | -0.0066      |\n",
      "|    value_loss           | 2.69e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2331     |\n",
      "|    iterations      | 1080     |\n",
      "|    time_elapsed    | 7590     |\n",
      "|    total_timesteps | 17694720 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1081         |\n",
      "|    time_elapsed         | 7596         |\n",
      "|    total_timesteps      | 17711104     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023988313 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.502       |\n",
      "|    explained_variance   | 0.0152       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.56e+03     |\n",
      "|    n_updates            | 25270        |\n",
      "|    policy_gradient_loss | -0.00626     |\n",
      "|    value_loss           | 3.2e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2331        |\n",
      "|    iterations           | 1082        |\n",
      "|    time_elapsed         | 7602        |\n",
      "|    total_timesteps      | 17727488    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002348869 |\n",
      "|    clip_fraction        | 0.0135      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.491      |\n",
      "|    explained_variance   | 0.045       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.31e+03    |\n",
      "|    n_updates            | 25280       |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    value_loss           | 2.94e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2332         |\n",
      "|    iterations           | 1083         |\n",
      "|    time_elapsed         | 7608         |\n",
      "|    total_timesteps      | 17743872     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021598015 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.0258       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 25290        |\n",
      "|    policy_gradient_loss | -0.00565     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=17760000, episode_reward=776.40 +/- 137.26\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 776          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 17760000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022459468 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.0573       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 25300        |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    value_loss           | 3.14e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2330     |\n",
      "|    iterations      | 1084     |\n",
      "|    time_elapsed    | 7619     |\n",
      "|    total_timesteps | 17760256 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1085         |\n",
      "|    time_elapsed         | 7626         |\n",
      "|    total_timesteps      | 17776640     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021409807 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.00433      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.66e+03     |\n",
      "|    n_updates            | 25310        |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    value_loss           | 3.29e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1086         |\n",
      "|    time_elapsed         | 7632         |\n",
      "|    total_timesteps      | 17793024     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023408139 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.489       |\n",
      "|    explained_variance   | 0.0144       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 25320        |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    value_loss           | 3.17e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1087         |\n",
      "|    time_elapsed         | 7638         |\n",
      "|    total_timesteps      | 17809408     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021615354 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0379       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 25330        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    value_loss           | 3.12e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1088         |\n",
      "|    time_elapsed         | 7644         |\n",
      "|    total_timesteps      | 17825792     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023555683 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.0399       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 25340        |\n",
      "|    policy_gradient_loss | -0.00616     |\n",
      "|    value_loss           | 3.06e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=17840000, episode_reward=760.40 +/- 95.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 760          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 17840000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020995387 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.0153       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 25350        |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    value_loss           | 3.22e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2330     |\n",
      "|    iterations      | 1089     |\n",
      "|    time_elapsed    | 7655     |\n",
      "|    total_timesteps | 17842176 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1090         |\n",
      "|    time_elapsed         | 7661         |\n",
      "|    total_timesteps      | 17858560     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028995504 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.00519      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 25360        |\n",
      "|    policy_gradient_loss | -0.00653     |\n",
      "|    value_loss           | 2.96e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2331       |\n",
      "|    iterations           | 1091       |\n",
      "|    time_elapsed         | 7667       |\n",
      "|    total_timesteps      | 17874944   |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00260049 |\n",
      "|    clip_fraction        | 0.0154     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.494     |\n",
      "|    explained_variance   | 0.067      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 1.67e+03   |\n",
      "|    n_updates            | 25370      |\n",
      "|    policy_gradient_loss | -0.00581   |\n",
      "|    value_loss           | 3.15e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2331        |\n",
      "|    iterations           | 1092        |\n",
      "|    time_elapsed         | 7673        |\n",
      "|    total_timesteps      | 17891328    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002332823 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.492      |\n",
      "|    explained_variance   | 0.0124      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.91e+03    |\n",
      "|    n_updates            | 25380       |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    value_loss           | 2.99e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1093         |\n",
      "|    time_elapsed         | 7679         |\n",
      "|    total_timesteps      | 17907712     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022346117 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.0428       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.06e+03     |\n",
      "|    n_updates            | 25390        |\n",
      "|    policy_gradient_loss | -0.00517     |\n",
      "|    value_loss           | 3.33e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=17920000, episode_reward=776.80 +/- 89.43\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 777          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 17920000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024543004 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.0345       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.51e+03     |\n",
      "|    n_updates            | 25400        |\n",
      "|    policy_gradient_loss | -0.00613     |\n",
      "|    value_loss           | 3.16e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2330     |\n",
      "|    iterations      | 1094     |\n",
      "|    time_elapsed    | 7690     |\n",
      "|    total_timesteps | 17924096 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1095         |\n",
      "|    time_elapsed         | 7696         |\n",
      "|    total_timesteps      | 17940480     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024512447 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.0423       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.68e+03     |\n",
      "|    n_updates            | 25410        |\n",
      "|    policy_gradient_loss | -0.00611     |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1096         |\n",
      "|    time_elapsed         | 7702         |\n",
      "|    total_timesteps      | 17956864     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023401421 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.506       |\n",
      "|    explained_variance   | 0.0248       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.12e+03     |\n",
      "|    n_updates            | 25420        |\n",
      "|    policy_gradient_loss | -0.00605     |\n",
      "|    value_loss           | 2.93e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1097         |\n",
      "|    time_elapsed         | 7708         |\n",
      "|    total_timesteps      | 17973248     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023388732 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0624       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.43e+03     |\n",
      "|    n_updates            | 25430        |\n",
      "|    policy_gradient_loss | -0.00606     |\n",
      "|    value_loss           | 3.37e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2331        |\n",
      "|    iterations           | 1098        |\n",
      "|    time_elapsed         | 7714        |\n",
      "|    total_timesteps      | 17989632    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002501975 |\n",
      "|    clip_fraction        | 0.0158      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.498      |\n",
      "|    explained_variance   | 0.0397      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.68e+03    |\n",
      "|    n_updates            | 25440       |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    value_loss           | 3.13e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=18000000, episode_reward=810.00 +/- 95.37\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 810         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 18000000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002405961 |\n",
      "|    clip_fraction        | 0.0166      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.479      |\n",
      "|    explained_variance   | 0.0596      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 989         |\n",
      "|    n_updates            | 25450       |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    value_loss           | 3.15e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2330     |\n",
      "|    iterations      | 1099     |\n",
      "|    time_elapsed    | 7725     |\n",
      "|    total_timesteps | 18006016 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1100         |\n",
      "|    time_elapsed         | 7731         |\n",
      "|    total_timesteps      | 18022400     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022379465 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.0704       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.45e+03     |\n",
      "|    n_updates            | 25460        |\n",
      "|    policy_gradient_loss | -0.00519     |\n",
      "|    value_loss           | 3.12e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2331        |\n",
      "|    iterations           | 1101        |\n",
      "|    time_elapsed         | 7738        |\n",
      "|    total_timesteps      | 18038784    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002399644 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.496      |\n",
      "|    explained_variance   | 0.0238      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 2.07e+03    |\n",
      "|    n_updates            | 25470       |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    value_loss           | 3.35e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2331        |\n",
      "|    iterations           | 1102        |\n",
      "|    time_elapsed         | 7744        |\n",
      "|    total_timesteps      | 18055168    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002549173 |\n",
      "|    clip_fraction        | 0.0161      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.5        |\n",
      "|    explained_variance   | 0.0384      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 25480       |\n",
      "|    policy_gradient_loss | -0.00617    |\n",
      "|    value_loss           | 3.12e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1103         |\n",
      "|    time_elapsed         | 7750         |\n",
      "|    total_timesteps      | 18071552     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024066921 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | -0.00504     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.45e+03     |\n",
      "|    n_updates            | 25490        |\n",
      "|    policy_gradient_loss | -0.00613     |\n",
      "|    value_loss           | 3.06e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=18080000, episode_reward=818.00 +/- 84.47\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 818          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18080000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027258447 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.0518       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 25500        |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    value_loss           | 3.17e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2330     |\n",
      "|    iterations      | 1104     |\n",
      "|    time_elapsed    | 7761     |\n",
      "|    total_timesteps | 18087936 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1105         |\n",
      "|    time_elapsed         | 7767         |\n",
      "|    total_timesteps      | 18104320     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023066667 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.0628       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.72e+03     |\n",
      "|    n_updates            | 25510        |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    value_loss           | 3.28e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1106         |\n",
      "|    time_elapsed         | 7773         |\n",
      "|    total_timesteps      | 18120704     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026137582 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0186       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.33e+03     |\n",
      "|    n_updates            | 25520        |\n",
      "|    policy_gradient_loss | -0.00652     |\n",
      "|    value_loss           | 3.22e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2331        |\n",
      "|    iterations           | 1107        |\n",
      "|    time_elapsed         | 7779        |\n",
      "|    total_timesteps      | 18137088    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002413002 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.497      |\n",
      "|    explained_variance   | 0.037       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.58e+03    |\n",
      "|    n_updates            | 25530       |\n",
      "|    policy_gradient_loss | -0.00607    |\n",
      "|    value_loss           | 3.09e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1108         |\n",
      "|    time_elapsed         | 7785         |\n",
      "|    total_timesteps      | 18153472     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023022331 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0828       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 25540        |\n",
      "|    policy_gradient_loss | -0.00638     |\n",
      "|    value_loss           | 3.11e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=18160000, episode_reward=818.00 +/- 101.78\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 818          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18160000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021355369 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0302       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.09e+03     |\n",
      "|    n_updates            | 25550        |\n",
      "|    policy_gradient_loss | -0.00551     |\n",
      "|    value_loss           | 3.15e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2330     |\n",
      "|    iterations      | 1109     |\n",
      "|    time_elapsed    | 7796     |\n",
      "|    total_timesteps | 18169856 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1110         |\n",
      "|    time_elapsed         | 7802         |\n",
      "|    total_timesteps      | 18186240     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022555247 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.0647       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.58e+03     |\n",
      "|    n_updates            | 25560        |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    value_loss           | 3.32e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1111         |\n",
      "|    time_elapsed         | 7808         |\n",
      "|    total_timesteps      | 18202624     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024987306 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.484       |\n",
      "|    explained_variance   | 0.0347       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.69e+03     |\n",
      "|    n_updates            | 25570        |\n",
      "|    policy_gradient_loss | -0.00597     |\n",
      "|    value_loss           | 3.14e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1112         |\n",
      "|    time_elapsed         | 7814         |\n",
      "|    total_timesteps      | 18219008     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023957277 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.485       |\n",
      "|    explained_variance   | 0.043        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.95e+03     |\n",
      "|    n_updates            | 25580        |\n",
      "|    policy_gradient_loss | -0.00559     |\n",
      "|    value_loss           | 3.1e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1113         |\n",
      "|    time_elapsed         | 7820         |\n",
      "|    total_timesteps      | 18235392     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022152876 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.0555       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.46e+03     |\n",
      "|    n_updates            | 25590        |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    value_loss           | 3.1e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=18240000, episode_reward=811.60 +/- 106.72\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 812          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18240000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021885857 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.0644       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.47e+03     |\n",
      "|    n_updates            | 25600        |\n",
      "|    policy_gradient_loss | -0.00594     |\n",
      "|    value_loss           | 3.49e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2330     |\n",
      "|    iterations      | 1114     |\n",
      "|    time_elapsed    | 7832     |\n",
      "|    total_timesteps | 18251776 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1115         |\n",
      "|    time_elapsed         | 7838         |\n",
      "|    total_timesteps      | 18268160     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024063597 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.0529       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 25610        |\n",
      "|    policy_gradient_loss | -0.00583     |\n",
      "|    value_loss           | 2.92e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1116         |\n",
      "|    time_elapsed         | 7844         |\n",
      "|    total_timesteps      | 18284544     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024550704 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.0432       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 25620        |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    value_loss           | 3.05e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2331        |\n",
      "|    iterations           | 1117        |\n",
      "|    time_elapsed         | 7850        |\n",
      "|    total_timesteps      | 18300928    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002184126 |\n",
      "|    clip_fraction        | 0.012       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.488      |\n",
      "|    explained_variance   | 0.0134      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.48e+03    |\n",
      "|    n_updates            | 25630       |\n",
      "|    policy_gradient_loss | -0.00568    |\n",
      "|    value_loss           | 3.08e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2331        |\n",
      "|    iterations           | 1118        |\n",
      "|    time_elapsed         | 7856        |\n",
      "|    total_timesteps      | 18317312    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002556455 |\n",
      "|    clip_fraction        | 0.0184      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.492      |\n",
      "|    explained_variance   | 0.0522      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.55e+03    |\n",
      "|    n_updates            | 25640       |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    value_loss           | 3.2e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=18320000, episode_reward=787.20 +/- 94.76\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 787          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18320000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026953334 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.0304       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.33e+03     |\n",
      "|    n_updates            | 25650        |\n",
      "|    policy_gradient_loss | -0.0064      |\n",
      "|    value_loss           | 3.21e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2330     |\n",
      "|    iterations      | 1119     |\n",
      "|    time_elapsed    | 7867     |\n",
      "|    total_timesteps | 18333696 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1120         |\n",
      "|    time_elapsed         | 7873         |\n",
      "|    total_timesteps      | 18350080     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027894655 |\n",
      "|    clip_fraction        | 0.023        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.0431       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 25660        |\n",
      "|    policy_gradient_loss | -0.00642     |\n",
      "|    value_loss           | 3.31e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1121         |\n",
      "|    time_elapsed         | 7879         |\n",
      "|    total_timesteps      | 18366464     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023588298 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.0647       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.51e+03     |\n",
      "|    n_updates            | 25670        |\n",
      "|    policy_gradient_loss | -0.0055      |\n",
      "|    value_loss           | 3.14e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2331        |\n",
      "|    iterations           | 1122        |\n",
      "|    time_elapsed         | 7885        |\n",
      "|    total_timesteps      | 18382848    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002390869 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.487      |\n",
      "|    explained_variance   | 0.0313      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.93e+03    |\n",
      "|    n_updates            | 25680       |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    value_loss           | 3.29e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1123         |\n",
      "|    time_elapsed         | 7891         |\n",
      "|    total_timesteps      | 18399232     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024503185 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.0185       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.36e+03     |\n",
      "|    n_updates            | 25690        |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    value_loss           | 2.91e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=18400000, episode_reward=860.00 +/- 110.53\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 860          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18400000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029097411 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.501       |\n",
      "|    explained_variance   | 0.0105       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.51e+03     |\n",
      "|    n_updates            | 25700        |\n",
      "|    policy_gradient_loss | -0.00604     |\n",
      "|    value_loss           | 3.11e+03     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2330     |\n",
      "|    iterations      | 1124     |\n",
      "|    time_elapsed    | 7902     |\n",
      "|    total_timesteps | 18415616 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1125         |\n",
      "|    time_elapsed         | 7909         |\n",
      "|    total_timesteps      | 18432000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021060875 |\n",
      "|    clip_fraction        | 0.0113       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.489       |\n",
      "|    explained_variance   | 0.0368       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.57e+03     |\n",
      "|    n_updates            | 25710        |\n",
      "|    policy_gradient_loss | -0.00517     |\n",
      "|    value_loss           | 3.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1126         |\n",
      "|    time_elapsed         | 7915         |\n",
      "|    total_timesteps      | 18448384     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023943414 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.017        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.89e+03     |\n",
      "|    n_updates            | 25720        |\n",
      "|    policy_gradient_loss | -0.0053      |\n",
      "|    value_loss           | 3.42e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1127         |\n",
      "|    time_elapsed         | 7921         |\n",
      "|    total_timesteps      | 18464768     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025193729 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.0381       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.68e+03     |\n",
      "|    n_updates            | 25730        |\n",
      "|    policy_gradient_loss | -0.00586     |\n",
      "|    value_loss           | 3.25e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=18480000, episode_reward=805.20 +/- 117.48\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 805          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18480000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022436948 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.475       |\n",
      "|    explained_variance   | 0.0384       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.8e+03      |\n",
      "|    n_updates            | 25740        |\n",
      "|    policy_gradient_loss | -0.00557     |\n",
      "|    value_loss           | 3.08e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2329     |\n",
      "|    iterations      | 1128     |\n",
      "|    time_elapsed    | 7932     |\n",
      "|    total_timesteps | 18481152 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1129         |\n",
      "|    time_elapsed         | 7938         |\n",
      "|    total_timesteps      | 18497536     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025175563 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0213       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.64e+03     |\n",
      "|    n_updates            | 25750        |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    value_loss           | 3.01e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1130         |\n",
      "|    time_elapsed         | 7944         |\n",
      "|    total_timesteps      | 18513920     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030006617 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | 0.0679       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.98e+03     |\n",
      "|    n_updates            | 25760        |\n",
      "|    policy_gradient_loss | -0.00679     |\n",
      "|    value_loss           | 3.14e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1131         |\n",
      "|    time_elapsed         | 7950         |\n",
      "|    total_timesteps      | 18530304     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025595361 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.481       |\n",
      "|    explained_variance   | 0.0247       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.67e+03     |\n",
      "|    n_updates            | 25770        |\n",
      "|    policy_gradient_loss | -0.00562     |\n",
      "|    value_loss           | 3.51e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1132         |\n",
      "|    time_elapsed         | 7956         |\n",
      "|    total_timesteps      | 18546688     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025412596 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.481       |\n",
      "|    explained_variance   | 0.0725       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.5e+03      |\n",
      "|    n_updates            | 25780        |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    value_loss           | 3.2e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=18560000, episode_reward=824.80 +/- 103.31\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 825          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18560000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022709079 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.0821       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.74e+03     |\n",
      "|    n_updates            | 25790        |\n",
      "|    policy_gradient_loss | -0.0056      |\n",
      "|    value_loss           | 3.18e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2329     |\n",
      "|    iterations      | 1133     |\n",
      "|    time_elapsed    | 7967     |\n",
      "|    total_timesteps | 18563072 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2329         |\n",
      "|    iterations           | 1134         |\n",
      "|    time_elapsed         | 7974         |\n",
      "|    total_timesteps      | 18579456     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026578484 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.0574       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 25800        |\n",
      "|    policy_gradient_loss | -0.00609     |\n",
      "|    value_loss           | 3.22e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2330        |\n",
      "|    iterations           | 1135        |\n",
      "|    time_elapsed         | 7980        |\n",
      "|    total_timesteps      | 18595840    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002185469 |\n",
      "|    clip_fraction        | 0.0127      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.481      |\n",
      "|    explained_variance   | 0.0251      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.29e+03    |\n",
      "|    n_updates            | 25810       |\n",
      "|    policy_gradient_loss | -0.00529    |\n",
      "|    value_loss           | 3.24e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1136         |\n",
      "|    time_elapsed         | 7986         |\n",
      "|    total_timesteps      | 18612224     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030625733 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.483       |\n",
      "|    explained_variance   | 0.0722       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.5e+03      |\n",
      "|    n_updates            | 25820        |\n",
      "|    policy_gradient_loss | -0.00556     |\n",
      "|    value_loss           | 3.08e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1137         |\n",
      "|    time_elapsed         | 7992         |\n",
      "|    total_timesteps      | 18628608     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021242835 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.475       |\n",
      "|    explained_variance   | 0.0277       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 25830        |\n",
      "|    policy_gradient_loss | -0.00536     |\n",
      "|    value_loss           | 3.26e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=18640000, episode_reward=805.60 +/- 100.04\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 806          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18640000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021441393 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.469       |\n",
      "|    explained_variance   | 0.0559       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.98e+03     |\n",
      "|    n_updates            | 25840        |\n",
      "|    policy_gradient_loss | -0.0049      |\n",
      "|    value_loss           | 3.13e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2329     |\n",
      "|    iterations      | 1138     |\n",
      "|    time_elapsed    | 8003     |\n",
      "|    total_timesteps | 18644992 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2329        |\n",
      "|    iterations           | 1139        |\n",
      "|    time_elapsed         | 8009        |\n",
      "|    total_timesteps      | 18661376    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002381677 |\n",
      "|    clip_fraction        | 0.013       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.479      |\n",
      "|    explained_variance   | -0.00319    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.41e+03    |\n",
      "|    n_updates            | 25850       |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    value_loss           | 3.46e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1140         |\n",
      "|    time_elapsed         | 8015         |\n",
      "|    total_timesteps      | 18677760     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023829401 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | 0.00724      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.55e+03     |\n",
      "|    n_updates            | 25860        |\n",
      "|    policy_gradient_loss | -0.00567     |\n",
      "|    value_loss           | 3.05e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1141         |\n",
      "|    time_elapsed         | 8021         |\n",
      "|    total_timesteps      | 18694144     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025252465 |\n",
      "|    clip_fraction        | 0.0152       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | 0.0341       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.44e+03     |\n",
      "|    n_updates            | 25870        |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    value_loss           | 3.37e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1142         |\n",
      "|    time_elapsed         | 8027         |\n",
      "|    total_timesteps      | 18710528     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020426963 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.467       |\n",
      "|    explained_variance   | 0.0497       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.79e+03     |\n",
      "|    n_updates            | 25880        |\n",
      "|    policy_gradient_loss | -0.00568     |\n",
      "|    value_loss           | 3.31e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=18720000, episode_reward=857.20 +/- 98.73\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 857          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18720000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023545963 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.473       |\n",
      "|    explained_variance   | 0.0232       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.72e+03     |\n",
      "|    n_updates            | 25890        |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    value_loss           | 3.24e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2329     |\n",
      "|    iterations      | 1143     |\n",
      "|    time_elapsed    | 8039     |\n",
      "|    total_timesteps | 18726912 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2329         |\n",
      "|    iterations           | 1144         |\n",
      "|    time_elapsed         | 8045         |\n",
      "|    total_timesteps      | 18743296     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021406328 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.00247      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 880          |\n",
      "|    n_updates            | 25900        |\n",
      "|    policy_gradient_loss | -0.00514     |\n",
      "|    value_loss           | 3.07e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2329         |\n",
      "|    iterations           | 1145         |\n",
      "|    time_elapsed         | 8051         |\n",
      "|    total_timesteps      | 18759680     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023133343 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.469       |\n",
      "|    explained_variance   | 0.000958     |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.82e+03     |\n",
      "|    n_updates            | 25910        |\n",
      "|    policy_gradient_loss | -0.00588     |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1146         |\n",
      "|    time_elapsed         | 8057         |\n",
      "|    total_timesteps      | 18776064     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018957765 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.472       |\n",
      "|    explained_variance   | 0.0431       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.33e+03     |\n",
      "|    n_updates            | 25920        |\n",
      "|    policy_gradient_loss | -0.00474     |\n",
      "|    value_loss           | 3.24e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1147         |\n",
      "|    time_elapsed         | 8063         |\n",
      "|    total_timesteps      | 18792448     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021515773 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.481       |\n",
      "|    explained_variance   | 0.0375       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.5e+03      |\n",
      "|    n_updates            | 25930        |\n",
      "|    policy_gradient_loss | -0.00548     |\n",
      "|    value_loss           | 3.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=18800000, episode_reward=843.60 +/- 83.71\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 844          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18800000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022799857 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.477       |\n",
      "|    explained_variance   | 0.038        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 25940        |\n",
      "|    policy_gradient_loss | -0.006       |\n",
      "|    value_loss           | 3.04e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2329     |\n",
      "|    iterations      | 1148     |\n",
      "|    time_elapsed    | 8075     |\n",
      "|    total_timesteps | 18808832 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2329         |\n",
      "|    iterations           | 1149         |\n",
      "|    time_elapsed         | 8080         |\n",
      "|    total_timesteps      | 18825216     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023261472 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.0531       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.47e+03     |\n",
      "|    n_updates            | 25950        |\n",
      "|    policy_gradient_loss | -0.00557     |\n",
      "|    value_loss           | 3.16e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2329        |\n",
      "|    iterations           | 1150        |\n",
      "|    time_elapsed         | 8087        |\n",
      "|    total_timesteps      | 18841600    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002112344 |\n",
      "|    clip_fraction        | 0.0106      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.469      |\n",
      "|    explained_variance   | 0.0593      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.38e+03    |\n",
      "|    n_updates            | 25960       |\n",
      "|    policy_gradient_loss | -0.00522    |\n",
      "|    value_loss           | 3.09e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1151         |\n",
      "|    time_elapsed         | 8093         |\n",
      "|    total_timesteps      | 18857984     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020207358 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.0199       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.83e+03     |\n",
      "|    n_updates            | 25970        |\n",
      "|    policy_gradient_loss | -0.00524     |\n",
      "|    value_loss           | 3.46e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1152         |\n",
      "|    time_elapsed         | 8099         |\n",
      "|    total_timesteps      | 18874368     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026998348 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.483       |\n",
      "|    explained_variance   | 0.0187       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 25980        |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    value_loss           | 3.17e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=18880000, episode_reward=808.80 +/- 90.83\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 809          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18880000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023782519 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.47        |\n",
      "|    explained_variance   | 0.0351       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.15e+03     |\n",
      "|    n_updates            | 25990        |\n",
      "|    policy_gradient_loss | -0.00555     |\n",
      "|    value_loss           | 3.19e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2329     |\n",
      "|    iterations      | 1153     |\n",
      "|    time_elapsed    | 8110     |\n",
      "|    total_timesteps | 18890752 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2329         |\n",
      "|    iterations           | 1154         |\n",
      "|    time_elapsed         | 8116         |\n",
      "|    total_timesteps      | 18907136     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023596543 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.00301      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 26000        |\n",
      "|    policy_gradient_loss | -0.00571     |\n",
      "|    value_loss           | 2.94e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2329         |\n",
      "|    iterations           | 1155         |\n",
      "|    time_elapsed         | 8122         |\n",
      "|    total_timesteps      | 18923520     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025024882 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.489       |\n",
      "|    explained_variance   | 0.0448       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 26010        |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    value_loss           | 3.13e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2330        |\n",
      "|    iterations           | 1156        |\n",
      "|    time_elapsed         | 8128        |\n",
      "|    total_timesteps      | 18939904    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002454306 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.48       |\n",
      "|    explained_variance   | 0.0571      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.66e+03    |\n",
      "|    n_updates            | 26020       |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    value_loss           | 3.41e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1157         |\n",
      "|    time_elapsed         | 8134         |\n",
      "|    total_timesteps      | 18956288     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021763458 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.499       |\n",
      "|    explained_variance   | 0.0636       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.44e+03     |\n",
      "|    n_updates            | 26030        |\n",
      "|    policy_gradient_loss | -0.00504     |\n",
      "|    value_loss           | 3.01e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=18960000, episode_reward=803.20 +/- 122.50\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 803          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 18960000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018663388 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.483       |\n",
      "|    explained_variance   | 0.0669       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 26040        |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    value_loss           | 3.38e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2329     |\n",
      "|    iterations      | 1158     |\n",
      "|    time_elapsed    | 8144     |\n",
      "|    total_timesteps | 18972672 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2329         |\n",
      "|    iterations           | 1159         |\n",
      "|    time_elapsed         | 8150         |\n",
      "|    total_timesteps      | 18989056     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024105827 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.0236       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.58e+03     |\n",
      "|    n_updates            | 26050        |\n",
      "|    policy_gradient_loss | -0.00541     |\n",
      "|    value_loss           | 3.05e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2329         |\n",
      "|    iterations           | 1160         |\n",
      "|    time_elapsed         | 8156         |\n",
      "|    total_timesteps      | 19005440     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021382808 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.0451       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 26060        |\n",
      "|    policy_gradient_loss | -0.00576     |\n",
      "|    value_loss           | 3.41e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1161         |\n",
      "|    time_elapsed         | 8162         |\n",
      "|    total_timesteps      | 19021824     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024371673 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.0852       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 26070        |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    value_loss           | 3.18e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1162         |\n",
      "|    time_elapsed         | 8168         |\n",
      "|    total_timesteps      | 19038208     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026893746 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.0535       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 26080        |\n",
      "|    policy_gradient_loss | -0.0054      |\n",
      "|    value_loss           | 2.99e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19040000, episode_reward=790.00 +/- 72.77\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 790          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 19040000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024869926 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.479       |\n",
      "|    explained_variance   | 0.106        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.46e+03     |\n",
      "|    n_updates            | 26090        |\n",
      "|    policy_gradient_loss | -0.00608     |\n",
      "|    value_loss           | 2.99e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2329     |\n",
      "|    iterations      | 1163     |\n",
      "|    time_elapsed    | 8179     |\n",
      "|    total_timesteps | 19054592 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2329         |\n",
      "|    iterations           | 1164         |\n",
      "|    time_elapsed         | 8185         |\n",
      "|    total_timesteps      | 19070976     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021619257 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.48        |\n",
      "|    explained_variance   | 0.0475       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.95e+03     |\n",
      "|    n_updates            | 26100        |\n",
      "|    policy_gradient_loss | -0.00559     |\n",
      "|    value_loss           | 3.37e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2330        |\n",
      "|    iterations           | 1165        |\n",
      "|    time_elapsed         | 8191        |\n",
      "|    total_timesteps      | 19087360    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002435675 |\n",
      "|    clip_fraction        | 0.0156      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.482      |\n",
      "|    explained_variance   | 0.0178      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 26110       |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    value_loss           | 3.11e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2330        |\n",
      "|    iterations           | 1166        |\n",
      "|    time_elapsed         | 8197        |\n",
      "|    total_timesteps      | 19103744    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002222113 |\n",
      "|    clip_fraction        | 0.0124      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.485      |\n",
      "|    explained_variance   | 0.0303      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.73e+03    |\n",
      "|    n_updates            | 26120       |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    value_loss           | 3.21e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=19120000, episode_reward=781.20 +/- 187.94\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 781          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 19120000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021792501 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | 0.045        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.53e+03     |\n",
      "|    n_updates            | 26130        |\n",
      "|    policy_gradient_loss | -0.00555     |\n",
      "|    value_loss           | 3.1e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2329     |\n",
      "|    iterations      | 1167     |\n",
      "|    time_elapsed    | 8208     |\n",
      "|    total_timesteps | 19120128 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2329         |\n",
      "|    iterations           | 1168         |\n",
      "|    time_elapsed         | 8214         |\n",
      "|    total_timesteps      | 19136512     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021445141 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.0271       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.72e+03     |\n",
      "|    n_updates            | 26140        |\n",
      "|    policy_gradient_loss | -0.00556     |\n",
      "|    value_loss           | 3.35e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2329         |\n",
      "|    iterations           | 1169         |\n",
      "|    time_elapsed         | 8220         |\n",
      "|    total_timesteps      | 19152896     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024087003 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.484       |\n",
      "|    explained_variance   | 0.0431       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.71e+03     |\n",
      "|    n_updates            | 26150        |\n",
      "|    policy_gradient_loss | -0.00612     |\n",
      "|    value_loss           | 3.16e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1170         |\n",
      "|    time_elapsed         | 8225         |\n",
      "|    total_timesteps      | 19169280     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023193285 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.47        |\n",
      "|    explained_variance   | 0.0543       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.24e+03     |\n",
      "|    n_updates            | 26160        |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    value_loss           | 3.21e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1171         |\n",
      "|    time_elapsed         | 8231         |\n",
      "|    total_timesteps      | 19185664     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028095325 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | 0.0399       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.42e+03     |\n",
      "|    n_updates            | 26170        |\n",
      "|    policy_gradient_loss | -0.00596     |\n",
      "|    value_loss           | 3.15e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19200000, episode_reward=777.60 +/- 113.22\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 778          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 19200000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023554068 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.485       |\n",
      "|    explained_variance   | 0.0584       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.68e+03     |\n",
      "|    n_updates            | 26180        |\n",
      "|    policy_gradient_loss | -0.00581     |\n",
      "|    value_loss           | 3.39e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2329     |\n",
      "|    iterations      | 1172     |\n",
      "|    time_elapsed    | 8242     |\n",
      "|    total_timesteps | 19202048 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2329         |\n",
      "|    iterations           | 1173         |\n",
      "|    time_elapsed         | 8248         |\n",
      "|    total_timesteps      | 19218432     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025743404 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.0635       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.62e+03     |\n",
      "|    n_updates            | 26190        |\n",
      "|    policy_gradient_loss | -0.00586     |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1174         |\n",
      "|    time_elapsed         | 8254         |\n",
      "|    total_timesteps      | 19234816     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022739752 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.0416       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.5e+03      |\n",
      "|    n_updates            | 26200        |\n",
      "|    policy_gradient_loss | -0.0055      |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1175         |\n",
      "|    time_elapsed         | 8260         |\n",
      "|    total_timesteps      | 19251200     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024422552 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.0273       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.51e+03     |\n",
      "|    n_updates            | 26210        |\n",
      "|    policy_gradient_loss | -0.00587     |\n",
      "|    value_loss           | 3.1e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1176         |\n",
      "|    time_elapsed         | 8266         |\n",
      "|    total_timesteps      | 19267584     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023876678 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.475       |\n",
      "|    explained_variance   | 0.0201       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.65e+03     |\n",
      "|    n_updates            | 26220        |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    value_loss           | 3.25e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19280000, episode_reward=804.80 +/- 123.42\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 805          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 19280000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023415682 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0438       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.37e+03     |\n",
      "|    n_updates            | 26230        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    value_loss           | 3.08e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2329     |\n",
      "|    iterations      | 1177     |\n",
      "|    time_elapsed    | 8277     |\n",
      "|    total_timesteps | 19283968 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1178         |\n",
      "|    time_elapsed         | 8283         |\n",
      "|    total_timesteps      | 19300352     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022648417 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.494       |\n",
      "|    explained_variance   | 0.0519       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.96e+03     |\n",
      "|    n_updates            | 26240        |\n",
      "|    policy_gradient_loss | -0.00546     |\n",
      "|    value_loss           | 3.11e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1179         |\n",
      "|    time_elapsed         | 8289         |\n",
      "|    total_timesteps      | 19316736     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024189884 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.497       |\n",
      "|    explained_variance   | 0.0471       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.48e+03     |\n",
      "|    n_updates            | 26250        |\n",
      "|    policy_gradient_loss | -0.00518     |\n",
      "|    value_loss           | 3.08e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1180         |\n",
      "|    time_elapsed         | 8294         |\n",
      "|    total_timesteps      | 19333120     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027847346 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.49        |\n",
      "|    explained_variance   | 0.0327       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 26260        |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    value_loss           | 3.05e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1181         |\n",
      "|    time_elapsed         | 8300         |\n",
      "|    total_timesteps      | 19349504     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024976346 |\n",
      "|    clip_fraction        | 0.0164       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.496       |\n",
      "|    explained_variance   | 0.0094       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.71e+03     |\n",
      "|    n_updates            | 26270        |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    value_loss           | 3.23e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19360000, episode_reward=789.60 +/- 111.59\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 790          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 19360000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024099222 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.504       |\n",
      "|    explained_variance   | 0.0777       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 831          |\n",
      "|    n_updates            | 26280        |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2329     |\n",
      "|    iterations      | 1182     |\n",
      "|    time_elapsed    | 8311     |\n",
      "|    total_timesteps | 19365888 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1183         |\n",
      "|    time_elapsed         | 8317         |\n",
      "|    total_timesteps      | 19382272     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020522608 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.481       |\n",
      "|    explained_variance   | 0.0573       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.06e+03     |\n",
      "|    n_updates            | 26290        |\n",
      "|    policy_gradient_loss | -0.00543     |\n",
      "|    value_loss           | 3.07e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1184         |\n",
      "|    time_elapsed         | 8323         |\n",
      "|    total_timesteps      | 19398656     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020379315 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.0705       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.33e+03     |\n",
      "|    n_updates            | 26300        |\n",
      "|    policy_gradient_loss | -0.00563     |\n",
      "|    value_loss           | 2.99e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1185         |\n",
      "|    time_elapsed         | 8329         |\n",
      "|    total_timesteps      | 19415040     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017614064 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | 0.0385       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.6e+03      |\n",
      "|    n_updates            | 26310        |\n",
      "|    policy_gradient_loss | -0.00458     |\n",
      "|    value_loss           | 3.37e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1186         |\n",
      "|    time_elapsed         | 8335         |\n",
      "|    total_timesteps      | 19431424     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026353048 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.5         |\n",
      "|    explained_variance   | 0.0576       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.04e+03     |\n",
      "|    n_updates            | 26320        |\n",
      "|    policy_gradient_loss | -0.00543     |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19440000, episode_reward=780.80 +/- 179.06\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 781          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 19440000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023177553 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | 0.0303       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 26330        |\n",
      "|    policy_gradient_loss | -0.00568     |\n",
      "|    value_loss           | 3.19e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2330     |\n",
      "|    iterations      | 1187     |\n",
      "|    time_elapsed    | 8346     |\n",
      "|    total_timesteps | 19447808 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1188         |\n",
      "|    time_elapsed         | 8352         |\n",
      "|    total_timesteps      | 19464192     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022855524 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.485       |\n",
      "|    explained_variance   | 0.047        |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 26340        |\n",
      "|    policy_gradient_loss | -0.00599     |\n",
      "|    value_loss           | 2.91e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1189         |\n",
      "|    time_elapsed         | 8358         |\n",
      "|    total_timesteps      | 19480576     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025054195 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.0516       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 2.14e+03     |\n",
      "|    n_updates            | 26350        |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    value_loss           | 3.26e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2330        |\n",
      "|    iterations           | 1190        |\n",
      "|    time_elapsed         | 8364        |\n",
      "|    total_timesteps      | 19496960    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002521867 |\n",
      "|    clip_fraction        | 0.0152      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.491      |\n",
      "|    explained_variance   | 0.076       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.77e+03    |\n",
      "|    n_updates            | 26360       |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    value_loss           | 3.14e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1191         |\n",
      "|    time_elapsed         | 8370         |\n",
      "|    total_timesteps      | 19513344     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024407657 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0299       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 26370        |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    value_loss           | 3.03e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19520000, episode_reward=793.20 +/- 101.50\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 793         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 19520000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002726505 |\n",
      "|    clip_fraction        | 0.0186      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.494      |\n",
      "|    explained_variance   | 0.0289      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.43e+03    |\n",
      "|    n_updates            | 26380       |\n",
      "|    policy_gradient_loss | -0.00591    |\n",
      "|    value_loss           | 3.13e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2330     |\n",
      "|    iterations      | 1192     |\n",
      "|    time_elapsed    | 8381     |\n",
      "|    total_timesteps | 19529728 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2330        |\n",
      "|    iterations           | 1193        |\n",
      "|    time_elapsed         | 8387        |\n",
      "|    total_timesteps      | 19546112    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002452431 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.492      |\n",
      "|    explained_variance   | 0.0403      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.56e+03    |\n",
      "|    n_updates            | 26390       |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    value_loss           | 3.17e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2330        |\n",
      "|    iterations           | 1194        |\n",
      "|    time_elapsed         | 8393        |\n",
      "|    total_timesteps      | 19562496    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002186001 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.485      |\n",
      "|    explained_variance   | 0.0234      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.53e+03    |\n",
      "|    n_updates            | 26400       |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    value_loss           | 2.89e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1195         |\n",
      "|    time_elapsed         | 8399         |\n",
      "|    total_timesteps      | 19578880     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023073917 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | 0.0415       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.7e+03      |\n",
      "|    n_updates            | 26410        |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    value_loss           | 3.07e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1196         |\n",
      "|    time_elapsed         | 8405         |\n",
      "|    total_timesteps      | 19595264     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024053296 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.471       |\n",
      "|    explained_variance   | 0.0301       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.44e+03     |\n",
      "|    n_updates            | 26420        |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    value_loss           | 2.92e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19600000, episode_reward=780.40 +/- 114.45\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 780          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 19600000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023600277 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.473       |\n",
      "|    explained_variance   | 0.0258       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 26430        |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    value_loss           | 3.17e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2330     |\n",
      "|    iterations      | 1197     |\n",
      "|    time_elapsed    | 8416     |\n",
      "|    total_timesteps | 19611648 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1198         |\n",
      "|    time_elapsed         | 8422         |\n",
      "|    total_timesteps      | 19628032     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025177551 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.475       |\n",
      "|    explained_variance   | 0.0901       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.36e+03     |\n",
      "|    n_updates            | 26440        |\n",
      "|    policy_gradient_loss | -0.00543     |\n",
      "|    value_loss           | 3.07e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2330        |\n",
      "|    iterations           | 1199        |\n",
      "|    time_elapsed         | 8428        |\n",
      "|    total_timesteps      | 19644416    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002809704 |\n",
      "|    clip_fraction        | 0.018       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.484      |\n",
      "|    explained_variance   | 0.0374      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 26450       |\n",
      "|    policy_gradient_loss | -0.00641    |\n",
      "|    value_loss           | 2.98e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1200         |\n",
      "|    time_elapsed         | 8434         |\n",
      "|    total_timesteps      | 19660800     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020917784 |\n",
      "|    clip_fraction        | 0.0121       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.478       |\n",
      "|    explained_variance   | 0.0229       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.87e+03     |\n",
      "|    n_updates            | 26460        |\n",
      "|    policy_gradient_loss | -0.00535     |\n",
      "|    value_loss           | 3.06e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1201         |\n",
      "|    time_elapsed         | 8440         |\n",
      "|    total_timesteps      | 19677184     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020916737 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.488       |\n",
      "|    explained_variance   | 0.0508       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.55e+03     |\n",
      "|    n_updates            | 26470        |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    value_loss           | 3.06e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19680000, episode_reward=778.80 +/- 91.80\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 779          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 19680000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020115962 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.466       |\n",
      "|    explained_variance   | 0.0522       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.8e+03      |\n",
      "|    n_updates            | 26480        |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    value_loss           | 3.25e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2330     |\n",
      "|    iterations      | 1202     |\n",
      "|    time_elapsed    | 8451     |\n",
      "|    total_timesteps | 19693568 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2330        |\n",
      "|    iterations           | 1203        |\n",
      "|    time_elapsed         | 8457        |\n",
      "|    total_timesteps      | 19709952    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002467142 |\n",
      "|    clip_fraction        | 0.015       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.476      |\n",
      "|    explained_variance   | -0.00631    |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.41e+03    |\n",
      "|    n_updates            | 26490       |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    value_loss           | 3.14e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1204         |\n",
      "|    time_elapsed         | 8463         |\n",
      "|    total_timesteps      | 19726336     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026051507 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.486       |\n",
      "|    explained_variance   | 0.0408       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.49e+03     |\n",
      "|    n_updates            | 26500        |\n",
      "|    policy_gradient_loss | -0.00608     |\n",
      "|    value_loss           | 3.04e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1205         |\n",
      "|    time_elapsed         | 8468         |\n",
      "|    total_timesteps      | 19742720     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024958479 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.484       |\n",
      "|    explained_variance   | 0.0584       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 957          |\n",
      "|    n_updates            | 26510        |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    value_loss           | 2.9e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1206         |\n",
      "|    time_elapsed         | 8475         |\n",
      "|    total_timesteps      | 19759104     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025584307 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.485       |\n",
      "|    explained_variance   | 0.0457       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.39e+03     |\n",
      "|    n_updates            | 26520        |\n",
      "|    policy_gradient_loss | -0.00556     |\n",
      "|    value_loss           | 3.1e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19760000, episode_reward=814.40 +/- 137.52\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 814          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 19760000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022874975 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.487       |\n",
      "|    explained_variance   | 0.0204       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 26530        |\n",
      "|    policy_gradient_loss | -0.0056      |\n",
      "|    value_loss           | 3.08e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2330     |\n",
      "|    iterations      | 1207     |\n",
      "|    time_elapsed    | 8486     |\n",
      "|    total_timesteps | 19775488 |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2330        |\n",
      "|    iterations           | 1208        |\n",
      "|    time_elapsed         | 8492        |\n",
      "|    total_timesteps      | 19791872    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002027952 |\n",
      "|    clip_fraction        | 0.0117      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.477      |\n",
      "|    explained_variance   | 0.0568      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.32e+03    |\n",
      "|    n_updates            | 26540       |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    value_loss           | 3.09e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1209         |\n",
      "|    time_elapsed         | 8498         |\n",
      "|    total_timesteps      | 19808256     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026307055 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.476       |\n",
      "|    explained_variance   | 0.0421       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.4e+03      |\n",
      "|    n_updates            | 26550        |\n",
      "|    policy_gradient_loss | -0.00603     |\n",
      "|    value_loss           | 3.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1210         |\n",
      "|    time_elapsed         | 8504         |\n",
      "|    total_timesteps      | 19824640     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021992007 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.472       |\n",
      "|    explained_variance   | 0.0418       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.71e+03     |\n",
      "|    n_updates            | 26560        |\n",
      "|    policy_gradient_loss | -0.00576     |\n",
      "|    value_loss           | 3.14e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19840000, episode_reward=785.60 +/- 108.48\n",
      "Episode length: 200.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 786         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 19840000    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002246072 |\n",
      "|    clip_fraction        | 0.0121      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.485      |\n",
      "|    explained_variance   | 0.0117      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.48e+03    |\n",
      "|    n_updates            | 26570       |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    value_loss           | 2.99e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2329     |\n",
      "|    iterations      | 1211     |\n",
      "|    time_elapsed    | 8515     |\n",
      "|    total_timesteps | 19841024 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1212         |\n",
      "|    time_elapsed         | 8521         |\n",
      "|    total_timesteps      | 19857408     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025452806 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.472       |\n",
      "|    explained_variance   | 0.0382       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.24e+03     |\n",
      "|    n_updates            | 26580        |\n",
      "|    policy_gradient_loss | -0.00616     |\n",
      "|    value_loss           | 3.05e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2330        |\n",
      "|    iterations           | 1213        |\n",
      "|    time_elapsed         | 8527        |\n",
      "|    total_timesteps      | 19873792    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002509125 |\n",
      "|    clip_fraction        | 0.0149      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.478      |\n",
      "|    explained_variance   | 0.0186      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.69e+03    |\n",
      "|    n_updates            | 26590       |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    value_loss           | 2.97e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1214         |\n",
      "|    time_elapsed         | 8533         |\n",
      "|    total_timesteps      | 19890176     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023537634 |\n",
      "|    clip_fraction        | 0.0126       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.463       |\n",
      "|    explained_variance   | 0.0261       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.54e+03     |\n",
      "|    n_updates            | 26600        |\n",
      "|    policy_gradient_loss | -0.00565     |\n",
      "|    value_loss           | 3.2e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2331         |\n",
      "|    iterations           | 1215         |\n",
      "|    time_elapsed         | 8539         |\n",
      "|    total_timesteps      | 19906560     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023518768 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.469       |\n",
      "|    explained_variance   | 0.04         |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.02e+03     |\n",
      "|    n_updates            | 26610        |\n",
      "|    policy_gradient_loss | -0.00581     |\n",
      "|    value_loss           | 2.91e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=19920000, episode_reward=794.40 +/- 101.31\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 794          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 19920000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023500305 |\n",
      "|    clip_fraction        | 0.0138       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.482       |\n",
      "|    explained_variance   | 0.0399       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.5e+03      |\n",
      "|    n_updates            | 26620        |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    value_loss           | 2.88e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2329     |\n",
      "|    iterations      | 1216     |\n",
      "|    time_elapsed    | 8550     |\n",
      "|    total_timesteps | 19922944 |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1217         |\n",
      "|    time_elapsed         | 8556         |\n",
      "|    total_timesteps      | 19939328     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027787036 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.0273       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.31e+03     |\n",
      "|    n_updates            | 26630        |\n",
      "|    policy_gradient_loss | -0.00631     |\n",
      "|    value_loss           | 2.96e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1218         |\n",
      "|    time_elapsed         | 8562         |\n",
      "|    total_timesteps      | 19955712     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024486426 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.474       |\n",
      "|    explained_variance   | 0.0191       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 26640        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    value_loss           | 3.03e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2330         |\n",
      "|    iterations           | 1219         |\n",
      "|    time_elapsed         | 8568         |\n",
      "|    total_timesteps      | 19972096     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026865266 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.472       |\n",
      "|    explained_variance   | 0.00954      |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.84e+03     |\n",
      "|    n_updates            | 26650        |\n",
      "|    policy_gradient_loss | -0.00562     |\n",
      "|    value_loss           | 3.05e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2331        |\n",
      "|    iterations           | 1220        |\n",
      "|    time_elapsed         | 8574        |\n",
      "|    total_timesteps      | 19988480    |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002586462 |\n",
      "|    clip_fraction        | 0.0184      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.475      |\n",
      "|    explained_variance   | 0.0283      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 1.38e+03    |\n",
      "|    n_updates            | 26660       |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    value_loss           | 3.01e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000000, episode_reward=752.00 +/- 179.98\n",
      "Episode length: 200.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | 752          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 20000000     |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026589406 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.468       |\n",
      "|    explained_variance   | 0.0356       |\n",
      "|    learning_rate        | 0.0001       |\n",
      "|    loss                 | 1.69e+03     |\n",
      "|    n_updates            | 26670        |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    value_loss           | 2.92e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| time/              |          |\n",
      "|    fps             | 2329     |\n",
      "|    iterations      | 1221     |\n",
      "|    time_elapsed    | 8585     |\n",
      "|    total_timesteps | 20004864 |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7eff5ec71c00>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3.common.callbacks import CallbackList, CheckpointCallback, EvalCallback\n",
    "\n",
    "best_model_save_path = \"./models/4_adv/best_model_50M\"\n",
    "\n",
    "# # Save a checkpoint every 1000 steps\n",
    "# checkpoint_callback = CheckpointCallback(\n",
    "#                              save_freq=500_000,\n",
    "#                              save_path=\"./models/4_adv\",\n",
    "#                              name_prefix=\"4_adv\",\n",
    "#                             )\n",
    "eval_callback = EvalCallback(conv_env,\n",
    "                             eval_freq=10_000,\n",
    "                             best_model_save_path=best_model_save_path,\n",
    "                             log_path=log_path,\n",
    "                             n_eval_episodes=100,\n",
    "                             verbose=1)\n",
    "\n",
    "# callback = CallbackList([eval_callback])\n",
    "\n",
    "# first 10M timesteps\n",
    "model.learn(total_timesteps=20_000_000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mPPO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBufferedIOBase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0menv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgymnasium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'VecEnv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcustom_objects\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mprint_system_info\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mforce_reset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mSelfBaseAlgorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "    \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# noqa: C901\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSelfBaseAlgorithm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBufferedIOBase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0menv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGymEnv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mcustom_objects\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mprint_system_info\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mforce_reset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelfBaseAlgorithm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m\"\"\"\u001b[0m\n",
      "\u001b[0;34m        Load the model from a zip-file.\u001b[0m\n",
      "\u001b[0;34m        Warning: ``load`` re-creates the model from scratch, it does not update it in-place!\u001b[0m\n",
      "\u001b[0;34m        For an in-place load use ``set_parameters`` instead.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        :param path: path to the file (or a file-like) where to\u001b[0m\n",
      "\u001b[0;34m            load the agent from\u001b[0m\n",
      "\u001b[0;34m        :param env: the new environment to run the loaded model on\u001b[0m\n",
      "\u001b[0;34m            (can be None if you only need prediction from a trained model) has priority over any saved environment\u001b[0m\n",
      "\u001b[0;34m        :param device: Device on which the code should run.\u001b[0m\n",
      "\u001b[0;34m        :param custom_objects: Dictionary of objects to replace\u001b[0m\n",
      "\u001b[0;34m            upon loading. If a variable is present in this dictionary as a\u001b[0m\n",
      "\u001b[0;34m            key, it will not be deserialized and the corresponding item\u001b[0m\n",
      "\u001b[0;34m            will be used instead. Similar to custom_objects in\u001b[0m\n",
      "\u001b[0;34m            ``keras.models.load_model``. Useful when you have an object in\u001b[0m\n",
      "\u001b[0;34m            file that can not be deserialized.\u001b[0m\n",
      "\u001b[0;34m        :param print_system_info: Whether to print system info from the saved model\u001b[0m\n",
      "\u001b[0;34m            and the current system info (useful to debug loading issues)\u001b[0m\n",
      "\u001b[0;34m        :param force_reset: Force call to ``reset()`` before training\u001b[0m\n",
      "\u001b[0;34m            to avoid unexpected behavior.\u001b[0m\n",
      "\u001b[0;34m            See https://github.com/DLR-RM/stable-baselines3/issues/597\u001b[0m\n",
      "\u001b[0;34m        :param kwargs: extra arguments to change the model when loading\u001b[0m\n",
      "\u001b[0;34m        :return: new model instance with loaded parameters\u001b[0m\n",
      "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mprint_system_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"== CURRENT SYSTEM INFO ==\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mget_system_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpytorch_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_from_zip_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mprint_system_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_system_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No data found in the saved file\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32massert\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No params found in the saved file\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Remove stored device information and replace with ours\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"policy_kwargs\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m\"device\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mdel\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# backward compatibility, convert to new format\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m\"net_arch\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"net_arch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0msaved_net_arch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"net_arch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_net_arch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_net_arch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"net_arch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_net_arch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"policy_kwargs\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy_kwargs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"The specified policy kwargs do not equal the stored policy kwargs.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34mf\"Stored kwargs: {data['policy_kwargs']}, specified kwargs: {kwargs['policy_kwargs']}\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m\"observation_space\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"action_space\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The observation_space and action_space were not given, can't verify new environments\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Gym -> Gymnasium space conversion\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"observation_space\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"action_space\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0menv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Wrap first if needed\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"verbose\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Check if given env is valid\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mcheck_for_correct_spaces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"observation_space\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"action_space\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Discard `_last_obs`, this will force the env to reset before training\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# See issue https://github.com/DLR-RM/stable-baselines3/issues/597\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mforce_reset\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_last_obs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# `n_envs` must be updated. See issue https://github.com/DLR-RM/stable-baselines3/issues/1018\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_envs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Use stored env, if one exists. If not, continue as is (can be used for predict)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m\"env\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"env\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mpolicy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"policy_class\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0m_init_setup_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# load parameters\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# put state_dicts back in place\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact_match\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Patch to load Policy saved using SB3 < 1.7.0\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# the error is probably due to old policy being loaded\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# See https://github.com/DLR-RM/stable-baselines3/issues/1233\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m\"pi_features_extractor\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"Missing key(s) in state_dict\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexact_match\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"You are probably loading a model saved with SB3 < 1.7.0, \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"we deactivated exact_match so you can save the model \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"again to avoid issues in the future \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"(see https://github.com/DLR-RM/stable-baselines3/issues/1233 for more info). \"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34mf\"Original error: {e} \\n\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;34m\"Note: the model should still work fine, this only a warning.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# put other pytorch variables back in place\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mpytorch_variables\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpytorch_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# Skip if PyTorch variable was not defined (to ensure backward compatibility).\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# This happens when using SAC/TQC.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# SAC has an entropy coefficient which can be fixed or optimized.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# If it is optimized, an additional PyTorch variable `log_ent_coef` is defined,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# otherwise it is initialized to `None`.\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mpytorch_variables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# Set the data attribute directly to avoid issue when using optimizers\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;31m# See https://github.com/DLR-RM/stable-baselines3/issues/391\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mrecursive_setattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{name}.data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpytorch_variables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Sample gSDE exploration matrix, so it uses the right device\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# see issue #44\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_sde\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[operator]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/.local/lib/python3.10/site-packages/stable_baselines3/common/base_class.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "PPO.load??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(841.34, 95.57617067030881)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "evaluate_policy(model=model, env=conv_env, n_eval_episodes=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adversary_0', 'adversary_1', 'adversary_2']\n",
      "Episode reward: 710.0\n"
     ]
    }
   ],
   "source": [
    "RENDER_MODE = None\n",
    "MAX_CYCLES = 200\n",
    "env = CustomEnvironment(num_good=NUM_GOOD, num_adversaries=NUM_ADV, num_obstacles=NUM_OBST, max_cycles=MAX_CYCLES, continuous_actions=CONTINOUS_ACTIONS, render_mode=RENDER_MODE)\n",
    "observations, infos = env.reset()\n",
    "\n",
    "terminated = False\n",
    "timestep = 1\n",
    "episode_reward = 0\n",
    "print(env.agents)\n",
    "while not terminated:\n",
    "\n",
    "    # this is where you would insert your policy\n",
    "    actions = {agent: model.predict(observations[agent])[0] for agent in env.agents}\n",
    "\n",
    "    observations, rewards, terminations, truncations, infos = env.step(actions)\n",
    "\n",
    "    episode_reward += sum(rewards.values()) / NUM_ADV\n",
    "\n",
    "    if not observations:\n",
    "        terminated = True\n",
    "    \n",
    "print(f\"Episode reward: {episode_reward}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1:\n",
      "\n",
      "from pettingzoo.mpe import simple_tag_v3\n",
      "from pettingzoo import ParallelEnv\n",
      "import numpy as np\n",
      "import functools\n",
      "import os\n",
      "import sys\n",
      "sys.path.append('/home/mariusvaardal/AAMAS_project/AAMAS_project')\n",
      "\n",
      "import supersuit as ss\n",
      "from stable_baselines3 import PPO\n",
      "from stable_baselines3.ppo import MlpPolicy\n",
      "\n",
      "from stable_baselines3.common.evaluation import evaluate_policy\n",
      "   2:\n",
      "NUM_GOOD = 1\n",
      "NUM_ADV = 3\n",
      "NUM_OBST = 0\n",
      "MAX_CYCLES = 50\n",
      "CONTINOUS_ACTIONS = False\n",
      "   3:\n",
      "def remove_agent_0_from_dicts(dicts):\n",
      "    ret = []\n",
      "    for dict in dicts:\n",
      "        del dict['agent_0']\n",
      "        ret.append(dict)\n",
      "    return ret\n",
      "   4:\n",
      "# from agent_types.AvoidingAgent import AvoidingAgent\n",
      "# from agent_types.AvoidingNearestAdversaryAgent import AvoidingNearestAdversaryAgent\n",
      "from agent_types.ImmobileAgent import ImmobileAgent\n",
      "\n",
      "class CustomEnvironment(ParallelEnv):\n",
      "    metadata = {\n",
      "        \"name\": \"custom_environment_v0\",\n",
      "    }\n",
      "\n",
      "    def __init__(self, num_good, num_adversaries, num_obstacles, max_cycles, continuous_actions, render_mode):\n",
      "        self.env = simple_tag_v3.parallel_env(num_good=num_good, num_adversaries=num_adversaries, num_obstacles=num_obstacles, max_cycles=max_cycles, continuous_actions=continuous_actions, render_mode=render_mode)\n",
      "        self.env.reset() \n",
      "        # Setting all the required attributes\n",
      "        self.agents = [agent for agent in self.env.agents if agent.startswith(\"adversary\")]\n",
      "        self.possible_agents = [adv for adv in self.env.possible_agents if adv.startswith(\"adversary\")]\n",
      "        self.render_mode = render_mode\n",
      "        # Adding agent_0 as part of the environment. Agent_0 is not meant to be included in the training\n",
      "        self.agent_0 = ImmobileAgent('agent_0', num_adversaries=NUM_ADV, num_landmarks=NUM_OBST)\n",
      "        \n",
      "    def reset(self, seed=None, options=None):\n",
      "        observations, infos = self.env.reset(seed=seed, options=options)\n",
      "        self.agent_0.see(observations[self.agent_0.name])\n",
      "        observations, infos = remove_agent_0_from_dicts([observations, infos])\n",
      "        return observations, infos\n",
      "\n",
      "    def step(self, actions):\n",
      "        actions['agent_0'] = self.agent_0.get_action()\n",
      "        observations, rewards, terminations, truncations, infos =  self.env.step(actions)\n",
      "        if observations:\n",
      "            self.agent_0.see(observations[self.agent_0.name])\n",
      "            observations, rewards, terminations, truncations, infos = remove_agent_0_from_dicts([observations, rewards, terminations, truncations, infos])\n",
      "        return observations, rewards, terminations, truncations, infos\n",
      "\n",
      "    def render(self):\n",
      "        self.env.render()\n",
      "\n",
      "    # Observation space should be defined here.\n",
      "    # lru_cache allows observation and action spaces to be memoized, reducing clock cycles required to get each agent's space.\n",
      "    # If your spaces change over time, remove this line (disable caching).\n",
      "    @functools.lru_cache(maxsize=None)\n",
      "    def observation_space(self, agent):\n",
      "        return self.env.observation_space(agent)\n",
      "\n",
      "    # Action space should be defined here.\n",
      "    # If your spaces change over time, remove this line (disable caching).\n",
      "    @functools.lru_cache(maxsize=None)\n",
      "    def action_space(self, agent):\n",
      "        return self.env.action_space(agent)\n",
      "   5:\n",
      "env = CustomEnvironment(num_good=NUM_GOOD, num_adversaries=NUM_ADV, num_obstacles=NUM_OBST, max_cycles=MAX_CYCLES, continuous_actions=CONTINOUS_ACTIONS, render_mode=RENDER_MODE)\n",
      "env.reset(seed=45)\n",
      "conv_env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
      "conv_env = ss.concat_vec_envs_v1(conv_env, 2, num_cpus=1, base_class=\"stable_baselines3\")\n",
      "   6:\n",
      "NUM_GOOD = 1\n",
      "NUM_ADV = 3\n",
      "NUM_OBST = 0\n",
      "MAX_CYCLES = 50\n",
      "CONTINOUS_ACTIONS = False\n",
      "RENDER_MODE = None\n",
      "   7:\n",
      "env = CustomEnvironment(num_good=NUM_GOOD, num_adversaries=NUM_ADV, num_obstacles=NUM_OBST, max_cycles=MAX_CYCLES, continuous_actions=CONTINOUS_ACTIONS, render_mode=RENDER_MODE)\n",
      "env.reset(seed=45)\n",
      "conv_env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
      "conv_env = ss.concat_vec_envs_v1(conv_env, 2, num_cpus=1, base_class=\"stable_baselines3\")\n",
      "   8:\n",
      "model = PPO(\n",
      "        MlpPolicy,\n",
      "        conv_env,\n",
      "        verbose=3,\n",
      "        learning_rate=1e-3,\n",
      "        batch_size=256,\n",
      "    )\n",
      "   9:\n",
      "model_save_path = \"../models\"\n",
      "model.learn(total_timesteps=1000)\n",
      "model.save(model_save_path)\n",
      "  10:\n",
      "model_save_path = \"../../models\"\n",
      "model.learn(total_timesteps=1000)\n",
      "model.save(model_save_path)\n",
      "  11:\n",
      "model_save_path = \"../../models/model\"\n",
      "model.learn(total_timesteps=1000)\n",
      "model.save(model_save_path)\n",
      "  12:\n",
      "\n",
      "from pettingzoo.mpe import simple_tag_v3\n",
      "from pettingzoo import ParallelEnv\n",
      "import numpy as np\n",
      "import functools\n",
      "import os\n",
      "import sys\n",
      "sys.path.append('/home/mariusvaardal/AAMAS_project/AAMAS_project')\n",
      "\n",
      "import supersuit as ss\n",
      "from stable_baselines3 import PPO\n",
      "from stable_baselines3.ppo import MlpPolicy\n",
      "\n",
      "from stable_baselines3.common.evaluation import evaluate_policy\n",
      "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
      "  13:\n",
      "best_model_save_path = \"../../best_model/best_model\"\n",
      "log_path = \"../../logs/log\"\n",
      "threshold_callback = StopTrainingOnRewardThreshold(reward_threshold=300, verbose=1)\n",
      "eval_callback = EvalCallback(env,\n",
      "                             eval_freq=10_000,\n",
      "                             best_model_save_path=best_model_save_path,\n",
      "                             callback_on_new_best=threshold_callback,\n",
      "                             log_path=log_path,\n",
      "                             n_eval_episodes=10,\n",
      "                             verbose=1)\n",
      "model.learn(total_timesteps=5_000_000, callback=eval_callback)\n",
      "  14:\n",
      "\n",
      "from pettingzoo.mpe import simple_tag_v3\n",
      "from pettingzoo import ParallelEnv\n",
      "import numpy as np\n",
      "import functools\n",
      "import os\n",
      "import sys\n",
      "sys.path.append('/home/mariusvaardal/AAMAS_project/AAMAS_project')\n",
      "\n",
      "import supersuit as ss\n",
      "from stable_baselines3 import PPO\n",
      "from stable_baselines3.ppo import MlpPolicy\n",
      "\n",
      "from stable_baselines3.common.evaluation import evaluate_policy\n",
      "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
      "import shimmy\n",
      "  15:\n",
      "best_model_save_path = \"../../best_model/best_model\"\n",
      "log_path = \"../../logs/log\"\n",
      "threshold_callback = StopTrainingOnRewardThreshold(reward_threshold=300, verbose=1)\n",
      "eval_callback = EvalCallback(env,\n",
      "                             eval_freq=10_000,\n",
      "                             best_model_save_path=best_model_save_path,\n",
      "                             callback_on_new_best=threshold_callback,\n",
      "                             log_path=log_path,\n",
      "                             n_eval_episodes=10,\n",
      "                             verbose=1)\n",
      "model.learn(total_timesteps=5_000_000, callback=eval_callback)\n",
      "  16:\n",
      "best_model_save_path = \"../../best_model/best_model\"\n",
      "log_path = \"../../logs/log\"\n",
      "threshold_callback = StopTrainingOnRewardThreshold(reward_threshold=300, verbose=1)\n",
      "eval_callback = EvalCallback(conv_env,\n",
      "                             eval_freq=10_000,\n",
      "                             best_model_save_path=best_model_save_path,\n",
      "                             callback_on_new_best=threshold_callback,\n",
      "                             log_path=log_path,\n",
      "                             n_eval_episodes=10,\n",
      "                             verbose=1)\n",
      "model.learn(total_timesteps=5_000_000, callback=eval_callback)\n",
      "  17: model.learn(total_timesteps=1000)\n",
      "  18:\n",
      "env = CustomEnvironment(num_good=NUM_GOOD, num_adversaries=NUM_ADV, num_obstacles=NUM_OBST, max_cycles=MAX_CYCLES, continuous_actions=CONTINOUS_ACTIONS, render_mode=RENDER_MODE)\n",
      "env.reset(seed=45)\n",
      "conv_env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
      "conv_env = ss.concat_vec_envs_v1(conv_env, 0, num_cpus=1, base_class=\"stable_baselines3\")\n",
      "  19:\n",
      "env = CustomEnvironment(num_good=NUM_GOOD, num_adversaries=NUM_ADV, num_obstacles=NUM_OBST, max_cycles=MAX_CYCLES, continuous_actions=CONTINOUS_ACTIONS, render_mode=RENDER_MODE)\n",
      "env.reset(seed=45)\n",
      "conv_env = ss.pettingzoo_env_to_vec_env_v1(env)\n",
      "conv_env = ss.concat_vec_envs_v1(conv_env, 2, num_cpus=0, base_class=\"stable_baselines3\")\n",
      "  20:\n",
      "model = PPO(\n",
      "        MlpPolicy,\n",
      "        conv_env,\n",
      "        verbose=3,\n",
      "        learning_rate=1e-3,\n",
      "        batch_size=256,\n",
      "    )\n"
     ]
    }
   ],
   "source": [
    "%history -n 1-20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from agent_types.AvoidingAgent import AvoidingAgent\n",
    "# from agent_types.AvoidingNearestAdversaryAgent import AvoidingNearestAdversaryAgent\n",
    "from agent_types.ImmobileAgent import ImmobileAgent\n",
    "\n",
    "class CustomEnvironment(ParallelEnv):\n",
    "    metadata = {\n",
    "        \"name\": \"custom_environment_v0\",\n",
    "    }\n",
    "\n",
    "    def __init__(self, num_good, num_adversaries, num_obstacles, max_cycles, continuous_actions, render_mode):\n",
    "        self.env = simple_tag_v3.parallel_env(num_good=num_good, num_adversaries=num_adversaries, num_obstacles=num_obstacles, max_cycles=max_cycles, continuous_actions=continuous_actions, render_mode=render_mode)\n",
    "        self.env.reset() \n",
    "        # Setting all the required attributes\n",
    "        self.agents = [agent for agent in self.env.agents if agent.startswith(\"adversary\")]\n",
    "        self.possible_agents = [adv for adv in self.env.possible_agents if adv.startswith(\"adversary\")]\n",
    "        self.render_mode = render_mode\n",
    "        # Adding agent_0 as part of the environment. Agent_0 is not meant to be included in the training\n",
    "        self.agent_0 = ImmobileAgent('agent_0', num_adversaries=NUM_ADV, num_landmarks=NUM_OBST)\n",
    "        \n",
    "    def reset(self, seed=None, options=None):\n",
    "        observations, infos = self.env.reset(seed=seed, options=options)\n",
    "        self.agent_0.see(observations[self.agent_0.name])\n",
    "        observations, infos = remove_agent_0_from_dicts([observations, infos])\n",
    "        return observations, infos\n",
    "\n",
    "    def step(self, actions):\n",
    "        actions['agent_0'] = self.agent_0.get_action()\n",
    "        observations, rewards, terminations, truncations, infos =  self.env.step(actions)\n",
    "        if observations:\n",
    "            self.agent_0.see(observations[self.agent_0.name])\n",
    "            observations, rewards, terminations, truncations, infos = remove_agent_0_from_dicts([observations, rewards, terminations, truncations, infos])\n",
    "        return observations, rewards, terminations, truncations, infos\n",
    "\n",
    "    def render(self):\n",
    "        self.env.render()\n",
    "\n",
    "    # Observation space should be defined here.\n",
    "    # lru_cache allows observation and action spaces to be memoized, reducing clock cycles required to get each agent's space.\n",
    "    # If your spaces change over time, remove this line (disable caching).\n",
    "    @functools.lru_cache(maxsize=None)\n",
    "    def observation_space(self, agent):\n",
    "        return self.env.observation_space(agent)\n",
    "\n",
    "    # Action space should be defined here.\n",
    "    # If your spaces change over time, remove this line (disable caching).\n",
    "    @functools.lru_cache(maxsize=None)\n",
    "    def action_space(self, agent):\n",
    "        return self.env.action_space(agent)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
