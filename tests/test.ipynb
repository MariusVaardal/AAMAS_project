{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "#INSERT THE PATH TO THE PROJECT FOLDER HERE\n",
    "PROJECT_PATH = \"/home/mariusvaardal/AAMAS_project/AAMAS_project\"\n",
    "sys.path.append(PROJECT_PATH)\n",
    "import utils.utils as utils\n",
    "import math\n",
    "from pettingzoo.mpe import simple_tag_v3\n",
    "\n",
    "from agent_types.CoordinatingAgent import CoordinatingAgent\n",
    "from agent_types.GreedyAgent import GreedyAgent\n",
    "from agent_types.RandomAgent import RandomAgent\n",
    "from agent_types.AvoidingAgent import AvoidingAgent\n",
    "from agent_types.AvoidingNearestAdversaryAgent import AvoidingNearestAdversaryAgent\n",
    "from agent_types.ImmobileAgent import ImmobileAgent\n",
    "from agent_types.RLAgent_2_adv import RLAgent2\n",
    "\n",
    "\n",
    "NUM_EPISODES = 50\n",
    "NUM_GOOD = 1\n",
    "NUM_ADVERSARIES = 2\n",
    "NUM_LANDMARKS = 0\n",
    "MAX_CYCLES = 200\n",
    "RENDER_MODE = 'human'\n",
    "\n",
    "env = simple_tag_v3.parallel_env(num_good=NUM_GOOD, num_adversaries=NUM_ADVERSARIES, num_obstacles=NUM_LANDMARKS, max_cycles=MAX_CYCLES, continuous_actions=False, render_mode=RENDER_MODE)\n",
    "env.reset()\n",
    "\n",
    "coord_agents = [RLAgent2(name, NUM_ADVERSARIES, NUM_LANDMARKS) for name in env.agents if name != \"agent_0\"]\n",
    "coord_agents.append(AvoidingAgent(\"agent_0\", NUM_ADVERSARIES, NUM_LANDMARKS))\n",
    "\n",
    "episode_rewards = []\n",
    "for episode in range(1, NUM_EPISODES + 1):\n",
    "    observations, infos = env.reset()\n",
    "    for agent in coord_agents:\n",
    "        agent.observations = observations[agent.name]\n",
    "        agent.update_observed_agent_positions()\n",
    "        \n",
    "    episode_reward = 0\n",
    "    while env.agents:\n",
    "        actions = {}\n",
    "        for agent in coord_agents:\n",
    "            action = agent.get_action()\n",
    "            actions[agent.name] = action if action != None else 0\n",
    "        observations, rewards, terminations, truncations, infos = env.step(actions)\n",
    "        for agent in coord_agents:\n",
    "            agent.observations = observations[agent.name]\n",
    "            agent.update_observed_agent_positions()\n",
    "        episode_reward += utils.get_timestep_reward(rewards)\n",
    "    episode_rewards.append(episode_reward)\n",
    "print(f\"Avg : {sum(episode_rewards) / len(episode_rewards)}. For {len(episode_rewards)} number of episodes\")\n",
    "\n",
    "env.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
